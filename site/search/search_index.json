{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to graphglue","text":"<p>This is the main documentation page.</p>"},{"location":"API_demo_notebook/","title":"API demo notebook","text":"In\u00a0[2]: Copied! <pre># preferred public surface\nimport os, sys\nsys.path.insert(0, os.path.abspath(\"..\"))  # adds .../src to sys.path\nfrom graphglue.core import Graph\nfrom graphglue.adapters.networkx_adapter import to_backend, to_nx, from_nx\n</pre> # preferred public surface import os, sys sys.path.insert(0, os.path.abspath(\"..\"))  # adds .../src to sys.path from graphglue.core import Graph from graphglue.adapters.networkx_adapter import to_backend, to_nx, from_nx In\u00a0[4]: Copied! <pre>print(\"=== Basic graph creation ===\")\nG = Graph()\nG.add_vertex(\"A\", color = \"red\", name = \"amine\")\nG.add_vertex(\"B\")\n\n\neidx = G.add_edge({\"A\"}, {\"B\"})\n\neidx = G.add_edge(\"D\", \"C\")\n\nprint(\"Vertices:\", tuple(G.V))\n\nprint(\"Edges (index, (S,T)):\", [(i, G.get_edge(i)) for i in range(G.num_edges)])\nprint(\"Number of vertices:\", G.num_vertices)\nprint(\"Number of edges:\", G.num_edges)\nprint(\"Shape (|V|,|E|):\", G.shape)\nprint()\n\nprint(\"=== Accessing edge info ===\")\nS, T = G.get_edge(eidx)\nprint(\"Edge definition:\", S, \"-&gt;\", T)\nprint()\n\nprint(\"=== Incidence matrix with per-vertex coefficients ===\")\nH = Graph()\nH.add_vertices([\"X\", \"Y\"])\n\ne2 = H.add_edge(\n     \"Xa\", \"Ya\",\n     edge_source_attr={\"Xa\": {\"__value\": 3}},\n     edge_target_attr={\"Ya\": {\"__value\": 2}}\n)\n\ne2 = H.add_edge(\"X\", \"Y\")\nattrs = H.get_edge_attrs(e2)\nsrc_map = dict(attrs.get(\"__source_attr\", {}))\ntgt_map = dict(attrs.get(\"__target_attr\", {}))\nsrc_map[\"X\"] = {\"__value\": 3}\ntgt_map[\"Y\"] = {\"__value\": 2}\nH.set_edge_attrs(e2, __source_attr=src_map, __target_attr=tgt_map)\n\nmat = H.vertex_incidence_matrix(values=True, sparse=False)\nprint(\"Vertices:\", tuple(H.V))\nprint(\"Incidence matrix:\\n\", mat)\nprint()\n\nprint(\"=== Subgraph ===\")\nSG = G.edge_subgraph([eidx])  # keep only that edge\nprint(\"Edge-subgraph edges:\", [(i, SG.get_edge(i)) for i in range(SG.num_edges)])\nprint()\n\nprint(\"=== Prune (if available) ===\")\nif hasattr(G, \"prune\"):\n    P = G.prune(source=[\"A\"], target=[\"C\"])\n    print(\"Pruned graph edges:\", [(i, P.get_edge(i)) for i in range(P.num_edges)])\nelse:\n    print(\"G.prune not implemented; skipping.\")\nprint()\n\nprint(\"=== Layers and per-layer weights ===\")\nD = Graph()\nD.add_vertex(\"A\"); D.add_vertex(\"B\")\nD.add_layer(\"t0\")\n\ne = D.add_edge(\"A\", \"B\", weight=1.5, label=\"ab\")\neid = D.idx_to_edge[e] if isinstance(e, int) else e\n\n# Attach same edge to layer (preserve stable eid), set per-layer weight\nw = D.edge_weights.get(eid, None)\nD.add_edge(\"A\", \"B\", layer=\"t0\", edge_id=eid, edge_directed=True, weight=w)\nD.set_layer_edge_weight(\"t0\", eid, 2.0)\n\nprint(\"Edge definitions:\", list(D.edge_definitions.items()))\nprint(\"Global edge weight:\", D.edge_weights.get(eid))\nprint(\"Layer t0 weight:\", D.get_effective_edge_weight(eid, layer=\"t0\"))\nprint(\"Layers containing edge:\", D.edge_presence_across_layers(eid, include_default=True))\n</pre> print(\"=== Basic graph creation ===\") G = Graph() G.add_vertex(\"A\", color = \"red\", name = \"amine\") G.add_vertex(\"B\")   eidx = G.add_edge({\"A\"}, {\"B\"})  eidx = G.add_edge(\"D\", \"C\")  print(\"Vertices:\", tuple(G.V))  print(\"Edges (index, (S,T)):\", [(i, G.get_edge(i)) for i in range(G.num_edges)]) print(\"Number of vertices:\", G.num_vertices) print(\"Number of edges:\", G.num_edges) print(\"Shape (|V|,|E|):\", G.shape) print()  print(\"=== Accessing edge info ===\") S, T = G.get_edge(eidx) print(\"Edge definition:\", S, \"-&gt;\", T) print()  print(\"=== Incidence matrix with per-vertex coefficients ===\") H = Graph() H.add_vertices([\"X\", \"Y\"])  e2 = H.add_edge(      \"Xa\", \"Ya\",      edge_source_attr={\"Xa\": {\"__value\": 3}},      edge_target_attr={\"Ya\": {\"__value\": 2}} )  e2 = H.add_edge(\"X\", \"Y\") attrs = H.get_edge_attrs(e2) src_map = dict(attrs.get(\"__source_attr\", {})) tgt_map = dict(attrs.get(\"__target_attr\", {})) src_map[\"X\"] = {\"__value\": 3} tgt_map[\"Y\"] = {\"__value\": 2} H.set_edge_attrs(e2, __source_attr=src_map, __target_attr=tgt_map)  mat = H.vertex_incidence_matrix(values=True, sparse=False) print(\"Vertices:\", tuple(H.V)) print(\"Incidence matrix:\\n\", mat) print()  print(\"=== Subgraph ===\") SG = G.edge_subgraph([eidx])  # keep only that edge print(\"Edge-subgraph edges:\", [(i, SG.get_edge(i)) for i in range(SG.num_edges)]) print()  print(\"=== Prune (if available) ===\") if hasattr(G, \"prune\"):     P = G.prune(source=[\"A\"], target=[\"C\"])     print(\"Pruned graph edges:\", [(i, P.get_edge(i)) for i in range(P.num_edges)]) else:     print(\"G.prune not implemented; skipping.\") print()  print(\"=== Layers and per-layer weights ===\") D = Graph() D.add_vertex(\"A\"); D.add_vertex(\"B\") D.add_layer(\"t0\")  e = D.add_edge(\"A\", \"B\", weight=1.5, label=\"ab\") eid = D.idx_to_edge[e] if isinstance(e, int) else e  # Attach same edge to layer (preserve stable eid), set per-layer weight w = D.edge_weights.get(eid, None) D.add_edge(\"A\", \"B\", layer=\"t0\", edge_id=eid, edge_directed=True, weight=w) D.set_layer_edge_weight(\"t0\", eid, 2.0)  print(\"Edge definitions:\", list(D.edge_definitions.items())) print(\"Global edge weight:\", D.edge_weights.get(eid)) print(\"Layer t0 weight:\", D.get_effective_edge_weight(eid, layer=\"t0\")) print(\"Layers containing edge:\", D.edge_presence_across_layers(eid, include_default=True))  <pre>=== Basic graph creation ===\nVertices: ('A', 'B', 'D', 'C')\nEdges (index, (S,T)): [(0, (frozenset({'A'}), frozenset({'B'}))), (1, (frozenset({'D'}), frozenset({'C'})))]\nNumber of vertices: 4\nNumber of edges: 2\nShape (|V|,|E|): (4, 2)\n\n=== Accessing edge info ===\nEdge definition: frozenset({'D'}) -&gt; frozenset({'C'})\n\n=== Incidence matrix with per-vertex coefficients ===\nVertices: ('X', 'Y', 'Xa', 'Ya')\nIncidence matrix:\n [[ 0.  1.  0.  0.  0.  0.  0.  0.]\n [ 0. -1.  0.  0.  0.  0.  0.  0.]\n [ 1.  0.  0.  0.  0.  0.  0.  0.]\n [-1.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n\n=== Subgraph ===\nEdge-subgraph edges: [(0, (frozenset({'D'}), frozenset({'C'})))]\n\n=== Prune (if available) ===\nG.prune not implemented; skipping.\n\n=== Layers and per-layer weights ===\nEdge definitions: [('edge_0', ('A', 'B', 'regular'))]\nGlobal edge weight: 1.5\nLayer t0 weight: 2.0\nLayers containing edge: ['default', 't0']\n</pre> In\u00a0[6]: Copied! <pre># convert to a networkx graph\nimport networkx as nx\nnxG = to_backend(G, directed=True)  # or directed=False if you prefer\n\nprint(\"Nodes:\", nxG.nodes(data=True))\nprint(\"Edges:\", nxG.edges(data=True))\n\n# quick visualization\nimport matplotlib.pyplot as plt\npos = nx.spring_layout(nxG)\nnx.draw(nxG, pos, with_labels=True, node_color=\"lightblue\")\nnx.draw_networkx_edge_labels(nxG, pos, edge_labels=nx.get_edge_attributes(nxG, \"weight\"))\nplt.show()\n</pre> # convert to a networkx graph import networkx as nx nxG = to_backend(G, directed=True)  # or directed=False if you prefer  print(\"Nodes:\", nxG.nodes(data=True)) print(\"Edges:\", nxG.edges(data=True))  # quick visualization import matplotlib.pyplot as plt pos = nx.spring_layout(nxG) nx.draw(nxG, pos, with_labels=True, node_color=\"lightblue\") nx.draw_networkx_edge_labels(nxG, pos, edge_labels=nx.get_edge_attributes(nxG, \"weight\")) plt.show() <pre>Nodes: [('A', {'color': 'red', 'name': 'amine'}), ('B', {'color': None, 'name': None}), ('D', {'color': None, 'name': None}), ('C', {'color': None, 'name': None})]\nEdges: [('A', 'B', {'__weight': 1.0}), ('D', 'C', {'__weight': 1.0})]\n</pre> In\u00a0[8]: Copied! <pre>nxG, man = to_nx(G, directed=True, hyperedge_mode=\"skip\")\n</pre> nxG, man = to_nx(G, directed=True, hyperedge_mode=\"skip\")  In\u00a0[10]: Copied! <pre>H2 = from_nx(nxG, man)\nprint(list(H2.edges()))\n</pre> H2 = from_nx(nxG, man) print(list(H2.edges()))  <pre>['edge_0', 'edge_1']\n</pre> In\u00a0[12]: Copied! <pre>for eid in H2.edges():                     # eid is a string\n    eidx = H2.edge_to_idx[eid]             # index (int), if you need it\n    S, T = H2.get_edge(eid)                # make sure get_edge accepts id OR index\n    attrs = H2.get_edge_attrs(eid)         # &lt;-- use the dict getter you added\n    print(eid, S, T, attrs)\n</pre> for eid in H2.edges():                     # eid is a string     eidx = H2.edge_to_idx[eid]             # index (int), if you need it     S, T = H2.get_edge(eid)                # make sure get_edge accepts id OR index     attrs = H2.get_edge_attrs(eid)         # &lt;-- use the dict getter you added     print(eid, S, T, attrs)  <pre>edge_0 frozenset({'A'}) frozenset({'B'}) {}\nedge_1 frozenset({'C'}) frozenset({'D'}) {}\n</pre> In\u00a0[14]: Copied! <pre>print(H2.vertex_attributes.head())  # attrs present\nprint(H2.edge_attributes.head())    # attrs present\n</pre> print(H2.vertex_attributes.head())  # attrs present print(H2.edge_attributes.head())    # attrs present  <pre>shape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 vertex_id \u2506 color \u2506 name  \u2502\n\u2502 ---       \u2506 ---   \u2506 ---   \u2502\n\u2502 str       \u2506 str   \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 A         \u2506 red   \u2506 amine \u2502\n\u2502 B         \u2506 null  \u2506 null  \u2502\n\u2502 D         \u2506 null  \u2506 null  \u2502\n\u2502 C         \u2506 null  \u2506 null  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nshape: (0, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id \u2502\n\u2502 ---     \u2502\n\u2502 str     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[16]: Copied! <pre>G.vertex_attributes.head()\n</pre> G.vertex_attributes.head() Out[16]: shape: (4, 3)vertex_idcolornamestrstrstr\"A\"\"red\"\"amine\"\"B\"nullnull\"D\"nullnull\"C\"nullnull <p>g</p> In\u00a0[23]: Copied! <pre>from graphglue.adapters.igraph_adapter import to_igraph, from_igraph, save_manifest, load_manifest\n</pre> from graphglue.adapters.igraph_adapter import to_igraph, from_igraph, save_manifest, load_manifest In\u00a0[29]: Copied! <pre>igG, manifest = to_igraph(G, directed=True, hyperedge_mode=\"skip\", public_only=False)\nH = from_igraph(igG, manifest)\nH\n</pre> igG, manifest = to_igraph(G, directed=True, hyperedge_mode=\"skip\", public_only=False) H = from_igraph(igG, manifest) H Out[29]: <pre>&lt;graphglue.core.graph.Graph at 0x1cbe13a4320&gt;</pre> In\u00a0[31]: Copied! <pre>nxG, _ = to_nx(G, directed=True, hyperedge_mode=\"skip\")\n\npos = nx.spring_layout(nxG)\nnx.draw(nxG, pos, with_labels=True, node_color=\"lightblue\")\nnx.draw_networkx_edge_labels(nxG, pos, edge_labels=nx.get_edge_attributes(nxG, \"weight\"))\nplt.show()\n</pre> nxG, _ = to_nx(G, directed=True, hyperedge_mode=\"skip\")  pos = nx.spring_layout(nxG) nx.draw(nxG, pos, with_labels=True, node_color=\"lightblue\") nx.draw_networkx_edge_labels(nxG, pos, edge_labels=nx.get_edge_attributes(nxG, \"weight\")) plt.show() In\u00a0[53]: Copied! <pre>from pathlib import Path\nfrom IPython.display import SVG, display\n\nfrom graphglue.utils.plotting import plot, render\n\n\nobj = plot(\n    G,\n    backend=\"graphviz\",\n    layout=\"dot\",\n    use_weight_style=False,\n    show_edge_labels=True,\n    **{\n        \"graph_attr\": {\"bgcolor\": \"white\"},\n        \"node_attr\":  {\"shape\": \"circle\", \"fixedsize\": \"true\"},\n        \"edge_attr\":  {\"color\": \"black\", \"penwidth\": \"3.0\"},\n    }\n)\n\nsvg_data = obj.pipe(format=\"svg\").decode(\"utf-8\")\ndisplay(SVG(svg_data))\n</pre> from pathlib import Path from IPython.display import SVG, display  from graphglue.utils.plotting import plot, render   obj = plot(     G,     backend=\"graphviz\",     layout=\"dot\",     use_weight_style=False,     show_edge_labels=True,     **{         \"graph_attr\": {\"bgcolor\": \"white\"},         \"node_attr\":  {\"shape\": \"circle\", \"fixedsize\": \"true\"},         \"edge_attr\":  {\"color\": \"black\", \"penwidth\": \"3.0\"},     } )  svg_data = obj.pipe(format=\"svg\").decode(\"utf-8\") display(SVG(svg_data)) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"about/","title":"About","text":"<p>This project was created by Daniele Bottazzi.</p>"},{"location":"incidencegraph_stress_notebook/","title":"Graph \u2014 End\u2011to\u2011End Stress Notebook","text":"In\u00a0[1]: Copied! <pre># Robust import of Graph\nimport os, importlib.util, random, math, time\nfrom time import perf_counter\n\nimport sys, os\nsys.path.insert(0, os.path.abspath(\"..\"))  # must be the parent folder that CONTAINS 'graphglue'\n\nfrom graphglue.core.graph import Graph\nfrom graphglue.adapters.networkx_adapter import to_backend, to_nx, from_nx\n\nG = Graph(directed=True)\n\n\nimport polars as pl\n</pre> # Robust import of Graph import os, importlib.util, random, math, time from time import perf_counter  import sys, os sys.path.insert(0, os.path.abspath(\"..\"))  # must be the parent folder that CONTAINS 'graphglue'  from graphglue.core.graph import Graph from graphglue.adapters.networkx_adapter import to_backend, to_nx, from_nx  G = Graph(directed=True)   import polars as pl In\u00a0[3]: Copied! <pre># Parameters \u2014 choose a scale\n# - DEMO runs fast on laptops\n# - STRESS creates 10^4\u201310^5 scale objects; adjust upward to your machine limits\n\nSCALE = \"DEMO\"  # \"DEMO\" or \"STRESS\"\n\nif SCALE.upper() == \"DEMO\":\n    N_PROTEINS = 5_00\n    N_TRANSCRIPTS = 2_00\n    N_METABOLITES = 1_00\n    N_EDGE_ENTITIES = 40\n    N_BIN_EDGES = 25_00       # binary protein-protein interactions (base layer)\n    N_HYPER_COMPLEX = 1_00    # undirected complexes\n    N_HYPER_CASCADE = 1_00    # directed signaling cascades\n    N_vertex_EDGE_BIDIR = 2_00  # vertex&lt;-&gt;edge-entity links (counted as pairs)\nelse:\n    N_PROTEINS = 30_000\n    N_TRANSCRIPTS = 12_000\n    N_METABOLITES = 8_000\n    N_EDGE_ENTITIES = 2_500\n    N_BIN_EDGES = 160_000\n    N_HYPER_COMPLEX = 4,000    # use commas? We'll correct below to int\n    N_HYPER_CASCADE = 4_000\n    N_vertex_EDGE_BIDIR = 10_000\n\n# fix typo for N_HYPER_COMPLEX in STRESS case\nif isinstance(N_HYPER_COMPLEX, tuple):\n    N_HYPER_COMPLEX = 4000\n\nLAYERS = [\"Healthy\",\"Stressed\",\"Disease\",\"DrugA\",\"DrugB\"]\nORDERED_FOR_TEMPORAL = [\"Healthy\",\"Stressed\",\"Disease\",\"DrugA\",\"DrugB\"]\n\n# How many parallel edges to create as duplicates between random pairs\nN_PARALLEL_DUPES = max(1, N_BIN_EDGES // 20)\n\n# Fraction of vertices seeded into each non-default layer (to make propagate='shared'/'all' meaningful)\nSEED_FRAC_PER_LAYER = 0.6\n</pre> # Parameters \u2014 choose a scale # - DEMO runs fast on laptops # - STRESS creates 10^4\u201310^5 scale objects; adjust upward to your machine limits  SCALE = \"DEMO\"  # \"DEMO\" or \"STRESS\"  if SCALE.upper() == \"DEMO\":     N_PROTEINS = 5_00     N_TRANSCRIPTS = 2_00     N_METABOLITES = 1_00     N_EDGE_ENTITIES = 40     N_BIN_EDGES = 25_00       # binary protein-protein interactions (base layer)     N_HYPER_COMPLEX = 1_00    # undirected complexes     N_HYPER_CASCADE = 1_00    # directed signaling cascades     N_vertex_EDGE_BIDIR = 2_00  # vertex&lt;-&gt;edge-entity links (counted as pairs) else:     N_PROTEINS = 30_000     N_TRANSCRIPTS = 12_000     N_METABOLITES = 8_000     N_EDGE_ENTITIES = 2_500     N_BIN_EDGES = 160_000     N_HYPER_COMPLEX = 4,000    # use commas? We'll correct below to int     N_HYPER_CASCADE = 4_000     N_vertex_EDGE_BIDIR = 10_000  # fix typo for N_HYPER_COMPLEX in STRESS case if isinstance(N_HYPER_COMPLEX, tuple):     N_HYPER_COMPLEX = 4000  LAYERS = [\"Healthy\",\"Stressed\",\"Disease\",\"DrugA\",\"DrugB\"] ORDERED_FOR_TEMPORAL = [\"Healthy\",\"Stressed\",\"Disease\",\"DrugA\",\"DrugB\"]  # How many parallel edges to create as duplicates between random pairs N_PARALLEL_DUPES = max(1, N_BIN_EDGES // 20)  # Fraction of vertices seeded into each non-default layer (to make propagate='shared'/'all' meaningful) SEED_FRAC_PER_LAYER = 0.6  In\u00a0[5]: Copied! <pre># Helpers\n\ndef rand_weight(base=1.0, jitter=0.5):\n    # positive weight with variability\n    w = base + (random.random() - 0.5) * 2 * jitter\n    return max(0.01, w)\n\ndef try_to_pandas(df):\n    if df is None:\n        return None\n    if 'polars' in type(df).__module__.lower():\n        return df.to_pandas() if hasattr(df, \"to_pandas\") else None\n    return df  # assume already pandas-like\n\ndef head_df(df, n=5):\n    p = try_to_pandas(df)\n    return p.head(n) if p is not None else None\n</pre> # Helpers  def rand_weight(base=1.0, jitter=0.5):     # positive weight with variability     w = base + (random.random() - 0.5) * 2 * jitter     return max(0.01, w)  def try_to_pandas(df):     if df is None:         return None     if 'polars' in type(df).__module__.lower():         return df.to_pandas() if hasattr(df, \"to_pandas\") else None     return df  # assume already pandas-like  def head_df(df, n=5):     p = try_to_pandas(df)     return p.head(n) if p is not None else None  In\u00a0[7]: Copied! <pre># Build graph &amp; layers\nt0 = perf_counter()\nG = Graph(directed=True)\n\nfor lid in LAYERS:\n    G.add_layer(lid, desc=f\"condition={lid}\")\nG.set_active_layer(LAYERS[0])\nbuild_layers_time = perf_counter() - t0\nprint(\"Layers ready:\", G.list_layers(), \"active:\", G.get_active_layer())\n</pre> # Build graph &amp; layers t0 = perf_counter() G = Graph(directed=True)  for lid in LAYERS:     G.add_layer(lid, desc=f\"condition={lid}\") G.set_active_layer(LAYERS[0]) build_layers_time = perf_counter() - t0 print(\"Layers ready:\", G.list_layers(), \"active:\", G.get_active_layer())  <pre>Layers ready: ['Healthy', 'Stressed', 'Disease', 'DrugA', 'DrugB'] active: Healthy\n</pre> In\u00a0[9]: Copied! <pre># ---- progress helpers ----\nfrom time import perf_counter\ntry:\n    from tqdm.auto import tqdm  # uses notebook bar if available\n    _TQDM = True\nexcept Exception:\n    _TQDM = False\n\ndef prog_iter(it, total=None, desc=\"\", mininterval=0.25):\n    \"\"\"Wrap any iterable with a progress display (tqdm if available, else no-op).\"\"\"\n    if _TQDM:\n        return tqdm(it, total=total, desc=desc, mininterval=mininterval, leave=False)\n    return it\n\ndef batched(iterable, batch_size):\n    \"\"\"Yield lists of size &lt;= batch_size (Py&lt;3.12 compatible).\"\"\"\n    buf = []\n    for x in iterable:\n        buf.append(x)\n        if len(buf) == batch_size:\n            yield buf\n            buf = []\n    if buf:\n        yield buf\n</pre> # ---- progress helpers ---- from time import perf_counter try:     from tqdm.auto import tqdm  # uses notebook bar if available     _TQDM = True except Exception:     _TQDM = False  def prog_iter(it, total=None, desc=\"\", mininterval=0.25):     \"\"\"Wrap any iterable with a progress display (tqdm if available, else no-op).\"\"\"     if _TQDM:         return tqdm(it, total=total, desc=desc, mininterval=mininterval, leave=False)     return it  def batched(iterable, batch_size):     \"\"\"Yield lists of size &lt;= batch_size (Py&lt;3.12 compatible).\"\"\"     buf = []     for x in iterable:         buf.append(x)         if len(buf) == batch_size:             yield buf             buf = []     if buf:         yield buf In\u00a0[11]: Copied! <pre>import numpy as np\nrng = np.random.default_rng(42)\n\nt = perf_counter()\n\nproteins    = [f\"P{i}\"  for i in range(1, N_PROTEINS+1)]\ntranscripts = [f\"T{i}\"  for i in range(1, N_TRANSCRIPTS+1)]\nmetabolites = [f\"M{i}\"  for i in range(1, N_METABOLITES+1)]\nedge_entities = [f\"EE{i}\" for i in range(1, N_EDGE_ENTITIES+1)]\n\n# --- Seed vertices in \"Healthy\" ---\nkinase_mask = rng.random(len(proteins)) &lt; 0.15\nG.add_vertices_bulk(\n    (\n        {\"vertex_id\": p, \"kind\": \"protein\", **({\"family\": \"kinase\"} if km else {})}\n        for p, km in zip(proteins, kinase_mask)\n    ),\n    layer=\"Healthy\",\n)\nG.add_vertices_bulk(({\"vertex_id\": t, \"kind\": \"transcript\"} for t in transcripts), layer=\"Healthy\")\nG.add_vertices_bulk(({\"vertex_id\": m, \"kind\": \"metabolite\"} for m in metabolites), layer=\"Healthy\")\n\n# --- Edge-entities in \"Healthy\" (bulk) ---\npathways = np.array([\"glycolysis\",\"tca\",\"mapk\",\"pi3k\"])\ndrawn_pathways = pathways[rng.integers(0, len(pathways), size=len(edge_entities))]\nG.add_edge_entities_bulk(\n    ({\"edge_entity_id\": ee, \"role\": \"enzyme\", \"pathway\": pw} for ee, pw in zip(edge_entities, drawn_pathways)),\n    layer=\"Healthy\",\n)\n\n# --- Seed presence into other layers (bulk per layer) ---\np_keep = SEED_FRAC_PER_LAYER\nfor lid in LAYERS[1:]:\n    pmask = rng.random(len(proteins))    &lt; p_keep\n    tmask = rng.random(len(transcripts)) &lt; p_keep\n    mmask = rng.random(len(metabolites)) &lt; p_keep\n\n    G.add_vertices_bulk(\n        ({\"vertex_id\": p, \"kind\": \"protein\"} for p, keep in zip(proteins, pmask) if keep),\n        layer=lid,\n    )\n    G.add_vertices_bulk(\n        ({\"vertex_id\": t, \"kind\": \"transcript\"} for t, keep in zip(transcripts, tmask) if keep),\n        layer=lid,\n    )\n    G.add_vertices_bulk(\n        ({\"vertex_id\": m, \"kind\": \"metabolite\"} for m, keep in zip(metabolites, mmask) if keep),\n        layer=lid,\n    )\n\nbuild_vertices_time = perf_counter() - t\nprint(\n    \"vertices done. #vertices:\", G.number_of_vertices(),\n    \"Edge-entities:\", sum(1 for k,v in G.entity_types.items() if v=='edge'),\n    \"time(s)=\", round(build_vertices_time, 3)\n)\n</pre> import numpy as np rng = np.random.default_rng(42)  t = perf_counter()  proteins    = [f\"P{i}\"  for i in range(1, N_PROTEINS+1)] transcripts = [f\"T{i}\"  for i in range(1, N_TRANSCRIPTS+1)] metabolites = [f\"M{i}\"  for i in range(1, N_METABOLITES+1)] edge_entities = [f\"EE{i}\" for i in range(1, N_EDGE_ENTITIES+1)]  # --- Seed vertices in \"Healthy\" --- kinase_mask = rng.random(len(proteins)) &lt; 0.15 G.add_vertices_bulk(     (         {\"vertex_id\": p, \"kind\": \"protein\", **({\"family\": \"kinase\"} if km else {})}         for p, km in zip(proteins, kinase_mask)     ),     layer=\"Healthy\", ) G.add_vertices_bulk(({\"vertex_id\": t, \"kind\": \"transcript\"} for t in transcripts), layer=\"Healthy\") G.add_vertices_bulk(({\"vertex_id\": m, \"kind\": \"metabolite\"} for m in metabolites), layer=\"Healthy\")  # --- Edge-entities in \"Healthy\" (bulk) --- pathways = np.array([\"glycolysis\",\"tca\",\"mapk\",\"pi3k\"]) drawn_pathways = pathways[rng.integers(0, len(pathways), size=len(edge_entities))] G.add_edge_entities_bulk(     ({\"edge_entity_id\": ee, \"role\": \"enzyme\", \"pathway\": pw} for ee, pw in zip(edge_entities, drawn_pathways)),     layer=\"Healthy\", )  # --- Seed presence into other layers (bulk per layer) --- p_keep = SEED_FRAC_PER_LAYER for lid in LAYERS[1:]:     pmask = rng.random(len(proteins))    &lt; p_keep     tmask = rng.random(len(transcripts)) &lt; p_keep     mmask = rng.random(len(metabolites)) &lt; p_keep      G.add_vertices_bulk(         ({\"vertex_id\": p, \"kind\": \"protein\"} for p, keep in zip(proteins, pmask) if keep),         layer=lid,     )     G.add_vertices_bulk(         ({\"vertex_id\": t, \"kind\": \"transcript\"} for t, keep in zip(transcripts, tmask) if keep),         layer=lid,     )     G.add_vertices_bulk(         ({\"vertex_id\": m, \"kind\": \"metabolite\"} for m, keep in zip(metabolites, mmask) if keep),         layer=lid,     )  build_vertices_time = perf_counter() - t print(     \"vertices done. #vertices:\", G.number_of_vertices(),     \"Edge-entities:\", sum(1 for k,v in G.entity_types.items() if v=='edge'),     \"time(s)=\", round(build_vertices_time, 3) ) <pre>vertices done. #vertices: 800 Edge-entities: 40 time(s)= 0.346\n</pre> In\u00a0[13]: Copied! <pre># Binary edges (PPIs mostly among proteins), defined in Healthy then layered variants\nfrom time import perf_counter\nimport random\n\nt = perf_counter()\n\n# ---------- 1) Bulk create binary edges on \"Healthy\" ----------\npairs = []\nneed = N_BIN_EDGES\nnames = proteins\nn = len(names)\n\n# Generate candidate pairs quickly; reject self-loops\nwhile len(pairs) &lt; need:\n    k = min(need - len(pairs), max(1024, need // 4))\n    us = random.choices(names, k=k)\n    vs = random.choices(names, k=k)\n    for u, v in zip(us, vs):\n        if u != v:\n            pairs.append((u, v))\n        if len(pairs) == need:\n            break\n\ndirs = [random.random() &lt; 0.8 for _ in range(need)]\nws   = [rand_weight(1.2, 0.6) for _ in range(need)]\n\nbulk = [\n    {\"source\": u, \"target\": v, \"weight\": w, \"edge_directed\": d, \"edge_type\": \"regular\", \"layer\": \"Healthy\"}\n    for (u, v), w, d in zip(pairs, ws, dirs)\n]\nppis = G.add_edges_bulk(bulk, layer=\"Healthy\")  # list of edge_ids\n\n# ---------- 2) Bulk add parallel dupes ----------\nif ppis and N_PARALLEL_DUPES &gt; 0:\n    chosen = random.choices(ppis, k=N_PARALLEL_DUPES)\n    par_edges = []\n    for eid in chosen:\n        u, v, _ = G.edge_definitions[eid]\n        par_edges.append({\n            \"source\": u, \"target\": v,\n            \"weight\": rand_weight(1.0, 0.3),\n            \"edge_type\": \"regular\",\n            \"layer\": \"Healthy\"\n        })\n    G.add_edges_bulk(par_edges, layer=\"Healthy\")\n\n# ---------- 3) Bulk per-layer variants ----------\nbase_w = {eid: G.edge_weights[eid] for eid in ppis}\n\nfor lid in LAYERS[1:]:\n    # Add all PPI edges to this layer in one shot\n    G.add_edges_to_layer_bulk(lid, ppis)\n    \n    # Compute modifiers and upsert all weights for this layer at once\n    weights_rows = []\n    for eid in ppis:\n        bw = base_w[eid]\n        factor = {\n            \"Stressed\": rand_weight(1.10, 0.10),\n            \"Disease\":  (0.7 if random.random() &lt; 0.4 else rand_weight(1.30, 0.15)),\n            \"DrugA\":    rand_weight(0.9, 0.25),\n            \"DrugB\":    rand_weight(1.2, 0.20),\n        }[lid]\n        weights_rows.append((eid, {\"weight\": bw * factor, \"note\": f\"layer={lid}\"}))\n    \n    G.set_edge_layer_attrs_bulk(lid, weights_rows)\n\nbuild_binary_time = perf_counter() - t\nprint(\"Binary edges built:\", len(ppis), \"total edges now:\", G.number_of_edges(),\n      \"time(s)=\", round(build_binary_time, 3))\n</pre> # Binary edges (PPIs mostly among proteins), defined in Healthy then layered variants from time import perf_counter import random  t = perf_counter()  # ---------- 1) Bulk create binary edges on \"Healthy\" ---------- pairs = [] need = N_BIN_EDGES names = proteins n = len(names)  # Generate candidate pairs quickly; reject self-loops while len(pairs) &lt; need:     k = min(need - len(pairs), max(1024, need // 4))     us = random.choices(names, k=k)     vs = random.choices(names, k=k)     for u, v in zip(us, vs):         if u != v:             pairs.append((u, v))         if len(pairs) == need:             break  dirs = [random.random() &lt; 0.8 for _ in range(need)] ws   = [rand_weight(1.2, 0.6) for _ in range(need)]  bulk = [     {\"source\": u, \"target\": v, \"weight\": w, \"edge_directed\": d, \"edge_type\": \"regular\", \"layer\": \"Healthy\"}     for (u, v), w, d in zip(pairs, ws, dirs) ] ppis = G.add_edges_bulk(bulk, layer=\"Healthy\")  # list of edge_ids  # ---------- 2) Bulk add parallel dupes ---------- if ppis and N_PARALLEL_DUPES &gt; 0:     chosen = random.choices(ppis, k=N_PARALLEL_DUPES)     par_edges = []     for eid in chosen:         u, v, _ = G.edge_definitions[eid]         par_edges.append({             \"source\": u, \"target\": v,             \"weight\": rand_weight(1.0, 0.3),             \"edge_type\": \"regular\",             \"layer\": \"Healthy\"         })     G.add_edges_bulk(par_edges, layer=\"Healthy\")  # ---------- 3) Bulk per-layer variants ---------- base_w = {eid: G.edge_weights[eid] for eid in ppis}  for lid in LAYERS[1:]:     # Add all PPI edges to this layer in one shot     G.add_edges_to_layer_bulk(lid, ppis)          # Compute modifiers and upsert all weights for this layer at once     weights_rows = []     for eid in ppis:         bw = base_w[eid]         factor = {             \"Stressed\": rand_weight(1.10, 0.10),             \"Disease\":  (0.7 if random.random() &lt; 0.4 else rand_weight(1.30, 0.15)),             \"DrugA\":    rand_weight(0.9, 0.25),             \"DrugB\":    rand_weight(1.2, 0.20),         }[lid]         weights_rows.append((eid, {\"weight\": bw * factor, \"note\": f\"layer={lid}\"}))          G.set_edge_layer_attrs_bulk(lid, weights_rows)  build_binary_time = perf_counter() - t print(\"Binary edges built:\", len(ppis), \"total edges now:\", G.number_of_edges(),       \"time(s)=\", round(build_binary_time, 3)) <pre>Binary edges built: 2500 total edges now: 2625 time(s)= 0.111\n</pre> In\u00a0[15]: Copied! <pre># Propagation semantics via add_edge(..., propagate=...)\nt = perf_counter()\n# Ensure varied vertex presence across layers for a few pairs\npairs = [(random.choice(proteins), random.choice(transcripts)) for _ in range(2000)]\nfor u,v in pairs:\n    # 'shared': only layers where both endpoints already present\n    G.add_edge(u, v, layer=\"Healthy\", edge_type=\"regular\", weight=rand_weight(0.8,0.2), propagate=\"shared\")\npairs2 = [(random.choice(proteins), random.choice(metabolites)) for _ in range(2000)]\nfor u,v in pairs2:\n    # 'all': appears everywhere either endpoint exists (pulls other endpoint in)\n    G.add_edge(u, v, layer=\"Healthy\", edge_type=\"regular\", weight=rand_weight(0.8,0.2), propagate=\"all\")\n\nbuild_propagation_time = perf_counter() - t\nprint(\"Propagation examples added (shared/all).\")\n</pre> # Propagation semantics via add_edge(..., propagate=...) t = perf_counter() # Ensure varied vertex presence across layers for a few pairs pairs = [(random.choice(proteins), random.choice(transcripts)) for _ in range(2000)] for u,v in pairs:     # 'shared': only layers where both endpoints already present     G.add_edge(u, v, layer=\"Healthy\", edge_type=\"regular\", weight=rand_weight(0.8,0.2), propagate=\"shared\") pairs2 = [(random.choice(proteins), random.choice(metabolites)) for _ in range(2000)] for u,v in pairs2:     # 'all': appears everywhere either endpoint exists (pulls other endpoint in)     G.add_edge(u, v, layer=\"Healthy\", edge_type=\"regular\", weight=rand_weight(0.8,0.2), propagate=\"all\")  build_propagation_time = perf_counter() - t print(\"Propagation examples added (shared/all).\")  <pre>Propagation examples added (shared/all).\n</pre> In\u00a0[17]: Copied! <pre># Hyperedges: undirected complexes, directed cascades\nt = perf_counter()\n\ncomplex_ids = []\nfor _ in range(N_HYPER_COMPLEX):\n    size = random.choice([3,4,5,6])\n    members = set(random.sample(proteins, size))\n    hid = G.add_hyperedge(members=members, layer=\"Healthy\", weight=rand_weight(1.0, 0.2), tag=\"complex\")\n    complex_ids.append(hid)\n    for lid in LAYERS[1:]:\n        G.add_edge_to_layer(lid, hid)\n\ncascade_ids = []\ntries = 0\nwhile len(cascade_ids) &lt; N_HYPER_CASCADE and tries &lt; N_HYPER_CASCADE*5:\n    tries += 1\n    head = set(random.sample(proteins, random.choice([1,2])))\n    tail = set(random.sample(proteins, random.choice([2,3,4])))\n    if head &amp; tail:\n        continue\n    hid = G.add_hyperedge(head=head, tail=tail, layer=\"Healthy\", weight=rand_weight(1.0,0.4), tag=\"cascade\")\n    cascade_ids.append(hid)\n    for lid in LAYERS[1:]:\n        G.add_edge_to_layer(lid, hid)\n\nbuild_hyper_time = perf_counter() - t\nprint(\"Hyperedges built: complexes=\", len(complex_ids), \"cascades=\", len(cascade_ids))\n</pre> # Hyperedges: undirected complexes, directed cascades t = perf_counter()  complex_ids = [] for _ in range(N_HYPER_COMPLEX):     size = random.choice([3,4,5,6])     members = set(random.sample(proteins, size))     hid = G.add_hyperedge(members=members, layer=\"Healthy\", weight=rand_weight(1.0, 0.2), tag=\"complex\")     complex_ids.append(hid)     for lid in LAYERS[1:]:         G.add_edge_to_layer(lid, hid)  cascade_ids = [] tries = 0 while len(cascade_ids) &lt; N_HYPER_CASCADE and tries &lt; N_HYPER_CASCADE*5:     tries += 1     head = set(random.sample(proteins, random.choice([1,2])))     tail = set(random.sample(proteins, random.choice([2,3,4])))     if head &amp; tail:         continue     hid = G.add_hyperedge(head=head, tail=tail, layer=\"Healthy\", weight=rand_weight(1.0,0.4), tag=\"cascade\")     cascade_ids.append(hid)     for lid in LAYERS[1:]:         G.add_edge_to_layer(lid, hid)  build_hyper_time = perf_counter() - t print(\"Hyperedges built: complexes=\", len(complex_ids), \"cascades=\", len(cascade_ids))  <pre>Hyperedges built: complexes= 100 cascades= 100\n</pre> In\u00a0[19]: Copied! <pre># vertex\u2013edge (edge-entity) reactions: A -&gt; EE -&gt; B (bidir variants)\nt = perf_counter()\nfor _ in range(N_vertex_EDGE_BIDIR):\n    ee = random.choice(edge_entities)\n    s = random.choice(proteins + transcripts + metabolites)\n    tvertex = random.choice(proteins + transcripts + metabolites)\n    G.add_edge(s, ee, layer=\"Healthy\", edge_type=\"vertex_edge\", weight=rand_weight(1.0,0.5))\n    G.add_edge(ee, tvertex, layer=\"Healthy\", edge_type=\"vertex_edge\", weight=rand_weight(1.0,0.5))\n    # reflect into other layers\n    for lid in LAYERS[1:]:\n        G.add_edge_to_layer(lid, list(G.get_edge_ids(s, ee))[-1])\n        G.add_edge_to_layer(lid, list(G.get_edge_ids(ee, tvertex))[-1])\n\nbuild_vertexedge_time = perf_counter() - t\nprint(\"vertex\u2013edge reaction links added (pairs):\", N_vertex_EDGE_BIDIR)\n</pre> # vertex\u2013edge (edge-entity) reactions: A -&gt; EE -&gt; B (bidir variants) t = perf_counter() for _ in range(N_vertex_EDGE_BIDIR):     ee = random.choice(edge_entities)     s = random.choice(proteins + transcripts + metabolites)     tvertex = random.choice(proteins + transcripts + metabolites)     G.add_edge(s, ee, layer=\"Healthy\", edge_type=\"vertex_edge\", weight=rand_weight(1.0,0.5))     G.add_edge(ee, tvertex, layer=\"Healthy\", edge_type=\"vertex_edge\", weight=rand_weight(1.0,0.5))     # reflect into other layers     for lid in LAYERS[1:]:         G.add_edge_to_layer(lid, list(G.get_edge_ids(s, ee))[-1])         G.add_edge_to_layer(lid, list(G.get_edge_ids(ee, tvertex))[-1])  build_vertexedge_time = perf_counter() - t print(\"vertex\u2013edge reaction links added (pairs):\", N_vertex_EDGE_BIDIR)  <pre>vertex\u2013edge reaction links added (pairs): 200\n</pre> In\u00a0[21]: Copied! <pre># Sanity &amp; counts\nprint(\"vertices:\", G.number_of_vertices(), \"Edges:\", G.number_of_edges())\nassert G.number_of_vertices() &gt; 0 and G.number_of_edges() &gt; 0\n\n# Edge-entity count\nedge_entity_count = sum(1 for _id, et in G.entity_types.items() if et == \"edge\" and _id in set(edge_entities))\nprint(\"Edge-entities:\", edge_entity_count)\nassert edge_entity_count == len(edge_entities)\n</pre> # Sanity &amp; counts print(\"vertices:\", G.number_of_vertices(), \"Edges:\", G.number_of_edges()) assert G.number_of_vertices() &gt; 0 and G.number_of_edges() &gt; 0  # Edge-entity count edge_entity_count = sum(1 for _id, et in G.entity_types.items() if et == \"edge\" and _id in set(edge_entities)) print(\"Edge-entities:\", edge_entity_count) assert edge_entity_count == len(edge_entities)  <pre>vertices: 800 Edges: 7225\nEdge-entities: 40\n</pre> In\u00a0[23]: Copied! <pre># Views &amp; Top edges per layer\ntry:\n    for lid in LAYERS:\n        EV = G.edges_view(layer=lid, resolved_weight=True)\n        print(f\"[{lid}] edges_view rows:\", getattr(EV, 'height', getattr(EV, 'shape', ['?','?'])[0]))\n        # filter binary only, sort by effective weight\n        if pl is not None and isinstance(EV, pl.DataFrame):\n            top = (EV.filter(pl.col(\"kind\")==\"binary\")\n                     .sort(\"effective_weight\", descending=True)\n                     .select([\"edge_id\",\"source\",\"target\",\"effective_weight\"])\n                     .head(5))\n            print(f\"Top 5 binary edges in {lid}:\\n\", top)\n        else:\n            # Try pandas-like\n            try:\n                df = EV\n                if hasattr(df, \"query\"):\n                    bf = df.query(\"kind == 'binary'\").sort_values(\"effective_weight\", ascending=False).head(5)\n                    print(bf[[\"edge_id\",\"source\",\"target\",\"effective_weight\"]])\n            except Exception:\n                pass\nexcept Exception as e:\n    print(\"edges_view failed softly:\", e)\n\ntry:\n    NV = G.vertices_view()\n    LV = G.layers_view()\n    print(\"vertices view cols:\", getattr(NV, 'columns', None))\n    print(\"Layers view cols:\", getattr(LV, 'columns', None))\nexcept Exception as e:\n    print(\"vertices_view/layers_view failed softly:\", e)\n</pre> # Views &amp; Top edges per layer try:     for lid in LAYERS:         EV = G.edges_view(layer=lid, resolved_weight=True)         print(f\"[{lid}] edges_view rows:\", getattr(EV, 'height', getattr(EV, 'shape', ['?','?'])[0]))         # filter binary only, sort by effective weight         if pl is not None and isinstance(EV, pl.DataFrame):             top = (EV.filter(pl.col(\"kind\")==\"binary\")                      .sort(\"effective_weight\", descending=True)                      .select([\"edge_id\",\"source\",\"target\",\"effective_weight\"])                      .head(5))             print(f\"Top 5 binary edges in {lid}:\\n\", top)         else:             # Try pandas-like             try:                 df = EV                 if hasattr(df, \"query\"):                     bf = df.query(\"kind == 'binary'\").sort_values(\"effective_weight\", ascending=False).head(5)                     print(bf[[\"edge_id\",\"source\",\"target\",\"effective_weight\"]])             except Exception:                 pass except Exception as e:     print(\"edges_view failed softly:\", e)  try:     NV = G.vertices_view()     LV = G.layers_view()     print(\"vertices view cols:\", getattr(NV, 'columns', None))     print(\"Layers view cols:\", getattr(LV, 'columns', None)) except Exception as e:     print(\"vertices_view/layers_view failed softly:\", e)  <pre>[Healthy] edges_view rows: 7225\nTop 5 binary edges in Healthy:\n shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id   \u2506 source \u2506 target \u2506 effective_weight \u2502\n\u2502 ---       \u2506 ---    \u2506 ---    \u2506 ---              \u2502\n\u2502 str       \u2506 str    \u2506 str    \u2506 f64              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_1511 \u2506 P403   \u2506 P466   \u2506 1.799077         \u2502\n\u2502 edge_2138 \u2506 P478   \u2506 P79    \u2506 1.799077         \u2502\n\u2502 edge_2254 \u2506 P237   \u2506 P428   \u2506 1.79828          \u2502\n\u2502 edge_406  \u2506 P449   \u2506 P341   \u2506 1.796167         \u2502\n\u2502 edge_2494 \u2506 P101   \u2506 P33    \u2506 1.796059         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n[Stressed] edges_view rows: 7225\nTop 5 binary edges in Stressed:\n shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id   \u2506 source \u2506 target \u2506 effective_weight \u2502\n\u2502 ---       \u2506 ---    \u2506 ---    \u2506 ---              \u2502\n\u2502 str       \u2506 str    \u2506 str    \u2506 f64              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_406  \u2506 P449   \u2506 P341   \u2506 2.131998         \u2502\n\u2502 edge_1573 \u2506 P360   \u2506 P11    \u2506 2.112816         \u2502\n\u2502 edge_1826 \u2506 P316   \u2506 P270   \u2506 2.110934         \u2502\n\u2502 edge_1150 \u2506 P128   \u2506 P369   \u2506 2.108738         \u2502\n\u2502 edge_2057 \u2506 P129   \u2506 P14    \u2506 2.100799         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n[Disease] edges_view rows: 7225\nTop 5 binary edges in Disease:\n shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id   \u2506 source \u2506 target \u2506 effective_weight \u2502\n\u2502 ---       \u2506 ---    \u2506 ---    \u2506 ---              \u2502\n\u2502 str       \u2506 str    \u2506 str    \u2506 f64              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_600  \u2506 P346   \u2506 P344   \u2506 2.572232         \u2502\n\u2502 edge_1175 \u2506 P452   \u2506 P275   \u2506 2.571111         \u2502\n\u2502 edge_792  \u2506 P354   \u2506 P425   \u2506 2.564687         \u2502\n\u2502 edge_2287 \u2506 P65    \u2506 P37    \u2506 2.56391          \u2502\n\u2502 edge_1149 \u2506 P41    \u2506 P331   \u2506 2.550489         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n[DrugA] edges_view rows: 7225\nTop 5 binary edges in DrugA:\n shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id   \u2506 source \u2506 target \u2506 effective_weight \u2502\n\u2502 ---       \u2506 ---    \u2506 ---    \u2506 ---              \u2502\n\u2502 str       \u2506 str    \u2506 str    \u2506 f64              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_1748 \u2506 P43    \u2506 P147   \u2506 2.052591         \u2502\n\u2502 edge_952  \u2506 P328   \u2506 P10    \u2506 2.029163         \u2502\n\u2502 edge_2499 \u2506 P209   \u2506 P21    \u2506 2.01207          \u2502\n\u2502 edge_1198 \u2506 P152   \u2506 P256   \u2506 2.01199          \u2502\n\u2502 edge_2287 \u2506 P65    \u2506 P37    \u2506 1.997597         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n[DrugB] edges_view rows: 7225\nTop 5 binary edges in DrugB:\n shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id   \u2506 source \u2506 target \u2506 effective_weight \u2502\n\u2502 ---       \u2506 ---    \u2506 ---    \u2506 ---              \u2502\n\u2502 str       \u2506 str    \u2506 str    \u2506 f64              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_2494 \u2506 P101   \u2506 P33    \u2506 2.494891         \u2502\n\u2502 edge_2481 \u2506 P407   \u2506 P454   \u2506 2.454188         \u2502\n\u2502 edge_1288 \u2506 P452   \u2506 P355   \u2506 2.44479          \u2502\n\u2502 edge_985  \u2506 P209   \u2506 P164   \u2506 2.441334         \u2502\n\u2502 edge_830  \u2506 P48    \u2506 P8     \u2506 2.438881         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nvertices view cols: ['vertex_id', 'kind', 'family', 'pathway', 'role']\nLayers view cols: ['layer_id', 'desc']\n</pre> In\u00a0[25]: Copied! <pre># Presence queries\nany_e = next(iter(G.edge_to_idx.keys()))\nprint(\"Edge presence across layers:\", G.edge_presence_across_layers(edge_id=any_e))\n\nany_p = random.choice(proteins)\nprint(\"vertex presence across layers:\", G.vertex_presence_across_layers(any_p))\n\n# Hyperedge presence by members and head/tail\nif complex_ids:\n    m = random.choice(complex_ids)\n    members = G.hyperedge_definitions[m].get(\"members\", set())\n    if members:\n        print(\"Hyperedge presence (members):\", G.hyperedge_presence_across_layers(members=set(members)))\nif cascade_ids:\n    h = random.choice(cascade_ids)\n    hd = G.hyperedge_definitions[h]\n    if hd.get(\"head\") and hd.get(\"tail\"):\n        print(\"Hyperedge presence (head/tail):\", G.hyperedge_presence_across_layers(head=set(hd[\"head\"]), tail=set(hd[\"tail\"])))\n</pre> # Presence queries any_e = next(iter(G.edge_to_idx.keys())) print(\"Edge presence across layers:\", G.edge_presence_across_layers(edge_id=any_e))  any_p = random.choice(proteins) print(\"vertex presence across layers:\", G.vertex_presence_across_layers(any_p))  # Hyperedge presence by members and head/tail if complex_ids:     m = random.choice(complex_ids)     members = G.hyperedge_definitions[m].get(\"members\", set())     if members:         print(\"Hyperedge presence (members):\", G.hyperedge_presence_across_layers(members=set(members))) if cascade_ids:     h = random.choice(cascade_ids)     hd = G.hyperedge_definitions[h]     if hd.get(\"head\") and hd.get(\"tail\"):         print(\"Hyperedge presence (head/tail):\", G.hyperedge_presence_across_layers(head=set(hd[\"head\"]), tail=set(hd[\"tail\"])))  <pre>Edge presence across layers: ['Healthy', 'Stressed', 'Disease', 'DrugA', 'DrugB']\nvertex presence across layers: ['Healthy', 'Stressed', 'Disease', 'DrugA', 'DrugB']\nHyperedge presence (members): {'Healthy': ['edge_6686'], 'Stressed': ['edge_6686'], 'Disease': ['edge_6686'], 'DrugA': ['edge_6686'], 'DrugB': ['edge_6686']}\nHyperedge presence (head/tail): {'Healthy': ['edge_6725'], 'Stressed': ['edge_6725'], 'Disease': ['edge_6725'], 'DrugA': ['edge_6725'], 'DrugB': ['edge_6725']}\n</pre> In\u00a0[27]: Copied! <pre># Traversal\nq = random.choice(proteins)\nprint(f\"Neighbors({q}) sample:\", G.neighbors(q)[:10])\nprint(f\"Out({q}) sample:\", G.out_neighbors(q)[:10])\nprint(f\"In({q}) sample:\", G.in_neighbors(q)[:10])\n</pre> # Traversal q = random.choice(proteins) print(f\"Neighbors({q}) sample:\", G.neighbors(q)[:10]) print(f\"Out({q}) sample:\", G.out_neighbors(q)[:10]) print(f\"In({q}) sample:\", G.in_neighbors(q)[:10])  <pre>Neighbors(P20) sample: ['P234', 'P399', 'P422', 'P148', 'P89']\nOut(P20) sample: ['P234', 'P399', 'P422', 'P148', 'P89']\nIn(P20) sample: ['P486', 'P422', 'P89']\n</pre> In\u00a0[29]: Copied! <pre># Layer analytics, conserved/specific, temporal\nstats = G.layer_statistics()\nprint(\"Layer stats keys:\", list(stats.keys())[:5])\n\nconserved = G.conserved_edges(min_layers=len(LAYERS))\nprint(\"Conserved edges (present in all layers):\", len(conserved))\n\ndisease_specific = G.layer_specific_edges(\"Disease\")\nprint(\"Disease-specific edges:\", len(disease_specific))\n\nchanges_e = G.temporal_dynamics(ORDERED_FOR_TEMPORAL, metric=\"edge_change\")\nchanges_n = G.temporal_dynamics(ORDERED_FOR_TEMPORAL, metric=\"vertex_change\")\nprint(\"Temporal edge changes entries:\", len(changes_e), \"vertex changes entries:\", len(changes_n))\n</pre> # Layer analytics, conserved/specific, temporal stats = G.layer_statistics() print(\"Layer stats keys:\", list(stats.keys())[:5])  conserved = G.conserved_edges(min_layers=len(LAYERS)) print(\"Conserved edges (present in all layers):\", len(conserved))  disease_specific = G.layer_specific_edges(\"Disease\") print(\"Disease-specific edges:\", len(disease_specific))  changes_e = G.temporal_dynamics(ORDERED_FOR_TEMPORAL, metric=\"edge_change\") changes_n = G.temporal_dynamics(ORDERED_FOR_TEMPORAL, metric=\"vertex_change\") print(\"Temporal edge changes entries:\", len(changes_e), \"vertex changes entries:\", len(changes_n))  <pre>Layer stats keys: ['Healthy', 'Stressed', 'Disease', 'DrugA', 'DrugB']\nConserved edges (present in all layers): 5319\nDisease-specific edges: 0\nTemporal edge changes entries: 4 vertex changes entries: 4\n</pre> In\u00a0[31]: Copied! <pre># Layer set ops and derived layers\nu = G.layer_union([\"Healthy\",\"Stressed\"])\ni = G.layer_intersection([\"Healthy\",\"Stressed\"])\nd = G.layer_difference(\"Healthy\",\"Stressed\")\nprint(\"Union edges&gt;=intersection edges:\", len(u[\"edges\"]) &gt;= len(i[\"edges\"]))\n\nlid_u = G.create_layer_from_operation(\"HS_union\", u, desc=\"H\u222aS\")\nlid_i = G.create_layer_from_operation(\"HS_intersection\", i, desc=\"H\u2229S\")\nlid_d = G.create_layer_from_operation(\"H_minus_S\", d, desc=\"H\\\\S\")\nprint(\"Derived layers exist:\", G.has_layer(\"HS_union\"), G.has_layer(\"HS_intersection\"), G.has_layer(\"H_minus_S\"))\n\n# Aggregations\nG.create_aggregated_layer([\"Healthy\",\"Stressed\"], \"Agg_union\", method=\"union\", tag=\"agg_u\")\nG.create_aggregated_layer([\"Healthy\",\"Stressed\"], \"Agg_intersection\", method=\"intersection\", tag=\"agg_i\")\nprint(\"Aggregated layers added.\")\n</pre> # Layer set ops and derived layers u = G.layer_union([\"Healthy\",\"Stressed\"]) i = G.layer_intersection([\"Healthy\",\"Stressed\"]) d = G.layer_difference(\"Healthy\",\"Stressed\") print(\"Union edges&gt;=intersection edges:\", len(u[\"edges\"]) &gt;= len(i[\"edges\"]))  lid_u = G.create_layer_from_operation(\"HS_union\", u, desc=\"H\u222aS\") lid_i = G.create_layer_from_operation(\"HS_intersection\", i, desc=\"H\u2229S\") lid_d = G.create_layer_from_operation(\"H_minus_S\", d, desc=\"H\\\\S\") print(\"Derived layers exist:\", G.has_layer(\"HS_union\"), G.has_layer(\"HS_intersection\"), G.has_layer(\"H_minus_S\"))  # Aggregations G.create_aggregated_layer([\"Healthy\",\"Stressed\"], \"Agg_union\", method=\"union\", tag=\"agg_u\") G.create_aggregated_layer([\"Healthy\",\"Stressed\"], \"Agg_intersection\", method=\"intersection\", tag=\"agg_i\") print(\"Aggregated layers added.\")  <pre>Union edges&gt;=intersection edges: True\nDerived layers exist: True True True\nAggregated layers added.\n</pre> In\u00a0[33]: Copied! <pre># Edge list &amp; global counts\nel = G.edge_list()\nprint(\"Edge list tuple length check (u,v,kind,id):\", all(len(t)==4 for t in el))\nprint(\"Global entity/edge counts:\", G.global_entity_count(), G.global_edge_count())\n</pre> # Edge list &amp; global counts el = G.edge_list() print(\"Edge list tuple length check (u,v,kind,id):\", all(len(t)==4 for t in el)) print(\"Global entity/edge counts:\", G.global_entity_count(), G.global_edge_count())  <pre>Edge list tuple length check (u,v,kind,id): True\nGlobal entity/edge counts: 840 7225\n</pre> In\u00a0[35]: Copied! <pre># Subgraph &amp; copy\nSG = G.subgraph_from_layer(\"DrugB\", resolve_layer_weights=True)\nprint(\"DrugB subgraph vertices/edges:\", SG.number_of_vertices(), SG.number_of_edges())\n\nCP = G.copy()\n# quick consistency checks\nassert set(CP.vertices()) == set(G.vertices())\nassert set(CP.edges()) == set(G.edges())\nany_hyper = next(e for e,k in G.edge_kind.items() if k == \"hyper\")\nassert CP.edge_kind.get(any_hyper) == \"hyper\"\nfor lid in G.list_layers(include_default=True):\n    assert CP._layers[lid][\"vertices\"] == G._layers[lid][\"vertices\"]\n    assert CP._layers[lid][\"edges\"] == G._layers[lid][\"edges\"]\nprint(\"Deep copy OK.\")\n</pre> # Subgraph &amp; copy SG = G.subgraph_from_layer(\"DrugB\", resolve_layer_weights=True) print(\"DrugB subgraph vertices/edges:\", SG.number_of_vertices(), SG.number_of_edges())  CP = G.copy() # quick consistency checks assert set(CP.vertices()) == set(G.vertices()) assert set(CP.edges()) == set(G.edges()) any_hyper = next(e for e,k in G.edge_kind.items() if k == \"hyper\") assert CP.edge_kind.get(any_hyper) == \"hyper\" for lid in G.list_layers(include_default=True):     assert CP._layers[lid][\"vertices\"] == G._layers[lid][\"vertices\"]     assert CP._layers[lid][\"edges\"] == G._layers[lid][\"edges\"] print(\"Deep copy OK.\")  <pre>DrugB subgraph vertices/edges: 781 6233\nDeep copy OK.\n</pre> In\u00a0[37]: Copied! <pre># Removals: drop a slice of vertices/edges\n\n# Drop ~1% of proteins\ndrop_vertices = random.sample(proteins, max(1, len(proteins)//100))\nG.remove_vertices(drop_vertices)   # one pass\n\n# Drop up to 500 edges\ndrop_edges = list(G.edge_to_idx.keys())[: min(500, len(G.edge_to_idx))]\nG.remove_edges(drop_edges)         # one pass\n\nprint(\"After removals: vertices=\", G.number_of_vertices(), \"edges=\", G.number_of_edges())\n</pre> # Removals: drop a slice of vertices/edges  # Drop ~1% of proteins drop_vertices = random.sample(proteins, max(1, len(proteins)//100)) G.remove_vertices(drop_vertices)   # one pass  # Drop up to 500 edges drop_edges = list(G.edge_to_idx.keys())[: min(500, len(G.edge_to_idx))] G.remove_edges(drop_edges)         # one pass  print(\"After removals: vertices=\", G.number_of_vertices(), \"edges=\", G.number_of_edges()) <pre>After removals: vertices= 795 edges= 6616\n</pre> In\u00a0[39]: Copied! <pre># Audit &amp; memory\naudit = G.audit_attributes()\nmem_bytes = G.memory_usage()\nprint(\"Audit keys:\", list(audit.keys())[:10])\nprint(\"Approx memory usage (bytes):\", int(mem_bytes))\n</pre> # Audit &amp; memory audit = G.audit_attributes() mem_bytes = G.memory_usage() print(\"Audit keys:\", list(audit.keys())[:10]) print(\"Approx memory usage (bytes):\", int(mem_bytes))  <pre>Audit keys: ['extra_vertex_rows', 'extra_edge_rows', 'missing_vertex_rows', 'missing_edge_rows', 'invalid_edge_layer_rows']\nApprox memory usage (bytes): 1586724\n</pre> In\u00a0[41]: Copied! <pre># Timing summary\nimport pandas as pd\n\ntimings = {\n    \"build_layers\": build_layers_time,\n    \"build_vertices\": build_vertices_time,\n    \"build_binary_edges\": build_binary_time,\n    \"build_hyperedges\": build_hyper_time,\n    \"build_vertexedge\": build_vertexedge_time,\n}\n\ndf = pd.DataFrame(sorted(timings.items(), key=lambda x: x[0]), columns=[\"stage\",\"seconds\"])\n\nprint(\"Build timings (seconds)\", df)\n\n# Simple chart\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.bar(df[\"stage\"], df[\"seconds\"])\nplt.xticks(rotation=45, ha=\"right\")\nplt.ylabel(\"seconds\")\nplt.title(\"Graph Build Timings\")\nplt.tight_layout()\nplt.show()\n</pre> # Timing summary import pandas as pd  timings = {     \"build_layers\": build_layers_time,     \"build_vertices\": build_vertices_time,     \"build_binary_edges\": build_binary_time,     \"build_hyperedges\": build_hyper_time,     \"build_vertexedge\": build_vertexedge_time, }  df = pd.DataFrame(sorted(timings.items(), key=lambda x: x[0]), columns=[\"stage\",\"seconds\"])  print(\"Build timings (seconds)\", df)  # Simple chart import matplotlib.pyplot as plt plt.figure() plt.bar(df[\"stage\"], df[\"seconds\"]) plt.xticks(rotation=45, ha=\"right\") plt.ylabel(\"seconds\") plt.title(\"Graph Build Timings\") plt.tight_layout() plt.show()  <pre>Build timings (seconds)                 stage   seconds\n0  build_binary_edges  0.111388\n1    build_hyperedges  0.033243\n2        build_layers  0.002652\n3    build_vertexedge  0.498512\n4      build_vertices  0.345543\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"incidencegraph_stress_notebook/#graph-endtoend-stress-notebook","title":"Graph \u2014 End\u2011to\u2011End Stress Notebook\u00b6","text":"<p>Goal: build a realistic, multi\u2011layer biological interaction graph with tens of thousands of vertices and a mix of binary edges, hyperedges, and vertex\u2013edge (edge\u2011entity) links, then exercise every public API: layers, presence queries, propagation (<code>shared</code> / <code>all</code>), views, analytics, set operations, aggregations, subgraph/copy, deletions, auditing, and memory usage.</p>"},{"location":"installation/","title":"Installation guide","text":"<p>We strongly recommend installing a few prerequisites to ensure a smooth experience. These prerequisites are:</p> <ol> <li>Python 3 (version &gt;= 3.10)<ul> <li>Install Python 3</li> </ul> </li> <li>Poetry (Python packaging and dependency manager)<ul> <li>Install Poetry</li> </ul> </li> <li>git (version control manager)<ul> <li>Install git</li> </ul> </li> <li>Docker (containerization technology) [optional]<ul> <li>Install Docker</li> </ul> </li> </ol> <p>Tip</p> <p>If you are missing any of those pre-requisites, please follow the installation guide in each resource before you continue.</p>"},{"location":"installation/#checking-prerequisites","title":"Checking prerequisites","text":"<p>You can verify access to these components in your terminal:</p> <ol> <li><code>Python</code> version 3.10 or higher.    <pre><code>python --version\n</code></pre></li> <li><code>Poetry</code> <pre><code>poetry --version\n</code></pre></li> <li><code>git</code> <pre><code>git --version\n</code></pre></li> <li><code>Docker</code> <pre><code>docker --version\n</code></pre></li> </ol>"},{"location":"io_annnet/","title":"AnnNet Zero-Loss Serialization: Zarr + Parquet","text":""},{"location":"io_annnet/#design-goals","title":"Design Goals","text":"<ol> <li>Zero topology loss: Preserve exact incidence matrix, all edge types, hyperedges, parallel edges</li> <li>Complete metadata: All attributes, layers, history, provenance</li> <li>Cross-platform: Works on Windows/Linux/Mac, Python/R/Julia</li> <li>Incremental updates: Can append without full rewrite</li> <li>Cloud support: S3/GCS/Azure compatible via Zarr</li> <li>Fast random access: Chunked storage for large graphs</li> </ol>"},{"location":"io_annnet/#file-structure","title":"File Structure","text":"<pre><code>graph.annnet/\n\u251c\u2500\u2500 manifest.json                 # root descriptor (format, counts, compression, etc.)\n\u251c\u2500\u2500 structure/\n\u2502   \u251c\u2500\u2500 incidence.zarr/           # Zarr v3 group holding COO [coordinate list] arrays\n\u2502   \u2502   \u251c\u2500\u2500 zarr.json             # Zarr v3 group metadata (includes group attributes)\n\u2502   \u2502   \u251c\u2500\u2500 row/                  # Zarr array (int32) of entity indices (COO row)\n\u2502   \u2502   \u251c\u2500\u2500 col/                  # Zarr array (int32) of edge indices   (COO col)\n\u2502   \u2502   \u2514\u2500\u2500 data/                 # Zarr array (float32) of weights       (COO data)\n\u2502   \u2502   # group attributes include: {\"shape\": [n_entities, n_edges]}\n\u2502   \u251c\u2500\u2500 entity_to_idx.parquet     # entity_id \u2192 row index\n\u2502   \u251c\u2500\u2500 idx_to_entity.parquet     # row index \u2192 entity_id\n\u2502   \u251c\u2500\u2500 entity_types.parquet      # entity_id \u2192 \"vertex\" | \"edge\"\n\u2502   \u251c\u2500\u2500 edge_to_idx.parquet       # edge_id \u2192 column index\n\u2502   \u251c\u2500\u2500 idx_to_edge.parquet       # column index \u2192 edge_id\n\u2502   \u251c\u2500\u2500 edge_definitions.parquet  # edge_id \u2192 (source, target, edge_type) for simple edges\n\u2502   \u251c\u2500\u2500 edge_weights.parquet      # edge_id \u2192 weight\n\u2502   \u251c\u2500\u2500 edge_directed.parquet     # edge_id \u2192 bool | null\n\u2502   \u251c\u2500\u2500 edge_kind.parquet         # edge_id \u2192 \"binary\" | \"hyper\"\n\u2502   \u2514\u2500\u2500 hyperedge_definitions.parquet\n\u2502       # columns: edge_id, directed(bool), members(List[Utf8]) OR head(List[Utf8]), tail(List[Utf8])\n\u2502\n\u251c\u2500\u2500 tables/\n\u2502   \u251c\u2500\u2500 vertex_attributes.parquet     # vertex-level DF [dataframe]\n\u2502   \u251c\u2500\u2500 edge_attributes.parquet       # edge-level DF\n\u2502   \u251c\u2500\u2500 layer_attributes.parquet      # layer metadata\n\u2502   \u2514\u2500\u2500 edge_layer_attributes.parquet # (layer_id, edge_id, weight)\n\u2502\n\u251c\u2500\u2500 layers/\n\u2502   \u251c\u2500\u2500 registry.parquet              # layer_id, name, metadata\u2026\n\u2502   \u251c\u2500\u2500 vertex_memberships.parquet    # (layer_id, vertex_id)\n\u2502   \u2514\u2500\u2500 edge_memberships.parquet      # (layer_id, edge_id, weight)\n\u2502\n\u251c\u2500\u2500 cache/                            # optional materialized views\n\u2502   \u251c\u2500\u2500 csr.zarr/                     # CSR [compressed sparse row] cache\n\u2502   \u2514\u2500\u2500 csc.zarr/                     # CSC [compressed sparse column] cache\n\u2502\n\u251c\u2500\u2500 audit/\n\u2502   \u251c\u2500\u2500 history.parquet               # operation log (nested payloads stringified to JSON [JavaScript Object Notation])\n\u2502   \u251c\u2500\u2500 snapshots/                    # optional labeled snapshots\n\u2502   \u2514\u2500\u2500 provenance.json               # creation time, software versions, etc.\n\u2502\n\u2514\u2500\u2500 uns/                              # unstructured metadata &amp; results\n    \u251c\u2500\u2500 graph_attributes.json\n    \u2514\u2500\u2500 results/\n</code></pre>"},{"location":"io_annnet/#manifest-schema-manifestjson","title":"Manifest Schema (<code>manifest.json</code>)","text":"<pre><code>{\n  \"format\": \"annnet\",\n  \"version\": \"1.0.0\",\n  \"created\": \"2025-10-23T10:30:00Z\",\n  \"annnet_version\": \"0.1.0\",\n  \"graph_version\": 42,\n  \"directed\": true,\n  \"counts\": {\n    \"vertices\": 1000,\n    \"edges\": 5000,\n    \"entities\": 1050,\n    \"layers\": 3,\n    \"hyperedges\": 50\n  },\n  \"layers\": [\"default\", \"temporal_2023\", \"temporal_2024\"],\n  \"active_layer\": \"default\",\n  \"default_layer\": \"default\",\n  \"schema_version\": \"1.0\",\n  \"checksum\": \"sha256:abcdef...\",\n  \"compression\": \"zstd\",\n  \"encoding\": {\n    \"zarr\": \"v3\",\n    \"parquet\": \"2.0\"\n  }\n}\n</code></pre>"},{"location":"io_annnet/#advantages","title":"Advantages","text":"<ol> <li>Zero loss: topology + metadata round-trip exactly</li> <li>Portable: Parquet/Zarr are first-class in Python/R/Julia</li> <li>Incremental: replace just the parts you touched</li> <li>Cloud-native: Zarr stores are compatible with S3/GCS/Azure</li> <li>Interoperable: PaParquet works with Pandas/DuckDB/Arrow ecosystems</li> <li>Compressed: zstd/lz4 where supported</li> <li>Chunked: fast random access on large graphs</li> <li>Schema evolution: add new tables without breaking old readers</li> </ol>"},{"location":"ppi_example/","title":"Ppi example","text":"In\u00a0[1]: Copied! <pre>import sys\nsys.path.insert(0, r\"C:\\Users\\PC\\Desktop\\graphglue\")\nfrom graphglue.core.graph import Graph\n</pre> import sys sys.path.insert(0, r\"C:\\Users\\PC\\Desktop\\graphglue\") from graphglue.core.graph import Graph  In\u00a0[3]: Copied! <pre># ---------- Setup ----------\nG = Graph(directed=True)\nconditions = [\"Healthy\", \"Stressed\", \"Disease\"]\nfor c in conditions:\n    G.add_layer(c, condition=c)\n\n# Entities\nproteins = [f\"P{i}\" for i in range(1, 151)]   # P1..P150\ntranscripts = [f\"T{i}\" for i in range(1, 61)]  # T1..T60 (treat as vertices)\nenz_edge_entities = [f\"edge_rxn_{i}\" for i in range(1, 11)]  # edge-entities for reactions\n\n# Seed some vertex attributes\nfor p in proteins[:10]:\n    G.add_vertex(p, layer=\"Healthy\", family=\"kinase\")\nfor p in proteins[10:]:\n    G.add_vertex(p, layer=\"Healthy\")\nfor t in transcripts:\n    G.add_vertex(t, layer=\"Healthy\", kind=\"transcript\")\nfor ee in enz_edge_entities:\n    G.add_edge_entity(ee, layer=\"Healthy\", role=\"enzyme\")\n\n# Propagate initial vertices to all layers (cheaply)\nfor lid in [\"Stressed\", \"Disease\"]:\n    G._layers[lid][\"vertices\"].update(G._layers[\"Healthy\"][\"vertices\"])\n</pre> # ---------- Setup ---------- G = Graph(directed=True) conditions = [\"Healthy\", \"Stressed\", \"Disease\"] for c in conditions:     G.add_layer(c, condition=c)  # Entities proteins = [f\"P{i}\" for i in range(1, 151)]   # P1..P150 transcripts = [f\"T{i}\" for i in range(1, 61)]  # T1..T60 (treat as vertices) enz_edge_entities = [f\"edge_rxn_{i}\" for i in range(1, 11)]  # edge-entities for reactions  # Seed some vertex attributes for p in proteins[:10]:     G.add_vertex(p, layer=\"Healthy\", family=\"kinase\") for p in proteins[10:]:     G.add_vertex(p, layer=\"Healthy\") for t in transcripts:     G.add_vertex(t, layer=\"Healthy\", kind=\"transcript\") for ee in enz_edge_entities:     G.add_edge_entity(ee, layer=\"Healthy\", role=\"enzyme\")  # Propagate initial vertices to all layers (cheaply) for lid in [\"Stressed\", \"Disease\"]:     G._layers[lid][\"vertices\"].update(G._layers[\"Healthy\"][\"vertices\"]) In\u00a0[5]: Copied! <pre># ---------- Build PPI edges in all layers ----------\nimport random\n\ndef rand_weight(base=1.0, jitter=0.5):\n    return max(0.05, base + (random.random() - 0.5) * 2 * jitter)\n\nppis = []\nfor _ in range(320):\n    u, v = random.sample(proteins, 2)\n    w = rand_weight(1.2, 0.6)\n    e = G.add_edge(u, v, layer=\"Healthy\", weight=w, edge_directed=False)\n    ppis.append(e)\n\n# Stress/disease layer variants (override per-layer weights)\nfor eid in ppis:\n    # Stressed: mostly +10% with jitter\n    G.add_edge_to_layer(\"Stressed\", eid)\n    G.set_edge_layer_attrs(\"Stressed\", eid, weight=G.edge_weights[eid] * rand_weight(1.10, 0.1))\n    # Disease: some edges get weaker; others stronger\n    G.add_edge_to_layer(\"Disease\", eid)\n    factor = 0.7 if random.random() &lt; 0.4 else 1.3\n    G.set_edge_layer_attrs(\"Disease\", eid, weight=G.edge_weights[eid] * rand_weight(factor, 0.15))\n</pre> # ---------- Build PPI edges in all layers ---------- import random  def rand_weight(base=1.0, jitter=0.5):     return max(0.05, base + (random.random() - 0.5) * 2 * jitter)  ppis = [] for _ in range(320):     u, v = random.sample(proteins, 2)     w = rand_weight(1.2, 0.6)     e = G.add_edge(u, v, layer=\"Healthy\", weight=w, edge_directed=False)     ppis.append(e)  # Stress/disease layer variants (override per-layer weights) for eid in ppis:     # Stressed: mostly +10% with jitter     G.add_edge_to_layer(\"Stressed\", eid)     G.set_edge_layer_attrs(\"Stressed\", eid, weight=G.edge_weights[eid] * rand_weight(1.10, 0.1))     # Disease: some edges get weaker; others stronger     G.add_edge_to_layer(\"Disease\", eid)     factor = 0.7 if random.random() &lt; 0.4 else 1.3     G.set_edge_layer_attrs(\"Disease\", eid, weight=G.edge_weights[eid] * rand_weight(factor, 0.15)) In\u00a0[7]: Copied! <pre># ---------- Complexes as undirected hyperedges ----------\ncomplexes = []\nfor _ in range(12):\n    members = set(random.sample(proteins, random.choice([3, 4, 5])))\n    hid = G.add_hyperedge(members=members, layer=\"Healthy\", weight=rand_weight(1.0, 0.2))\n    complexes.append(hid)\n    # complex exists in all layers (same membership)\n    for lid in [\"Stressed\", \"Disease\"]:\n        G.add_edge_to_layer(lid, hid)\n</pre> # ---------- Complexes as undirected hyperedges ---------- complexes = [] for _ in range(12):     members = set(random.sample(proteins, random.choice([3, 4, 5])))     hid = G.add_hyperedge(members=members, layer=\"Healthy\", weight=rand_weight(1.0, 0.2))     complexes.append(hid)     # complex exists in all layers (same membership)     for lid in [\"Stressed\", \"Disease\"]:         G.add_edge_to_layer(lid, hid) In\u00a0[9]: Copied! <pre># ---------- Directed signaling cascades as hyperedges ----------\ncascades = []\nwhile len(cascades) &lt; 8:\n    head = set(random.sample(proteins, random.choice([1, 2])))\n    tail = set(random.sample(proteins, random.choice([2, 3, 4])))\n    if head &amp; tail:\n        continue  # resample until disjoint\n    hid = G.add_hyperedge(head=head, tail=tail, layer=\"Healthy\", weight=rand_weight(1.0, 0.4))\n    cascades.append(hid)\n    for lid in [\"Stressed\", \"Disease\"]:\n        G.add_edge_to_layer(lid, hid)\n</pre> # ---------- Directed signaling cascades as hyperedges ---------- cascades = [] while len(cascades) &lt; 8:     head = set(random.sample(proteins, random.choice([1, 2])))     tail = set(random.sample(proteins, random.choice([2, 3, 4])))     if head &amp; tail:         continue  # resample until disjoint     hid = G.add_hyperedge(head=head, tail=tail, layer=\"Healthy\", weight=rand_weight(1.0, 0.4))     cascades.append(hid)     for lid in [\"Stressed\", \"Disease\"]:         G.add_edge_to_layer(lid, hid) In\u00a0[11]: Copied! <pre># ---------- Reactions connecting vertices to edge-entities ----------\nfor ee in enz_edge_entities:\n    s, t = random.sample(proteins, 2)\n    G.add_edge(s, ee, layer=\"Healthy\", edge_type=\"vertex_edge\", weight=1.0 + random.random())\n    G.add_edge(ee, t, layer=\"Healthy\", edge_type=\"vertex_edge\", weight=1.0 + random.random())\n    # propagate across layers\n    for lid in [\"Stressed\", \"Disease\"]:\n        G._layers[lid][\"edges\"].update(G._layers[\"Healthy\"][\"edges\"])\n</pre> # ---------- Reactions connecting vertices to edge-entities ---------- for ee in enz_edge_entities:     s, t = random.sample(proteins, 2)     G.add_edge(s, ee, layer=\"Healthy\", edge_type=\"vertex_edge\", weight=1.0 + random.random())     G.add_edge(ee, t, layer=\"Healthy\", edge_type=\"vertex_edge\", weight=1.0 + random.random())     # propagate across layers     for lid in [\"Stressed\", \"Disease\"]:         G._layers[lid][\"edges\"].update(G._layers[\"Healthy\"][\"edges\"]) In\u00a0[13]: Copied! <pre># ---------- Basic sanity ----------\nprint(\"vertices:\", G.number_of_vertices(), \"Edges:\", G.number_of_edges())\n\n# Only true \"vertices\" are counted by number_of_vertices() (proteins + transcripts)\nexpected_vertices = len(set(proteins)) + len(set(transcripts))  # 150 + 60 = 210\nassert G.number_of_vertices() &gt;= expected_vertices, f\"Expected \u2265{expected_vertices}, got {G.number_of_vertices()}\"\n\n# Edge-entities are tracked as entity_type == 'edge' (not included in number_of_vertices)\nedge_entity_ids = set(enz_edge_entities)\nedge_entity_count = sum(1 for _id, et in G.entity_types.items() if et == \"edge\" and _id in edge_entity_ids)\nassert edge_entity_count == len(edge_entity_ids), f\"Expected {len(edge_entity_ids)} edge-entities, got {edge_entity_count}\"\n\n# Edges: PPIs (320) + complexes (12) + cascades (8) + reaction links (10*2) = 360 minimum\nassert G.number_of_edges() &gt;= 320 + 12 + 8 + (10 * 2)\n</pre> # ---------- Basic sanity ---------- print(\"vertices:\", G.number_of_vertices(), \"Edges:\", G.number_of_edges())  # Only true \"vertices\" are counted by number_of_vertices() (proteins + transcripts) expected_vertices = len(set(proteins)) + len(set(transcripts))  # 150 + 60 = 210 assert G.number_of_vertices() &gt;= expected_vertices, f\"Expected \u2265{expected_vertices}, got {G.number_of_vertices()}\"  # Edge-entities are tracked as entity_type == 'edge' (not included in number_of_vertices) edge_entity_ids = set(enz_edge_entities) edge_entity_count = sum(1 for _id, et in G.entity_types.items() if et == \"edge\" and _id in edge_entity_ids) assert edge_entity_count == len(edge_entity_ids), f\"Expected {len(edge_entity_ids)} edge-entities, got {edge_entity_count}\"  # Edges: PPIs (320) + complexes (12) + cascades (8) + reaction links (10*2) = 360 minimum assert G.number_of_edges() &gt;= 320 + 12 + 8 + (10 * 2)  <pre>vertices: 210 Edges: 360\n</pre> In\u00a0[15]: Copied! <pre># ---------- Views &amp; top edges by condition ----------\nimport polars as pl\n\nfor cond in conditions:\n    EV = G.edges_view(layer=cond, resolved_weight=True)\n    print(f\"[{cond}] edges_view rows =\", EV.height)\n    top = (\n        EV\n        .filter(pl.col(\"kind\") == \"binary\")\n        .sort(\"effective_weight\", descending=True)\n        .select([\"edge_id\", \"source\", \"target\", \"effective_weight\"])\n        .head(5)\n    )\n    print(f\"\\nTop 5 binary edges by effective_weight in {cond}:\")\n    print(top)\n</pre> # ---------- Views &amp; top edges by condition ---------- import polars as pl  for cond in conditions:     EV = G.edges_view(layer=cond, resolved_weight=True)     print(f\"[{cond}] edges_view rows =\", EV.height)     top = (         EV         .filter(pl.col(\"kind\") == \"binary\")         .sort(\"effective_weight\", descending=True)         .select([\"edge_id\", \"source\", \"target\", \"effective_weight\"])         .head(5)     )     print(f\"\\nTop 5 binary edges by effective_weight in {cond}:\")     print(top) <pre>[Healthy] edges_view rows = 360\n\nTop 5 binary edges by effective_weight in Healthy:\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id  \u2506 source \u2506 target      \u2506 effective_weight \u2502\n\u2502 ---      \u2506 ---    \u2506 ---         \u2506 ---              \u2502\n\u2502 str      \u2506 str    \u2506 str         \u2506 f64              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_356 \u2506 P114   \u2506 edge_rxn_9  \u2506 1.931019         \u2502\n\u2502 edge_342 \u2506 P43    \u2506 edge_rxn_2  \u2506 1.859952         \u2502\n\u2502 edge_358 \u2506 P4     \u2506 edge_rxn_10 \u2506 1.810736         \u2502\n\u2502 edge_36  \u2506 P71    \u2506 P79         \u2506 1.796444         \u2502\n\u2502 edge_86  \u2506 P15    \u2506 P27         \u2506 1.79025          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n[Stressed] edges_view rows = 360\n\nTop 5 binary edges by effective_weight in Stressed:\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id  \u2506 source \u2506 target \u2506 effective_weight \u2502\n\u2502 ---      \u2506 ---    \u2506 ---    \u2506 ---              \u2502\n\u2502 str      \u2506 str    \u2506 str    \u2506 f64              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_21  \u2506 P16    \u2506 P47    \u2506 2.098962         \u2502\n\u2502 edge_259 \u2506 P64    \u2506 P50    \u2506 2.03543          \u2502\n\u2502 edge_102 \u2506 P47    \u2506 P90    \u2506 2.004251         \u2502\n\u2502 edge_173 \u2506 P27    \u2506 P23    \u2506 1.995561         \u2502\n\u2502 edge_308 \u2506 P7     \u2506 P15    \u2506 1.989736         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n[Disease] edges_view rows = 360\n\nTop 5 binary edges by effective_weight in Disease:\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id  \u2506 source \u2506 target \u2506 effective_weight \u2502\n\u2502 ---      \u2506 ---    \u2506 ---    \u2506 ---              \u2502\n\u2502 str      \u2506 str    \u2506 str    \u2506 f64              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_140 \u2506 P31    \u2506 P123   \u2506 2.528918         \u2502\n\u2502 edge_163 \u2506 P115   \u2506 P121   \u2506 2.521661         \u2502\n\u2502 edge_308 \u2506 P7     \u2506 P15    \u2506 2.454858         \u2502\n\u2502 edge_15  \u2506 P139   \u2506 P57    \u2506 2.413417         \u2502\n\u2502 edge_149 \u2506 P30    \u2506 P76    \u2506 2.402707         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[17]: Copied! <pre># ---------- Layer analytics ----------\nstats = G.layer_statistics()\nprint(\"\\nLayer stats:\", stats)\n\nconserved = G.conserved_edges(min_layers=3)  # present in all 3 conditions\nprint(\"\\nConserved edges (in all conditions):\", len(conserved))\n\ndisease_specific = G.layer_specific_edges(\"Disease\")\nprint(\"Disease-specific edges:\", len(disease_specific))\n\nchanges = G.temporal_dynamics([\"Healthy\", \"Stressed\", \"Disease\"], metric=\"edge_change\")\nprint(\"\\nTemporal edge changes (Healthy\u2192Stressed\u2192Disease):\", changes)\nassert len(changes) == 2\n</pre> # ---------- Layer analytics ---------- stats = G.layer_statistics() print(\"\\nLayer stats:\", stats)  conserved = G.conserved_edges(min_layers=3)  # present in all 3 conditions print(\"\\nConserved edges (in all conditions):\", len(conserved))  disease_specific = G.layer_specific_edges(\"Disease\") print(\"Disease-specific edges:\", len(disease_specific))  changes = G.temporal_dynamics([\"Healthy\", \"Stressed\", \"Disease\"], metric=\"edge_change\") print(\"\\nTemporal edge changes (Healthy\u2192Stressed\u2192Disease):\", changes) assert len(changes) == 2 <pre>\nLayer stats: {'Healthy': {'vertices': 220, 'edges': 360, 'attributes': {'condition': 'Healthy'}}, 'Stressed': {'vertices': 220, 'edges': 360, 'attributes': {'condition': 'Stressed'}}, 'Disease': {'vertices': 220, 'edges': 360, 'attributes': {'condition': 'Disease'}}}\n\nConserved edges (in all conditions): 360\nDisease-specific edges: 0\n\nTemporal edge changes (Healthy\u2192Stressed\u2192Disease): [{'added': 0, 'removed': 0, 'net_change': 0}, {'added': 0, 'removed': 0, 'net_change': 0}]\n</pre> In\u00a0[19]: Copied! <pre># ---------- Presence queries ----------\nsome_e = next(iter(G.edge_to_idx.keys()))\nprint(\"\\nEdge presence for\", some_e, \":\", G.edge_presence_across_layers(edge_id=some_e))\nsome_p = random.choice(proteins)\nprint(\"vertex presence for\", some_p, \":\", G.vertex_presence_across_layers(some_p))\n</pre> # ---------- Presence queries ---------- some_e = next(iter(G.edge_to_idx.keys())) print(\"\\nEdge presence for\", some_e, \":\", G.edge_presence_across_layers(edge_id=some_e)) some_p = random.choice(proteins) print(\"vertex presence for\", some_p, \":\", G.vertex_presence_across_layers(some_p)) <pre>\nEdge presence for edge_0 : ['Healthy', 'Stressed', 'Disease']\nvertex presence for P62 : ['Healthy', 'Stressed', 'Disease']\n</pre> In\u00a0[21]: Copied! <pre># ---------- Traversal checks ----------\nq = random.choice(proteins)\nprint(f\"\\nNeighbors({q}) =&gt;\", G.neighbors(q)[:10])\nprint(f\"Out({q}) =&gt;\", G.out_neighbors(q)[:10])\nprint(f\"In({q}) =&gt;\", G.in_neighbors(q)[:10])\n</pre> # ---------- Traversal checks ---------- q = random.choice(proteins) print(f\"\\nNeighbors({q}) =&gt;\", G.neighbors(q)[:10]) print(f\"Out({q}) =&gt;\", G.out_neighbors(q)[:10]) print(f\"In({q}) =&gt;\", G.in_neighbors(q)[:10]) <pre>\nNeighbors(P64) =&gt; ['P130', 'P28', 'P113', 'P50', 'P12', 'P149', 'P31']\nOut(P64) =&gt; ['P130', 'P28', 'P113', 'P50', 'P12', 'P149', 'P31']\nIn(P64) =&gt; ['P130', 'P28', 'P113', 'P50', 'P12', 'P149', 'P31']\n</pre> In\u00a0[23]: Copied! <pre># ---------- Subgraph slice &amp; copy ----------\nH = G.subgraph_from_layer(\"Disease\", resolve_layer_weights=True)\n#assert set(H.vertices()).issubset(set(G.vertices()))\nassert set(H.edges()).issubset(set(G.edges()))\nprint(\"\\nDisease subgraph: vertices =\", H.number_of_vertices(), \"edges =\", H.number_of_edges())\n\nK = G.copy()\nassert set(K.vertices()) == set(G.vertices())\nassert set(K.edges()) == set(G.edges())\n# hyperedge shape preserved\nany_hyper = next(e for e,k in G.edge_kind.items() if k == \"hyper\")\nassert K.edge_kind.get(any_hyper) == \"hyper\"\n# layer sets preserved\nfor lid in G.list_layers(include_default=True):\n    assert K._layers[lid][\"vertices\"] == G._layers[lid][\"vertices\"]\n    assert K._layers[lid][\"edges\"] == G._layers[lid][\"edges\"]\nprint(\"copy() OK\")\n</pre> # ---------- Subgraph slice &amp; copy ---------- H = G.subgraph_from_layer(\"Disease\", resolve_layer_weights=True) #assert set(H.vertices()).issubset(set(G.vertices())) assert set(H.edges()).issubset(set(G.edges())) print(\"\\nDisease subgraph: vertices =\", H.number_of_vertices(), \"edges =\", H.number_of_edges())  K = G.copy() assert set(K.vertices()) == set(G.vertices()) assert set(K.edges()) == set(G.edges()) # hyperedge shape preserved any_hyper = next(e for e,k in G.edge_kind.items() if k == \"hyper\") assert K.edge_kind.get(any_hyper) == \"hyper\" # layer sets preserved for lid in G.list_layers(include_default=True):     assert K._layers[lid][\"vertices\"] == G._layers[lid][\"vertices\"]     assert K._layers[lid][\"edges\"] == G._layers[lid][\"edges\"] print(\"copy() OK\") <pre>\nDisease subgraph: vertices = 220 edges = 360\ncopy() OK\n</pre> In\u00a0[25]: Copied! <pre># ---------- Remove operations stress ----------\nto_drop_vertices = random.sample(proteins, 5)\nfor n in to_drop_vertices:\n    if n in G.entity_to_idx:\n        G.remove_vertex(n)\nprint(\"\\nAfter removing 5 proteins: vertices =\", G.number_of_vertices(), \"edges =\", G.number_of_edges())\n\nto_drop_edges = list(G.edge_to_idx.keys())[:10]\nfor eid in to_drop_edges:\n    if eid in G.edge_to_idx:\n        G.remove_edge(eid)\nprint(\"After removing 10 edges: vertices =\", G.number_of_vertices(), \"edges =\", G.number_of_edges())\n</pre> # ---------- Remove operations stress ---------- to_drop_vertices = random.sample(proteins, 5) for n in to_drop_vertices:     if n in G.entity_to_idx:         G.remove_vertex(n) print(\"\\nAfter removing 5 proteins: vertices =\", G.number_of_vertices(), \"edges =\", G.number_of_edges())  to_drop_edges = list(G.edge_to_idx.keys())[:10] for eid in to_drop_edges:     if eid in G.edge_to_idx:         G.remove_edge(eid) print(\"After removing 10 edges: vertices =\", G.number_of_vertices(), \"edges =\", G.number_of_edges()) <pre>\nAfter removing 5 proteins: vertices = 205 edges = 330\nAfter removing 10 edges: vertices = 205 edges = 320\n</pre> In\u00a0[27]: Copied! <pre># ---------- Audit &amp; memory ----------\naudit = G.audit_attributes()\nprint(\"\\nAudit:\", audit)\nmem_bytes = G.memory_usage()\nprint(\"Approx memory usage (bytes):\", int(mem_bytes))\nassert mem_bytes &gt; 0\n\nprint(\"\\nReality-check finished \u2705\")\n</pre> # ---------- Audit &amp; memory ---------- audit = G.audit_attributes() print(\"\\nAudit:\", audit) mem_bytes = G.memory_usage() print(\"Approx memory usage (bytes):\", int(mem_bytes)) assert mem_bytes &gt; 0  print(\"\\nReality-check finished \u2705\") <pre>\nAudit: {'extra_vertex_rows': ['edge_rxn_10', 'edge_rxn_4', 'edge_rxn_6', 'edge_rxn_2', 'edge_rxn_3', 'edge_rxn_1', 'edge_rxn_8', 'edge_rxn_7', 'edge_rxn_9', 'edge_rxn_5'], 'extra_edge_rows': [], 'missing_vertex_rows': [], 'missing_edge_rows': ['edge_235', 'edge_206', 'edge_282', 'edge_357', 'edge_99', 'edge_247', 'edge_348', 'edge_283', 'edge_269', 'edge_159', 'edge_62', 'edge_152', 'edge_207', 'edge_160', 'edge_327', 'edge_56', 'edge_285', 'edge_37', 'edge_298', 'edge_42', 'edge_74', 'edge_291', 'edge_135', 'edge_252', 'edge_140', 'edge_80', 'edge_25', 'edge_127', 'edge_300', 'edge_307', 'edge_122', 'edge_166', 'edge_173', 'edge_198', 'edge_281', 'edge_216', 'edge_299', 'edge_57', 'edge_26', 'edge_45', 'edge_179', 'edge_197', 'edge_287', 'edge_94', 'edge_264', 'edge_257', 'edge_273', 'edge_22', 'edge_83', 'edge_176', 'edge_212', 'edge_108', 'edge_305', 'edge_133', 'edge_237', 'edge_275', 'edge_338', 'edge_219', 'edge_213', 'edge_261', 'edge_254', 'edge_321', 'edge_218', 'edge_358', 'edge_346', 'edge_14', 'edge_279', 'edge_335', 'edge_82', 'edge_119', 'edge_353', 'edge_230', 'edge_125', 'edge_245', 'edge_296', 'edge_78', 'edge_342', 'edge_326', 'edge_156', 'edge_113', 'edge_193', 'edge_75', 'edge_88', 'edge_147', 'edge_53', 'edge_70', 'edge_170', 'edge_318', 'edge_51', 'edge_63', 'edge_228', 'edge_293', 'edge_249', 'edge_46', 'edge_191', 'edge_272', 'edge_142', 'edge_171', 'edge_117', 'edge_199', 'edge_255', 'edge_130', 'edge_123', 'edge_354', 'edge_67', 'edge_52', 'edge_120', 'edge_227', 'edge_221', 'edge_72', 'edge_328', 'edge_59', 'edge_270', 'edge_315', 'edge_139', 'edge_29', 'edge_286', 'edge_217', 'edge_301', 'edge_109', 'edge_351', 'edge_284', 'edge_178', 'edge_190', 'edge_102', 'edge_180', 'edge_325', 'edge_332', 'edge_149', 'edge_317', 'edge_222', 'edge_40', 'edge_350', 'edge_215', 'edge_85', 'edge_106', 'edge_194', 'edge_47', 'edge_274', 'edge_153', 'edge_242', 'edge_91', 'edge_238', 'edge_17', 'edge_174', 'edge_186', 'edge_144', 'edge_19', 'edge_169', 'edge_12', 'edge_331', 'edge_165', 'edge_138', 'edge_54', 'edge_267', 'edge_168', 'edge_202', 'edge_92', 'edge_288', 'edge_31', 'edge_131', 'edge_200', 'edge_209', 'edge_201', 'edge_34', 'edge_329', 'edge_98', 'edge_161', 'edge_38', 'edge_107', 'edge_104', 'edge_141', 'edge_308', 'edge_359', 'edge_195', 'edge_241', 'edge_44', 'edge_349', 'edge_27', 'edge_89', 'edge_116', 'edge_234', 'edge_128', 'edge_60', 'edge_114', 'edge_246', 'edge_110', 'edge_355', 'edge_231', 'edge_250', 'edge_192', 'edge_263', 'edge_196', 'edge_124', 'edge_312', 'edge_240', 'edge_289', 'edge_306', 'edge_145', 'edge_243', 'edge_35', 'edge_100', 'edge_172', 'edge_292', 'edge_66', 'edge_84', 'edge_96', 'edge_162', 'edge_163', 'edge_184', 'edge_65', 'edge_334', 'edge_15', 'edge_151', 'edge_340', 'edge_290', 'edge_294', 'edge_223', 'edge_256', 'edge_36', 'edge_77', 'edge_345', 'edge_336', 'edge_129', 'edge_187', 'edge_32', 'edge_232', 'edge_103', 'edge_111', 'edge_132', 'edge_183', 'edge_13', 'edge_304', 'edge_164', 'edge_175', 'edge_266', 'edge_21', 'edge_302', 'edge_320', 'edge_347', 'edge_150', 'edge_118', 'edge_337', 'edge_177', 'edge_343', 'edge_310', 'edge_313', 'edge_314', 'edge_79', 'edge_344', 'edge_90', 'edge_137', 'edge_181', 'edge_214', 'edge_277', 'edge_280', 'edge_271', 'edge_121', 'edge_28', 'edge_86', 'edge_203', 'edge_158', 'edge_136', 'edge_167', 'edge_220', 'edge_295', 'edge_259', 'edge_71', 'edge_204', 'edge_41', 'edge_39', 'edge_24', 'edge_49', 'edge_356', 'edge_95', 'edge_143', 'edge_316', 'edge_309', 'edge_339', 'edge_69', 'edge_268', 'edge_210', 'edge_185', 'edge_58', 'edge_146', 'edge_154', 'edge_157', 'edge_330', 'edge_253', 'edge_155', 'edge_20', 'edge_244', 'edge_81', 'edge_311', 'edge_188', 'edge_148', 'edge_324', 'edge_134', 'edge_205', 'edge_258', 'edge_16', 'edge_64', 'edge_115', 'edge_211', 'edge_30', 'edge_226', 'edge_43', 'edge_276', 'edge_18', 'edge_189', 'edge_55', 'edge_73', 'edge_23', 'edge_352', 'edge_236', 'edge_251', 'edge_278', 'edge_229', 'edge_341', 'edge_50'], 'invalid_edge_layer_rows': []}\nApprox memory usage (bytes): 95006\n\nReality-check finished \u2705\n</pre> In\u00a0[29]: Copied! <pre>events = G.history()           # list[dict]\ndf = G.history(as_df=True)     # Polars DF [DataFrame]\n</pre> events = G.history()           # list[dict] df = G.history(as_df=True)     # Polars DF [DataFrame] In\u00a0[31]: Copied! <pre>print(df.head())\nevents[:3]\n</pre> print(df.head()) events[:3] <pre>shape: (5, 10)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 version \u2506 ts_utc                      \u2506 mono_ns \u2506 op              \u2506 \u2026 \u2506 result \u2506 vertex_id \u2506 layer   \u2506 attributes \u2502\n\u2502 ---     \u2506 ---                         \u2506 ---     \u2506 ---             \u2506   \u2506 ---    \u2506 ---       \u2506 ---     \u2506 ---        \u2502\n\u2502 i64     \u2506 str                         \u2506 i64     \u2506 str             \u2506   \u2506 str    \u2506 str       \u2506 str     \u2506 struct[1]  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1       \u2506 2025-10-14T23:13:25.833774Z \u2506 2214900 \u2506 set_layer_attrs \u2506 \u2026 \u2506 null   \u2506 null      \u2506 null    \u2506 null       \u2502\n\u2502 2       \u2506 2025-10-14T23:13:25.833774Z \u2506 2321100 \u2506 set_layer_attrs \u2506 \u2026 \u2506 null   \u2506 null      \u2506 null    \u2506 null       \u2502\n\u2502 3       \u2506 2025-10-14T23:13:25.833774Z \u2506 2396300 \u2506 set_layer_attrs \u2506 \u2026 \u2506 null   \u2506 null      \u2506 null    \u2506 null       \u2502\n\u2502 4       \u2506 2025-10-14T23:13:25.835815Z \u2506 3708600 \u2506 add_vertex      \u2506 \u2026 \u2506 P1     \u2506 P1        \u2506 Healthy \u2506 {\"kinase\"} \u2502\n\u2502 5       \u2506 2025-10-14T23:13:25.835815Z \u2506 4067700 \u2506 add_vertex      \u2506 \u2026 \u2506 P2     \u2506 P2        \u2506 Healthy \u2506 {\"kinase\"} \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> Out[31]: <pre>[{'version': 1,\n  'ts_utc': '2025-10-14T23:13:25.833774Z',\n  'mono_ns': 2214900,\n  'op': 'set_layer_attrs',\n  'layer_id': 'Healthy',\n  'attrs': {'condition': 'Healthy'},\n  'result': None},\n {'version': 2,\n  'ts_utc': '2025-10-14T23:13:25.833774Z',\n  'mono_ns': 2321100,\n  'op': 'set_layer_attrs',\n  'layer_id': 'Stressed',\n  'attrs': {'condition': 'Stressed'},\n  'result': None},\n {'version': 3,\n  'ts_utc': '2025-10-14T23:13:25.833774Z',\n  'mono_ns': 2396300,\n  'op': 'set_layer_attrs',\n  'layer_id': 'Disease',\n  'attrs': {'condition': 'Disease'},\n  'result': None}]</pre> In\u00a0[33]: Copied! <pre>import sys, pathlib\n\n# add repo root to Python path\nsys.path.append(str(pathlib.Path.cwd().parent))\nfrom graphglue.io import csv as graph_csv\n</pre> import sys, pathlib  # add repo root to Python path sys.path.append(str(pathlib.Path.cwd().parent)) from graphglue.io import csv as graph_csv In\u00a0[35]: Copied! <pre>csv1_path = \"csv1_edges.csv\"\npl.DataFrame({\n    \"source\": [\"A\",\"A\",\"B\",\"C\",\"D\"],\n    \"target\": [\"B\",\"C\",\"C\",\"D\",\"A\"],\n    \"weight\": [1, 2, 3, 1, 5],\n    \"directed\": [True, True, False, True, True],\n    \"layer\": [\"L1\",\"L1\",\"L1\",\"L2\",\"L2\"],\n}) #.write_csv(csv1_path)\n\n#pl.read_csv(csv1_path).head()\n</pre> csv1_path = \"csv1_edges.csv\" pl.DataFrame({     \"source\": [\"A\",\"A\",\"B\",\"C\",\"D\"],     \"target\": [\"B\",\"C\",\"C\",\"D\",\"A\"],     \"weight\": [1, 2, 3, 1, 5],     \"directed\": [True, True, False, True, True],     \"layer\": [\"L1\",\"L1\",\"L1\",\"L2\",\"L2\"], }) #.write_csv(csv1_path)  #pl.read_csv(csv1_path).head()  Out[35]: shape: (5, 5)sourcetargetweightdirectedlayerstrstri64boolstr\"A\"\"B\"1true\"L1\"\"A\"\"C\"2true\"L1\"\"B\"\"C\"3false\"L1\"\"C\"\"D\"1true\"L2\"\"D\"\"A\"5true\"L2\" In\u00a0[37]: Copied! <pre>\"\"\"G = graph_csv.load_csv_to_graph(\n    csv1_path,\n    schema=\"auto\",            # or 'edge_list'/'incidence'/'adjacency'/'hyperedge'/'lil'\n    default_layer=None,       # fallback if no layer column is present\n    default_directed=None,    # fallback if no directed column and cannot infer\n    default_weight=1.0,\n)\n\n# Quick sanity: show first rows of an edges view (columns depend on your Graph implementation)\nedges = G.edges_view(layer=None, include_directed=True, resolved_weight=True)\nedges.head()\n\"\"\"\n</pre> \"\"\"G = graph_csv.load_csv_to_graph(     csv1_path,     schema=\"auto\",            # or 'edge_list'/'incidence'/'adjacency'/'hyperedge'/'lil'     default_layer=None,       # fallback if no layer column is present     default_directed=None,    # fallback if no directed column and cannot infer     default_weight=1.0, )  # Quick sanity: show first rows of an edges view (columns depend on your Graph implementation) edges = G.edges_view(layer=None, include_directed=True, resolved_weight=True) edges.head() \"\"\" Out[37]: <pre>'G = graph_csv.load_csv_to_graph(\\n    csv1_path,\\n    schema=\"auto\",            # or \\'edge_list\\'/\\'incidence\\'/\\'adjacency\\'/\\'hyperedge\\'/\\'lil\\'\\n    default_layer=None,       # fallback if no layer column is present\\n    default_directed=None,    # fallback if no directed column and cannot infer\\n    default_weight=1.0,\\n)\\n\\n# Quick sanity: show first rows of an edges view (columns depend on your Graph implementation)\\nedges = G.edges_view(layer=None, include_directed=True, resolved_weight=True)\\nedges.head()\\n'</pre> In\u00a0[39]: Copied! <pre># Count entities and edges (attribute names based on your class; adjust if different)\nnum_entities = G.global_entity_count        # vertices + edge-entities\nnum_edges    = G.global_edge_count          # binary + hyper\n\nprint(\"entities:\", num_entities, \"edges:\", num_edges)\n\n# A light \u201cdegree\u201d summary from edges_view for binary edges only (skip hyper)\ndf = G.edges_view(include_directed=True, resolved_weight=True)\n\n# Try to find endpoint column names robustly\ncols = {c.lower(): c for c in df.columns}\n# Common possibilities:\nsrc_col = next((cols[c] for c in [\"source\",\"src\",\"u\",\"from\"]), None)\ndst_col = next((cols[c] for c in [\"target\",\"dst\",\"v\",\"to\"]), None)\n\nif src_col and dst_col:\n    # out-degree (directed) / degree (undirected)\n    out_deg = df.group_by(src_col).len().rename({src_col: \"vertex\", \"len\": \"out_degree\"})\n    in_deg  = df.group_by(dst_col).len().rename({dst_col: \"vertex\", \"len\": \"in_degree\"})\n    deg = out_deg.join(in_deg, on=\"vertex\", how=\"outer\").fill_null(0)\n    deg = deg.with_columns((pl.col(\"out_degree\")+pl.col(\"in_degree\")).alias(\"total_degree\"))\n    deg.sort(\"total_degree\", descending=True).head(10)\nelse:\n    print(\"Skip degree summary: endpoint columns not found in edges_view output (likely hyperedge-only or different schema).\")\n</pre> # Count entities and edges (attribute names based on your class; adjust if different) num_entities = G.global_entity_count        # vertices + edge-entities num_edges    = G.global_edge_count          # binary + hyper  print(\"entities:\", num_entities, \"edges:\", num_edges)  # A light \u201cdegree\u201d summary from edges_view for binary edges only (skip hyper) df = G.edges_view(include_directed=True, resolved_weight=True)  # Try to find endpoint column names robustly cols = {c.lower(): c for c in df.columns} # Common possibilities: src_col = next((cols[c] for c in [\"source\",\"src\",\"u\",\"from\"]), None) dst_col = next((cols[c] for c in [\"target\",\"dst\",\"v\",\"to\"]), None)  if src_col and dst_col:     # out-degree (directed) / degree (undirected)     out_deg = df.group_by(src_col).len().rename({src_col: \"vertex\", \"len\": \"out_degree\"})     in_deg  = df.group_by(dst_col).len().rename({dst_col: \"vertex\", \"len\": \"in_degree\"})     deg = out_deg.join(in_deg, on=\"vertex\", how=\"outer\").fill_null(0)     deg = deg.with_columns((pl.col(\"out_degree\")+pl.col(\"in_degree\")).alias(\"total_degree\"))     deg.sort(\"total_degree\", descending=True).head(10) else:     print(\"Skip degree summary: endpoint columns not found in edges_view output (likely hyperedge-only or different schema).\")  <pre>entities: &lt;bound method Graph.global_entity_count of &lt;graphglue.core.graph.Graph object at 0x000001D6C90D2360&gt;&gt; edges: &lt;bound method Graph.global_edge_count of &lt;graphglue.core.graph.Graph object at 0x000001D6C90D2360&gt;&gt;\n</pre> <pre>C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_20548\\2468729116.py:20: DeprecationWarning: use of `how='outer'` should be replaced with `how='full'`.\n(Deprecated in version 0.20.29)\n  deg = out_deg.join(in_deg, on=\"vertex\", how=\"outer\").fill_null(0)\n</pre> In\u00a0[41]: Copied! <pre># Add a new vertex and an edge on layer L3\nG.add_vertex(\"E\")\neid = G.add_edge(\"E\", \"A\", layer=\"L3\", directed=True, weight=2.5)\n\n# Per-layer weight override example:\nG.set_edge_layer_attrs(\"L3\", eid, weight=3.0)\n\n# Inspect the updated edges\nG.edges_view(include_directed=True, resolved_weight=True).tail()\n</pre> # Add a new vertex and an edge on layer L3 G.add_vertex(\"E\") eid = G.add_edge(\"E\", \"A\", layer=\"L3\", directed=True, weight=2.5)  # Per-layer weight override example: G.set_edge_layer_attrs(\"L3\", eid, weight=3.0)  # Inspect the updated edges G.edges_view(include_directed=True, resolved_weight=True).tail()  Out[41]: shape: (5, 11)edge_idkinddirectedglobal_weightsourcetargetedge_typeheadtailmemberseffective_weightstrstrboolf64strstrstrlist[str]list[str]list[str]f64\"edge_356\"\"binary\"true1.931019\"P114\"\"edge_rxn_9\"\"vertex_edge\"nullnullnull1.931019\"edge_357\"\"binary\"true1.671693\"edge_rxn_9\"\"P80\"\"vertex_edge\"nullnullnull1.671693\"edge_358\"\"binary\"true1.810736\"P4\"\"edge_rxn_10\"\"vertex_edge\"nullnullnull1.810736\"edge_359\"\"binary\"true1.129537\"edge_rxn_10\"\"P131\"\"vertex_edge\"nullnullnull1.129537\"edge_360\"\"binary\"true2.5\"E\"\"A\"\"regular\"nullnullnull2.5 In\u00a0[43]: Copied! <pre>csv2_path = \"csv2_edges_view.csv\"\nG.edges_view(layer=None, include_directed=True, resolved_weight=True)\ncsv2_path\n</pre> csv2_path = \"csv2_edges_view.csv\" G.edges_view(layer=None, include_directed=True, resolved_weight=True) csv2_path  Out[43]: <pre>'csv2_edges_view.csv'</pre> In\u00a0[45]: Copied! <pre>def export_edge_list_csv(G, path, layer=None):\n    df = G.edges_view(layer=layer, include_directed=True, resolved_weight=True)\n    cols = {c.lower(): c for c in df.columns}\n    src_col = next((cols[c] for c in [\"source\",\"src\",\"u\",\"from\"]), None)\n    dst_col = next((cols[c] for c in [\"target\",\"dst\",\"v\",\"to\"]), None)\n    dir_col = next((cols[c] for c in [\"directed\"]), None)\n    w_eff   = next((cols[c] for c in [\"effective_weight\",\"weight\",\"w\"]), None)\n\n    if not (src_col and dst_col):\n        raise ValueError(\"No binary endpoint columns found; the view may be hyperedge-only. Try the generic edges_view export.\")\n\n    out = pl.DataFrame({\n        \"source\": df[src_col],\n        \"target\": df[dst_col],\n        \"weight\": df[w_eff] if w_eff else pl.Series([1.0]*df.height),\n        \"directed\": df[dir_col] if dir_col in df.columns else pl.Series([None]*df.height),\n        \"layer\": pl.Series([layer]*df.height) if layer else pl.Series([None]*df.height),\n    })\n    out #.write_csv(path)\n\n# Usage:\ncsv2_edge_list_path = \"csv2_edge_list.csv\"\nexport_edge_list_csv(G, csv2_edge_list_path, layer=None)\ncsv2_edge_list_path\n</pre> def export_edge_list_csv(G, path, layer=None):     df = G.edges_view(layer=layer, include_directed=True, resolved_weight=True)     cols = {c.lower(): c for c in df.columns}     src_col = next((cols[c] for c in [\"source\",\"src\",\"u\",\"from\"]), None)     dst_col = next((cols[c] for c in [\"target\",\"dst\",\"v\",\"to\"]), None)     dir_col = next((cols[c] for c in [\"directed\"]), None)     w_eff   = next((cols[c] for c in [\"effective_weight\",\"weight\",\"w\"]), None)      if not (src_col and dst_col):         raise ValueError(\"No binary endpoint columns found; the view may be hyperedge-only. Try the generic edges_view export.\")      out = pl.DataFrame({         \"source\": df[src_col],         \"target\": df[dst_col],         \"weight\": df[w_eff] if w_eff else pl.Series([1.0]*df.height),         \"directed\": df[dir_col] if dir_col in df.columns else pl.Series([None]*df.height),         \"layer\": pl.Series([layer]*df.height) if layer else pl.Series([None]*df.height),     })     out #.write_csv(path)  # Usage: csv2_edge_list_path = \"csv2_edge_list.csv\" export_edge_list_csv(G, csv2_edge_list_path, layer=None) csv2_edge_list_path  Out[45]: <pre>'csv2_edge_list.csv'</pre> In\u00a0[47]: Copied! <pre># In-memory look at last few events\nhist = G.history(as_df=True)   # DF [DataFrame]\nhist.tail()\n\n# Save to Parquet/CSV/JSON [JavaScript Object Notation]/NDJSON [Newline-Delimited JSON]\nG.export_history(\"graph_history.parquet\")\n</pre> # In-memory look at last few events hist = G.history(as_df=True)   # DF [DataFrame] hist.tail()  # Save to Parquet/CSV/JSON [JavaScript Object Notation]/NDJSON [Newline-Delimited JSON] G.export_history(\"graph_history.parquet\")  Out[47]: <pre>1283</pre> In\u00a0[49]: Copied! <pre>import sys, pathlib\nsys.path.append(str(pathlib.Path.cwd().parent))\n\nfrom graphglue.io import excel as graph_excel\nfrom graphglue.core.graph import Graph\n</pre> import sys, pathlib sys.path.append(str(pathlib.Path.cwd().parent))  from graphglue.io import excel as graph_excel from graphglue.core.graph import Graph  In\u00a0[51]: Copied! <pre>#G = graph_excel.load_excel_to_graph(\"graph_input.xlsx\", schema=\"auto\")\n</pre> #G = graph_excel.load_excel_to_graph(\"graph_input.xlsx\", schema=\"auto\") In\u00a0[53]: Copied! <pre>G.global_entity_count()\n</pre> G.global_entity_count() Out[53]: <pre>217</pre> In\u00a0[55]: Copied! <pre>from graphglue.adapters.networkx_adapter import to_backend, to_nx, from_nx\n</pre> from graphglue.adapters.networkx_adapter import to_backend, to_nx, from_nx In\u00a0[56]: Copied! <pre>nxG, man = to_nx(G, directed=True, hyperedge_mode=\"skip\")\n</pre> nxG, man = to_nx(G, directed=True, hyperedge_mode=\"skip\") In\u00a0[58]: Copied! <pre>from graphglue.adapters.igraph_adapter import to_backend, to_igraph, from_igraph\n</pre> from graphglue.adapters.igraph_adapter import to_backend, to_igraph, from_igraph In\u00a0[61]: Copied! <pre>nxG, man = to_igraph(G, directed=True, hyperedge_mode=\"skip\", public_only=False)\n</pre> nxG, man = to_igraph(G, directed=True, hyperedge_mode=\"skip\", public_only=False)  In\u00a0[63]: Copied! <pre>G.shape\n</pre> G.shape Out[63]: <pre>(207, 321)</pre> In\u00a0[65]: Copied! <pre># Deterministic smoke tests for the lazy NX (NetworkX) proxy\n\n# ---------- G1: PATH GRAPH (for weighted/unweighted shortest paths) ----------\ndef build_path_graph() -&gt; Graph:\n    \"\"\"\n    Directed chain a\u2192b\u2192c\u2192d\u2192e\u2192f with weights on each edge.\n    - Weighted shortest path a\u2192f = 1+2+3+1+4 = 11\n    - Unweighted hops a\u2192f = 5\n    \"\"\"\n    G = Graph(directed=True)\n    # vertices (+ labels for the label\u2192ID mapping)\n    G.add_vertex(\"a\", name=\"alpha\")\n    G.add_vertex(\"b\", name=\"bravo\")\n    G.add_vertex(\"c\", name=\"charlie\")\n    G.add_vertex(\"d\", name=\"delta\")\n    G.add_vertex(\"e\", name=\"echo\")\n    G.add_vertex(\"f\", name=\"phi\")\n\n    # pure chain (NO chords)\n    G.add_edge(\"a\", \"b\", weight=1)\n    G.add_edge(\"b\", \"c\", weight=2)\n    G.add_edge(\"c\", \"d\", weight=3)\n    G.add_edge(\"d\", \"e\", weight=1)\n    G.add_edge(\"e\", \"f\", weight=4)\n\n    return G\n\n\n# ---------- G2: COMMUNITY GRAPH (two cliques + weak bridge) ----------\ndef build_community_graph() -&gt; Graph:\n    \"\"\"\n    Two undirected cliques: K6 on {a..f} and K4 on {w,x,y,z}, joined by a single weak bridge e--x (weight=0.01).\n    Louvain should give communities of sizes [4,6] (stable with seed); betweenness top in {'e','x'};\n    PR (PageRank) top is 'e' in undirected view (highest degree).\n    \"\"\"\n    G = Graph(directed=True)  # we\u2019ll add undirected edges explicitly\n\n    for v in [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"w\",\"x\",\"y\",\"z\"]:\n        G.add_vertex(v)\n\n    # K6 clique on a..f (undirected, weight=1)\n    k6 = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"]\n    for i in range(len(k6)):\n        for j in range(i+1, len(k6)):\n            G.add_edge(k6[i], k6[j], weight=1, edge_directed=False)\n\n    # K4 clique on w,x,y,z (undirected, weight=1)\n    k4 = [\"w\",\"x\",\"y\",\"z\"]\n    for i in range(len(k4)):\n        for j in range(i+1, len(k4)):\n            G.add_edge(k4[i], k4[j], weight=1, edge_directed=False)\n\n    # Single weak bridge e--x\n    G.add_edge(\"e\", \"x\", weight=0.01, edge_directed=False)\n\n    return G\n\ndef run_tests():\n    # ----- G1: shortest paths -----\n    G1 = build_path_graph()\n\n    # Weighted Dijkstra via labels -&gt; expect 11.0\n    dist_w = G1.nx.shortest_path_length(\n        G1, source=\"alpha\", target=\"phi\", weight=\"weight\", _nx_label_field=\"name\"\n    )\n    print(\"[G1:dijkstra weighted] alpha-&gt;phi:\", dist_w, \"(expect 11.0)\")\n\n    # Unweighted hop count -&gt; expect 5 (a-b-c-d-e-f)\n    dist_hops = G1.nx.shortest_path_length(G1, source=\"a\", target=\"f\", weight=None)\n    print(\"[G1:unweighted hops] a-&gt;f:\", dist_hops, \"(expect 5)\")\n\n    # Cache invalidation: add fast a-&gt;f edge (weight=2) and re-check -&gt; expect 2.0\n    G1.add_edge(\"a\", \"f\", weight=2)\n    dist_new = G1.nx.shortest_path_length(G1, source=\"a\", target=\"f\", weight=\"weight\")\n    print(\"[G1:after mutation] a-&gt;f:\", dist_new, \"(expect 2.0)\")\n\n    # ----- G2: communities / centrality / PR / components -----\n    G2 = build_community_graph()\n\n    # Louvain on undirected view -&gt; expect sizes [4, 6]\n    comms = G2.nx.louvain_communities(G2, _nx_directed=False, seed=42, weight=\"weight\")\n    sizes = sorted(len(c) for c in comms)\n    print(\"[G2:louvain] sizes:\", sizes, \"(expect [4, 6])\")\n\n    # Betweenness centrality (unweighted, undirected) -&gt; bridge endpoints dominate\n    bc = G2.nx.betweenness_centrality(G2, _nx_directed=False, normalized=True)\n    top_bc = max(bc, key=bc.get)\n    print(\"[G2:betweenness] top:\", top_bc, \"(expect 'e' or 'x')\")\n\n    # PageRank (PR) on undirected view (unweighted edges) -&gt; highest degree node is 'e'\n    pr = G2.nx.pagerank(G2, _nx_directed=False)\n    top_pr = max(pr, key=pr.get)\n    print(\"[G2:pagerank] top:\", top_pr, \"(expect 'e')\")\n\n    # Connected components (undirected) -&gt; single component of size 10\n    comps = list(G2.nx.connected_components(G2, _nx_directed=False))\n    print(\"[G2:connected components]:\", [sorted(c) for c in comps], \"(expect one component of size 10)\")\n\n\nif __name__ == \"__main__\":\n    run_tests()\n</pre> # Deterministic smoke tests for the lazy NX (NetworkX) proxy  # ---------- G1: PATH GRAPH (for weighted/unweighted shortest paths) ---------- def build_path_graph() -&gt; Graph:     \"\"\"     Directed chain a\u2192b\u2192c\u2192d\u2192e\u2192f with weights on each edge.     - Weighted shortest path a\u2192f = 1+2+3+1+4 = 11     - Unweighted hops a\u2192f = 5     \"\"\"     G = Graph(directed=True)     # vertices (+ labels for the label\u2192ID mapping)     G.add_vertex(\"a\", name=\"alpha\")     G.add_vertex(\"b\", name=\"bravo\")     G.add_vertex(\"c\", name=\"charlie\")     G.add_vertex(\"d\", name=\"delta\")     G.add_vertex(\"e\", name=\"echo\")     G.add_vertex(\"f\", name=\"phi\")      # pure chain (NO chords)     G.add_edge(\"a\", \"b\", weight=1)     G.add_edge(\"b\", \"c\", weight=2)     G.add_edge(\"c\", \"d\", weight=3)     G.add_edge(\"d\", \"e\", weight=1)     G.add_edge(\"e\", \"f\", weight=4)      return G   # ---------- G2: COMMUNITY GRAPH (two cliques + weak bridge) ---------- def build_community_graph() -&gt; Graph:     \"\"\"     Two undirected cliques: K6 on {a..f} and K4 on {w,x,y,z}, joined by a single weak bridge e--x (weight=0.01).     Louvain should give communities of sizes [4,6] (stable with seed); betweenness top in {'e','x'};     PR (PageRank) top is 'e' in undirected view (highest degree).     \"\"\"     G = Graph(directed=True)  # we\u2019ll add undirected edges explicitly      for v in [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"w\",\"x\",\"y\",\"z\"]:         G.add_vertex(v)      # K6 clique on a..f (undirected, weight=1)     k6 = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"]     for i in range(len(k6)):         for j in range(i+1, len(k6)):             G.add_edge(k6[i], k6[j], weight=1, edge_directed=False)      # K4 clique on w,x,y,z (undirected, weight=1)     k4 = [\"w\",\"x\",\"y\",\"z\"]     for i in range(len(k4)):         for j in range(i+1, len(k4)):             G.add_edge(k4[i], k4[j], weight=1, edge_directed=False)      # Single weak bridge e--x     G.add_edge(\"e\", \"x\", weight=0.01, edge_directed=False)      return G  def run_tests():     # ----- G1: shortest paths -----     G1 = build_path_graph()      # Weighted Dijkstra via labels -&gt; expect 11.0     dist_w = G1.nx.shortest_path_length(         G1, source=\"alpha\", target=\"phi\", weight=\"weight\", _nx_label_field=\"name\"     )     print(\"[G1:dijkstra weighted] alpha-&gt;phi:\", dist_w, \"(expect 11.0)\")      # Unweighted hop count -&gt; expect 5 (a-b-c-d-e-f)     dist_hops = G1.nx.shortest_path_length(G1, source=\"a\", target=\"f\", weight=None)     print(\"[G1:unweighted hops] a-&gt;f:\", dist_hops, \"(expect 5)\")      # Cache invalidation: add fast a-&gt;f edge (weight=2) and re-check -&gt; expect 2.0     G1.add_edge(\"a\", \"f\", weight=2)     dist_new = G1.nx.shortest_path_length(G1, source=\"a\", target=\"f\", weight=\"weight\")     print(\"[G1:after mutation] a-&gt;f:\", dist_new, \"(expect 2.0)\")      # ----- G2: communities / centrality / PR / components -----     G2 = build_community_graph()      # Louvain on undirected view -&gt; expect sizes [4, 6]     comms = G2.nx.louvain_communities(G2, _nx_directed=False, seed=42, weight=\"weight\")     sizes = sorted(len(c) for c in comms)     print(\"[G2:louvain] sizes:\", sizes, \"(expect [4, 6])\")      # Betweenness centrality (unweighted, undirected) -&gt; bridge endpoints dominate     bc = G2.nx.betweenness_centrality(G2, _nx_directed=False, normalized=True)     top_bc = max(bc, key=bc.get)     print(\"[G2:betweenness] top:\", top_bc, \"(expect 'e' or 'x')\")      # PageRank (PR) on undirected view (unweighted edges) -&gt; highest degree node is 'e'     pr = G2.nx.pagerank(G2, _nx_directed=False)     top_pr = max(pr, key=pr.get)     print(\"[G2:pagerank] top:\", top_pr, \"(expect 'e')\")      # Connected components (undirected) -&gt; single component of size 10     comps = list(G2.nx.connected_components(G2, _nx_directed=False))     print(\"[G2:connected components]:\", [sorted(c) for c in comps], \"(expect one component of size 10)\")   if __name__ == \"__main__\":     run_tests()  <pre>[G1:dijkstra weighted] alpha-&gt;phi: 11 (expect 11.0)\n[G1:unweighted hops] a-&gt;f: 5 (expect 5)\n[G1:after mutation] a-&gt;f: 2 (expect 2.0)\n[G2:louvain] sizes: [4, 6] (expect [4, 6])\n[G2:betweenness] top: e (expect 'e' or 'x')\n[G2:pagerank] top: e (expect 'e')\n[G2:connected components]: [['a', 'b', 'c', 'd', 'e', 'f', 'w', 'x', 'y', 'z']] (expect one component of size 10)\n</pre> In\u00a0[67]: Copied! <pre># Deterministic smoke tests for the lazy ig (igraph) proxy\n\nfrom graphglue.core.graph import Graph\n\n# ---------- G1: PATH GRAPH (for weighted/unweighted shortest paths) ----------\ndef build_path_graph() -&gt; Graph:\n    \"\"\"\n    Directed chain a\u2192b\u2192c\u2192d\u2192e\u2192f with weights on each edge.\n    - Weighted shortest path a\u2192f = 1+2+3+1+4 = 11\n    - Unweighted hops a\u2192f = 5\n    \"\"\"\n    G = Graph(directed=True)\n    # vertices (+ labels for the label\u2192ID mapping)\n    G.add_vertex(\"a\", name=\"alpha\")\n    G.add_vertex(\"b\", name=\"bravo\")\n    G.add_vertex(\"c\", name=\"charlie\")\n    G.add_vertex(\"d\", name=\"delta\")\n    G.add_vertex(\"e\", name=\"echo\")\n    G.add_vertex(\"f\", name=\"phi\")\n\n    # pure chain (NO chords)\n    G.add_edge(\"a\", \"b\", weight=1)\n    G.add_edge(\"b\", \"c\", weight=2)\n    G.add_edge(\"c\", \"d\", weight=3)\n    G.add_edge(\"d\", \"e\", weight=1)\n    G.add_edge(\"e\", \"f\", weight=4)\n    return G\n\n\n# ---------- G2: COMMUNITY GRAPH (two cliques + weak bridge) ----------\ndef build_community_graph() -&gt; Graph:\n    \"\"\"\n    Two undirected cliques: K6 on {a..f} and K4 on {w,x,y,z}, joined by a single weak bridge e--x (weight=0.01).\n    multilevel (Louvain-like) should give communities of sizes [4,6] (stable with seed);\n    betweenness top in {'e','x'}; PageRank (PR) top is 'e'.\n    \"\"\"\n    G = Graph(directed=True)  # add undirected edges explicitly\n\n    for v in [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"w\",\"x\",\"y\",\"z\"]:\n        G.add_vertex(v)\n\n    # K6 clique on a..f (undirected, weight=1)\n    k6 = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"]\n    for i in range(len(k6)):\n        for j in range(i + 1, len(k6)):\n            G.add_edge(k6[i], k6[j], weight=1, edge_directed=False)\n\n    # K4 clique on w,x,y,z (undirected, weight=1)\n    k4 = [\"w\",\"x\",\"y\",\"z\"]\n    for i in range(len(k4)):\n        for j in range(i + 1, len(k4)):\n            G.add_edge(k4[i], k4[j], weight=1, edge_directed=False)\n\n    # Single weak bridge e--x\n    G.add_edge(\"e\", \"x\", weight=0.01, edge_directed=False)\n    return G\n\n\n# ---------- helpers ----------\ndef _unwrap_ig_distance(obj):\n    \"\"\"igraph returns [[dist]] for single source/target; unwrap to a scalar.\"\"\"\n    if isinstance(obj, (list, tuple)) and len(obj) == 1:\n        inner = obj[0]\n        if isinstance(inner, (list, tuple)) and len(inner) == 1:\n            return inner[0]\n        return inner\n    return obj\n\n\ndef run_tests():\n    # ----- G1: shortest paths -----\n    G1 = build_path_graph()\n\n    # Weighted Dijkstra via labels -&gt; expect 11.0\n    dist_w = G1.ig.shortest_paths_dijkstra(\n        source=\"alpha\", target=\"phi\", weights=\"weight\", _ig_guess_labels=False\n    )\n    dist_w = _unwrap_ig_distance(dist_w)\n    print(\"[IG:G1 dijkstra weighted] alpha-&gt;phi:\", dist_w, \"(expect 11.0)\")\n\n    # Unweighted hop count -&gt; expect 5 (alpha\u2192phi)\n    dist_hops = G1.ig.distances(\n        source=\"alpha\", target=\"phi\", weights=None, _ig_guess_labels=False\n    )\n    dist_hops = _unwrap_ig_distance(dist_hops)\n    print(\"[IG:G1 unweighted hops] alpha-&gt;phi:\", dist_hops, \"(expect 5)\")\n\n    # Cache invalidation: add fast a-&gt;f edge (weight=2) and re-check -&gt; expect 2.0\n    G1.add_edge(\"a\", \"f\", weight=2)\n    dist_new = G1.ig.shortest_paths_dijkstra(\n        source=\"alpha\", target=\"phi\", weights=\"weight\", _ig_guess_labels=False\n    )\n    dist_new = _unwrap_ig_distance(dist_new)\n    print(\"[IG:G1 after mutation] alpha-&gt;phi:\", dist_new, \"(expect 2.0)\")\n\n    # ----- G2: communities / betweenness / PR / components -----\n    G2 = build_community_graph()\n\n    # multilevel (Louvain-like) on undirected view -&gt; expect sizes [4, 6]\n    vc = G2.ig.community_multilevel(weights=\"weight\", _ig_directed=False)\n    sizes = sorted(vc.sizes())\n    print(\"[IG:G2 multilevel] sizes:\", sizes, \"(expect [4, 6])\")\n\n    # Betweenness centrality (undirected). igraph returns list aligned to vertex order.\n    igG_und = G2.ig.backend(directed=False)  # no simple=True needed here\n    names = igG_und.vs[\"name\"] if \"name\" in igG_und.vs.attributes() else list(range(igG_und.vcount()))\n    bc_vals = G2.ig.betweenness(directed=False, weights=None)\n    top_bc = max(dict(zip(names, bc_vals)), key=lambda k: dict(zip(names, bc_vals))[k])\n    print(\"[IG:G2 betweenness] top:\", top_bc, \"(expect 'e' or 'x')\")\n\n    # PageRank (undirected, unweighted) -&gt; 'e' should dominate\n    pr_vals = G2.ig.pagerank(directed=False)\n    top_pr = max(dict(zip(names, pr_vals)), key=lambda k: dict(zip(names, pr_vals))[k])\n    print(\"[IG:G2 pagerank] top:\", top_pr, \"(expect 'e')\")\n\n    # Connected components (undirected) -&gt; single component of size 10\n    comps = G2.ig.components(_ig_directed=False)  # VertexClustering\n    comp_sizes = sorted(comps.sizes())\n    print(\"[IG:G2 connected components]:\", comp_sizes, \"(expect [10])\")\n\n    # ----- Optional: verify simple collapse + aggregation policy -----\n    G3 = Graph(directed=True)\n    G3.add_vertex(\"u\"); G3.add_vertex(\"v\")\n    # parallel undirected edges with attrs\n    G3.add_edge(\"u\", \"v\", weight=5, capacity=3, edge_directed=False)\n    G3.add_edge(\"u\", \"v\", weight=2, capacity=7, edge_directed=False)\n\n    try:\n        # Preferred: via proxy (needs the one-line proxy patch shown above)\n        igG_simple = G3.ig.backend(\n            directed=False, simple=True,\n            needed_attrs={\"weight\", \"capacity\"},\n            edge_aggs={\"weight\": \"min\", \"capacity\": \"sum\"}\n        )\n        e = igG_simple.es[0]\n        print(\"[IG:G3 collapse agg via proxy] weight:\", e[\"weight\"], \"capacity:\", e[\"capacity\"], \"(expect 2, 10)\")\n    except Exception:\n        # Fallback: ensure attrs exist, then collapse using igraph.simplify\n        igG_raw = G3.ig.backend(directed=False, needed_attrs={\"weight\", \"capacity\"})\n        igG_raw.simplify(multiple=True, loops=True,\n                         combine_edges={\"weight\": \"min\", \"capacity\": \"sum\"})\n        e = igG_raw.es[0]\n        # after simplify, attrs may be missing if combine didn't carry them; handle safely\n        w = e[\"weight\"] if \"weight\" in igG_raw.es.attributes() else None\n        c = e[\"capacity\"] if \"capacity\" in igG_raw.es.attributes() else None\n        print(\"[IG:G3 collapse agg via simplify] weight:\", w, \"capacity:\", c, \"(expect 2, 10)\")\n\n\nif __name__ == \"__main__\":\n    run_tests()\n</pre> # Deterministic smoke tests for the lazy ig (igraph) proxy  from graphglue.core.graph import Graph  # ---------- G1: PATH GRAPH (for weighted/unweighted shortest paths) ---------- def build_path_graph() -&gt; Graph:     \"\"\"     Directed chain a\u2192b\u2192c\u2192d\u2192e\u2192f with weights on each edge.     - Weighted shortest path a\u2192f = 1+2+3+1+4 = 11     - Unweighted hops a\u2192f = 5     \"\"\"     G = Graph(directed=True)     # vertices (+ labels for the label\u2192ID mapping)     G.add_vertex(\"a\", name=\"alpha\")     G.add_vertex(\"b\", name=\"bravo\")     G.add_vertex(\"c\", name=\"charlie\")     G.add_vertex(\"d\", name=\"delta\")     G.add_vertex(\"e\", name=\"echo\")     G.add_vertex(\"f\", name=\"phi\")      # pure chain (NO chords)     G.add_edge(\"a\", \"b\", weight=1)     G.add_edge(\"b\", \"c\", weight=2)     G.add_edge(\"c\", \"d\", weight=3)     G.add_edge(\"d\", \"e\", weight=1)     G.add_edge(\"e\", \"f\", weight=4)     return G   # ---------- G2: COMMUNITY GRAPH (two cliques + weak bridge) ---------- def build_community_graph() -&gt; Graph:     \"\"\"     Two undirected cliques: K6 on {a..f} and K4 on {w,x,y,z}, joined by a single weak bridge e--x (weight=0.01).     multilevel (Louvain-like) should give communities of sizes [4,6] (stable with seed);     betweenness top in {'e','x'}; PageRank (PR) top is 'e'.     \"\"\"     G = Graph(directed=True)  # add undirected edges explicitly      for v in [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"w\",\"x\",\"y\",\"z\"]:         G.add_vertex(v)      # K6 clique on a..f (undirected, weight=1)     k6 = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"]     for i in range(len(k6)):         for j in range(i + 1, len(k6)):             G.add_edge(k6[i], k6[j], weight=1, edge_directed=False)      # K4 clique on w,x,y,z (undirected, weight=1)     k4 = [\"w\",\"x\",\"y\",\"z\"]     for i in range(len(k4)):         for j in range(i + 1, len(k4)):             G.add_edge(k4[i], k4[j], weight=1, edge_directed=False)      # Single weak bridge e--x     G.add_edge(\"e\", \"x\", weight=0.01, edge_directed=False)     return G   # ---------- helpers ---------- def _unwrap_ig_distance(obj):     \"\"\"igraph returns [[dist]] for single source/target; unwrap to a scalar.\"\"\"     if isinstance(obj, (list, tuple)) and len(obj) == 1:         inner = obj[0]         if isinstance(inner, (list, tuple)) and len(inner) == 1:             return inner[0]         return inner     return obj   def run_tests():     # ----- G1: shortest paths -----     G1 = build_path_graph()      # Weighted Dijkstra via labels -&gt; expect 11.0     dist_w = G1.ig.shortest_paths_dijkstra(         source=\"alpha\", target=\"phi\", weights=\"weight\", _ig_guess_labels=False     )     dist_w = _unwrap_ig_distance(dist_w)     print(\"[IG:G1 dijkstra weighted] alpha-&gt;phi:\", dist_w, \"(expect 11.0)\")      # Unweighted hop count -&gt; expect 5 (alpha\u2192phi)     dist_hops = G1.ig.distances(         source=\"alpha\", target=\"phi\", weights=None, _ig_guess_labels=False     )     dist_hops = _unwrap_ig_distance(dist_hops)     print(\"[IG:G1 unweighted hops] alpha-&gt;phi:\", dist_hops, \"(expect 5)\")      # Cache invalidation: add fast a-&gt;f edge (weight=2) and re-check -&gt; expect 2.0     G1.add_edge(\"a\", \"f\", weight=2)     dist_new = G1.ig.shortest_paths_dijkstra(         source=\"alpha\", target=\"phi\", weights=\"weight\", _ig_guess_labels=False     )     dist_new = _unwrap_ig_distance(dist_new)     print(\"[IG:G1 after mutation] alpha-&gt;phi:\", dist_new, \"(expect 2.0)\")      # ----- G2: communities / betweenness / PR / components -----     G2 = build_community_graph()      # multilevel (Louvain-like) on undirected view -&gt; expect sizes [4, 6]     vc = G2.ig.community_multilevel(weights=\"weight\", _ig_directed=False)     sizes = sorted(vc.sizes())     print(\"[IG:G2 multilevel] sizes:\", sizes, \"(expect [4, 6])\")      # Betweenness centrality (undirected). igraph returns list aligned to vertex order.     igG_und = G2.ig.backend(directed=False)  # no simple=True needed here     names = igG_und.vs[\"name\"] if \"name\" in igG_und.vs.attributes() else list(range(igG_und.vcount()))     bc_vals = G2.ig.betweenness(directed=False, weights=None)     top_bc = max(dict(zip(names, bc_vals)), key=lambda k: dict(zip(names, bc_vals))[k])     print(\"[IG:G2 betweenness] top:\", top_bc, \"(expect 'e' or 'x')\")      # PageRank (undirected, unweighted) -&gt; 'e' should dominate     pr_vals = G2.ig.pagerank(directed=False)     top_pr = max(dict(zip(names, pr_vals)), key=lambda k: dict(zip(names, pr_vals))[k])     print(\"[IG:G2 pagerank] top:\", top_pr, \"(expect 'e')\")      # Connected components (undirected) -&gt; single component of size 10     comps = G2.ig.components(_ig_directed=False)  # VertexClustering     comp_sizes = sorted(comps.sizes())     print(\"[IG:G2 connected components]:\", comp_sizes, \"(expect [10])\")      # ----- Optional: verify simple collapse + aggregation policy -----     G3 = Graph(directed=True)     G3.add_vertex(\"u\"); G3.add_vertex(\"v\")     # parallel undirected edges with attrs     G3.add_edge(\"u\", \"v\", weight=5, capacity=3, edge_directed=False)     G3.add_edge(\"u\", \"v\", weight=2, capacity=7, edge_directed=False)      try:         # Preferred: via proxy (needs the one-line proxy patch shown above)         igG_simple = G3.ig.backend(             directed=False, simple=True,             needed_attrs={\"weight\", \"capacity\"},             edge_aggs={\"weight\": \"min\", \"capacity\": \"sum\"}         )         e = igG_simple.es[0]         print(\"[IG:G3 collapse agg via proxy] weight:\", e[\"weight\"], \"capacity:\", e[\"capacity\"], \"(expect 2, 10)\")     except Exception:         # Fallback: ensure attrs exist, then collapse using igraph.simplify         igG_raw = G3.ig.backend(directed=False, needed_attrs={\"weight\", \"capacity\"})         igG_raw.simplify(multiple=True, loops=True,                          combine_edges={\"weight\": \"min\", \"capacity\": \"sum\"})         e = igG_raw.es[0]         # after simplify, attrs may be missing if combine didn't carry them; handle safely         w = e[\"weight\"] if \"weight\" in igG_raw.es.attributes() else None         c = e[\"capacity\"] if \"capacity\" in igG_raw.es.attributes() else None         print(\"[IG:G3 collapse agg via simplify] weight:\", w, \"capacity:\", c, \"(expect 2, 10)\")   if __name__ == \"__main__\":     run_tests()  <pre>[IG:G1 dijkstra weighted] alpha-&gt;phi: 11.0 (expect 11.0)\n[IG:G1 unweighted hops] alpha-&gt;phi: 5 (expect 5)\n[IG:G1 after mutation] alpha-&gt;phi: 2.0 (expect 2.0)\n[IG:G2 multilevel] sizes: [4, 6] (expect [4, 6])\n[IG:G2 betweenness] top: e (expect 'e' or 'x')\n[IG:G2 pagerank] top: e (expect 'e')\n[IG:G2 connected components]: [10] (expect [10])\n[IG:G3 collapse agg via proxy] weight: 2 capacity: 10 (expect 2, 10)\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"sbml_io/","title":"SBML adapter (Elowitz repressilator)","text":"In\u00a0[5]: Copied! <pre>import sys, os\nsys.path.insert(0, os.path.abspath(\"..\")) \n\nimport polars as pl\nimport numpy as np\nfrom datetime import datetime\n\nfrom graphglue.core.graph import Graph\nfrom graphglue.adapters.sbml_adapter import from_sbml, BOUNDARY_SOURCE, BOUNDARY_SINK\n</pre> import sys, os sys.path.insert(0, os.path.abspath(\"..\"))   import polars as pl import numpy as np from datetime import datetime  from graphglue.core.graph import Graph from graphglue.adapters.sbml_adapter import from_sbml, BOUNDARY_SOURCE, BOUNDARY_SINK In\u00a0[8]: Copied! <pre>G = from_sbml(\"Elowitz.sbml.xml\", graph=Graph(directed=True), preserve_stoichiometry=True)\n\nprint(\"vertices:\", G.num_vertices)      # expect 8 (6 real + 2 boundary)\nprint(\"edges:\", G.num_edges)            # expect 12\nprint(\"boundary nodes:\", BOUNDARY_SOURCE in G.entity_to_idx, BOUNDARY_SINK in G.entity_to_idx)\nprint(\"sample edges:\", list(G.edge_to_idx)[:5])\n</pre> G = from_sbml(\"Elowitz.sbml.xml\", graph=Graph(directed=True), preserve_stoichiometry=True)  print(\"vertices:\", G.num_vertices)      # expect 8 (6 real + 2 boundary) print(\"edges:\", G.num_edges)            # expect 12 print(\"boundary nodes:\", BOUNDARY_SOURCE in G.entity_to_idx, BOUNDARY_SINK in G.entity_to_idx) print(\"sample edges:\", list(G.edge_to_idx)[:5])  <pre>Model does not contain SBML fbc package information.\nSBML package 'layout' not supported by cobrapy, information is not parsed\nSBML package 'render' not supported by cobrapy, information is not parsed\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction1 \"degradation of LacI transcripts\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction1 \"degradation of LacI transcripts\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction2 \"degradation of TetR transcripts\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction2 \"degradation of TetR transcripts\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction3 \"degradation of CI transcripts\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction3 \"degradation of CI transcripts\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction4 \"translation of LacI\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction4 \"translation of LacI\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction5 \"translation of TetR\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction5 \"translation of TetR\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction6 \"translation of CI\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction6 \"translation of CI\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction7 \"degradation of LacI\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction7 \"degradation of LacI\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction8 \"degradation of TetR\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction8 \"degradation of TetR\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction9 \"degradation of CI\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction9 \"degradation of CI\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction10 \"transcription of LacI\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction10 \"transcription of LacI\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction11 \"transcription of TetR\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction11 \"transcription of TetR\"&gt;'\nMissing lower flux bound set to '-1000.0' for reaction: '&lt;Reaction Reaction12 \"transcription of CI\"&gt;'\nMissing upper flux bound set to '1000.0' for reaction: '&lt;Reaction Reaction12 \"transcription of CI\"&gt;'\nNo objective coefficients in model. Unclear what should be optimized\nMissing flux bounds on reactions set to default bounds.As best practise and to avoid confusion flux bounds should be set explicitly on all reactions.\n</pre> <pre>vertices: 8\nedges: 12\nboundary nodes: True True\nsample edges: ['Reaction1', 'Reaction2', 'Reaction3', 'Reaction4', 'Reaction5']\n</pre> In\u00a0[10]: Copied! <pre>def show_reaction(eid: str):\n    if eid not in G.edge_to_idx:\n        print(\"no such edge:\", eid); return\n    h = G.hyperedge_definitions[eid]\n    attrs = G.get_edge_attrs(eid)\n    sto = attrs.get(\"stoich\")  # present if you didn't add set_hyperedge_coeffs OR adapter stored it anyway\n    print(f\"[{eid}]\")\n    print(\"  head (products):\", sorted(h[\"head\"]))\n    print(\"  tail (reactants):\", sorted(h[\"tail\"]))\n    if sto:\n        # filter zeros if any\n        sto = {k: float(v) for k, v in sto.items() if abs(float(v)) &gt; 1e-12}\n        print(\"  stoich map:\", sto)\n\n# examples\nshow_reaction(\"Reaction1\")\nshow_reaction(\"Reaction4\")\n</pre> def show_reaction(eid: str):     if eid not in G.edge_to_idx:         print(\"no such edge:\", eid); return     h = G.hyperedge_definitions[eid]     attrs = G.get_edge_attrs(eid)     sto = attrs.get(\"stoich\")  # present if you didn't add set_hyperedge_coeffs OR adapter stored it anyway     print(f\"[{eid}]\")     print(\"  head (products):\", sorted(h[\"head\"]))     print(\"  tail (reactants):\", sorted(h[\"tail\"]))     if sto:         # filter zeros if any         sto = {k: float(v) for k, v in sto.items() if abs(float(v)) &gt; 1e-12}         print(\"  stoich map:\", sto)  # examples show_reaction(\"Reaction1\") show_reaction(\"Reaction4\")  <pre>[Reaction1]\n  head (products): ['__BOUNDARY_SINK__']\n  tail (reactants): ['X']\n[Reaction4]\n  head (products): ['PX']\n  tail (reactants): ['__BOUNDARY_SOURCE__']\n</pre> In\u00a0[12]: Copied! <pre>BOUNDARY = {BOUNDARY_SOURCE, BOUNDARY_SINK}\n\nproduced = {v:0 for v in G.entity_to_idx}\nconsumed = {v:0 for v in G.entity_to_idx}\n\nfor eid in G.edge_to_idx:\n    h = G.hyperedge_definitions[eid]\n    for v in h[\"head\"]: produced[v] += 1\n    for v in h[\"tail\"]: consumed[v] += 1\n\nreal_species = [v for v in G.entity_to_idx if v not in BOUNDARY]\nstats = [(v, produced[v], consumed[v]) for v in real_species]\nstats.sort(key=lambda t: (t[1], t[2]), reverse=True)\nfor v,p,c in stats:\n    print(f\"{v:&gt;4}  produced_in={p}  consumed_in={c}\")\n</pre> BOUNDARY = {BOUNDARY_SOURCE, BOUNDARY_SINK}  produced = {v:0 for v in G.entity_to_idx} consumed = {v:0 for v in G.entity_to_idx}  for eid in G.edge_to_idx:     h = G.hyperedge_definitions[eid]     for v in h[\"head\"]: produced[v] += 1     for v in h[\"tail\"]: consumed[v] += 1  real_species = [v for v in G.entity_to_idx if v not in BOUNDARY] stats = [(v, produced[v], consumed[v]) for v in real_species] stats.sort(key=lambda t: (t[1], t[2]), reverse=True) for v,p,c in stats:     print(f\"{v:&gt;4}  produced_in={p}  consumed_in={c}\")  <pre>  PX  produced_in=1  consumed_in=1\n  PY  produced_in=1  consumed_in=1\n  PZ  produced_in=1  consumed_in=1\n   X  produced_in=1  consumed_in=1\n   Y  produced_in=1  consumed_in=1\n   Z  produced_in=1  consumed_in=1\n</pre> In\u00a0[14]: Copied! <pre>species_to_reactions = {v: {\"as_product\": [], \"as_reactant\": []} for v in G.entity_to_idx}\n\nfor eid in G.edge_to_idx:\n    h = G.hyperedge_definitions[eid]\n    for v in h[\"head\"]:\n        species_to_reactions[v][\"as_product\"].append(eid)\n    for v in h[\"tail\"]:\n        species_to_reactions[v][\"as_reactant\"].append(eid)\n\n# example: show for each real species\nfor v in real_species:\n    rp = species_to_reactions[v][\"as_product\"]\n    rr = species_to_reactions[v][\"as_reactant\"]\n    print(f\"\\n{v}\")\n    print(\"  as product :\", rp)\n    print(\"  as reactant:\", rr)\n</pre> species_to_reactions = {v: {\"as_product\": [], \"as_reactant\": []} for v in G.entity_to_idx}  for eid in G.edge_to_idx:     h = G.hyperedge_definitions[eid]     for v in h[\"head\"]:         species_to_reactions[v][\"as_product\"].append(eid)     for v in h[\"tail\"]:         species_to_reactions[v][\"as_reactant\"].append(eid)  # example: show for each real species for v in real_species:     rp = species_to_reactions[v][\"as_product\"]     rr = species_to_reactions[v][\"as_reactant\"]     print(f\"\\n{v}\")     print(\"  as product :\", rp)     print(\"  as reactant:\", rr)  <pre>\nPX\n  as product : ['Reaction4']\n  as reactant: ['Reaction7']\n\nPY\n  as product : ['Reaction5']\n  as reactant: ['Reaction8']\n\nPZ\n  as product : ['Reaction6']\n  as reactant: ['Reaction9']\n\nX\n  as product : ['Reaction10']\n  as reactant: ['Reaction1']\n\nY\n  as product : ['Reaction11']\n  as reactant: ['Reaction2']\n\nZ\n  as product : ['Reaction12']\n  as reactant: ['Reaction3']\n</pre> In\u00a0[16]: Copied! <pre># signs: by definition head=products (+), tail=reactants (\u2212)\ndef signs_consistent(eid):\n    h = G.hyperedge_definitions[eid]\n    attrs = G.get_edge_attrs(eid)\n    sto = attrs.get(\"stoich\")\n    if not sto:\n        # no per-vertex coeffs exposed via attrs; just check sets are present\n        return bool(h[\"head\"] or h[\"tail\"])\n    # if stoich map exists, check sign consistency vs head/tail sets\n    ok = True\n    for v, coeff in sto.items():\n        coeff = float(coeff)\n        if v in h[\"head\"]: ok &amp;= coeff &gt; 0\n        if v in h[\"tail\"]: ok &amp;= coeff &lt; 0\n    return ok\n\nsign_ok_all = all(signs_consistent(e) for e in G.edge_to_idx)\nprint(\"signs consistent (based on available attrs):\", sign_ok_all)\n\n# balance: if stoich map exists, sum should be ~0 including boundary nodes\ndef balanced(eid):\n    attrs = G.get_edge_attrs(eid)\n    sto = attrs.get(\"stoich\")\n    if not sto: return True  # can't check without exposed coeffs; treat as pass\n    s = sum(float(v) for v in sto.values())\n    return abs(s) &lt; 1e-9\n\nbal_ok_all = all(balanced(e) for e in G.edge_to_idx)\nprint(\"columns balanced (based on available attrs):\", bal_ok_all)\n</pre> # signs: by definition head=products (+), tail=reactants (\u2212) def signs_consistent(eid):     h = G.hyperedge_definitions[eid]     attrs = G.get_edge_attrs(eid)     sto = attrs.get(\"stoich\")     if not sto:         # no per-vertex coeffs exposed via attrs; just check sets are present         return bool(h[\"head\"] or h[\"tail\"])     # if stoich map exists, check sign consistency vs head/tail sets     ok = True     for v, coeff in sto.items():         coeff = float(coeff)         if v in h[\"head\"]: ok &amp;= coeff &gt; 0         if v in h[\"tail\"]: ok &amp;= coeff &lt; 0     return ok  sign_ok_all = all(signs_consistent(e) for e in G.edge_to_idx) print(\"signs consistent (based on available attrs):\", sign_ok_all)  # balance: if stoich map exists, sum should be ~0 including boundary nodes def balanced(eid):     attrs = G.get_edge_attrs(eid)     sto = attrs.get(\"stoich\")     if not sto: return True  # can't check without exposed coeffs; treat as pass     s = sum(float(v) for v in sto.values())     return abs(s) &lt; 1e-9  bal_ok_all = all(balanced(e) for e in G.edge_to_idx) print(\"columns balanced (based on available attrs):\", bal_ok_all)  <pre>signs consistent (based on available attrs): True\ncolumns balanced (based on available attrs): True\n</pre> In\u00a0[18]: Copied! <pre># degrees on your underlying NX projection (pass G explicitly)\ndeg = dict(G.nx.degree(G=G))\nprint(\"nx nodes:\", G.nx.number_of_nodes(G=G), \" nx edges:\", G.nx.number_of_edges(G=G))\nprint(\"top-degree nodes:\", sorted(deg.items(), key=lambda kv: kv[1], reverse=True)[:10])\n\n# simple paths (between two species if connected in your projection)\ntry:\n    path = G.nx.shortest_path(G=G, source=\"X\", target=\"PX\")  # tweak names if different\n    print(\"shortest path X\u2192PX:\", path)\nexcept Exception as e:\n    print(\"shortest_path failed:\", e)\n\n# cycles (directed projection)\ntry:\n    cyc = list(G.nx.simple_cycles(G=G))\n    print(\"cycles(count):\", len(cyc))\n    print(\"sample cycles:\", cyc[:3])\nexcept Exception as e:\n    print(\"simple_cycles failed:\", e)\n\n# neighbors / predecessors / successors\ntry:\n    print(\"neighbors(X):\", list(G.nx.neighbors(G=G, n=\"X\")))\nexcept Exception as e:\n    print(\"neighbors failed:\", e)\n\ntry:\n    print(\"successors(X):\", list(G.nx.successors(G=G, n=\"X\")))\n    print(\"predecessors(X):\", list(G.nx.predecessors(G=G, n=\"X\")))\nexcept Exception:\n    pass\n\n# connected components (weakly for directed; else undirected)\ntry:\n    comps = list(G.nx.weakly_connected_components(G=G))\n    print(\"weakly components:\", len(comps))\n    print(\"largest component size:\", max(len(c) for c in comps))\nexcept Exception:\n    try:\n        comps = list(G.nx.connected_components(G=G))\n        print(\"connected components:\", len(comps))\n        print(\"largest component size:\", max(len(c) for c in comps))\n    except Exception as e:\n        print(\"components failed:\", e)\n\n# degree centrality (works the same way)\ntry:\n    dc = G.nx.degree_centrality(G=G)\n    print(\"top degree_centrality:\", sorted(dc.items(), key=lambda kv: kv[1], reverse=True)[:5])\nexcept Exception as e:\n    print(\"degree_centrality failed:\", e)\n\n# species-only subgraph with the proxy (filters out boundary nodes)\nBOUNDARY = {\"__BOUNDARY_SOURCE__\", \"__BOUNDARY_SINK__\"}\ntry:\n    species = [n for n in G.nx.nodes(G=G) if n not in BOUNDARY]\n    SG = G.nx.subgraph(G=G, nbunch=species)  # returns an NX graph\n    print(\"species-subgraph nodes:\", SG.number_of_nodes(), \"edges:\", SG.number_of_edges())\nexcept Exception as e:\n    print(\"subgraph failed:\", e)\n</pre> # degrees on your underlying NX projection (pass G explicitly) deg = dict(G.nx.degree(G=G)) print(\"nx nodes:\", G.nx.number_of_nodes(G=G), \" nx edges:\", G.nx.number_of_edges(G=G)) print(\"top-degree nodes:\", sorted(deg.items(), key=lambda kv: kv[1], reverse=True)[:10])  # simple paths (between two species if connected in your projection) try:     path = G.nx.shortest_path(G=G, source=\"X\", target=\"PX\")  # tweak names if different     print(\"shortest path X\u2192PX:\", path) except Exception as e:     print(\"shortest_path failed:\", e)  # cycles (directed projection) try:     cyc = list(G.nx.simple_cycles(G=G))     print(\"cycles(count):\", len(cyc))     print(\"sample cycles:\", cyc[:3]) except Exception as e:     print(\"simple_cycles failed:\", e)  # neighbors / predecessors / successors try:     print(\"neighbors(X):\", list(G.nx.neighbors(G=G, n=\"X\"))) except Exception as e:     print(\"neighbors failed:\", e)  try:     print(\"successors(X):\", list(G.nx.successors(G=G, n=\"X\")))     print(\"predecessors(X):\", list(G.nx.predecessors(G=G, n=\"X\"))) except Exception:     pass  # connected components (weakly for directed; else undirected) try:     comps = list(G.nx.weakly_connected_components(G=G))     print(\"weakly components:\", len(comps))     print(\"largest component size:\", max(len(c) for c in comps)) except Exception:     try:         comps = list(G.nx.connected_components(G=G))         print(\"connected components:\", len(comps))         print(\"largest component size:\", max(len(c) for c in comps))     except Exception as e:         print(\"components failed:\", e)  # degree centrality (works the same way) try:     dc = G.nx.degree_centrality(G=G)     print(\"top degree_centrality:\", sorted(dc.items(), key=lambda kv: kv[1], reverse=True)[:5]) except Exception as e:     print(\"degree_centrality failed:\", e)  # species-only subgraph with the proxy (filters out boundary nodes) BOUNDARY = {\"__BOUNDARY_SOURCE__\", \"__BOUNDARY_SINK__\"} try:     species = [n for n in G.nx.nodes(G=G) if n not in BOUNDARY]     SG = G.nx.subgraph(G=G, nbunch=species)  # returns an NX graph     print(\"species-subgraph nodes:\", SG.number_of_nodes(), \"edges:\", SG.number_of_edges()) except Exception as e:     print(\"subgraph failed:\", e)  <pre>nx nodes: 8  nx edges: 12\ntop-degree nodes: [('__BOUNDARY_SOURCE__', 6), ('__BOUNDARY_SINK__', 6), ('PX', 2), ('PY', 2), ('PZ', 2), ('X', 2), ('Y', 2), ('Z', 2)]\nshortest_path failed: No path between X and PX.\ncycles(count): 0\nsample cycles: []\nneighbors(X): ['__BOUNDARY_SOURCE__']\nweakly components: 1\nlargest component size: 8\ntop degree_centrality: [('__BOUNDARY_SOURCE__', 0.8571428571428571), ('__BOUNDARY_SINK__', 0.8571428571428571), ('PX', 0.2857142857142857), ('PY', 0.2857142857142857), ('PZ', 0.2857142857142857)]\nspecies-subgraph nodes: 6 edges: 0\n</pre> In\u00a0[21]: Copied! <pre># Create graph\nG = Graph(directed=True)\n\nprint(\"=\" * 60)\nprint(\"CREATING MULTI-LAYER TEMPORAL GRAPH\")\nprint(\"=\" * 60)\n\n# Add layers\nG.layers.add(\"2022\", year=2022, description=\"Year 2022\")\nG.layers.add(\"2023\", year=2023, description=\"Year 2023\")\nG.layers.add(\"2024\", year=2024, description=\"Year 2024\")\n\nprint(f\"\\n\u2713 Created {G.layers.count()} layers\")\nprint(f\"  Layers: {G.layers.list()}\")\n</pre> # Create graph G = Graph(directed=True)  print(\"=\" * 60) print(\"CREATING MULTI-LAYER TEMPORAL GRAPH\") print(\"=\" * 60)  # Add layers G.layers.add(\"2022\", year=2022, description=\"Year 2022\") G.layers.add(\"2023\", year=2023, description=\"Year 2023\") G.layers.add(\"2024\", year=2024, description=\"Year 2024\")  print(f\"\\n\u2713 Created {G.layers.count()} layers\") print(f\"  Layers: {G.layers.list()}\") <pre>============================================================\nCREATING MULTI-LAYER TEMPORAL GRAPH\n============================================================\n\n\u2713 Created 4 layers\n  Layers: ['2022', '2023', '2024']\n</pre> In\u00a0[23]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"LAYER 2022: Adding nodes\")\nprint(\"=\" * 60)\n\nG.layers.active = \"2022\"\n\n# Add people\npeople_2022 = {\n    \"alice\": {\"name\": \"Alice\", \"age\": 25, \"role\": \"engineer\", \"salary\": 80000},\n    \"bob\": {\"name\": \"Bob\", \"age\": 30, \"role\": \"manager\", \"salary\": 95000},\n    \"charlie\": {\"name\": \"Charlie\", \"age\": 28, \"role\": \"engineer\", \"salary\": 85000},\n    \"diana\": {\"name\": \"Diana\", \"age\": 35, \"role\": \"director\", \"salary\": 120000},\n}\n\nfor vid, attrs in people_2022.items():\n    G.add_vertex(vid, **attrs)\n\n# Add collaborations (edges)\ncollaborations_2022 = [\n    (\"alice\", \"bob\", 0.8, {\"project\": \"ProjectX\", \"hours\": 120}),\n    (\"alice\", \"charlie\", 0.9, {\"project\": \"ProjectX\", \"hours\": 150}),\n    (\"bob\", \"diana\", 0.7, {\"project\": \"Management\", \"hours\": 80}),\n    (\"charlie\", \"diana\", 0.6, {\"project\": \"ProjectY\", \"hours\": 60}),\n]\n\nfor source, target, weight, attrs in collaborations_2022:\n    G.add_edge(source, target, weight=weight, **attrs)\n\nprint(f\"\\n\u2713 Layer 2022:\")\nprint(f\"  Vertices: {G.number_of_vertices()}\")\nprint(f\"  Edges: {G.number_of_edges()}\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"LAYER 2022: Adding nodes\") print(\"=\" * 60)  G.layers.active = \"2022\"  # Add people people_2022 = {     \"alice\": {\"name\": \"Alice\", \"age\": 25, \"role\": \"engineer\", \"salary\": 80000},     \"bob\": {\"name\": \"Bob\", \"age\": 30, \"role\": \"manager\", \"salary\": 95000},     \"charlie\": {\"name\": \"Charlie\", \"age\": 28, \"role\": \"engineer\", \"salary\": 85000},     \"diana\": {\"name\": \"Diana\", \"age\": 35, \"role\": \"director\", \"salary\": 120000}, }  for vid, attrs in people_2022.items():     G.add_vertex(vid, **attrs)  # Add collaborations (edges) collaborations_2022 = [     (\"alice\", \"bob\", 0.8, {\"project\": \"ProjectX\", \"hours\": 120}),     (\"alice\", \"charlie\", 0.9, {\"project\": \"ProjectX\", \"hours\": 150}),     (\"bob\", \"diana\", 0.7, {\"project\": \"Management\", \"hours\": 80}),     (\"charlie\", \"diana\", 0.6, {\"project\": \"ProjectY\", \"hours\": 60}), ]  for source, target, weight, attrs in collaborations_2022:     G.add_edge(source, target, weight=weight, **attrs)  print(f\"\\n\u2713 Layer 2022:\") print(f\"  Vertices: {G.number_of_vertices()}\") print(f\"  Edges: {G.number_of_edges()}\") <pre>\n============================================================\nLAYER 2022: Adding nodes\n============================================================\n\n\u2713 Layer 2022:\n  Vertices: 4\n  Edges: 4\n</pre> In\u00a0[25]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"LAYER 2023: Adding nodes and edges\")\nprint(\"=\" * 60)\n\nG.layers.active = \"2023\"\n\n# Add existing people (some with updated attributes)\npeople_2023 = {\n    \"alice\": {\"name\": \"Alice\", \"age\": 26, \"role\": \"senior_engineer\", \"salary\": 92000},\n    \"bob\": {\"name\": \"Bob\", \"age\": 31, \"role\": \"senior_manager\", \"salary\": 105000},\n    \"charlie\": {\"name\": \"Charlie\", \"age\": 29, \"role\": \"engineer\", \"salary\": 88000},\n    \"diana\": {\"name\": \"Diana\", \"age\": 36, \"role\": \"director\", \"salary\": 125000},\n    \"eve\": {\"name\": \"Eve\", \"age\": 27, \"role\": \"engineer\", \"salary\": 83000},  # New hire\n}\n\nfor vid, attrs in people_2023.items():\n    if not G.has_vertex(vid):\n        G.add_vertex(vid, **attrs)\n\n# New collaborations\ncollaborations_2023 = [\n    (\"alice\", \"bob\", 0.85, {\"project\": \"ProjectZ\", \"hours\": 140}),\n    (\"alice\", \"eve\", 0.95, {\"project\": \"ProjectZ\", \"hours\": 180}),  # New collaboration\n    (\"bob\", \"diana\", 0.75, {\"project\": \"Management\", \"hours\": 90}),\n    (\"charlie\", \"eve\", 0.8, {\"project\": \"ProjectW\", \"hours\": 100}),\n    (\"eve\", \"diana\", 0.7, {\"project\": \"ProjectW\", \"hours\": 70}),\n]\n\nfor source, target, weight, attrs in collaborations_2023:\n    G.add_edge(source, target, weight=weight, **attrs)\n\nprint(f\"\\n\u2713 Layer 2023:\")\nprint(f\"  Total vertices: {G.number_of_vertices()}\")\nprint(f\"  Edges in layer: {len(G.layers.edges('2023'))}\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"LAYER 2023: Adding nodes and edges\") print(\"=\" * 60)  G.layers.active = \"2023\"  # Add existing people (some with updated attributes) people_2023 = {     \"alice\": {\"name\": \"Alice\", \"age\": 26, \"role\": \"senior_engineer\", \"salary\": 92000},     \"bob\": {\"name\": \"Bob\", \"age\": 31, \"role\": \"senior_manager\", \"salary\": 105000},     \"charlie\": {\"name\": \"Charlie\", \"age\": 29, \"role\": \"engineer\", \"salary\": 88000},     \"diana\": {\"name\": \"Diana\", \"age\": 36, \"role\": \"director\", \"salary\": 125000},     \"eve\": {\"name\": \"Eve\", \"age\": 27, \"role\": \"engineer\", \"salary\": 83000},  # New hire }  for vid, attrs in people_2023.items():     if not G.has_vertex(vid):         G.add_vertex(vid, **attrs)  # New collaborations collaborations_2023 = [     (\"alice\", \"bob\", 0.85, {\"project\": \"ProjectZ\", \"hours\": 140}),     (\"alice\", \"eve\", 0.95, {\"project\": \"ProjectZ\", \"hours\": 180}),  # New collaboration     (\"bob\", \"diana\", 0.75, {\"project\": \"Management\", \"hours\": 90}),     (\"charlie\", \"eve\", 0.8, {\"project\": \"ProjectW\", \"hours\": 100}),     (\"eve\", \"diana\", 0.7, {\"project\": \"ProjectW\", \"hours\": 70}), ]  for source, target, weight, attrs in collaborations_2023:     G.add_edge(source, target, weight=weight, **attrs)  print(f\"\\n\u2713 Layer 2023:\") print(f\"  Total vertices: {G.number_of_vertices()}\") print(f\"  Edges in layer: {len(G.layers.edges('2023'))}\") <pre>\n============================================================\nLAYER 2023: Adding nodes and edges\n============================================================\n\n\u2713 Layer 2023:\n  Total vertices: 5\n  Edges in layer: 5\n</pre> In\u00a0[27]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"LAYER 2024: Adding nodes and edges\")\nprint(\"=\" * 60)\n\nG.layers.active = \"2024\"\n\n# 2024 people (Bob left, Frank joined)\npeople_2024 = {\n    \"alice\": {\"name\": \"Alice\", \"age\": 27, \"role\": \"tech_lead\", \"salary\": 110000},\n    \"charlie\": {\"name\": \"Charlie\", \"age\": 30, \"role\": \"senior_engineer\", \"salary\": 98000},\n    \"diana\": {\"name\": \"Diana\", \"age\": 37, \"role\": \"vp\", \"salary\": 150000},\n    \"eve\": {\"name\": \"Eve\", \"age\": 28, \"role\": \"senior_engineer\", \"salary\": 95000},\n    \"frank\": {\"name\": \"Frank\", \"age\": 32, \"role\": \"manager\", \"salary\": 100000},  # Replaced Bob\n}\n\nfor vid, attrs in people_2024.items():\n    if not G.has_vertex(vid):\n        G.add_vertex(vid, **attrs)\n\n# 2024 collaborations\ncollaborations_2024 = [\n    (\"alice\", \"frank\", 0.9, {\"project\": \"NextGen\", \"hours\": 160}),\n    (\"alice\", \"eve\", 0.92, {\"project\": \"NextGen\", \"hours\": 170}),\n    (\"charlie\", \"eve\", 0.85, {\"project\": \"NextGen\", \"hours\": 120}),\n    (\"frank\", \"diana\", 0.8, {\"project\": \"Strategy\", \"hours\": 100}),\n    (\"eve\", \"diana\", 0.75, {\"project\": \"Strategy\", \"hours\": 80}),\n]\n\nfor source, target, weight, attrs in collaborations_2024:\n    G.add_edge(source, target, weight=weight, **attrs)\n\nprint(f\"\\n\u2713 Layer 2024:\")\nprint(f\"  Total vertices: {G.number_of_vertices()}\")\nprint(f\"  Edges in layer: {len(G.layers.edges('2024'))}\")\n\nprint(f\"\\n{'='*60}\")\nprint(\"GRAPH SUMMARY\")\nprint(f\"{'='*60}\")\nprint(f\"Total unique vertices: {G.number_of_vertices()}\")\nprint(f\"Total unique edges: {G.number_of_edges()}\")\nprint(f\"Layers: {G.layers.count()}\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"LAYER 2024: Adding nodes and edges\") print(\"=\" * 60)  G.layers.active = \"2024\"  # 2024 people (Bob left, Frank joined) people_2024 = {     \"alice\": {\"name\": \"Alice\", \"age\": 27, \"role\": \"tech_lead\", \"salary\": 110000},     \"charlie\": {\"name\": \"Charlie\", \"age\": 30, \"role\": \"senior_engineer\", \"salary\": 98000},     \"diana\": {\"name\": \"Diana\", \"age\": 37, \"role\": \"vp\", \"salary\": 150000},     \"eve\": {\"name\": \"Eve\", \"age\": 28, \"role\": \"senior_engineer\", \"salary\": 95000},     \"frank\": {\"name\": \"Frank\", \"age\": 32, \"role\": \"manager\", \"salary\": 100000},  # Replaced Bob }  for vid, attrs in people_2024.items():     if not G.has_vertex(vid):         G.add_vertex(vid, **attrs)  # 2024 collaborations collaborations_2024 = [     (\"alice\", \"frank\", 0.9, {\"project\": \"NextGen\", \"hours\": 160}),     (\"alice\", \"eve\", 0.92, {\"project\": \"NextGen\", \"hours\": 170}),     (\"charlie\", \"eve\", 0.85, {\"project\": \"NextGen\", \"hours\": 120}),     (\"frank\", \"diana\", 0.8, {\"project\": \"Strategy\", \"hours\": 100}),     (\"eve\", \"diana\", 0.75, {\"project\": \"Strategy\", \"hours\": 80}), ]  for source, target, weight, attrs in collaborations_2024:     G.add_edge(source, target, weight=weight, **attrs)  print(f\"\\n\u2713 Layer 2024:\") print(f\"  Total vertices: {G.number_of_vertices()}\") print(f\"  Edges in layer: {len(G.layers.edges('2024'))}\")  print(f\"\\n{'='*60}\") print(\"GRAPH SUMMARY\") print(f\"{'='*60}\") print(f\"Total unique vertices: {G.number_of_vertices()}\") print(f\"Total unique edges: {G.number_of_edges()}\") print(f\"Layers: {G.layers.count()}\") <pre>\n============================================================\nLAYER 2024: Adding nodes and edges\n============================================================\n\n\u2713 Layer 2024:\n  Total vertices: 6\n  Edges in layer: 5\n\n============================================================\nGRAPH SUMMARY\n============================================================\nTotal unique vertices: 6\nTotal unique edges: 14\nLayers: 4\n</pre> In\u00a0[29]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"TESTING ANNNET PROPERTIES\")\nprint(\"=\" * 60)\n\n# Test obs (vertex attributes)\nprint(\"\\n1. obs (vertex attributes):\")\nprint(G.obs)\nprint(f\"\\n   Shape: {G.obs.shape}\")\nprint(f\"   Columns: {G.obs.columns}\")\n\n# Test var (edge attributes)\nprint(\"\\n2. var (edge attributes):\")\nprint(G.var.head())\nprint(f\"\\n   Shape: {G.var.shape}\")\nprint(f\"   Columns: {G.var.columns}\")\n\n# Test X (incidence matrix)\nprint(\"\\n3. X (incidence matrix):\")\nX = G.X()\nprint(f\"   Type: {type(X)}\")\nprint(f\"   Shape: {X.shape}\")\nprint(f\"   Non-zero entries: {X.nnz}\")\nprint(f\"   Density: {X.nnz / (X.shape[0] * X.shape[1]):.4f}\")\n\n# Test uns (unstructured metadata)\nprint(\"\\n4. uns (unstructured metadata):\")\nG.uns[\"dataset_name\"] = \"Company Collaboration Network\"\nG.uns[\"created\"] = datetime.now().isoformat()\nG.uns[\"description\"] = \"Multi-year collaboration network\"\nprint(f\"   {G.uns}\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"TESTING ANNNET PROPERTIES\") print(\"=\" * 60)  # Test obs (vertex attributes) print(\"\\n1. obs (vertex attributes):\") print(G.obs) print(f\"\\n   Shape: {G.obs.shape}\") print(f\"   Columns: {G.obs.columns}\")  # Test var (edge attributes) print(\"\\n2. var (edge attributes):\") print(G.var.head()) print(f\"\\n   Shape: {G.var.shape}\") print(f\"   Columns: {G.var.columns}\")  # Test X (incidence matrix) print(\"\\n3. X (incidence matrix):\") X = G.X() print(f\"   Type: {type(X)}\") print(f\"   Shape: {X.shape}\") print(f\"   Non-zero entries: {X.nnz}\") print(f\"   Density: {X.nnz / (X.shape[0] * X.shape[1]):.4f}\")  # Test uns (unstructured metadata) print(\"\\n4. uns (unstructured metadata):\") G.uns[\"dataset_name\"] = \"Company Collaboration Network\" G.uns[\"created\"] = datetime.now().isoformat() G.uns[\"description\"] = \"Multi-year collaboration network\" print(f\"   {G.uns}\") <pre>\n============================================================\nTESTING ANNNET PROPERTIES\n============================================================\n\n1. obs (vertex attributes):\nshape: (6, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 vertex_id \u2506 name    \u2506 age \u2506 role     \u2506 salary \u2502\n\u2502 ---       \u2506 ---     \u2506 --- \u2506 ---      \u2506 ---    \u2502\n\u2502 str       \u2506 str     \u2506 i64 \u2506 str      \u2506 i64    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 alice     \u2506 Alice   \u2506 25  \u2506 engineer \u2506 80000  \u2502\n\u2502 bob       \u2506 Bob     \u2506 30  \u2506 manager  \u2506 95000  \u2502\n\u2502 charlie   \u2506 Charlie \u2506 28  \u2506 engineer \u2506 85000  \u2502\n\u2502 diana     \u2506 Diana   \u2506 35  \u2506 director \u2506 120000 \u2502\n\u2502 eve       \u2506 Eve     \u2506 27  \u2506 engineer \u2506 83000  \u2502\n\u2502 frank     \u2506 Frank   \u2506 32  \u2506 manager  \u2506 100000 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n   Shape: (6, 5)\n   Columns: ['vertex_id', 'name', 'age', 'role', 'salary']\n\n2. var (edge attributes):\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id \u2506 project    \u2506 hours \u2502\n\u2502 ---     \u2506 ---        \u2506 ---   \u2502\n\u2502 str     \u2506 str        \u2506 i64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_0  \u2506 ProjectX   \u2506 120   \u2502\n\u2502 edge_1  \u2506 ProjectX   \u2506 150   \u2502\n\u2502 edge_2  \u2506 Management \u2506 80    \u2502\n\u2502 edge_3  \u2506 ProjectY   \u2506 60    \u2502\n\u2502 edge_4  \u2506 ProjectZ   \u2506 140   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n   Shape: (14, 3)\n   Columns: ['edge_id', 'project', 'hours']\n\n3. X (incidence matrix):\n   Type: &lt;class 'scipy.sparse._dok.dok_matrix'&gt;\n   Shape: (8, 16)\n   Non-zero entries: 28\n   Density: 0.2188\n\n4. uns (unstructured metadata):\n   {'dataset_name': 'Company Collaboration Network', 'created': '2025-10-23T20:01:28.206121', 'description': 'Multi-year collaboration network'}\n</pre> In\u00a0[31]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"TESTING LAYERMANAGER\")\nprint(\"=\" * 60)\n\n# Basic operations\nprint(\"\\n1. Layer Info:\")\nprint(f\"   Active layer: {G.layers.active}\")\nprint(f\"   All layers: {G.layers.list()}\")\nprint(f\"   Layer count: {G.layers.count()}\")\n\n# Layer statistics\nprint(\"\\n2. Layer Statistics:\")\nstats = G.layers.stats()\nfor layer_id, info in stats.items():\n    print(f\"\\n   {layer_id}:\")\n    print(f\"     Vertices: {info['vertices']}\")\n    print(f\"     Edges: {info['edges']}\")\n    print(f\"     Attributes: {info['attributes']}\")\n\n# Layer operations - union\nprint(\"\\n3. Union of 2022 and 2023:\")\nunion_result = G.layers.union([\"2022\", \"2023\"])\nprint(f\"   Vertices: {len(union_result['vertices'])}\")\nprint(f\"   Edges: {len(union_result['edges'])}\")\nprint(f\"   Vertex IDs: {sorted(union_result['vertices'])}\")\n\n# Layer operations - intersection\nprint(\"\\n4. Intersection of 2022 and 2023:\")\nintersect_result = G.layers.intersect([\"2022\", \"2023\"])\nprint(f\"   Common vertices: {sorted(intersect_result['vertices'])}\")\nprint(f\"   Common edges: {len(intersect_result['edges'])}\")\n\n# Create aggregated layer\nprint(\"\\n5. Create 'all_years' layer (union):\")\nG.layers.union_create([\"2022\", \"2023\", \"2024\"], \"all_years\", \n                     description=\"All years combined\")\nprint(f\"   \u2713 Created layer: all_years\")\nprint(f\"   Vertices: {len(G.layers.vertices('all_years'))}\")\nprint(f\"   Edges: {len(G.layers.edges('all_years'))}\")\n\n# Summary\nprint(\"\\n6. Layer Summary:\")\nprint(G.layers.summary())\n</pre> print(\"\\n\" + \"=\" * 60) print(\"TESTING LAYERMANAGER\") print(\"=\" * 60)  # Basic operations print(\"\\n1. Layer Info:\") print(f\"   Active layer: {G.layers.active}\") print(f\"   All layers: {G.layers.list()}\") print(f\"   Layer count: {G.layers.count()}\")  # Layer statistics print(\"\\n2. Layer Statistics:\") stats = G.layers.stats() for layer_id, info in stats.items():     print(f\"\\n   {layer_id}:\")     print(f\"     Vertices: {info['vertices']}\")     print(f\"     Edges: {info['edges']}\")     print(f\"     Attributes: {info['attributes']}\")  # Layer operations - union print(\"\\n3. Union of 2022 and 2023:\") union_result = G.layers.union([\"2022\", \"2023\"]) print(f\"   Vertices: {len(union_result['vertices'])}\") print(f\"   Edges: {len(union_result['edges'])}\") print(f\"   Vertex IDs: {sorted(union_result['vertices'])}\")  # Layer operations - intersection print(\"\\n4. Intersection of 2022 and 2023:\") intersect_result = G.layers.intersect([\"2022\", \"2023\"]) print(f\"   Common vertices: {sorted(intersect_result['vertices'])}\") print(f\"   Common edges: {len(intersect_result['edges'])}\")  # Create aggregated layer print(\"\\n5. Create 'all_years' layer (union):\") G.layers.union_create([\"2022\", \"2023\", \"2024\"], \"all_years\",                       description=\"All years combined\") print(f\"   \u2713 Created layer: all_years\") print(f\"   Vertices: {len(G.layers.vertices('all_years'))}\") print(f\"   Edges: {len(G.layers.edges('all_years'))}\")  # Summary print(\"\\n6. Layer Summary:\") print(G.layers.summary()) <pre>\n============================================================\nTESTING LAYERMANAGER\n============================================================\n\n1. Layer Info:\n   Active layer: 2024\n   All layers: ['2022', '2023', '2024']\n   Layer count: 4\n\n2. Layer Statistics:\n\n   2022:\n     Vertices: 4\n     Edges: 4\n     Attributes: {'year': 2022, 'description': 'Year 2022'}\n\n   2023:\n     Vertices: 5\n     Edges: 5\n     Attributes: {'year': 2023, 'description': 'Year 2023'}\n\n   2024:\n     Vertices: 5\n     Edges: 5\n     Attributes: {'year': 2024, 'description': 'Year 2024'}\n\n3. Union of 2022 and 2023:\n   Vertices: 5\n   Edges: 9\n   Vertex IDs: ['alice', 'bob', 'charlie', 'diana', 'eve']\n\n4. Intersection of 2022 and 2023:\n   Common vertices: ['alice', 'bob', 'charlie', 'diana']\n   Common edges: 0\n\n5. Create 'all_years' layer (union):\n   \u2713 Created layer: all_years\n   Vertices: 6\n   Edges: 14\n\n6. Layer Summary:\nLayers: 5\n\u251c\u2500 default: 0 vertices, 0 edges\n\u251c\u2500 2022: 4 vertices, 4 edges\n\u251c\u2500 2023: 5 vertices, 5 edges\n\u251c\u2500 2024: 5 vertices, 5 edges\n\u2514\u2500 all_years: 6 vertices, 14 edges\n</pre> In\u00a0[33]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"TESTING CROSS-LAYER ANALYTICS\")\nprint(\"=\" * 60)\n\n# Vertex presence\nprint(\"\\n1. Vertex Presence Across Layers:\")\nfor vid in [\"alice\", \"bob\", \"eve\", \"frank\"]:\n    layers = G.layers.vertex_presence(vid)\n    print(f\"   {vid}: {layers}\")\n\n# Edge presence\nprint(\"\\n2. Edge Presence (alice\u2192bob):\")\nedge_presence = G.layers.edge_presence(source=\"alice\", target=\"bob\")\nfor layer_id, edge_ids in edge_presence.items():\n    print(f\"   {layer_id}: {edge_ids}\")\n\n# Conserved edges\nprint(\"\\n3. Conserved Edges (in 2+ layers):\")\nconserved = G.layers.conserved_edges(min_layers=2)\nprint(f\"   Found {len(conserved)} conserved edges:\")\nfor eid, count in sorted(conserved.items(), key=lambda x: x[1], reverse=True)[:5]:\n    edge_def = G.edge_definitions.get(eid)\n    if edge_def:\n        print(f\"   {eid}: {edge_def[0]} \u2192 {edge_def[1]} (in {count} layers)\")\n\n# Layer-specific edges\nprint(\"\\n4. Layer-Specific Edges:\")\nfor layer_id in [\"2022\", \"2023\", \"2024\"]:\n    specific = G.layers.specific_edges(layer_id)\n    print(f\"   {layer_id} only: {len(specific)} edges\")\n\n# Temporal dynamics\nprint(\"\\n5. Temporal Dynamics:\")\nchanges = G.layers.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"edge_change\")\nfor i, change in enumerate(changes):\n    year_from = [\"2022\", \"2023\"][i]\n    year_to = [\"2023\", \"2024\"][i]\n    print(f\"\\n   {year_from} \u2192 {year_to}:\")\n    print(f\"     Edges added: {change['added']}\")\n    print(f\"     Edges removed: {change['removed']}\")\n    print(f\"     Net change: {change['net_change']:+d}\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"TESTING CROSS-LAYER ANALYTICS\") print(\"=\" * 60)  # Vertex presence print(\"\\n1. Vertex Presence Across Layers:\") for vid in [\"alice\", \"bob\", \"eve\", \"frank\"]:     layers = G.layers.vertex_presence(vid)     print(f\"   {vid}: {layers}\")  # Edge presence print(\"\\n2. Edge Presence (alice\u2192bob):\") edge_presence = G.layers.edge_presence(source=\"alice\", target=\"bob\") for layer_id, edge_ids in edge_presence.items():     print(f\"   {layer_id}: {edge_ids}\")  # Conserved edges print(\"\\n3. Conserved Edges (in 2+ layers):\") conserved = G.layers.conserved_edges(min_layers=2) print(f\"   Found {len(conserved)} conserved edges:\") for eid, count in sorted(conserved.items(), key=lambda x: x[1], reverse=True)[:5]:     edge_def = G.edge_definitions.get(eid)     if edge_def:         print(f\"   {eid}: {edge_def[0]} \u2192 {edge_def[1]} (in {count} layers)\")  # Layer-specific edges print(\"\\n4. Layer-Specific Edges:\") for layer_id in [\"2022\", \"2023\", \"2024\"]:     specific = G.layers.specific_edges(layer_id)     print(f\"   {layer_id} only: {len(specific)} edges\")  # Temporal dynamics print(\"\\n5. Temporal Dynamics:\") changes = G.layers.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"edge_change\") for i, change in enumerate(changes):     year_from = [\"2022\", \"2023\"][i]     year_to = [\"2023\", \"2024\"][i]     print(f\"\\n   {year_from} \u2192 {year_to}:\")     print(f\"     Edges added: {change['added']}\")     print(f\"     Edges removed: {change['removed']}\")     print(f\"     Net change: {change['net_change']:+d}\") <pre>\n============================================================\nTESTING CROSS-LAYER ANALYTICS\n============================================================\n\n1. Vertex Presence Across Layers:\n   alice: ['2022', '2023', '2024', 'all_years']\n   bob: ['2022', '2023', 'all_years']\n   eve: ['2023', '2024', 'all_years']\n   frank: ['2024', 'all_years']\n\n2. Edge Presence (alice\u2192bob):\n   2022: ['edge_0']\n   2023: ['edge_4']\n   all_years: ['edge_4', 'edge_0']\n\n3. Conserved Edges (in 2+ layers):\n   Found 14 conserved edges:\n   edge_3: charlie \u2192 diana (in 2 layers)\n   edge_1: alice \u2192 charlie (in 2 layers)\n   edge_0: alice \u2192 bob (in 2 layers)\n   edge_2: bob \u2192 diana (in 2 layers)\n   edge_4: alice \u2192 bob (in 2 layers)\n\n4. Layer-Specific Edges:\n   2022 only: 0 edges\n   2023 only: 0 edges\n   2024 only: 0 edges\n\n5. Temporal Dynamics:\n\n   2022 \u2192 2023:\n     Edges added: 5\n     Edges removed: 4\n     Net change: +1\n\n   2023 \u2192 2024:\n     Edges added: 5\n     Edges removed: 5\n     Net change: +0\n</pre> In\u00a0[35]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"TESTING INDEXMANAGER\")\nprint(\"=\" * 60)\n\n# Entity lookups\nprint(\"\\n1. Entity Index Lookups:\")\nprint(f\"   alice \u2192 row index: {G.idx.entity_to_row('alice')}\")\nprint(f\"   diana \u2192 row index: {G.idx.entity_to_row('diana')}\")\nprint(f\"   Row 0 \u2192 entity: {G.idx.row_to_entity(0)}\")\nprint(f\"   Row 3 \u2192 entity: {G.idx.row_to_entity(3)}\")\n\n# Edge lookups\nprint(\"\\n2. Edge Index Lookups:\")\nedge_ids = list(G.edge_to_idx.keys())[:3]\nfor eid in edge_ids:\n    col = G.idx.edge_to_col(eid)\n    back = G.idx.col_to_edge(col)\n    print(f\"   {eid} \u2192 col {col} \u2192 {back}\")\n\n# Batch lookups\nprint(\"\\n3. Batch Lookups:\")\nvertices = [\"alice\", \"bob\", \"charlie\"]\nrows = G.idx.entities_to_rows(vertices)\nprint(f\"   {vertices}\")\nprint(f\"   \u2192 rows: {rows}\")\nback_entities = G.idx.rows_to_entities(rows)\nprint(f\"   \u2192 back: {back_entities}\")\n\n# Check existence\nprint(\"\\n4. Existence Checks:\")\nprint(f\"   'alice' exists: {G.idx.has_entity('alice')}\")\nprint(f\"   'unknown' exists: {G.idx.has_entity('unknown')}\")\nprint(f\"   edge count: {G.idx.edge_count()}\")\nprint(f\"   entity count: {G.idx.entity_count()}\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"TESTING INDEXMANAGER\") print(\"=\" * 60)  # Entity lookups print(\"\\n1. Entity Index Lookups:\") print(f\"   alice \u2192 row index: {G.idx.entity_to_row('alice')}\") print(f\"   diana \u2192 row index: {G.idx.entity_to_row('diana')}\") print(f\"   Row 0 \u2192 entity: {G.idx.row_to_entity(0)}\") print(f\"   Row 3 \u2192 entity: {G.idx.row_to_entity(3)}\")  # Edge lookups print(\"\\n2. Edge Index Lookups:\") edge_ids = list(G.edge_to_idx.keys())[:3] for eid in edge_ids:     col = G.idx.edge_to_col(eid)     back = G.idx.col_to_edge(col)     print(f\"   {eid} \u2192 col {col} \u2192 {back}\")  # Batch lookups print(\"\\n3. Batch Lookups:\") vertices = [\"alice\", \"bob\", \"charlie\"] rows = G.idx.entities_to_rows(vertices) print(f\"   {vertices}\") print(f\"   \u2192 rows: {rows}\") back_entities = G.idx.rows_to_entities(rows) print(f\"   \u2192 back: {back_entities}\")  # Check existence print(\"\\n4. Existence Checks:\") print(f\"   'alice' exists: {G.idx.has_entity('alice')}\") print(f\"   'unknown' exists: {G.idx.has_entity('unknown')}\") print(f\"   edge count: {G.idx.edge_count()}\") print(f\"   entity count: {G.idx.entity_count()}\") <pre>\n============================================================\nTESTING INDEXMANAGER\n============================================================\n\n1. Entity Index Lookups:\n   alice \u2192 row index: 0\n   diana \u2192 row index: 3\n   Row 0 \u2192 entity: alice\n   Row 3 \u2192 entity: diana\n\n2. Edge Index Lookups:\n   edge_0 \u2192 col 0 \u2192 edge_0\n   edge_1 \u2192 col 1 \u2192 edge_1\n   edge_2 \u2192 col 2 \u2192 edge_2\n\n3. Batch Lookups:\n   ['alice', 'bob', 'charlie']\n   \u2192 rows: [0, 1, 2]\n   \u2192 back: ['alice', 'bob', 'charlie']\n\n4. Existence Checks:\n   'alice' exists: True\n   'unknown' exists: False\n   edge count: 14\n   entity count: 6\n</pre> In\u00a0[37]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"TESTING CACHEMANAGER\")\nprint(\"=\" * 60)\n\n# Check cache status\nprint(\"\\n1. Initial Cache Status:\")\nprint(f\"   CSR cached: {G.cache.has_csr()}\")\nprint(f\"   CSC cached: {G.cache.has_csc()}\")\n\n# Build CSR\nprint(\"\\n2. Building CSR cache...\")\nimport time\nt0 = time.time()\ncsr = G.cache.get_csr()\nt1 = time.time()\nprint(f\"   \u2713 Built in {(t1-t0)*1000:.2f}ms\")\nprint(f\"   Shape: {csr.shape}\")\nprint(f\"   Type: {type(csr)}\")\n\n# Build CSC\nprint(\"\\n3. Building CSC cache...\")\nt0 = time.time()\ncsc = G.cache.get_csc()\nt1 = time.time()\nprint(f\"   \u2713 Built in {(t1-t0)*1000:.2f}ms\")\nprint(f\"   Shape: {csc.shape}\")\n\n# Check cache hit\nprint(\"\\n4. Cache Hit Test:\")\nt0 = time.time()\ncsr2 = G.cache.get_csr()  # Should be instant\nt1 = time.time()\nprint(f\"   \u2713 Retrieved in {(t1-t0)*1000:.4f}ms (cached)\")\n\n# Clear cache\nprint(\"\\n5. Clearing Cache:\")\nG.cache.clear()\nprint(f\"   CSR cached: {G.cache.has_csr()}\")\nprint(f\"   CSC cached: {G.cache.has_csc()}\")\n\n# Rebuild\nprint(\"\\n6. Rebuild All:\")\nG.cache.build()\nprint(f\"   \u2713 CSR cached: {G.cache.has_csr()}\")\nprint(f\"   \u2713 CSC cached: {G.cache.has_csc()}\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"TESTING CACHEMANAGER\") print(\"=\" * 60)  # Check cache status print(\"\\n1. Initial Cache Status:\") print(f\"   CSR cached: {G.cache.has_csr()}\") print(f\"   CSC cached: {G.cache.has_csc()}\")  # Build CSR print(\"\\n2. Building CSR cache...\") import time t0 = time.time() csr = G.cache.get_csr() t1 = time.time() print(f\"   \u2713 Built in {(t1-t0)*1000:.2f}ms\") print(f\"   Shape: {csr.shape}\") print(f\"   Type: {type(csr)}\")  # Build CSC print(\"\\n3. Building CSC cache...\") t0 = time.time() csc = G.cache.get_csc() t1 = time.time() print(f\"   \u2713 Built in {(t1-t0)*1000:.2f}ms\") print(f\"   Shape: {csc.shape}\")  # Check cache hit print(\"\\n4. Cache Hit Test:\") t0 = time.time() csr2 = G.cache.get_csr()  # Should be instant t1 = time.time() print(f\"   \u2713 Retrieved in {(t1-t0)*1000:.4f}ms (cached)\")  # Clear cache print(\"\\n5. Clearing Cache:\") G.cache.clear() print(f\"   CSR cached: {G.cache.has_csr()}\") print(f\"   CSC cached: {G.cache.has_csc()}\")  # Rebuild print(\"\\n6. Rebuild All:\") G.cache.build() print(f\"   \u2713 CSR cached: {G.cache.has_csr()}\") print(f\"   \u2713 CSC cached: {G.cache.has_csc()}\") <pre>\n============================================================\nTESTING CACHEMANAGER\n============================================================\n\n1. Initial Cache Status:\n   CSR cached: False\n   CSC cached: False\n\n2. Building CSR cache...\n   \u2713 Built in 0.93ms\n   Shape: (8, 16)\n   Type: &lt;class 'scipy.sparse._csr.csr_matrix'&gt;\n\n3. Building CSC cache...\n   \u2713 Built in 1.08ms\n   Shape: (8, 16)\n\n4. Cache Hit Test:\n   \u2713 Retrieved in 0.0000ms (cached)\n\n5. Clearing Cache:\n   CSR cached: False\n   CSC cached: False\n\n6. Rebuild All:\n   \u2713 CSR cached: True\n   \u2713 CSC cached: True\n</pre> In\u00a0[39]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"TESTING GRAPHVIEW - BASIC FILTERING\")\nprint(\"=\" * 60)\n\n# View specific nodes\nprint(\"\\n1. View Specific Nodes:\")\nv = G.view(nodes=[\"alice\", \"bob\", \"charlie\"])\nprint(f\"   View: {v}\")\nprint(f\"   Nodes: {v.node_count}\")\nprint(f\"   Edges: {v.edge_count}\")\nprint(f\"\\n   Node table:\")\nprint(v.obs)\n\n# View specific layer\nprint(\"\\n2. View Layer 2023:\")\nv2023 = G.view(layers=\"2023\")\nprint(f\"   View: {v2023}\")\nprint(f\"   Nodes: {v2023.node_count}\")\nprint(f\"   Edges: {v2023.edge_count}\")\n\n# View multiple layers\nprint(\"\\n3. View Layers 2022+2023:\")\nv_early = G.view(layers=[\"2022\", \"2023\"])\nprint(f\"   View: {v_early}\")\nprint(f\"   Nodes: {v_early.node_count}\")\nprint(f\"   Edges: {v_early.edge_count}\")\n\n# Combined filters\nprint(\"\\n4. Combined: Specific nodes in 2023:\")\nv_combo = G.view(nodes=[\"alice\", \"eve\"], layers=\"2023\")\nprint(f\"   View: {v_combo}\")\nprint(f\"   Nodes: {v_combo.node_count}\")\nprint(f\"   Edges: {v_combo.edge_count}\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"TESTING GRAPHVIEW - BASIC FILTERING\") print(\"=\" * 60)  # View specific nodes print(\"\\n1. View Specific Nodes:\") v = G.view(nodes=[\"alice\", \"bob\", \"charlie\"]) print(f\"   View: {v}\") print(f\"   Nodes: {v.node_count}\") print(f\"   Edges: {v.edge_count}\") print(f\"\\n   Node table:\") print(v.obs)  # View specific layer print(\"\\n2. View Layer 2023:\") v2023 = G.view(layers=\"2023\") print(f\"   View: {v2023}\") print(f\"   Nodes: {v2023.node_count}\") print(f\"   Edges: {v2023.edge_count}\")  # View multiple layers print(\"\\n3. View Layers 2022+2023:\") v_early = G.view(layers=[\"2022\", \"2023\"]) print(f\"   View: {v_early}\") print(f\"   Nodes: {v_early.node_count}\") print(f\"   Edges: {v_early.edge_count}\")  # Combined filters print(\"\\n4. Combined: Specific nodes in 2023:\") v_combo = G.view(nodes=[\"alice\", \"eve\"], layers=\"2023\") print(f\"   View: {v_combo}\") print(f\"   Nodes: {v_combo.node_count}\") print(f\"   Edges: {v_combo.edge_count}\") <pre>\n============================================================\nTESTING GRAPHVIEW - BASIC FILTERING\n============================================================\n\n1. View Specific Nodes:\n   View: GraphView(nodes=3, edges=14)\n   Nodes: 3\n   Edges: 14\n\n   Node table:\nshape: (3, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 vertex_id \u2506 name    \u2506 age \u2506 role     \u2506 salary \u2502\n\u2502 ---       \u2506 ---     \u2506 --- \u2506 ---      \u2506 ---    \u2502\n\u2502 str       \u2506 str     \u2506 i64 \u2506 str      \u2506 i64    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 alice     \u2506 Alice   \u2506 25  \u2506 engineer \u2506 80000  \u2502\n\u2502 bob       \u2506 Bob     \u2506 30  \u2506 manager  \u2506 95000  \u2502\n\u2502 charlie   \u2506 Charlie \u2506 28  \u2506 engineer \u2506 85000  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n2. View Layer 2023:\n   View: GraphView(nodes=5, edges=5)\n   Nodes: 5\n   Edges: 5\n\n3. View Layers 2022+2023:\n   View: GraphView(nodes=5, edges=9)\n   Nodes: 5\n   Edges: 9\n\n4. Combined: Specific nodes in 2023:\n   View: GraphView(nodes=2, edges=1)\n   Nodes: 2\n   Edges: 1\n</pre> In\u00a0[41]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"TESTING GRAPHVIEW - PREDICATE FILTERING\")\nprint(\"=\" * 60)\n\n# View by node predicate (high salary)\nprint(\"\\n1. High Salary Employees (&gt;100k):\")\nv_rich = G.view(nodes=lambda vid: \n    G.get_vertex_attrs(vid).get(\"salary\", 0) &gt; 100000\n)\nprint(f\"   View: {v_rich}\")\nprint(f\"   High earners: {sorted(v_rich.node_ids)}\")\nprint(f\"\\n   Details:\")\nprint(v_rich.obs.select([\"vertex_id\", \"name\", \"salary\", \"role\"]))\n\n# View by edge predicate (strong collaboration)\nprint(\"\\n2. Strong Collaborations (weight &gt; 0.8):\")\nv_strong = G.view(edges=lambda eid:\n    G.edge_weights.get(eid, 0) &gt; 0.8\n)\nprint(f\"   View: {v_strong}\")\nprint(f\"   Strong edges: {v_strong.edge_count}\")\nedges_df = v_strong.edges_df(include_weight=True)\nprint(f\"\\n   Top collaborations:\")\nprint(edges_df.select([\"edge_id\", \"source\", \"target\", \"global_weight\"]).head(10))\n\n# Combined predicate (engineers in recent years)\nprint(\"\\n3. Engineers in 2023/2024:\")\nv_eng = G.view(\n    nodes=lambda vid: \"engineer\" in G.get_vertex_attrs(vid).get(\"role\", \"\"),\n    layers=[\"2023\", \"2024\"]\n)\nprint(f\"   View: {v_eng}\")\nprint(f\"   Engineers: {sorted(v_eng.node_ids)}\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"TESTING GRAPHVIEW - PREDICATE FILTERING\") print(\"=\" * 60)  # View by node predicate (high salary) print(\"\\n1. High Salary Employees (&gt;100k):\") v_rich = G.view(nodes=lambda vid:      G.get_vertex_attrs(vid).get(\"salary\", 0) &gt; 100000 ) print(f\"   View: {v_rich}\") print(f\"   High earners: {sorted(v_rich.node_ids)}\") print(f\"\\n   Details:\") print(v_rich.obs.select([\"vertex_id\", \"name\", \"salary\", \"role\"]))  # View by edge predicate (strong collaboration) print(\"\\n2. Strong Collaborations (weight &gt; 0.8):\") v_strong = G.view(edges=lambda eid:     G.edge_weights.get(eid, 0) &gt; 0.8 ) print(f\"   View: {v_strong}\") print(f\"   Strong edges: {v_strong.edge_count}\") edges_df = v_strong.edges_df(include_weight=True) print(f\"\\n   Top collaborations:\") print(edges_df.select([\"edge_id\", \"source\", \"target\", \"global_weight\"]).head(10))  # Combined predicate (engineers in recent years) print(\"\\n3. Engineers in 2023/2024:\") v_eng = G.view(     nodes=lambda vid: \"engineer\" in G.get_vertex_attrs(vid).get(\"role\", \"\"),     layers=[\"2023\", \"2024\"] ) print(f\"   View: {v_eng}\") print(f\"   Engineers: {sorted(v_eng.node_ids)}\") <pre>\n============================================================\nTESTING GRAPHVIEW - PREDICATE FILTERING\n============================================================\n\n1. High Salary Employees (&gt;100k):\n   View: GraphView(nodes=1, edges=14)\n   High earners: ['diana']\n\n   Details:\nshape: (1, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 vertex_id \u2506 name  \u2506 salary \u2506 role     \u2502\n\u2502 ---       \u2506 ---   \u2506 ---    \u2506 ---      \u2502\n\u2502 str       \u2506 str   \u2506 i64    \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 diana     \u2506 Diana \u2506 120000 \u2506 director \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n2. Strong Collaborations (weight &gt; 0.8):\n   View: GraphView(nodes=6, edges=6)\n   Strong edges: 6\n\n   Top collaborations:\nshape: (6, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id \u2506 source  \u2506 target  \u2506 global_weight \u2502\n\u2502 ---     \u2506 ---     \u2506 ---     \u2506 ---           \u2502\n\u2502 str     \u2506 str     \u2506 str     \u2506 f64           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_1  \u2506 alice   \u2506 charlie \u2506 0.9           \u2502\n\u2502 edge_4  \u2506 alice   \u2506 bob     \u2506 0.85          \u2502\n\u2502 edge_5  \u2506 alice   \u2506 eve     \u2506 0.95          \u2502\n\u2502 edge_9  \u2506 alice   \u2506 frank   \u2506 0.9           \u2502\n\u2502 edge_10 \u2506 alice   \u2506 eve     \u2506 0.92          \u2502\n\u2502 edge_11 \u2506 charlie \u2506 eve     \u2506 0.85          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n3. Engineers in 2023/2024:\n   View: GraphView(nodes=3, edges=4)\n   Engineers: ['alice', 'charlie', 'eve']\n</pre> In\u00a0[43]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"TESTING GRAPHVIEW - ADVANCED OPERATIONS\")\nprint(\"=\" * 60)\n\n# Access properties\nprint(\"\\n1. View Properties:\")\nv = G.view(layers=\"2023\")\nprint(f\"   node_count: {v.node_count}\")\nprint(f\"   edge_count: {v.edge_count}\")\nprint(f\"   node_ids: {sorted(list(v.node_ids))}\")\nprint(f\"\\n   Matrix shape: {v.X.shape}\")\nprint(f\"   Matrix nnz: {v.X.nnz}\")\n\n# Get DataFrames\nprint(\"\\n2. View DataFrames:\")\nvertices_df = v.vertices_df()\nedges_df = v.edges_df(include_weight=True, include_directed=True)\nprint(f\"   Vertices DF: {vertices_df.shape}\")\nprint(f\"   Edges DF: {edges_df.shape}\")\n\n# Summary\nprint(\"\\n3. View Summary:\")\nprint(v.summary())\n\n# Nested views\nprint(\"\\n4. Nested Views:\")\nv1 = G.view(layers=\"2023\")\nprint(f\"   v1 (2023): {v1.node_count} nodes, {v1.edge_count} edges\")\n\nv2 = v1.subview(nodes=[\"alice\", \"bob\", \"eve\"])\nprint(f\"   v2 (alice/bob/eve in 2023): {v2.node_count} nodes, {v2.edge_count} edges\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"TESTING GRAPHVIEW - ADVANCED OPERATIONS\") print(\"=\" * 60)  # Access properties print(\"\\n1. View Properties:\") v = G.view(layers=\"2023\") print(f\"   node_count: {v.node_count}\") print(f\"   edge_count: {v.edge_count}\") print(f\"   node_ids: {sorted(list(v.node_ids))}\") print(f\"\\n   Matrix shape: {v.X.shape}\") print(f\"   Matrix nnz: {v.X.nnz}\")  # Get DataFrames print(\"\\n2. View DataFrames:\") vertices_df = v.vertices_df() edges_df = v.edges_df(include_weight=True, include_directed=True) print(f\"   Vertices DF: {vertices_df.shape}\") print(f\"   Edges DF: {edges_df.shape}\")  # Summary print(\"\\n3. View Summary:\") print(v.summary())  # Nested views print(\"\\n4. Nested Views:\") v1 = G.view(layers=\"2023\") print(f\"   v1 (2023): {v1.node_count} nodes, {v1.edge_count} edges\")  v2 = v1.subview(nodes=[\"alice\", \"bob\", \"eve\"]) print(f\"   v2 (alice/bob/eve in 2023): {v2.node_count} nodes, {v2.edge_count} edges\") <pre>\n============================================================\nTESTING GRAPHVIEW - ADVANCED OPERATIONS\n============================================================\n\n1. View Properties:\n   node_count: 5\n   edge_count: 5\n   node_ids: ['alice', 'bob', 'charlie', 'diana', 'eve']\n\n   Matrix shape: (5, 5)\n   Matrix nnz: 10\n\n2. View DataFrames:\n   Vertices DF: (5, 5)\n   Edges DF: (5, 13)\n\n3. View Summary:\nGraphView Summary\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nNodes: 5\nEdges: 5\nFilters: layers=['2023']\n\n4. Nested Views:\n   v1 (2023): 5 nodes, 5 edges\n   v2 (alice/bob/eve in 2023): 3 nodes, 2 edges\n</pre> In\u00a0[45]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"TESTING GRAPHVIEW - MATERIALIZATION\")\nprint(\"=\" * 60)\n\n# Materialize layer 2023\nprint(\"\\n1. Materialize Layer 2023:\")\nv2023 = G.view(layers=\"2023\")\nsubG = v2023.materialize(copy_attributes=True)\n\nprint(f\"   Original graph: {G.number_of_vertices()} nodes, {G.number_of_edges()} edges\")\nprint(f\"   Subgraph 2023: {subG.number_of_vertices()} nodes, {subG.number_of_edges()} edges\")\nprint(f\"   Subgraph vertices: {sorted(subG.vertices())}\")\n\n# Check attributes were copied\nprint(f\"\\n   Sample attributes:\")\nalice_attrs = subG.get_vertex_attrs(\"alice\")\nprint(f\"   alice: {alice_attrs}\")\n\n# Materialize high earners\nprint(\"\\n2. Materialize High Earners Network:\")\nv_rich = G.view(nodes=lambda vid: \n    G.get_vertex_attrs(vid).get(\"salary\", 0) &gt; 95000\n)\nrich_network = v_rich.materialize(copy_attributes=True)\n\nprint(f\"   High earners network: {rich_network.number_of_vertices()} nodes\")\nprint(f\"   Nodes: {sorted(rich_network.vertices())}\")\nprint(f\"   Edges: {rich_network.number_of_edges()}\")\n\n# Verify independence\nprint(\"\\n3. Verify Independence:\")\nprint(f\"   Original graph edges: {G.number_of_edges()}\")\nprint(f\"   Subgraph edges: {subG.number_of_edges()}\")\nsubG.add_vertex(\"test_node\")\nprint(f\"   After modifying subgraph:\")\nprint(f\"     Original: {G.number_of_vertices()} nodes\")\nprint(f\"     Subgraph: {subG.number_of_vertices()} nodes\")\nprint(f\"   \u2713 Graphs are independent\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"TESTING GRAPHVIEW - MATERIALIZATION\") print(\"=\" * 60)  # Materialize layer 2023 print(\"\\n1. Materialize Layer 2023:\") v2023 = G.view(layers=\"2023\") subG = v2023.materialize(copy_attributes=True)  print(f\"   Original graph: {G.number_of_vertices()} nodes, {G.number_of_edges()} edges\") print(f\"   Subgraph 2023: {subG.number_of_vertices()} nodes, {subG.number_of_edges()} edges\") print(f\"   Subgraph vertices: {sorted(subG.vertices())}\")  # Check attributes were copied print(f\"\\n   Sample attributes:\") alice_attrs = subG.get_vertex_attrs(\"alice\") print(f\"   alice: {alice_attrs}\")  # Materialize high earners print(\"\\n2. Materialize High Earners Network:\") v_rich = G.view(nodes=lambda vid:      G.get_vertex_attrs(vid).get(\"salary\", 0) &gt; 95000 ) rich_network = v_rich.materialize(copy_attributes=True)  print(f\"   High earners network: {rich_network.number_of_vertices()} nodes\") print(f\"   Nodes: {sorted(rich_network.vertices())}\") print(f\"   Edges: {rich_network.number_of_edges()}\")  # Verify independence print(\"\\n3. Verify Independence:\") print(f\"   Original graph edges: {G.number_of_edges()}\") print(f\"   Subgraph edges: {subG.number_of_edges()}\") subG.add_vertex(\"test_node\") print(f\"   After modifying subgraph:\") print(f\"     Original: {G.number_of_vertices()} nodes\") print(f\"     Subgraph: {subG.number_of_vertices()} nodes\") print(f\"   \u2713 Graphs are independent\") <pre>\n============================================================\nTESTING GRAPHVIEW - MATERIALIZATION\n============================================================\n\n1. Materialize Layer 2023:\n   Original graph: 6 nodes, 14 edges\n   Subgraph 2023: 5 nodes, 5 edges\n   Subgraph vertices: ['alice', 'bob', 'charlie', 'diana', 'eve']\n\n   Sample attributes:\n   alice: {'vertex_id': 'alice', 'name': 'Alice', 'age': 25, 'role': 'engineer', 'salary': 80000}\n\n2. Materialize High Earners Network:\n   High earners network: 2 nodes\n   Nodes: ['diana', 'frank']\n   Edges: 1\n\n3. Verify Independence:\n   Original graph edges: 14\n   Subgraph edges: 5\n   After modifying subgraph:\n     Original: 6 nodes\n     Subgraph: 6 nodes\n   \u2713 Graphs are independent\n</pre> In\u00a0[47]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"TESTING SNAPSHOT AND DIFF\")\nprint(\"=\" * 60)\n\n# Create initial snapshot\nprint(\"\\n1. Create Initial Snapshot:\")\nG.layers.active = \"2024\"\nsnap1 = G.snapshot(\"initial_state\")\nprint(f\"   \u2713 Created snapshot: {snap1['label']}\")\nprint(f\"   Vertices: {snap1['counts']['vertices']}\")\nprint(f\"   Edges: {snap1['counts']['edges']}\")\nprint(f\"   Layers: {snap1['counts']['layers']}\")\n\n# Make changes\nprint(\"\\n2. Make Changes:\")\nprint(\"   Adding new vertices...\")\nG.add_vertex(\"grace\", name=\"Grace\", age=29, role=\"engineer\", salary=87000)\nG.add_vertex(\"henry\", name=\"Henry\", age=33, role=\"architect\", salary=115000)\n\nprint(\"   Adding new edges...\")\nG.add_edge(\"grace\", \"alice\", weight=0.85, project=\"Innovation\")\nG.add_edge(\"henry\", \"diana\", weight=0.9, project=\"Architecture\")\n\nprint(\"   Removing a vertex...\")\nG.remove_vertex(\"frank\")\n\n# Create second snapshot\nsnap2 = G.snapshot(\"after_changes\")\nprint(f\"\\n   \u2713 Created snapshot: {snap2['label']}\")\n\n# Diff\nprint(\"\\n3. Compare Snapshots:\")\ndiff = G.diff(\"initial_state\", \"after_changes\")\nprint(diff.summary())\n\nprint(f\"\\n   Details:\")\nprint(f\"   Added vertices: {sorted(diff.vertices_added)}\")\nprint(f\"   Removed vertices: {sorted(diff.vertices_removed)}\")\nprint(f\"   Added edges: {len(diff.edges_added)}\")\nprint(f\"   Removed edges: {len(diff.edges_removed)}\")\n\n# Compare with current\nprint(\"\\n4. Compare with Current State:\")\nG.add_vertex(\"iris\", name=\"Iris\", age=26, role=\"data_scientist\", salary=92000)\ndiff_current = G.diff(\"after_changes\")\nprint(diff_current.summary())\n\n# List all snapshots\nprint(\"\\n5. List All Snapshots:\")\nsnapshots = G.list_snapshots()\nfor snap in snapshots:\n    print(f\"\\n   {snap['label']}:\")\n    print(f\"     Timestamp: {snap['timestamp']}\")\n    print(f\"     Vertices: {snap['counts']['vertices']}\")\n    print(f\"     Edges: {snap['counts']['edges']}\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"TESTING SNAPSHOT AND DIFF\") print(\"=\" * 60)  # Create initial snapshot print(\"\\n1. Create Initial Snapshot:\") G.layers.active = \"2024\" snap1 = G.snapshot(\"initial_state\") print(f\"   \u2713 Created snapshot: {snap1['label']}\") print(f\"   Vertices: {snap1['counts']['vertices']}\") print(f\"   Edges: {snap1['counts']['edges']}\") print(f\"   Layers: {snap1['counts']['layers']}\")  # Make changes print(\"\\n2. Make Changes:\") print(\"   Adding new vertices...\") G.add_vertex(\"grace\", name=\"Grace\", age=29, role=\"engineer\", salary=87000) G.add_vertex(\"henry\", name=\"Henry\", age=33, role=\"architect\", salary=115000)  print(\"   Adding new edges...\") G.add_edge(\"grace\", \"alice\", weight=0.85, project=\"Innovation\") G.add_edge(\"henry\", \"diana\", weight=0.9, project=\"Architecture\")  print(\"   Removing a vertex...\") G.remove_vertex(\"frank\")  # Create second snapshot snap2 = G.snapshot(\"after_changes\") print(f\"\\n   \u2713 Created snapshot: {snap2['label']}\")  # Diff print(\"\\n3. Compare Snapshots:\") diff = G.diff(\"initial_state\", \"after_changes\") print(diff.summary())  print(f\"\\n   Details:\") print(f\"   Added vertices: {sorted(diff.vertices_added)}\") print(f\"   Removed vertices: {sorted(diff.vertices_removed)}\") print(f\"   Added edges: {len(diff.edges_added)}\") print(f\"   Removed edges: {len(diff.edges_removed)}\")  # Compare with current print(\"\\n4. Compare with Current State:\") G.add_vertex(\"iris\", name=\"Iris\", age=26, role=\"data_scientist\", salary=92000) diff_current = G.diff(\"after_changes\") print(diff_current.summary())  # List all snapshots print(\"\\n5. List All Snapshots:\") snapshots = G.list_snapshots() for snap in snapshots:     print(f\"\\n   {snap['label']}:\")     print(f\"     Timestamp: {snap['timestamp']}\")     print(f\"     Vertices: {snap['counts']['vertices']}\")     print(f\"     Edges: {snap['counts']['edges']}\") <pre>\n============================================================\nTESTING SNAPSHOT AND DIFF\n============================================================\n\n1. Create Initial Snapshot:\n   \u2713 Created snapshot: initial_state\n   Vertices: 6\n   Edges: 14\n   Layers: 5\n\n2. Make Changes:\n   Adding new vertices...\n   Adding new edges...\n   Removing a vertex...\n\n   \u2713 Created snapshot: after_changes\n\n3. Compare Snapshots:\nDiff: initial_state \u2192 after_changes\n\nVertices: +2 added, 1 removed\nEdges: +2 added, 2 removed\nLayers: +0 added, 0 removed\n\n   Details:\n   Added vertices: ['grace', 'henry']\n   Removed vertices: ['frank']\n   Added edges: 2\n   Removed edges: 2\n\n4. Compare with Current State:\nDiff: after_changes \u2192 current\n\nVertices: +1 added, 0 removed\nEdges: +0 added, 0 removed\nLayers: +0 added, 0 removed\n\n5. List All Snapshots:\n\n   initial_state:\n     Timestamp: 2025-10-23T19:01:31.548907+00:00\n     Vertices: 6\n     Edges: 14\n\n   after_changes:\n     Timestamp: 2025-10-23T19:01:31.553366+00:00\n     Vertices: 7\n     Edges: 14\n</pre> In\u00a0[56]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"ADVANCED ANALYSIS - NETWORK METRICS\")\nprint(\"=\" * 60)\n\n# Per-layer analysis\nprint(\"\\n1. Per-Layer Network Metrics:\")\nfor layer_id in [\"2022\", \"2023\", \"2024\"]:\n    v = G.view(layers=layer_id)\n    \n    print(f\"\\n   {layer_id}:\")\n    print(f\"     Nodes: {v.node_count}\")\n    print(f\"     Edges: {v.edge_count}\")\n    \n    if v.edge_count &gt; 0:\n        avg_weight = v.var.select(\"weight\").mean().item() if \"weight\" in v.var.columns else 0\n        print(f\"     Avg edge weight: {avg_weight:.3f}\")\n    \n    # Degree analysis (using materialized subgraph)\n    subG = v.materialize()\n    degrees = {vid: subG.degree(vid) for vid in subG.vertices()}\n    if degrees:\n        print(f\"     Avg degree: {sum(degrees.values()) / len(degrees):.2f}\")\n        print(f\"     Max degree: {max(degrees.values())}\")\n        max_degree_node = max(degrees, key=degrees.get)\n        print(f\"     Hub: {max_degree_node} (degree={degrees[max_degree_node]})\")\n\n# Compare layers\nprint(\"\\n2. Layer Comparison:\")\nchanges = G.layers.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"vertex_change\")\nprint(\"\\n   Vertex changes over time:\")\nfor i, change in enumerate(changes):\n    year_from = [\"2022\", \"2023\"][i]\n    year_to = [\"2023\", \"2024\"][i]\n    print(f\"   {year_from}\u2192{year_to}: {change['added']:+d} added, {change['removed']} removed\")\n\nchanges = G.layers.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"edge_change\")\nprint(\"\\n   Edge changes over time:\")\nfor i, change in enumerate(changes):\n    year_from = [\"2022\", \"2023\"][i]\n    year_to = [\"2023\", \"2024\"][i]\n    print(f\"   {year_from}\u2192{year_to}: {change['added']:+d} added, {change['removed']} removed\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"ADVANCED ANALYSIS - NETWORK METRICS\") print(\"=\" * 60)  # Per-layer analysis print(\"\\n1. Per-Layer Network Metrics:\") for layer_id in [\"2022\", \"2023\", \"2024\"]:     v = G.view(layers=layer_id)          print(f\"\\n   {layer_id}:\")     print(f\"     Nodes: {v.node_count}\")     print(f\"     Edges: {v.edge_count}\")          if v.edge_count &gt; 0:         avg_weight = v.var.select(\"weight\").mean().item() if \"weight\" in v.var.columns else 0         print(f\"     Avg edge weight: {avg_weight:.3f}\")          # Degree analysis (using materialized subgraph)     subG = v.materialize()     degrees = {vid: subG.degree(vid) for vid in subG.vertices()}     if degrees:         print(f\"     Avg degree: {sum(degrees.values()) / len(degrees):.2f}\")         print(f\"     Max degree: {max(degrees.values())}\")         max_degree_node = max(degrees, key=degrees.get)         print(f\"     Hub: {max_degree_node} (degree={degrees[max_degree_node]})\")  # Compare layers print(\"\\n2. Layer Comparison:\") changes = G.layers.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"vertex_change\") print(\"\\n   Vertex changes over time:\") for i, change in enumerate(changes):     year_from = [\"2022\", \"2023\"][i]     year_to = [\"2023\", \"2024\"][i]     print(f\"   {year_from}\u2192{year_to}: {change['added']:+d} added, {change['removed']} removed\")  changes = G.layers.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"edge_change\") print(\"\\n   Edge changes over time:\") for i, change in enumerate(changes):     year_from = [\"2022\", \"2023\"][i]     year_to = [\"2023\", \"2024\"][i]     print(f\"   {year_from}\u2192{year_to}: {change['added']:+d} added, {change['removed']} removed\") <pre>\n============================================================\nADVANCED ANALYSIS - NETWORK METRICS\n============================================================\n\n1. Per-Layer Network Metrics:\n\n   2022:\n     Nodes: 4\n     Edges: 4\n     Avg edge weight: 0.000\n     Avg degree: 2.00\n     Max degree: 2\n     Hub: charlie (degree=2)\n\n   2023:\n     Nodes: 5\n     Edges: 5\n     Avg edge weight: 0.000\n     Avg degree: 2.00\n     Max degree: 3\n     Hub: eve (degree=3)\n\n   2024:\n     Nodes: 7\n     Edges: 5\n     Avg edge weight: 0.000\n     Avg degree: 1.43\n     Max degree: 3\n     Hub: eve (degree=3)\n\n2. Layer Comparison:\n\n   Vertex changes over time:\n   2022\u21922023: +1 added, 0 removed\n   2023\u21922024: +3 added, 1 removed\n\n   Edge changes over time:\n   2022\u21922023: +5 added, 4 removed\n   2023\u21922024: +5 added, 5 removed\n</pre> In\u00a0[58]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"ADVANCED ANALYSIS - POLARS QUERIES\")\nprint(\"=\" * 60)\n\n# Query 1: Top earners\nprint(\"\\n1. Top 3 Earners:\")\ntop_earners = G.obs.sort(\"salary\", descending=True).head(3)\nprint(top_earners.select([\"vertex_id\", \"name\", \"role\", \"salary\"]))\n\n# Query 2: Role distribution\nprint(\"\\n2. Role Distribution:\")\nrole_dist = G.obs.group_by(\"role\").agg([\n    pl.count(\"vertex_id\").alias(\"count\"),\n    pl.mean(\"salary\").alias(\"avg_salary\")\n]).sort(\"count\", descending=True)\nprint(role_dist)\n\n# Query 3: High-weight collaborations\nprint(\"\\n3. Top 5 Collaborations by Weight:\")\ntop_edges = (\n    G.view(layers=\"2023\")\n     .edges_df(layer=\"2023\", include_weight=True, resolved_weight=True)  # adds global_weight, layer_weight, effective_weight\n     .sort(\"effective_weight\", descending=True)\n     .select([\"edge_id\", \"effective_weight\"])\n     .head(5)\n)\nprint(top_edges)\n\n# Query 4: Projects by hours\nprint(\"\\n4. Total Hours by Project:\")\nif \"project\" in G.var.columns and \"hours\" in G.var.columns:\n    project_hours = G.var.group_by(\"project\").agg([\n        pl.count(\"edge_id\").alias(\"collaborations\"),\n        pl.sum(\"hours\").alias(\"total_hours\")\n    ]).sort(\"total_hours\", descending=True)\n    print(project_hours)\n\n# Query 5: Salary growth (across snapshots if attributes updated)\nprint(\"\\n5. Salary Statistics:\")\nsalary_stats = G.obs.select([\n    pl.col(\"salary\").min().alias(\"min_salary\"),\n    pl.col(\"salary\").max().alias(\"max_salary\"),\n    pl.col(\"salary\").mean().alias(\"avg_salary\"),\n    pl.col(\"salary\").median().alias(\"median_salary\")\n])\nprint(salary_stats)\n</pre> print(\"\\n\" + \"=\" * 60) print(\"ADVANCED ANALYSIS - POLARS QUERIES\") print(\"=\" * 60)  # Query 1: Top earners print(\"\\n1. Top 3 Earners:\") top_earners = G.obs.sort(\"salary\", descending=True).head(3) print(top_earners.select([\"vertex_id\", \"name\", \"role\", \"salary\"]))  # Query 2: Role distribution print(\"\\n2. Role Distribution:\") role_dist = G.obs.group_by(\"role\").agg([     pl.count(\"vertex_id\").alias(\"count\"),     pl.mean(\"salary\").alias(\"avg_salary\") ]).sort(\"count\", descending=True) print(role_dist)  # Query 3: High-weight collaborations print(\"\\n3. Top 5 Collaborations by Weight:\") top_edges = (     G.view(layers=\"2023\")      .edges_df(layer=\"2023\", include_weight=True, resolved_weight=True)  # adds global_weight, layer_weight, effective_weight      .sort(\"effective_weight\", descending=True)      .select([\"edge_id\", \"effective_weight\"])      .head(5) ) print(top_edges)  # Query 4: Projects by hours print(\"\\n4. Total Hours by Project:\") if \"project\" in G.var.columns and \"hours\" in G.var.columns:     project_hours = G.var.group_by(\"project\").agg([         pl.count(\"edge_id\").alias(\"collaborations\"),         pl.sum(\"hours\").alias(\"total_hours\")     ]).sort(\"total_hours\", descending=True)     print(project_hours)  # Query 5: Salary growth (across snapshots if attributes updated) print(\"\\n5. Salary Statistics:\") salary_stats = G.obs.select([     pl.col(\"salary\").min().alias(\"min_salary\"),     pl.col(\"salary\").max().alias(\"max_salary\"),     pl.col(\"salary\").mean().alias(\"avg_salary\"),     pl.col(\"salary\").median().alias(\"median_salary\") ]) print(salary_stats) <pre>\n============================================================\nADVANCED ANALYSIS - POLARS QUERIES\n============================================================\n\n1. Top 3 Earners:\nshape: (3, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 vertex_id \u2506 name  \u2506 role      \u2506 salary \u2502\n\u2502 ---       \u2506 ---   \u2506 ---       \u2506 ---    \u2502\n\u2502 str       \u2506 str   \u2506 str       \u2506 i64    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 diana     \u2506 Diana \u2506 director  \u2506 120000 \u2502\n\u2502 henry     \u2506 Henry \u2506 architect \u2506 115000 \u2502\n\u2502 bob       \u2506 Bob   \u2506 manager   \u2506 95000  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n2. Role Distribution:\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 role           \u2506 count \u2506 avg_salary \u2502\n\u2502 ---            \u2506 ---   \u2506 ---        \u2502\n\u2502 str            \u2506 u32   \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 engineer       \u2506 4     \u2506 83750.0    \u2502\n\u2502 data_scientist \u2506 1     \u2506 92000.0    \u2502\n\u2502 director       \u2506 1     \u2506 120000.0   \u2502\n\u2502 manager        \u2506 1     \u2506 95000.0    \u2502\n\u2502 architect      \u2506 1     \u2506 115000.0   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n3. Top 5 Collaborations by Weight:\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 edge_id \u2506 effective_weight \u2502\n\u2502 ---     \u2506 ---              \u2502\n\u2502 str     \u2506 f64              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 edge_5  \u2506 0.95             \u2502\n\u2502 edge_4  \u2506 0.85             \u2502\n\u2502 edge_7  \u2506 0.8              \u2502\n\u2502 edge_6  \u2506 0.75             \u2502\n\u2502 edge_8  \u2506 0.7              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n4. Total Hours by Project:\nshape: (9, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 project      \u2506 collaborations \u2506 total_hours \u2502\n\u2502 ---          \u2506 ---            \u2506 ---         \u2502\n\u2502 str          \u2506 u32            \u2506 i64         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 ProjectZ     \u2506 2              \u2506 320         \u2502\n\u2502 NextGen      \u2506 2              \u2506 290         \u2502\n\u2502 ProjectX     \u2506 2              \u2506 270         \u2502\n\u2502 ProjectW     \u2506 2              \u2506 170         \u2502\n\u2502 Management   \u2506 2              \u2506 170         \u2502\n\u2502 Strategy     \u2506 1              \u2506 80          \u2502\n\u2502 ProjectY     \u2506 1              \u2506 60          \u2502\n\u2502 Architecture \u2506 1              \u2506 0           \u2502\n\u2502 Innovation   \u2506 1              \u2506 0           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n5. Salary Statistics:\nshape: (1, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 min_salary \u2506 max_salary \u2506 avg_salary \u2506 median_salary \u2502\n\u2502 ---        \u2506 ---        \u2506 ---        \u2506 ---           \u2502\n\u2502 i64        \u2506 i64        \u2506 f64        \u2506 f64           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 80000      \u2506 120000     \u2506 94625.0    \u2506 89500.0       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[60]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"PERFORMANCE BENCHMARKS\")\nprint(\"=\" * 60)\n\nimport time\n\n# Benchmark 1: View creation\nprint(\"\\n1. View Creation (1000 iterations):\")\nt0 = time.time()\nfor _ in range(1000):\n    v = G.view(layers=\"2023\")\nt1 = time.time()\nprint(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0):.4f}ms per view)\")\n\n# Benchmark 2: Property access\nprint(\"\\n2. Property Access (1000 iterations):\")\nv = G.view(layers=\"2023\")\nt0 = time.time()\nfor _ in range(1000):\n    _ = v.obs\n    _ = v.var\nt1 = time.time()\nprint(f\"   Time: {(t1-t0)*1000:.2f}ms total\")\n\n# Benchmark 3: Materialization\nprint(\"\\n3. Materialization (100 iterations):\")\nv = G.view(layers=\"2023\")\nt0 = time.time()\nfor _ in range(100):\n    subG = v.materialize(copy_attributes=False)\nt1 = time.time()\nprint(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0)*10:.2f}ms per materialization)\")\n\n# Benchmark 4: Snapshot creation\nprint(\"\\n4. Snapshot Creation (100 iterations):\")\nt0 = time.time()\nfor i in range(100):\n    G.snapshot(f\"bench_{i}\")\nt1 = time.time()\nprint(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0)*10:.2f}ms per snapshot)\")\nprint(f\"   Total snapshots: {len(G._snapshots)}\")\n\n# Benchmark 5: DataFrame filtering\nprint(\"\\n5. DataFrame Filtering (1000 iterations):\")\nt0 = time.time()\nfor _ in range(1000):\n    filtered = G.obs.filter(pl.col(\"salary\") &gt; 90000)\nt1 = time.time()\nprint(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0):.4f}ms per filter)\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"PERFORMANCE BENCHMARKS\") print(\"=\" * 60)  import time  # Benchmark 1: View creation print(\"\\n1. View Creation (1000 iterations):\") t0 = time.time() for _ in range(1000):     v = G.view(layers=\"2023\") t1 = time.time() print(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0):.4f}ms per view)\")  # Benchmark 2: Property access print(\"\\n2. Property Access (1000 iterations):\") v = G.view(layers=\"2023\") t0 = time.time() for _ in range(1000):     _ = v.obs     _ = v.var t1 = time.time() print(f\"   Time: {(t1-t0)*1000:.2f}ms total\")  # Benchmark 3: Materialization print(\"\\n3. Materialization (100 iterations):\") v = G.view(layers=\"2023\") t0 = time.time() for _ in range(100):     subG = v.materialize(copy_attributes=False) t1 = time.time() print(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0)*10:.2f}ms per materialization)\")  # Benchmark 4: Snapshot creation print(\"\\n4. Snapshot Creation (100 iterations):\") t0 = time.time() for i in range(100):     G.snapshot(f\"bench_{i}\") t1 = time.time() print(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0)*10:.2f}ms per snapshot)\") print(f\"   Total snapshots: {len(G._snapshots)}\")  # Benchmark 5: DataFrame filtering print(\"\\n5. DataFrame Filtering (1000 iterations):\") t0 = time.time() for _ in range(1000):     filtered = G.obs.filter(pl.col(\"salary\") &gt; 90000) t1 = time.time() print(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0):.4f}ms per filter)\") <pre>\n============================================================\nPERFORMANCE BENCHMARKS\n============================================================\n\n1. View Creation (1000 iterations):\n   Time: 1.00ms total (0.0010ms per view)\n\n2. Property Access (1000 iterations):\n   Time: 523.89ms total\n\n3. Materialization (100 iterations):\n   Time: 89.99ms total (0.90ms per materialization)\n\n4. Snapshot Creation (100 iterations):\n   Time: 0.00ms total (0.00ms per snapshot)\n   Total snapshots: 102\n\n5. DataFrame Filtering (1000 iterations):\n   Time: 194.86ms total (0.1949ms per filter)\n</pre> In\u00a0[62]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"ANNNET COMPLETE TEST SUMMARY\")\nprint(\"=\" * 60)\n\nprint(\"\\n\ud83d\udcca GRAPH STATISTICS\")\nprint(f\"   Vertices: {G.number_of_vertices()}\")\nprint(f\"   Edges: {G.number_of_edges()}\")\nprint(f\"   Layers: {G.layers.count()}\")\nprint(f\"   Snapshots: {len(G._snapshots)}\")\n\nprint(\"\\n\u2705 TESTED FEATURES\")\nfeatures = [\n    \"AnnNet Properties (X, obs, var, uns)\",\n    \"LayerManager (add, remove, union, intersect, stats)\",\n    \"IndexManager (entity/edge lookups)\",\n    \"CacheManager (CSR/CSC caching)\",\n    \"GraphView (filtering, predicates, materialization)\",\n    \"Snapshot &amp; Diff (versioning, comparison)\",\n    \"I/O (save/load .annnet format)\",\n    \"Cross-layer analytics\",\n    \"Polars integration\",\n    \"Performance benchmarks\"\n]\n\nfor i, feature in enumerate(features, 1):\n    print(f\"   {i:2d}. {feature}\")\n\nprint(\"\\n\ud83d\udcc8 LAYER DETAILS\")\nprint(G.layers.summary())\n\nprint(\"\\n\ud83c\udfaf RECOMMENDATIONS\")\nprint(\"   1. Use views for large subgraph operations (lazy, efficient)\")\nprint(\"   2. Create snapshots before major graph modifications\")\nprint(\"   3. Use layers for temporal/contextual data organization\")\nprint(\"   4. Leverage Polars for fast attribute queries\")\nprint(\"   5. Cache CSR/CSC for repeated matrix operations\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2713 ALL TESTS COMPLETED SUCCESSFULLY!\")\nprint(\"=\" * 60)\n</pre> print(\"\\n\" + \"=\" * 60) print(\"ANNNET COMPLETE TEST SUMMARY\") print(\"=\" * 60)  print(\"\\n\ud83d\udcca GRAPH STATISTICS\") print(f\"   Vertices: {G.number_of_vertices()}\") print(f\"   Edges: {G.number_of_edges()}\") print(f\"   Layers: {G.layers.count()}\") print(f\"   Snapshots: {len(G._snapshots)}\")  print(\"\\n\u2705 TESTED FEATURES\") features = [     \"AnnNet Properties (X, obs, var, uns)\",     \"LayerManager (add, remove, union, intersect, stats)\",     \"IndexManager (entity/edge lookups)\",     \"CacheManager (CSR/CSC caching)\",     \"GraphView (filtering, predicates, materialization)\",     \"Snapshot &amp; Diff (versioning, comparison)\",     \"I/O (save/load .annnet format)\",     \"Cross-layer analytics\",     \"Polars integration\",     \"Performance benchmarks\" ]  for i, feature in enumerate(features, 1):     print(f\"   {i:2d}. {feature}\")  print(\"\\n\ud83d\udcc8 LAYER DETAILS\") print(G.layers.summary())  print(\"\\n\ud83c\udfaf RECOMMENDATIONS\") print(\"   1. Use views for large subgraph operations (lazy, efficient)\") print(\"   2. Create snapshots before major graph modifications\") print(\"   3. Use layers for temporal/contextual data organization\") print(\"   4. Leverage Polars for fast attribute queries\") print(\"   5. Cache CSR/CSC for repeated matrix operations\")  print(\"\\n\" + \"=\" * 60) print(\"\u2713 ALL TESTS COMPLETED SUCCESSFULLY!\") print(\"=\" * 60) <pre>\n============================================================\nANNNET COMPLETE TEST SUMMARY\n============================================================\n\n\ud83d\udcca GRAPH STATISTICS\n   Vertices: 8\n   Edges: 14\n   Layers: 5\n   Snapshots: 102\n\n\u2705 TESTED FEATURES\n    1. AnnNet Properties (X, obs, var, uns)\n    2. LayerManager (add, remove, union, intersect, stats)\n    3. IndexManager (entity/edge lookups)\n    4. CacheManager (CSR/CSC caching)\n    5. GraphView (filtering, predicates, materialization)\n    6. Snapshot &amp; Diff (versioning, comparison)\n    7. I/O (save/load .annnet format)\n    8. Cross-layer analytics\n    9. Polars integration\n   10. Performance benchmarks\n\n\ud83d\udcc8 LAYER DETAILS\nLayers: 5\n\u251c\u2500 default: 0 vertices, 0 edges\n\u251c\u2500 2022: 4 vertices, 4 edges\n\u251c\u2500 2023: 5 vertices, 5 edges\n\u251c\u2500 2024: 7 vertices, 5 edges\n\u2514\u2500 all_years: 5 vertices, 12 edges\n\n\ud83c\udfaf RECOMMENDATIONS\n   1. Use views for large subgraph operations (lazy, efficient)\n   2. Create snapshots before major graph modifications\n   3. Use layers for temporal/contextual data organization\n   4. Leverage Polars for fast attribute queries\n   5. Cache CSR/CSC for repeated matrix operations\n\n============================================================\n\u2713 ALL TESTS COMPLETED SUCCESSFULLY!\n============================================================\n</pre> In\u00a0[64]: Copied! <pre>print(\"\\n\" + \"=\" * 60)\nprint(\"CLEANUP\")\nprint(\"=\" * 60)\n\nimport os\nimport shutil\n\n# Clean up test files\nfiles_to_remove = [\n    \"company_network.annnet\",\n    \"network_2023.annnet\",\n]\n\nprint(\"\\nRemoving test files:\")\nfor filepath in files_to_remove:\n    if os.path.exists(filepath):\n        if os.path.isdir(filepath):\n            shutil.rmtree(filepath)\n            print(f\"   \u2713 Removed directory: {filepath}\")\n        else:\n            os.remove(filepath)\n            print(f\"   \u2713 Removed file: {filepath}\")\n    else:\n        print(f\"   \u2298 Not found: {filepath}\")\n\nprint(\"\\n\u2713 Cleanup complete\")\n</pre> print(\"\\n\" + \"=\" * 60) print(\"CLEANUP\") print(\"=\" * 60)  import os import shutil  # Clean up test files files_to_remove = [     \"company_network.annnet\",     \"network_2023.annnet\", ]  print(\"\\nRemoving test files:\") for filepath in files_to_remove:     if os.path.exists(filepath):         if os.path.isdir(filepath):             shutil.rmtree(filepath)             print(f\"   \u2713 Removed directory: {filepath}\")         else:             os.remove(filepath)             print(f\"   \u2713 Removed file: {filepath}\")     else:         print(f\"   \u2298 Not found: {filepath}\")  print(\"\\n\u2713 Cleanup complete\") <pre>\n============================================================\nCLEANUP\n============================================================\n\nRemoving test files:\n   \u2713 Removed directory: company_network.annnet\n   \u2713 Removed directory: network_2023.annnet\n\n\u2713 Cleanup complete\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"sbml_io/#sbml-adapter-elowitz-repressilator","title":"SBML adapter (Elowitz repressilator)\u00b6","text":""},{"location":"sbml_io/#annnet-api","title":"AnnNet API\u00b6","text":""},{"location":"community/","title":"Join Us","text":"<p>Welcome to the graphglue community! We follow open-source principles and encourage any sort of contribution. We communicate on GitHub, where we also organise our projects.</p> <ul> <li> <p> Where to Start</p> <p>If you'd like to learn how to contribute to our projects, please follow the steps outlined in the contribution guide.</p> <p> To the contribution guide</p> </li> </ul>"},{"location":"community/#contributing-guidelines-github-links","title":"Contributing Guidelines GitHub Links","text":"<ul> <li> <p>Contribution guidelines</p> </li> <li> <p>Code of Conduct</p> </li> <li> <p>Developer Guide</p> </li> </ul>"},{"location":"community/contribute-codebase/","title":"Developer Guide","text":"<p>Thank you for considering to contribute to the project! This guide will help you to get started with the development of the project. If you have any questions, please feel free to ask them in the issue tracker on GitHub.</p>"},{"location":"community/contribute-codebase/#small-contributions","title":"Small Contributions","text":"<p>If you want to contribute a small change (e.g., a bugfix), you can probably immediately go ahead and create a pull request. For more substantial changes or additions, please read on.</p>"},{"location":"community/contribute-codebase/#larger-contributions","title":"Larger Contributions","text":"<p>If you want to contribute a larger change, please create an issue first. This will allow us to discuss the change and make sure that it fits into the project.  It can happen that development for a feature is already in progress, so it is important to check first to avoid duplicate work. If you have any questions, feel free to approach us in any way you like.</p>"},{"location":"community/contribute-codebase/#dependency-management","title":"Dependency management","text":"<p>We use Poetry for dependency management. Please make sure that you have installed Poetry and set up the environment correctly before starting development.</p>"},{"location":"community/contribute-codebase/#setting-up-the-environment","title":"Setting up the environment","text":"<ul> <li> <p>Install dependencies from the lock file: <code>poetry install</code></p> </li> <li> <p>Use the environment: You can either run commands directly with <code>poetry run &lt;command&gt;</code> or open a shell with <code>poetry shell</code> and then run commands directly.</p> </li> </ul>"},{"location":"community/contribute-codebase/#updating-the-environment","title":"Updating the environment","text":"<p>If you want to fix dependency issues, please do so in the Poetry framework. If Poetry does not work for you for some reason, please let us know.</p> <p>The Poetry dependencies are organized in groups. There are groups with dependencies needed for running graphglue (<code>[tool.poetry.dependencies]</code> with the group name <code>main</code>) and a group with dependencies needed for development (<code>[tool.poetry.group.dev.dependencies]</code> with the group name <code>dev</code>).</p> <p>For adding new dependencies:</p> <ul> <li> <p>Add new dependencies via <code>poetry add</code>: <code>poetry add &lt;dependency&gt; --group &lt;group&gt;</code>. This will update the <code>pyproject.toml</code> and lock file automatically.</p> </li> <li> <p>Add new dependencies via <code>pyproject.toml</code>: Add the dependency to the <code>pyproject.toml</code> file in the correct group, including version. Then update the lock file: <code>poetry lock</code> and install the dependencies: <code>poetry install</code>.</p> </li> </ul>"},{"location":"community/contribute-codebase/#code-quality-and-formal-requirements","title":"Code quality and formal requirements","text":"<p>For ensuring code quality, the following tools are used:</p> <ul> <li> <p>isort for sorting imports</p> </li> <li> <p>black for automated code formatting</p> </li> <li> <p>pre-commit-hooks for ensuring some general rules</p> </li> <li> <p>pep585-upgrade for automatically upgrading type hints to the new native types defined in PEP 585</p> </li> <li> <p>pygrep-hooks for ensuring some general naming rules</p> </li> <li> <p>Ruff An extremely fast Python linter and code formatter, written in Rust</p> </li> </ul> <p>We recommend configuring your IDE to execute Ruff on save/type, which will automatically keep your code clean and fix some linting errors as you type. This is made possible by the fast execution of Ruff and removes the need to run a dedicated pre-commit step. For instance, in VSCode or Cursor, you can add this to your <code>.vscode/settings.json</code>:</p> <pre><code>{\n    \"editor.formatOnType\": true,\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n        \"source.fixAll.ruff\": \"explicit\",\n        \"source.organizeImports.ruff\": \"explicit\"\n    },\n    \"editor.defaultFormatter\": \"charliermarsh.ruff\"\n}\n</code></pre> <p>Alternatively, pre-commit hooks can be used to automatically or manually run these tools before each commit. They are defined in <code>.pre-commit-config.yaml</code>. To install the hooks run <code>poetry run pre-commit install</code>. The hooks are then executed before each commit. For running the hook for all project files (not only the changed ones) run <code>poetry run pre-commit run --all-files</code>. Our CI runs the pre-commit hooks, so running them locally is a good way to check if your code conforms to the formatting rules.</p>"},{"location":"community/contribute-codebase/#testing","title":"Testing","text":"<p>The project uses pytest for testing. To run the tests, please run <code>pytest</code> in the root directory of the project. We are developing graphglue using test-driven development. Please make sure that you add tests for your code before submitting a pull request.</p> <p>The existing tests can also help you to understand how the code works. If you have any questions, please feel free to ask them in the issue tracker or on Zulip.</p> <p>Before submitting a pull request, please make sure that all tests pass and that the documentation builds correctly.</p>"},{"location":"community/contribute-codebase/#versioning","title":"Versioning","text":"<p>We use semantic versioning for the project. This means that the version number is incremented according to the following scheme:</p> <ul> <li> <p>Increment the major version number if you make incompatible API changes.</p> </li> <li> <p>Increment the minor version number if you add functionality in a backwards-   compatible manner. Since we are still in the 0.x.y version range, most of the   significant changes will increase the minor version number.</p> </li> <li> <p>Increment the patch version number if you make backwards-compatible bug fixes.</p> </li> </ul> <p>We use the <code>bumpversion</code> tool to update the version number in the <code>pyproject.toml</code> file. This will create a new git tag automatically. Usually, versioning is done by the maintainers, so please do not increment versions in pull requests by default.</p>"},{"location":"community/contribute-codebase/#finding-an-issue-to-contribute-to","title":"Finding an issue to contribute to","text":"<p>If you are brand new to graphglue or open-source development, we recommend searching the GitHub \"Issues\" tab to find issues that interest you. Unassigned issues labeled <code>Docs</code> and <code>good first</code> are typically good for newer contributors.</p> <p>Once you've found an interesting issue, it's a good idea to assign the issue to yourself, so nobody else duplicates the work on it.</p> <p>If for whatever reason you are not able to continue working with the issue, please unassign it, so other people know it's available again. If you want to work on an issue that is currently assigned but you're unsure whether work is actually being done, feel free to kindly ask the current assignee if you can take over (please allow at least a week of inactivity before getting in touch).</p>"},{"location":"community/contribute-codebase/#submitting-a-pull-request","title":"Submitting a Pull Request","text":""},{"location":"community/contribute-codebase/#tips-for-a-successful-pull-request","title":"Tips for a successful pull request","text":"<p>To improve the chances of your pull request being reviewed, you should:</p> <ul> <li>Reference an open issue for non-trivial changes to clarify the PR's purpose.</li> <li>Ensure you have appropriate tests. Tests should be the focus of any PR (apart from documentation changes).</li> <li>Keep your pull requests as simple as possible. Larger PRs take longer to review.</li> <li>Ensure that CI is in a green state. Reviewers may tell you to fix the CI before looking at anything else.</li> </ul>"},{"location":"community/contribute-codebase/#version-control-git-and-github","title":"Version control, Git, and GitHub","text":"<p>graphglue is hosted on GitHub, and to contribute, you will need to sign up for a free GitHub account. We use Git for version control to allow many people to work together on the project.</p> <p>If you are new to Git, you can reference some of these resources for learning Git. Feel free to reach out to the contributor community for help if needed:</p> <ul> <li>Git documentation.</li> </ul> <p>The project follows a forking workflow further described on this page whereby contributors fork the repository, make changes and then create a Pull Request. So please be sure to read and follow all the instructions in this guide.</p> <p>If you are new to contributing to projects through forking on GitHub, take a look at the GitHub documentation for contributing to projects. GitHub provides a quick tutorial using a test repository that may help you become more familiar with forking a repository, cloning a fork, creating a feature branch, pushing changes and making Pull Requests.</p> <p>Below are some useful resources for learning more about forking and Pull Requests on GitHub:</p> <ul> <li> <p>the GitHub documentation for forking a repo.</p> </li> <li> <p>the GitHub documentation for collaborating with Pull Requests.</p> </li> <li> <p>the GitHub documentation for working with forks.</p> </li> </ul> <p>There are also many unwritten rules and conventions that are helpful in interacting with other open-source contributors. These lessons from PyOpenSci are a good resource for learning more about how to interact with other open-source contributors in scientific computing.</p>"},{"location":"community/contribute-codebase/#getting-started-with-git","title":"Getting started with Git","text":"<p>GitHub has instructions for installing git, setting up your SSH key, and configuring git. All these steps need to be completed before you can work seamlessly between your local repository and GitHub.</p>"},{"location":"community/contribute-codebase/#create-a-fork-of-graphglue","title":"Create a fork of graphglue","text":"<p>You will need your own fork of graphgluein order to eventually open a Pull Request. Go to the graphglue project page and hit the Fork button. Please uncheck the box to copy only the main branch before selecting Create Fork. You will then want to clone your fork to your machine.</p> <pre><code>git clone https://github.com/your-user-name/graphglue.git\ncd graphglue\ngit remote add upstream https://github.com/graphglue/graphglue.git\ngit fetch upstream\n</code></pre> <p>This creates the directory <code>graphglue</code> and connects your repository to the upstream (main project) graphglue repository. They have the same name, but your local repository and fork are separate from the upstream repository.</p>"},{"location":"community/contribute-codebase/#creating-a-feature-branch","title":"Creating a feature branch","text":"<p>Your local <code>main</code> branch should always reflect the current state of graphglue repository. First ensure it's up-to-date with the main graphglue repository.</p> <pre><code>git checkout main\ngit pull upstream main --ff-only\n</code></pre> <p>Then, create a feature branch for making your changes. For example, we are going to create a branch called <code>my-new-feature-for-graphglue</code></p> <pre><code>git checkout -b my-new-feature-for-graphglue\n</code></pre> <p>This changes your working branch from <code>main</code> to the <code>my-new-feature-for-graphglue</code> branch. Keep any changes in this branch specific to one bug or feature so it is clear what the branch brings to graphglue. You can have many feature branches and switch between them using the <code>git checkout</code> command.</p>"},{"location":"community/contribute-codebase/#making-code-changes","title":"Making code changes","text":"<p>Before modifying any code, ensure you follow the contributing environment guidelines to set up an appropriate development environment.</p> <p>When making changes, follow these graphglue-specific guidelines:</p> <ol> <li> <p>Keep changes of that branch/PR focused on a single feature or bug fix.</p> </li> <li> <p>Follow roughly the conventional commit message conventions.</p> </li> </ol>"},{"location":"community/contribute-codebase/#pushing-your-changes","title":"Pushing your changes","text":"<p>When you want your committed changes to appear publicly on your GitHub page, you can push your forked feature branch's commits to your forked repository on GitHub.</p> <p>Now your code is on GitHub, but it is not yet a part of the graphglue project. For that to happen, a Pull Request (PR) needs to be submitted.</p>"},{"location":"community/contribute-codebase/#opening-a-pull-request-pr","title":"Opening a Pull Request (PR)","text":"<p>If everything looks good according to the general guidelines, you are ready to make a Pull Request. A Pull Request is how code from your fork becomes available to the project maintainers to review and merge into the project to appear in the next release. To submit a Pull Request:</p> <ol> <li> <p>Navigate to your repository on GitHub.</p> </li> <li> <p>Click on the Compare &amp; Pull Request button.</p> </li> <li> <p>You can then click on Commits and Files Changed to make sure everything looks okay one last time.</p> </li> <li> <p>Write a descriptive title that includes prefixes. graphglue uses a convention for title prefixes, most commonly, <code>feat:</code> for features, <code>fix:</code> for bug fixes, and <code>refactor:</code> for refactoring.</p> </li> <li> <p>Write a description of your changes in the <code>Preview Discussion</code> tab. This description will inform the reviewers about the changes you made, so please include all relevant information, including the motivation, implementation details, and references to any issues that you are addressing.</p> </li> <li> <p>Make sure to <code>Allow edits from maintainers</code>; this allows the maintainers to make changes to your PR directly, which is useful if you are not sure how to fix the PR.</p> </li> <li> <p>Click <code>Send Pull Request</code>.</p> </li> <li> <p>Optionally, you can assign reviewers to your PR, if you know who should review it.</p> </li> </ol> <p>This request then goes to the repository maintainers, and they will review the code.</p>"},{"location":"community/contribute-codebase/#updating-your-pull-request","title":"Updating your Pull Request","text":"<p>Based on the review you get on your pull request, you will probably need to make some changes to the code. You can follow the steps above again to address any feedback and update your pull request.</p>"},{"location":"community/contribute-codebase/#parallel-changes-in-the-upstream-main-branch","title":"Parallel changes in the upstream <code>main</code> branch","text":"<p>In case of simultaneous changes to the upstream code, it is important that these changes are reflected in your pull request. To update your feature branch with changes in the graphglue <code>main</code> branch, run:</p> <pre><code>    git checkout my-new-feature-for-graphglue\n    git fetch upstream\n    git merge upstream/main\n</code></pre> <p>If there are no conflicts (or they could be fixed automatically), a file with a default commit message will open, and you can simply save and quit this file.</p> <p>If there are merge conflicts, you need to resolve those conflicts. See here for an explanation on how to do this.</p> <p>Once the conflicts are resolved, run:</p> <ol> <li><code>git add -u</code> to stage any files you've updated;</li> <li><code>git commit</code> to finish the merge.</li> </ol> <p>After the feature branch has been updated locally, you can now update your pull request by pushing to the branch on GitHub:</p> <pre><code>    git push origin my-new-feature-for-graphglue\n</code></pre> <p>Any <code>git push</code> will automatically update your pull request with your branch's changes and restart the <code>Continuous Integration</code> checks.</p>"},{"location":"community/contribute-docs/","title":"Contributing to the documentation","text":"<p>Contributing to the documentation benefits everyone who uses graphglue. We encourage you to help us improve the documentation, and you don't have to be an expert on graphglue to do so! In fact, there are sections of the docs that are worse off after being written by experts. If something in the docs doesn't make sense to you, updating the relevant section after you figure it out is a great way to ensure it will help the next person.</p>"},{"location":"community/contribute-docs/#how-to-contribute-to-the-documentation","title":"How to contribute to the documentation","text":"<p>The documentation is written in Markdown, which is almost like writing in plain English, and built using Material for MkDocs. The simplest way to contribute to the docs is to click on the <code>Edit</code> button (pen and paper) at the top right of any page. This will take you to the source file on GitHub, where you can make your changes and create a pull request using GitHub's web interface (the <code>Commit changes...</code> button).</p> <p>Some other important things to know about the docs:</p> <ul> <li> <p>The graphglue documentation consists of two parts: the docstrings in the code   itself and the docs in the <code>docs/</code> folder. The docstrings provide a clear   explanation of the usage of the individual functions, while the documentation   website you are looking at is built from the <code>docs/</code> folder.</p> </li> <li> <p>The docstrings follow a convention, based on the Google Docstring   Standard.</p> </li> <li> <p>Our API documentation files in <code>docs/reference/source</code> contain the   instructions for the auto-generated documentation from the docstrings. For   classes, there are a few subtleties around controlling which methods and   attributes have pages auto-generated.</p> </li> </ul>"},{"location":"community/contribute/","title":"How to Start Contributing","text":"<p>There are many valuable ways to contribute besides writing code. Thank you for dedicating your time to improve our project!</p>"},{"location":"community/contribute/#bug-reports-and-enhancement-requests","title":"Bug reports and enhancement requests","text":"<p>Bug reports and enhancement requests are an important part of making any software more stable. We curate them though Github issues. When opening an issue or request, please select the appropriate category and fill out the issue form fully to ensure others and the core development team can fully understand the scope of the issue. If your category is not listed, you can create a blank issue.</p> <p>The issue will then show up to the graphglue community and be open to comments/ideas from others.</p>"},{"location":"community/contribute/#categories","title":"Categories","text":"<ul> <li>Bug Report: Report incorrect behavior in the graphglue library</li> <li>Register New Component: Register a new component in the graphglue ecosystem, either one you have created, or one that you would like to see added</li> <li>Documentation Improvement: Report wrong or missing documentation</li> <li>Feature Request: Suggest an idea for graphglue</li> </ul>"},{"location":"community/contribute/#detailed-guides","title":"Detailed Guides","text":"<ul> <li> <p> Contributing to the Documentation</p> <p>A simple way to get started is to contribute to the documentation. Please follow the guide here to learn how to do so.</p> <p> To the contribution guide</p> </li> </ul> <ul> <li> <p> Contributing to the Code Base</p> <p>The best way to contribute code is to open a pull request on Github. Please follow the guide here to learn how to do so.</p> <p> To the contribution guide</p> </li> </ul>"},{"location":"reference/api/","title":"API Reference","text":""},{"location":"reference/api/#graphglue-classes","title":"Classes","text":""},{"location":"reference/api/#graphglue.Graph","title":"<code>Graph</code>","text":"<p>Sparse incidence-matrix graph with layers, attributes, parallel edges, and hyperedges.</p> <p>The graph is backed by a DOK (Dictionary Of Keys) sparse matrix and exposes layered views and attribute tables stored as Polars DF (DataFrame). Supports: vertices, binary edges (directed/undirected), edge-entities (vertex-edge hybrids), k-ary hyperedges (directed/undirected), per-layer membership and weights, and Polars-backed attribute upserts.</p>"},{"location":"reference/api/#graphglue.Graph--parameters","title":"Parameters","text":"<p>directed : bool, optional     Whether edges are directed by default. Individual edges can override this.</p>"},{"location":"reference/api/#graphglue.Graph--notes","title":"Notes","text":"<ul> <li>Incidence columns encode orientation: +w on source/head, \u2212w on target/tail for   directed edges; +w on all members for undirected edges/hyperedges.</li> <li>Attributes are pure: structural keys are filtered out so attribute tables   contain only user data.</li> </ul>"},{"location":"reference/api/#graphglue.Graph--see-also","title":"See Also","text":"<p>add_vertex, add_edge, add_hyperedge, edges_view, vertices_view, layers_view</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    Sparse incidence-matrix graph with layers, attributes, parallel edges, and hyperedges.\n\n    The graph is backed by a DOK (Dictionary Of Keys) sparse matrix and exposes\n    layered views and attribute tables stored as Polars DF (DataFrame). Supports:\n    vertices, binary edges (directed/undirected), edge-entities (vertex-edge hybrids),\n    k-ary hyperedges (directed/undirected), per-layer membership and weights,\n    and Polars-backed attribute upserts.\n\n    Parameters\n    ----------\n    directed : bool, optional\n        Whether edges are directed by default. Individual edges can override this.\n\n    Notes\n    -----\n    - Incidence columns encode orientation: +w on source/head, \u2212w on target/tail for\n      directed edges; +w on all members for undirected edges/hyperedges.\n    - Attributes are **pure**: structural keys are filtered out so attribute tables\n      contain only user data.\n\n    See Also\n    --------\n    add_vertex, add_edge, add_hyperedge, edges_view, vertices_view, layers_view\n    \"\"\"\n    # Constants (Attribute helpers)\n    _vertex_RESERVED = {\"vertex_id\"}               # nothing structural for vertices\n    _EDGE_RESERVED = {\"edge_id\",\"source\",\"target\",\"weight\",\"edge_type\",\"directed\",\"layer\",\"layer_weight\",\"kind\",\"members\",\"head\",\"tail\"}    \n    _LAYER_RESERVED = {\"layer_id\"}\n\n    # Construction\n\n    def __init__(self, directed=None, n: int = 0, e: int = 0, **kwargs):\n        \"\"\"\n        Initialize an empty incidence-matrix graph.\n\n        Parameters\n        ----------\n        directed : bool, optional\n            Global default for edge directionality. Individual edges can override this.\n\n        Notes\n        -----\n        - Stores entities (vertices and edge-entities), edges (including parallels), and\n        an incidence matrix in DOK (Dictionary Of Keys) sparse format.\n        - Attribute tables are Polars DF (DataFrame) with canonical key columns:\n        ``vertex_attributes(vertex_id)``, ``edge_attributes(edge_id)``,\n        ``layer_attributes(layer_id)``, and\n        ``edge_layer_attributes(layer_id, edge_id, weight)``.\n        - A ``'default'`` layer is created and set active.\n        \"\"\"        \n        self.directed = directed\n\n        # Entity mappings (vertices + vertex-edge hybrids)\n        self.entity_to_idx = {}  # entity_id -&gt; row index\n        self.idx_to_entity = {}  # row index -&gt; entity_id\n        self.entity_types = {}   # entity_id -&gt; 'vertex' or 'edge'\n\n        # Edge mappings (supports parallel edges)\n        self.edge_to_idx = {}    # edge_id -&gt; column index\n        self.idx_to_edge = {}    # column index -&gt; edge_id\n        self.edge_definitions = {}  # edge_id -&gt; (source, target, edge_type)\n        self.edge_weights = {}   # edge_id -&gt; weight\n        self.edge_directed = {} # Per-edge directedness; edge_id -&gt; bool  (None = Mixed, True=directed, False=undirected)\n\n        # Sparse incidence matrix\n        self._matrix = sp.dok_matrix((0, 0), dtype=np.float32)\n        self._num_entities = 0\n        self._num_edges = 0\n\n        # Attribute storage using polars DataFrames\n        self.vertex_attributes = pl.DataFrame(schema={\"vertex_id\": pl.Utf8})\n        self.edge_attributes = pl.DataFrame(schema={\"edge_id\": pl.Utf8})\n        self.layer_attributes = pl.DataFrame(schema={\"layer_id\": pl.Utf8})\n        self.edge_layer_attributes = pl.DataFrame(\n            schema={\"layer_id\": pl.Utf8, \"edge_id\": pl.Utf8, \"weight\": pl.Float64}\n        )\n        self.edge_kind = {}\n        self.hyperedge_definitions = {}\n        self.graph_attributes = {}\n\n        # Edge ID counter for parallel edges\n        self._next_edge_id = 0\n\n        # Layer management - lightweight dict structure\n        self._layers = {}  # layer_id -&gt; {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n        self._current_layer = None\n        self._default_layer = 'default'\n        self.layer_edge_weights = defaultdict(dict)  # layer_id -&gt; {edge_id: weight}\n\n        # Initialize default layer\n        self._layers[self._default_layer] = {\n            \"vertices\": set(),\n            \"edges\": set(), \n            \"attributes\": {}\n        }\n        self._current_layer = self._default_layer\n\n        # counts stay logical (start empty)\n        self._num_entities = 0\n        self._num_edges = 0\n\n        # pre-size the incidence matrix to capacity (no zeros allocated in DOK)\n        n = int(n) if n and n &gt; 0 else 0\n        e = int(e) if e and e &gt; 0 else 0\n        self._matrix = sp.dok_matrix((n, e), dtype=np.float32)\n\n        # grow-only helpers to avoid per-insert exact resizes\n        def _grow_rows_to(target: int):\n            rows, cols = self._matrix.shape\n            if target &gt; rows:\n                # geometric bump; keeps behavior, reduces churn\n                new_rows = max(target, rows + max(8, rows &gt;&gt; 1))\n                self._matrix.resize((new_rows, cols))\n\n        def _grow_cols_to(target: int):\n            rows, cols = self._matrix.shape\n            if target &gt; cols:\n                new_cols = max(target, cols + max(8, cols &gt;&gt; 1))\n                self._matrix.resize((rows, new_cols))\n\n        # bind as privates\n        self._grow_rows_to = _grow_rows_to\n        self._grow_cols_to = _grow_cols_to\n\n        # History and Timeline\n        self._history_enabled = True\n        self._history = []           # list[dict]\n        self._version = 0\n        self._history_clock0 = time.perf_counter_ns()\n        self._install_history_hooks()  # wrap mutating methods\n        self._snapshots = []\n\n    # Layer basics\n\n    def add_layer(self, layer_id, **attributes):\n        \"\"\"\n        Create a new empty layer.\n\n        Parameters\n        ----------\n        layer_id : str\n            New layer identifier (ID).\n        **attributes\n            Pure layer attributes to store (non-structural).\n\n        Returns\n        -------\n        str\n            The created layer ID.\n\n        Raises\n        ------\n        ValueError\n            If the layer already exists.\n        \"\"\"\n        if layer_id in self._layers and layer_id != \"default\":\n            raise ValueError(f\"Layer {layer_id} already exists\")\n\n        self._layers[layer_id] = {\n            \"vertices\": set(),\n            \"edges\": set(),\n            \"attributes\": attributes\n        }\n        # Persist layer metadata to DF (pure attributes, upsert)\n        if attributes:\n            self.set_layer_attrs(layer_id, **attributes)\n        return layer_id\n\n    def set_active_layer(self, layer_id):\n        \"\"\"\n        Set the active layer for subsequent operations.\n\n        Parameters\n        ----------\n        layer_id : str\n            Existing layer ID.\n\n        Raises\n        ------\n        KeyError\n            If the layer does not exist.\n        \"\"\"\n        if layer_id not in self._layers:\n            raise KeyError(f\"Layer {layer_id} not found\")\n        self._current_layer = layer_id\n\n    def get_active_layer(self):\n        \"\"\"\n        Get the currently active layer ID.\n\n        Returns\n        -------\n        str\n            Active layer ID.\n        \"\"\"\n        return self._current_layer\n\n    def get_layers_dict(self, include_default: bool = False):\n        \"\"\"\n        Get a mapping of layer IDs to their metadata.\n\n        Parameters\n        ----------\n        include_default : bool, optional\n            Include the internal ``'default'`` layer if True.\n\n        Returns\n        -------\n        dict[str, dict]\n            ``{layer_id: {\"vertices\": set, \"edges\": set, \"attributes\": dict}}``.\n        \"\"\"\n        if include_default:\n            return self._layers\n        return {k: v for k, v in self._layers.items() if k != self._default_layer}\n\n    def list_layers(self, include_default: bool = False):\n        \"\"\"\n        List layer IDs.\n\n        Parameters\n        ----------\n        include_default : bool, optional\n            Include the internal ``'default'`` layer if True.\n\n        Returns\n        -------\n        list[str]\n            Layer IDs.\n        \"\"\"\n        return list(self.get_layers_dict(include_default=include_default).keys())\n\n    def has_layer(self, layer_id):\n        \"\"\"\n        Check whether a layer exists.\n\n        Parameters\n        ----------\n        layer_id : str\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return layer_id in self._layers\n\n    def layer_count(self):\n        \"\"\"\n        Get the number of layers (including the internal default).\n\n        Returns\n        -------\n        int\n        \"\"\"\n        return len(self._layers)\n\n    def get_layer_info(self, layer_id):\n        \"\"\"\n        Get a layer's metadata snapshot.\n\n        Parameters\n        ----------\n        layer_id : str\n\n        Returns\n        -------\n        dict\n            Copy of ``{\"vertices\": set, \"edges\": set, \"attributes\": dict}``.\n\n        Raises\n        ------\n        KeyError\n            If the layer does not exist.\n        \"\"\"\n        if layer_id not in self._layers:\n            raise KeyError(f\"Layer {layer_id} not found\")\n        return self._layers[layer_id].copy()\n\n    # ID + entity ensure helpers\n\n    def _get_next_edge_id(self) -&gt; str:\n        \"\"\"\n        INTERNAL: Generate a unique edge ID for parallel edges.\n\n        Returns\n        -------\n        str\n            Fresh ``edge_&lt;n&gt;`` identifier (monotonic counter).\n        \"\"\"\n        edge_id = f\"edge_{self._next_edge_id}\"\n        self._next_edge_id += 1\n        return edge_id\n\n    def _ensure_vertex_table(self) -&gt; None:\n        \"\"\"\n        INTERNAL: Ensure the vertex attribute table exists with a canonical schema.\n\n        Notes\n        -----\n        - Creates an empty Polars DF [DataFrame] with a single ``Utf8`` ``vertex_id`` column\n        if missing or malformed.\n        \"\"\"        \n        df = getattr(self, \"vertex_attributes\", None)\n        if not isinstance(df, pl.DataFrame) or \"vertex_id\" not in df.columns:\n            self.vertex_attributes = pl.DataFrame({\"vertex_id\": pl.Series([], dtype=pl.Utf8)})\n\n    def _ensure_vertex_row(self, vertex_id: str) -&gt; None:\n        \"\"\"\n        INTERNAL: Ensure a row for ``vertex_id`` exists in the vertex attribute DF.\n\n        Notes\n        -----\n        - Appends a new row with ``vertex_id`` and ``None`` for other columns if absent.\n        - Preserves existing schema and columns.\n        \"\"\"\n        # Intern for cheaper dict ops\n        try:\n            import sys as _sys\n            if isinstance(vertex_id, str):\n                vertex_id = _sys.intern(vertex_id)\n        except Exception:\n            pass\n\n        df = self.vertex_attributes\n\n        # Build/refresh a cached id-set if needed (auto-invalidates on DF object change)\n        try:\n            cached_ids = getattr(self, \"_vertex_attr_ids\", None)\n            cached_df_id = getattr(self, \"_vertex_attr_df_id\", None)\n            if cached_ids is None or cached_df_id != id(df):\n                ids = set()\n                if isinstance(df, pl.DataFrame) and df.height &gt; 0 and \"vertex_id\" in df.columns:\n                    # One-time scan to seed cache\n                    try:\n                        ids = set(df.get_column(\"vertex_id\").to_list())\n                    except Exception:\n                        # Fallback if column access path changes\n                        ids = set(df.select(\"vertex_id\").to_series().to_list())\n                self._vertex_attr_ids = ids\n                self._vertex_attr_df_id = id(df)\n        except Exception:\n            # If anything about caching fails, proceed without it\n            self._vertex_attr_ids = None\n            self._vertex_attr_df_id = None\n\n        # membership check via cache when available\n        ids = getattr(self, \"_vertex_attr_ids\", None)\n        if ids is not None and vertex_id in ids:\n            return\n\n        # If DF is empty, create the first row with the canonical schema\n        if df.is_empty():\n            self.vertex_attributes = pl.DataFrame({\"vertex_id\": [vertex_id]}, schema={\"vertex_id\": pl.Utf8})\n            # keep cache in sync\n            try:\n                if isinstance(self._vertex_attr_ids, set):\n                    self._vertex_attr_ids.add(vertex_id)\n                else:\n                    self._vertex_attr_ids = {vertex_id}\n                self._vertex_attr_df_id = id(self.vertex_attributes)\n            except Exception:\n                pass\n            return\n\n        # Align columns: create a single dict with all columns present\n        row = {c: None for c in df.columns}\n        row[\"vertex_id\"] = vertex_id\n\n        # Append one row efficiently\n        try:\n            new_df = df.vstack(pl.DataFrame([row]))\n        except Exception:\n            new_df = pl.concat([df, pl.DataFrame([row])], how=\"vertical\")\n        self.vertex_attributes = new_df\n\n        # Update cache after mutation\n        try:\n            if isinstance(self._vertex_attr_ids, set):\n                self._vertex_attr_ids.add(vertex_id)\n            else:\n                self._vertex_attr_ids = {vertex_id}\n            self._vertex_attr_df_id = id(self.vertex_attributes)\n        except Exception:\n            pass\n\n    # Build graph\n\n    def add_vertex(self, vertex_id, layer=None, **attributes):\n        \"\"\"\n        Add (or upsert) a vertex and optionally attach it to a layer.\n\n        Parameters\n        ----------\n        vertex_id : str\n            vertex ID (must be unique across entities).\n        layer : str, optional\n            Target layer. Defaults to the active layer.\n        **attributes\n            Pure vertex attributes to store.\n\n        Returns\n        -------\n        str\n            The vertex ID (echoed).\n\n        Notes\n        -----\n        - Ensures a row exists in the Polars DF [DataFrame] for attributes.\n        - Resizes the incidence matrix if needed.\n        \"\"\"\n        # Fast normalize to cut hashing/dup costs in dicts.\n        try:\n            import sys as _sys\n            if isinstance(vertex_id, str):\n                vertex_id = _sys.intern(vertex_id)\n            if layer is None:\n                layer = self._current_layer\n            elif isinstance(layer, str):\n                layer = _sys.intern(layer)\n        except Exception:\n            layer = layer or self._current_layer\n\n        entity_to_idx = self.entity_to_idx\n        idx_to_entity = self.idx_to_entity\n        entity_types = self.entity_types\n        M = self._matrix  # DOK\n\n        # Add to global superset if new\n        if vertex_id not in entity_to_idx:\n            idx = self._num_entities\n            entity_to_idx[vertex_id] = idx\n            idx_to_entity[idx] = vertex_id\n            entity_types[vertex_id] = \"vertex\"\n            self._num_entities = idx + 1\n\n            rows, cols = M.shape\n            if self._num_entities &gt; rows:\n                # geometric growth (\u22481.5x), minimum step 8 to avoid frequent resizes\n                new_rows = max(self._num_entities, rows + max(8, rows &gt;&gt; 1))\n                M.resize((new_rows, cols))\n\n        # Add to specified layer (create if needed)\n        layers = self._layers\n        if layer not in layers:\n            layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n        layers[layer][\"vertices\"].add(vertex_id)\n\n        # Ensure vertex_attributes has a row for this vertex (even with no attrs)\n        self._ensure_vertex_table()\n        self._ensure_vertex_row(vertex_id)\n\n        # Upsert passed attributes (if any)\n        if attributes:\n            self.vertex_attributes = self._upsert_row(self.vertex_attributes, vertex_id, attributes)\n\n        return vertex_id\n\n    def add_vertices(self, vertices, layer=None, **attributes):\n        # normalize to [(vertex_id, per_attrs), ...]\n        it = []\n        for item in vertices:\n            if isinstance(item, tuple) and len(item) == 2 and isinstance(item[1], dict):\n                it.append({\"vertex_id\": item[0], **item[1], **attributes})\n            elif isinstance(item, dict):\n                d = dict(item); d.update(attributes); it.append(d)\n            else:\n                it.append({\"vertex_id\": item, **attributes})\n        self.add_vertices_bulk([(d[\"vertex_id\"], {k:v for k,v in d.items() if k!=\"vertex_id\"}) for d in it], layer=layer)\n        return [d[\"vertex_id\"] for d in it]\n\n    def add_edge_entity(self, edge_entity_id, layer=None, **attributes):\n        \"\"\"\n        Add an **edge entity** (vertex-edge hybrid) that can connect to vertices/edges.\n\n        Parameters\n        ----------\n        edge_entity_id : str\n            Entity ID to register as type ``'edge'`` in the entity set.\n        layer : str, optional\n            Target layer. Defaults to the active layer.\n        **attributes\n            Attributes stored in the vertex attribute DF (treated like vertices).\n\n        Returns\n        -------\n        str\n            The edge-entity ID.\n        \"\"\"\n        # Resolve layer default and intern hot strings\n        layer = layer or self._current_layer\n        try:\n            import sys as _sys\n            if isinstance(edge_entity_id, str):\n                edge_entity_id = _sys.intern(edge_entity_id)\n            if isinstance(layer, str):\n                layer = _sys.intern(layer)\n        except Exception:\n            pass\n\n        entity_to_idx = self.entity_to_idx\n        layers = self._layers\n\n        # Add to global superset if new (delegate to existing helper)\n        if edge_entity_id not in entity_to_idx:\n            self._add_edge_entity(edge_entity_id)\n\n        # Add to specified layer\n        if layer not in layers:\n            layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n        layers[layer][\"vertices\"].add(edge_entity_id)\n\n        # Add attributes (treat edge entities like vertices for attributes)\n        if attributes:\n            self.set_vertex_attrs(edge_entity_id, **attributes)\n\n        return edge_entity_id\n\n    def _add_edge_entity(self, edge_id):\n        \"\"\"\n        INTERNAL: Register an **edge-entity** so edges can attach to it (vertex-edge mode).\n\n        Parameters\n        ----------\n        edge_id : str\n            Identifier to insert into the entity index as type ``'edge'``.\n\n        Notes\n        -----\n        - Adds a new entity row and resizes the DOK incidence matrix accordingly.\n        \"\"\"\n        try:\n            import sys as _sys\n            if isinstance(edge_id, str):\n                edge_id = _sys.intern(edge_id)\n        except Exception:\n            pass\n\n        if edge_id not in self.entity_to_idx:\n            idx = self._num_entities\n            self.entity_to_idx[edge_id] = idx\n            self.idx_to_entity[idx] = edge_id\n            self.entity_types[edge_id] = 'edge'\n            self._num_entities = idx + 1\n\n            # Grow-only resize (behavior: matrix &gt;= (num_entities, num_edges))\n            M = self._matrix  # DOK\n            rows, cols = M.shape\n            if self._num_entities &gt; rows:\n                # geometric growth to reduce repeated resizes; minimum bump of 8 rows\n                new_rows = max(self._num_entities, rows + max(8, rows &gt;&gt; 1))\n                M.resize((new_rows, cols))\n\n    def add_edge(\n        self,\n        source,\n        target,\n        layer=None,\n        weight=1.0,\n        edge_id=None,\n        edge_type=\"regular\",\n        propagate=\"none\",\n        layer_weight=None,\n        directed=None,\n        edge_directed=None,\n        **attributes,\n    ):\n        \"\"\"\n        Add or update a binary edge between two entities.\n\n        Parameters\n        ----------\n        source : str\n            Source entity ID (vertex or edge-entity for vertex-edge mode).\n        target : str\n            Target entity ID.\n        layer : str, optional\n            Layer to place the edge into. Defaults to the active layer.\n        weight : float, optional\n            Global edge weight stored in the incidence column (default 1.0).\n        edge_id : str, optional\n            Explicit edge ID. If omitted, a fresh ID is generated.\n        edge_type : {'regular', 'vertex_edge'}, optional\n            Edge kind. ``'vertex_edge'`` allows connecting to an edge-entity.\n        propagate : {'none', 'shared', 'all'}, optional\n            Layer propagation:\n            - ``'none'`` : only the specified layer\n            - ``'shared'`` : all layers that already contain **both** endpoints\n            - ``'all'`` : all layers that contain **either** endpoint (and add the other)\n        layer_weight : float, optional\n            Per-layer weight override for this edge (stored in edge-layer DF).\n        edge_directed : bool, optional\n            Override default directedness for this edge. If None, uses graph default.\n        **attributes\n            Pure edge attributes to upsert.\n\n        Returns\n        -------\n        str\n            The edge ID (new or updated).\n\n        Raises\n        ------\n        ValueError\n            If ``propagate`` or ``edge_type`` is invalid.\n        TypeError\n            If ``weight`` is not numeric.\n\n        Notes\n        -----\n        - Directed edges write ``+weight`` at source row and ``-weight`` at target row.\n        - Undirected edges write ``+weight`` at both endpoints.\n        - Updating an existing edge ID overwrites its matrix column and metadata.\n        \"\"\"\n        if edge_type is None:\n            edge_type = \"regular\"\n\n        # normalize endpoints: accept str OR iterable; route hyperedges\n        def _to_tuple(x):\n            if isinstance(x, (str, bytes)):\n                return (x,), False\n            try:\n                xs = tuple(x)\n            except TypeError:\n                return (x,), False\n            return xs, (len(xs) != 1)\n\n        S, src_multi = _to_tuple(source)\n        T, tgt_multi = _to_tuple(target)\n\n        # Hyperedge delegation\n        if src_multi or tgt_multi:\n            if edge_directed:\n                return self.add_hyperedge(\n                    head=S, tail=T, edge_directed=True,\n                    layer=layer, weight=weight, edge_id=edge_id, **attributes\n                )\n            else:\n                members = tuple(set(S) | set(T))\n                return self.add_hyperedge(\n                    members=members, edge_directed=False,\n                    layer=layer, weight=weight, edge_id=edge_id, **attributes\n                )\n\n        # Binary case: unwrap singletons to plain IDs\n        source, target = S[0], T[0]\n\n        # validate inputs\n        if propagate not in {\"none\", \"shared\", \"all\"}:\n            raise ValueError(f\"propagate must be one of 'none'|'shared'|'all', got {propagate!r}\")\n        if not isinstance(weight, (int, float)):\n            raise TypeError(f\"weight must be numeric, got {type(weight).__name__}\")\n        if edge_type not in {\"regular\", \"vertex_edge\"}:\n            raise ValueError(f\"edge_type must be 'regular' or 'vertex_edge', got {edge_type!r}\")\n\n        # resolve layer + whether to touch layering at all\n        layer = self._current_layer if layer is None else layer\n        touch_layer = layer is not None\n\n        # Intern common strings to speed up dict lookups\n        try:\n            import sys as _sys\n            if isinstance(source, str): source = _sys.intern(source)\n            if isinstance(target, str): target = _sys.intern(target)\n            if isinstance(layer, str):  layer  = _sys.intern(layer)\n            if isinstance(edge_id, str): edge_id = _sys.intern(edge_id)\n        except Exception:\n            pass\n\n        entity_to_idx = self.entity_to_idx\n        idx_to_edge = self.idx_to_edge\n        edge_to_idx = self.edge_to_idx\n        edge_defs = self.edge_definitions\n        edge_w = self.edge_weights\n        edge_dir = self.edge_directed\n        layers = self._layers\n        M = self._matrix  # DOK\n\n        # ensure vertices exist (global)\n        def _ensure_vertex_or_edge_entity(x):\n            if x in entity_to_idx:\n                return\n            if edge_type == \"vertex_edge\" and isinstance(x, str) and x.startswith(\"edge_\"):\n                self.add_edge_entity(x, layer=layer)\n            else:\n                self.add_vertex(x, layer=layer)\n\n        _ensure_vertex_or_edge_entity(source)\n        _ensure_vertex_or_edge_entity(target)\n\n        # indices (after potential vertex creation)\n        source_idx = entity_to_idx[source]\n        target_idx = entity_to_idx[target]\n\n        # edge id\n        if edge_id is None:\n            edge_id = self._get_next_edge_id()\n\n        # determine direction\n        if edge_directed is not None:\n            is_dir = bool(edge_directed)\n        elif self.directed is not None:\n            is_dir = self.directed\n        else:\n            is_dir = True\n\n        if edge_id in edge_to_idx:\n            # UPDATE existing column\n\n            col_idx = edge_to_idx[edge_id]\n\n            # allow explicit direction change; otherwise keep existing\n            if edge_directed is None:\n                is_dir = edge_dir.get(edge_id, is_dir)\n            edge_dir[edge_id] = is_dir\n\n            # keep edge_type attr write\n            self.set_edge_attrs(edge_id, edge_type=(EdgeType.DIRECTED if is_dir else EdgeType.UNDIRECTED))\n\n            # if source/target changed, update definition\n            old_src, old_tgt, old_type = edge_defs[edge_id]\n            edge_defs[edge_id] = (source, target, old_type)  # keep old_type by default\n\n            # ensure matrix has enough rows (in case vertices were added since creation)\n            self._grow_rows_to(self._num_entities)\n\n\n            # clear only the cells that were previously set, not the whole column\n            try:\n                old_src_idx = entity_to_idx[old_src]\n                M[old_src_idx, col_idx] = 0\n            except KeyError:\n                pass\n            if old_src != old_tgt:\n                try:\n                    old_tgt_idx = entity_to_idx[old_tgt]\n                    M[old_tgt_idx, col_idx] = 0\n                except KeyError:\n                    pass\n\n            # write new endpoints\n            M[source_idx, col_idx] = weight\n            if source != target:\n                M[target_idx, col_idx] = (-weight if is_dir else weight)\n\n            edge_w[edge_id] = weight\n\n        else:\n            # CREATE new column\n\n            col_idx = self._num_edges\n            edge_to_idx[edge_id] = col_idx\n            idx_to_edge[col_idx] = edge_id\n            edge_defs[edge_id] = (source, target, edge_type)\n            edge_w[edge_id] = weight\n            edge_dir[edge_id] = is_dir\n            self._num_edges = col_idx + 1\n\n            # grow-only to current logical capacity\n            self._grow_rows_to(self._num_entities)\n            self._grow_cols_to(self._num_edges)\n            M[source_idx, col_idx] = weight\n            if source != target:\n                M[target_idx, col_idx] = (-weight if is_dir else weight)\n\n        # layer handling\n        if touch_layer:\n            if layer not in layers:\n                layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n            layers[layer][\"edges\"].add(edge_id)\n            layers[layer][\"vertices\"].update((source, target))\n\n            if layer_weight is not None:\n                w = float(layer_weight)\n                self.set_edge_layer_attrs(layer, edge_id, weight=w)\n                self.layer_edge_weights.setdefault(layer, {})[edge_id] = w\n\n        # propagation\n        if propagate == \"shared\":\n            self._propagate_to_shared_layers(edge_id, source, target)\n        elif propagate == \"all\":\n            self._propagate_to_all_layers(edge_id, source, target)\n\n        # attributes\n        if attributes:\n            self.set_edge_attrs(edge_id, **attributes)\n\n        return edge_id\n\n    def add_parallel_edge(self, source, target, weight=1.0, **attributes):\n        \"\"\"\n        Add a parallel edge (same endpoints, different ID).\n\n        Parameters\n        ----------\n        source : str\n        target : str\n        weight : float, optional\n        **attributes\n            Pure edge attributes.\n\n        Returns\n        -------\n        str\n            The new edge ID.\n        \"\"\"\n        try:\n            import sys as _sys\n            if isinstance(source, str): source = _sys.intern(source)\n            if isinstance(target, str): target = _sys.intern(target)\n        except Exception:\n            pass\n\n        _add_edge = self.add_edge\n        return _add_edge(source, target, weight=weight, edge_id=None, **attributes)\n\n    def add_hyperedge(\n        self,\n        *,\n        members=None,\n        head=None,\n        tail=None,\n        layer=None,\n        weight=1.0,\n        edge_id=None,\n        edge_directed=None,   # bool or None (None -&gt; infer from params)\n        **attributes,\n    ):\n        \"\"\"\n        Create a k-ary hyperedge as a single incidence column.\n\n        Modes\n        -----\n        - **Undirected**: pass ``members`` (&gt;=2). Each member gets ``+weight``.\n        - **Directed**: pass ``head`` and ``tail`` (both non-empty, disjoint).\n        Head gets ``+weight``; tail gets ``-weight``.\n        \"\"\"\n        # validate form\n        if members is None and (head is None or tail is None):\n            raise ValueError(\"Provide members (undirected) OR head+tail (directed).\")\n        if members is not None and (head is not None or tail is not None):\n            raise ValueError(\"Use either members OR head+tail, not both.\")\n\n        if members is not None:\n            members = list(members)\n            if len(members) &lt; 2:\n                raise ValueError(\"Hyperedge needs &gt;=2 members.\")\n            directed = False if edge_directed is None else bool(edge_directed)\n            if directed:\n                raise ValueError(\"Directed=True requires head+tail, not members.\")\n        else:\n            head = list(head)\n            tail = list(tail)\n            if not head or not tail:\n                raise ValueError(\"Directed hyperedge needs non-empty head and tail.\")\n            if set(head) &amp; set(tail):\n                raise ValueError(\"head and tail must be disjoint.\")\n            directed = True if edge_directed is None else bool(edge_directed)\n            if not directed:\n                raise ValueError(\"Undirected=False conflicts with head/tail.\")\n\n        # set layer\n        layer = self._current_layer if layer is None else layer\n\n        # Intern frequently-used strings for cheaper dict ops\n        try:\n            import sys as _sys\n            if isinstance(layer, str): layer = _sys.intern(layer)\n            if isinstance(edge_id, str): edge_id = _sys.intern(edge_id)\n            if members is not None:\n                members = [ _sys.intern(u) if isinstance(u, str) else u for u in members ]\n            else:\n                head  = [ _sys.intern(u) if isinstance(u, str) else u for u in head ]\n                tail  = [ _sys.intern(v) if isinstance(v, str) else v for v in tail ]\n        except Exception:\n            pass\n\n        # locals for hot paths\n        entity_to_idx = self.entity_to_idx\n        layers = self._layers\n        M = self._matrix  # DOK\n\n        # ensure participants exist globally\n        def _ensure_entity(x):\n            if x in entity_to_idx:\n                return\n            if isinstance(x, str) and x.startswith(\"edge_\") and x in self.entity_types and self.entity_types[x] == \"edge\":\n                return\n            self.add_vertex(x, layer=layer)\n\n        if members is not None:\n            for u in members:\n                _ensure_entity(u)\n        else:\n            for u in head:\n                _ensure_entity(u)\n            for v in tail:\n                _ensure_entity(v)\n\n        # allocate edge id + column\n        if edge_id is None:\n            edge_id = self._get_next_edge_id()\n\n        is_new = edge_id not in self.edge_to_idx\n        if is_new:\n            col_idx = self._num_edges\n            self.edge_to_idx[edge_id] = col_idx\n            self.idx_to_edge[col_idx] = edge_id\n            self._num_edges += 1\n            self._grow_rows_to(self._num_entities)\n            self._grow_cols_to(self._num_edges)\n        else:\n            col_idx = self.edge_to_idx[edge_id]\n            # clear: delete only previously set cells instead of zeroing whole column\n            # handle prior hyperedge or binary edge reuse\n            prev_h = self.hyperedge_definitions.get(edge_id)\n            if prev_h is not None:\n                if prev_h.get(\"directed\", False):\n                    rows_to_clear = prev_h[\"head\"] | prev_h[\"tail\"]\n                else:\n                    rows_to_clear = prev_h[\"members\"]\n                for vid in rows_to_clear:\n                    try:\n                        M[entity_to_idx[vid], col_idx] = 0\n                    except KeyError:\n                        # vertex may not exist anymore; ignore\n                        pass\n            else:\n                # maybe it was a binary edge before\n                prev = self.edge_definitions.get(edge_id)\n                if prev is not None:\n                    src, tgt, _ = prev\n                    if src is not None:\n                        try:\n                            M[entity_to_idx[src], col_idx] = 0\n                        except KeyError:\n                            pass\n                    if tgt is not None and tgt != src:\n                        try:\n                            M[entity_to_idx[tgt], col_idx] = 0\n                        except KeyError:\n                            pass\n\n        self._grow_rows_to(self._num_entities)\n\n        # write column entries\n        w = float(weight)\n        if members is not None:\n            # undirected: +w at each member\n            for u in members:\n                M[entity_to_idx[u], col_idx] = w\n            self.hyperedge_definitions[edge_id] = {\n                \"directed\": False,\n                \"members\": set(members),\n            }\n        else:\n            # directed: +w on head, -w on tail\n            for u in head:\n                M[entity_to_idx[u], col_idx] = w\n            mw = -w\n            for v in tail:\n                M[entity_to_idx[v], col_idx] = mw\n            self.hyperedge_definitions[edge_id] = {\n                \"directed\": True,\n                \"head\": set(head),\n                \"tail\": set(tail),\n            }\n\n        # bookkeeping shared with binary edges\n        self.edge_weights[edge_id] = w\n        self.edge_directed[edge_id] = bool(directed)\n        self.edge_kind[edge_id] = \"hyper\"\n        # keep a sentinel in edge_definitions so old code won't crash\n        self.edge_definitions[edge_id] = (None, None, \"hyper\")\n\n        # layer membership + per-layer vertices\n        if layer is not None:\n            if layer not in layers:\n                layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n            layers[layer][\"edges\"].add(edge_id)\n            if members is not None:\n                layers[layer][\"vertices\"].update(members)\n            else:\n                layers[layer][\"vertices\"].update(self.hyperedge_definitions[edge_id][\"head\"])\n                layers[layer][\"vertices\"].update(self.hyperedge_definitions[edge_id][\"tail\"])\n\n        # attributes\n        if attributes:\n            self.set_edge_attrs(edge_id, **attributes)\n\n        return edge_id\n\n    def add_edge_to_layer(self, lid, eid):\n        \"\"\"\n        Attach an existing edge to a layer (no weight changes).\n\n        Parameters\n        ----------\n        lid : str\n            Layer ID.\n        eid : str\n            Edge ID.\n\n        Raises\n        ------\n        KeyError\n            If the layer does not exist.\n        \"\"\"\n        if lid not in self._layers:\n            raise KeyError(f\"Layer {lid} does not exist\")\n        self._layers[lid][\"edges\"].add(eid)\n\n    def _propagate_to_shared_layers(self, edge_id, source, target):\n        \"\"\"\n        INTERNAL: Add an edge to all layers that already contain **both** endpoints.\n\n        Parameters\n        ----------\n        edge_id : str\n        source : str\n        target : str\n        \"\"\"\n        for layer_id, layer_data in self._layers.items():\n            if source in layer_data[\"vertices\"] and target in layer_data[\"vertices\"]:\n                layer_data[\"edges\"].add(edge_id)\n\n    def _propagate_to_all_layers(self, edge_id, source, target):\n        \"\"\"\n        INTERNAL: Add an edge to any layer containing **either** endpoint and\n        insert the missing endpoint into that layer.\n\n        Parameters\n        ----------\n        edge_id : str\n        source : str\n        target : str\n        \"\"\"\n        for layer_id, layer_data in self._layers.items():\n            if source in layer_data[\"vertices\"] or target in layer_data[\"vertices\"]:\n                layer_data[\"edges\"].add(edge_id)\n                # Only add missing endpoint if both vertices should be in layer\n                if source in layer_data[\"vertices\"]:\n                    layer_data[\"vertices\"].add(target)\n                if target in layer_data[\"vertices\"]:\n                    layer_data[\"vertices\"].add(source)\n\n    def _normalize_vertices_arg(self, vertices):\n        \"\"\"\n        Normalize a single vertex or an iterable of vertices into a set.\n\n        This internal utility function standardizes input for methods like\n        `in_edges()` and `out_edges()` by converting the argument into a set\n        of vertex identifiers.\n\n        Parameters\n        ----------\n        vertices : str | Iterable[str] | None\n            - A single vertex ID (string).\n            - An iterable of vertex IDs (e.g., list, tuple, set).\n            - `None` is allowed and will return an empty set.\n\n        Returns\n        -------\n        set[str]\n            A set of vertex identifiers. If `vertices` is `None`, returns an\n            empty set. If a single vertex is provided, returns a one-element set.\n\n        Notes\n        -----\n        - Strings are treated as **single vertex IDs**, not iterables.\n        - If the argument is neither iterable nor a string, it is wrapped in a set.\n        - Used internally by API methods that accept flexible vertex arguments.\n        \"\"\"\n        if vertices is None:\n            return set()\n        if isinstance(vertices, (str, bytes)):\n            return {vertices}\n        try:\n            return set(vertices)\n        except TypeError:\n            return {vertices}\n\n    # Bulk build graph\n\n    def add_vertices_bulk(self, vertices, layer=None):\n        \"\"\"\n        Bulk add vertices (and edge-entities if prefixed externally).\n        Accepts: iterable of str  OR  iterable of (vertex_id, attrs_dict)  OR iterable of dicts with keys {'vertex_id', ...attrs}\n        Behavior: identical to calling add_vertex() for each, but resizes once and batches attribute inserts.\n        \"\"\"\n        import polars as pl\n\n        layer = layer or self._current_layer\n\n        # Normalize items -&gt; [(vid, attrs_dict), ...]\n        norm = []\n        for it in vertices:\n            if isinstance(it, dict):\n                vid = it.get(\"vertex_id\") or it.get(\"id\") or it.get(\"name\")\n                if vid is None:\n                    continue\n                a = {k: v for k, v in it.items() if k not in (\"vertex_id\", \"id\", \"name\")}\n                norm.append((vid, a))\n            elif isinstance(it, (tuple, list)) and it:\n                vid = it[0]\n                a = (it[1] if len(it) &gt; 1 and isinstance(it[1], dict) else {})\n                norm.append((vid, a))\n            else:\n                norm.append((it, {}))\n\n        if not norm:\n            return\n\n        # Intern hot strings\n        try:\n            import sys as _sys\n            norm = [(_sys.intern(vid) if isinstance(vid, str) else vid, attrs) for vid, attrs in norm]\n            if isinstance(layer, str):\n                layer = _sys.intern(layer)\n        except Exception:\n            pass\n\n        # Create missing vertices without per-item resize thrash\n        new_rows = 0\n        for vid, _ in norm:\n            if vid not in self.entity_to_idx:\n                idx = self._num_entities\n                self.entity_to_idx[vid] = idx\n                self.idx_to_entity[idx] = vid\n                self.entity_types[vid] = \"vertex\"\n                self._num_entities = idx + 1\n                new_rows += 1\n\n        # Grow rows once if needed\n        if new_rows:\n            self._grow_rows_to(self._num_entities)\n\n        # Layer membership (same semantics as add_vertex)\n        if layer not in self._layers:\n            self._layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n        self._layers[layer][\"vertices\"].update(vid for vid, _ in norm)\n\n        # Vertex attributes (batch insert for new ones, upsert for existing with attrs)\n        self._ensure_vertex_table()\n        df = self.vertex_attributes\n\n        # Collect existing ids (if any)\n        existing_ids = set()\n        try:\n            if isinstance(df, pl.DataFrame) and df.height and \"vertex_id\" in df.columns:\n                existing_ids = set(df.get_column(\"vertex_id\").to_list())\n        except Exception:\n            pass\n\n        # Rows to append for ids missing in DF\n        to_append = []\n        for vid, attrs in norm:\n            if df.is_empty() or vid not in existing_ids:\n                row = {c: None for c in df.columns} if not df.is_empty() else {\"vertex_id\": None}\n                row[\"vertex_id\"] = vid\n                for k, v in attrs.items():\n                    row[k] = v\n                to_append.append(row)\n\n        if to_append:\n            # Ensure df has any new columns first\n            need_cols = {k for row in to_append for k in row.keys() if k != \"vertex_id\"}\n            if need_cols:\n                df = self._ensure_attr_columns(df, {k: None for k in need_cols})\n\n            # Build add_df with full inference over the whole batch to avoid ComputeError\n            add_df = pl.DataFrame(\n                to_append,\n                infer_schema_length=len(to_append),\n                nan_to_null=True,\n                strict=False,\n            )\n\n            # Make sure all df columns exist on add_df\n            for c in df.columns:\n                if c not in add_df.columns:\n                    add_df = add_df.with_columns(pl.lit(None).cast(df.schema[c]).alias(c))\n\n            # Dtype reconciliation (mirror _upsert_row semantics)\n            for c in df.columns:\n                lc, rc = df.schema[c], add_df.schema[c]\n                if lc == pl.Null and rc != pl.Null:\n                    df = df.with_columns(pl.col(c).cast(rc))\n                elif rc == pl.Null and lc != pl.Null:\n                    add_df = add_df.with_columns(pl.col(c).cast(lc).alias(c))\n                elif lc != rc:\n                    # resolve mismatches by upcasting both to Utf8 (UTF-8 string)\n                    df = df.with_columns(pl.col(c).cast(pl.Utf8))\n                    add_df = add_df.with_columns(pl.col(c).cast(pl.Utf8).alias(c))\n\n            # Reorder columns EXACTLY to match df before vstack\n            add_df = add_df.select(df.columns)\n\n            df = df.vstack(add_df)\n\n        # Upsert attrs for existing ids (vector of updates via helper)\n        for vid, attrs in norm:\n            if attrs and (df.is_empty() or (vid in existing_ids)):\n                df = self._upsert_row(df, vid, attrs)\n\n        self.vertex_attributes = df\n\n    def add_edges_bulk(\n        self,\n        edges,\n        *,\n        layer=None,\n        default_weight=1.0,\n        default_edge_type=\"regular\",\n        default_propagate=\"none\",\n        default_layer_weight=None,\n        default_edge_directed=None,\n    ):\n        \"\"\"\n        Bulk add/update *binary* (and vertex-edge) edges.\n        Accepts each item as:\n        - (src, tgt)\n        - (src, tgt, weight)\n        - dict with keys: source, target, [weight, edge_id, edge_type, propagate, layer_weight, edge_directed, attributes]\n        Behavior: identical to calling add_edge() per item (same propagation/layer/attrs), but grows columns once and avoids full-column wipes.\n        \"\"\"\n        layer = self._current_layer if layer is None else layer\n\n        # Normalize into dicts\n        norm = []\n        for it in edges:\n            if isinstance(it, dict):\n                d = dict(it)\n            elif isinstance(it, (tuple, list)):\n                if len(it) == 2:\n                    d = {\"source\": it[0], \"target\": it[1], \"weight\": default_weight}\n                else:\n                    d = {\"source\": it[0], \"target\": it[1], \"weight\": it[2]}\n            else:\n                continue\n            d.setdefault(\"weight\", default_weight)\n            d.setdefault(\"edge_type\", default_edge_type)\n            d.setdefault(\"propagate\", default_propagate)\n            if \"layer\" not in d:\n                d[\"layer\"] = layer\n            if \"edge_directed\" not in d:\n                d[\"edge_directed\"] = default_edge_directed\n            norm.append(d)\n\n        if not norm:\n            return []\n\n        # Intern hot strings &amp; coerce weights\n        try:\n            import sys as _sys\n            for d in norm:\n                s, t = d[\"source\"], d[\"target\"]\n                if isinstance(s, str): d[\"source\"] = _sys.intern(s)\n                if isinstance(t, str): d[\"target\"] = _sys.intern(t)\n                lid = d.get(\"layer\")\n                if isinstance(lid, str): d[\"layer\"] = _sys.intern(lid)\n                eid = d.get(\"edge_id\")\n                if isinstance(eid, str): d[\"edge_id\"] = _sys.intern(eid)\n                try:\n                    d[\"weight\"] = float(d[\"weight\"])\n                except Exception:\n                    pass\n        except Exception:\n            pass\n\n        entity_to_idx = self.entity_to_idx\n        M = self._matrix\n        # 1) Ensure endpoints exist (global); we\u2019ll rely on layer handling below to add membership.\n        for d in norm:\n            s, t = d[\"source\"], d[\"target\"]\n            et = d.get(\"edge_type\", \"regular\")\n            if s not in entity_to_idx:\n                # vertex or edge-entity depending on mode?\n                if et == \"vertex_edge\" and isinstance(s, str) and s.startswith(\"edge_\"):\n                    self._add_edge_entity(s)\n                else:\n                    # bare global insert (no layer side-effects; membership handled later)\n                    idx = self._num_entities\n                    self.entity_to_idx[s] = idx\n                    self.idx_to_entity[idx] = s\n                    self.entity_types[s] = \"vertex\"\n                    self._num_entities = idx + 1\n            if t not in entity_to_idx:\n                if et == \"vertex_edge\" and isinstance(t, str) and t.startswith(\"edge_\"):\n                    self._add_edge_entity(t)\n                else:\n                    idx = self._num_entities\n                    self.entity_to_idx[t] = idx\n                    self.idx_to_entity[idx] = t\n                    self.entity_types[t] = \"vertex\"\n                    self._num_entities = idx + 1\n\n        # Grow rows once if needed\n        self._grow_rows_to(self._num_entities)\n\n        # 2) Pre-size columns for new edges\n        new_count = sum(1 for d in norm if d.get(\"edge_id\") not in self.edge_to_idx)\n        if new_count:\n            self._grow_cols_to(self._num_edges + new_count)\n\n        # 3) Create/update columns\n        out_ids = []\n        for d in norm:\n            s, t = d[\"source\"], d[\"target\"]\n            w = d[\"weight\"]\n            etype = d.get(\"edge_type\", \"regular\")\n            prop = d.get(\"propagate\", default_propagate)\n            layer_local = d.get(\"layer\", layer)\n            layer_w = d.get(\"layer_weight\", default_layer_weight)\n            e_dir = d.get(\"edge_directed\", default_edge_directed)\n            edge_id = d.get(\"edge_id\")\n\n            if e_dir is not None:\n                is_dir = bool(e_dir)\n            elif self.directed is not None:\n                is_dir = self.directed\n            else:\n                is_dir = True\n            s_idx = self.entity_to_idx[s]; t_idx = self.entity_to_idx[t]\n\n            if edge_id is None:\n                edge_id = self._get_next_edge_id()\n\n            # update vs create\n            if edge_id in self.edge_to_idx:\n                col = self.edge_to_idx[edge_id]\n                # keep old_type on update (mimic add_edge)\n                old_s, old_t, old_type = self.edge_definitions[edge_id]\n                # clear only previous cells (no full column wipe)\n                try:\n                    M[self.entity_to_idx[old_s], col] = 0\n                except Exception:\n                    pass\n                if old_t is not None and old_t != old_s:\n                    try:\n                        M[self.entity_to_idx[old_t], col] = 0\n                    except Exception:\n                        pass\n                # write new\n                M[s_idx, col] = w\n                if s != t:\n                    M[t_idx, col] = (-w if is_dir else w)\n                self.edge_definitions[edge_id] = (s, t, old_type)\n                self.edge_weights[edge_id] = w\n                self.edge_directed[edge_id] = is_dir\n                # keep attribute side-effect for directedness flag\n                self.set_edge_attrs(edge_id, edge_type=(EdgeType.DIRECTED if is_dir else EdgeType.UNDIRECTED))\n            else:\n                col = self._num_edges\n                self.edge_to_idx[edge_id] = col\n                self.idx_to_edge[col] = edge_id\n                self.edge_definitions[edge_id] = (s, t, etype)\n                self.edge_weights[edge_id] = w\n                self.edge_directed[edge_id] = is_dir\n                self._num_edges = col + 1\n                # write cells\n                M[s_idx, col] = w\n                if s != t:\n                    M[t_idx, col] = (-w if is_dir else w)\n\n            # layer membership + optional per-layer weight\n            if layer_local is not None:\n                if layer_local not in self._layers:\n                    self._layers[layer_local] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n                self._layers[layer_local][\"edges\"].add(edge_id)\n                self._layers[layer_local][\"vertices\"].update((s, t))\n                if layer_w is not None:\n                    self.set_edge_layer_attrs(layer_local, edge_id, weight=float(layer_w))\n                    self.layer_edge_weights.setdefault(layer_local, {})[edge_id] = float(layer_w)\n\n            # propagation\n            if prop == \"shared\":\n                self._propagate_to_shared_layers(edge_id, s, t)\n            elif prop == \"all\":\n                self._propagate_to_all_layers(edge_id, s, t)\n\n            # per-edge extra attributes\n            attrs = d.get(\"attributes\") or d.get(\"attrs\") or {}\n            if attrs:\n                self.set_edge_attrs(edge_id, **attrs)\n\n            out_ids.append(edge_id)\n\n        return out_ids\n\n    def add_hyperedges_bulk(\n        self,\n        hyperedges,\n        *,\n        layer=None,\n        default_weight=1.0,\n        default_edge_directed=None,\n    ):\n        \"\"\"\n        Bulk add/update hyperedges.\n        Each item can be:\n        - {'members': [...], 'edge_id': ..., 'weight': ..., 'layer': ..., 'attributes': {...}}\n        - {'head': [...], 'tail': [...], ...}\n        Behavior: identical to calling add_hyperedge() per item, but grows columns once and avoids full-column wipes.\n        \"\"\"\n        layer = self._current_layer if layer is None else layer\n\n        items = []\n        for it in hyperedges:\n            if not isinstance(it, dict):\n                continue\n            d = dict(it)\n            d.setdefault(\"weight\", default_weight)\n            if \"layer\" not in d:\n                d[\"layer\"] = layer\n            if \"edge_directed\" not in d:\n                d[\"edge_directed\"] = default_edge_directed\n            items.append(d)\n\n        if not items:\n            return []\n\n        # Intern + coerce\n        try:\n            import sys as _sys\n            for d in items:\n                if \"members\" in d and d[\"members\"] is not None:\n                    d[\"members\"] = [ _sys.intern(x) if isinstance(x, str) else x for x in d[\"members\"] ]\n                else:\n                    d[\"head\"] = [ _sys.intern(x) if isinstance(x, str) else x for x in d.get(\"head\", []) ]\n                    d[\"tail\"] = [ _sys.intern(x) if isinstance(x, str) else x for x in d.get(\"tail\", []) ]\n                lid = d.get(\"layer\")\n                if isinstance(lid, str): d[\"layer\"] = _sys.intern(lid)\n                eid = d.get(\"edge_id\")\n                if isinstance(eid, str): d[\"edge_id\"] = _sys.intern(eid)\n                try:\n                    d[\"weight\"] = float(d[\"weight\"])\n                except Exception:\n                    pass\n        except Exception:\n            pass\n\n        # Ensure participants exist (global)\n        for d in items:\n            if \"members\" in d and d[\"members\"] is not None:\n                for u in d[\"members\"]:\n                    if u not in self.entity_to_idx:\n                        idx = self._num_entities\n                        self.entity_to_idx[u] = idx\n                        self.idx_to_entity[idx] = u\n                        self.entity_types[u] = \"vertex\"\n                        self._num_entities = idx + 1\n            else:\n                for u in d.get(\"head\", []):\n                    if u not in self.entity_to_idx:\n                        idx = self._num_entities\n                        self.entity_to_idx[u] = idx\n                        self.idx_to_entity[idx] = u\n                        self.entity_types[u] = \"vertex\"\n                        self._num_entities = idx + 1\n                for v in d.get(\"tail\", []):\n                    if v not in self.entity_to_idx:\n                        idx = self._num_entities\n                        self.entity_to_idx[v] = idx\n                        self.entity_types[v] = \"vertex\"\n                        self.idx_to_entity[idx] = v\n                        self._num_entities = idx + 1\n\n        # Grow rows once\n        self._grow_rows_to(self._num_entities)\n\n        # Pre-size columns\n        new_count = sum(1 for d in items if d.get(\"edge_id\") not in self.edge_to_idx)\n        if new_count:\n            self._grow_cols_to(self._num_edges + new_count)\n\n        M = self._matrix\n        out_ids = []\n\n        for d in items:\n            members = d.get(\"members\")\n            head = d.get(\"head\")\n            tail = d.get(\"tail\")\n            layer_local = d.get(\"layer\", layer)\n            w = float(d.get(\"weight\", default_weight))\n            e_id = d.get(\"edge_id\")\n\n            # Decide directedness from form unless forced\n            directed = d.get(\"edge_directed\")\n            if directed is None:\n                directed = (members is None)\n\n            # allocate/update column\n            if e_id is None:\n                e_id = self._get_next_edge_id()\n\n            if e_id in self.edge_to_idx:\n                col = self.edge_to_idx[e_id]\n                # clear old cells (binary or hyper)\n                if e_id in self.hyperedge_definitions:\n                    h = self.hyperedge_definitions[e_id]\n                    if h.get(\"members\"):\n                        rows = h[\"members\"]\n                    else:\n                        rows = set(h.get(\"head\", ())) | set(h.get(\"tail\", ()))\n                    for vid in rows:\n                        try:\n                            M[self.entity_to_idx[vid], col] = 0\n                        except Exception:\n                            pass\n                else:\n                    old = self.edge_definitions.get(e_id)\n                    if old is not None:\n                        os, ot, _ = old\n                        try:\n                            M[self.entity_to_idx[os], col] = 0\n                        except Exception:\n                            pass\n                        if ot is not None and ot != os:\n                            try:\n                                M[self.entity_to_idx[ot], col] = 0\n                            except Exception:\n                                pass\n            else:\n                col = self._num_edges\n                self.edge_to_idx[e_id] = col\n                self.idx_to_edge[col] = e_id\n                self._num_edges = col + 1\n\n            # write new column values + metadata\n            if members is not None:\n                for u in members:\n                    M[self.entity_to_idx[u], col] = w\n                self.hyperedge_definitions[e_id] = {\"directed\": False, \"members\": set(members)}\n                self.edge_directed[e_id] = False\n                self.edge_kind[e_id] = \"hyper\"\n                self.edge_definitions[e_id] = (None, None, \"hyper\")\n            else:\n                for u in head:\n                    M[self.entity_to_idx[u], col] = w\n                for v in tail:\n                    M[self.entity_to_idx[v], col] = -w\n                self.hyperedge_definitions[e_id] = {\"directed\": True, \"head\": set(head), \"tail\": set(tail)}\n                self.edge_directed[e_id] = True\n                self.edge_kind[e_id] = \"hyper\"\n                self.edge_definitions[e_id] = (None, None, \"hyper\")\n\n            self.edge_weights[e_id] = w\n\n            # layer membership\n            if layer_local is not None:\n                if layer_local not in self._layers:\n                    self._layers[layer_local] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n                self._layers[layer_local][\"edges\"].add(e_id)\n                if members is not None:\n                    self._layers[layer_local][\"vertices\"].update(members)\n                else:\n                    self._layers[layer_local][\"vertices\"].update(head)\n                    self._layers[layer_local][\"vertices\"].update(tail)\n\n            # per-edge attributes (optional)\n            attrs = d.get(\"attributes\") or d.get(\"attrs\") or {}\n            if attrs:\n                self.set_edge_attrs(e_id, **attrs)\n\n            out_ids.append(e_id)\n\n        return out_ids\n\n    def add_edges_to_layer_bulk(self, layer_id, edge_ids):\n        \"\"\"\n        Bulk version of add_edge_to_layer: add many edges to a layer and attach\n        all incident vertices. No weights are changed here.\n        \"\"\"\n        layer = layer_id if layer_id is not None else self._current_layer\n        if layer not in self._layers:\n            self._layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n        L = self._layers[layer]\n\n        add_edges = {eid for eid in edge_ids if eid in self.edge_to_idx}\n        if not add_edges:\n            return\n\n        L[\"edges\"].update(add_edges)\n\n        verts = set()\n        for eid in add_edges:\n            kind = self.edge_kind.get(eid, \"binary\")\n            if kind == \"hyper\":\n                h = self.hyperedge_definitions[eid]\n                if h.get(\"members\") is not None:\n                    verts.update(h[\"members\"])\n                else:\n                    verts.update(h.get(\"head\", ()))\n                    verts.update(h.get(\"tail\", ()))\n            else:\n                s, t, _ = self.edge_definitions[eid]\n                verts.add(s); verts.add(t)\n\n        L[\"vertices\"].update(verts)\n\n    def add_edge_entities_bulk(self, items, layer=None):\n        \"\"\"\n        Bulk add edge-entities (vertex-edge hybrids). Accepts:\n        - iterable of str IDs\n        - iterable of (edge_entity_id, attrs_dict)\n        - iterable of dicts with key 'edge_entity_id' (or 'id')\n        Behavior: identical to calling add_edge_entity() for each, but grows rows once\n        and batches attribute inserts.\n        \"\"\"\n        layer = layer or self._current_layer\n\n        # normalize -&gt; [(eid, attrs)]\n        norm = []\n        for it in items:\n            if isinstance(it, dict):\n                eid = it.get(\"edge_entity_id\") or it.get(\"id\")\n                if eid is None: continue\n                a = {k: v for k, v in it.items() if k not in (\"edge_entity_id\",\"id\")}\n                norm.append((eid, a))\n            elif isinstance(it, (tuple, list)) and it:\n                eid = it[0]; a = (it[1] if len(it) &gt; 1 and isinstance(it[1], dict) else {})\n                norm.append((eid, a))\n            else:\n                norm.append((it, {}))\n        if not norm:\n            return\n\n        # intern hot strings\n        try:\n            import sys as _sys\n            norm = [(_sys.intern(eid) if isinstance(eid, str) else eid, attrs) for eid, attrs in norm]\n            if isinstance(layer, str): layer = _sys.intern(layer)\n        except Exception:\n            pass\n\n        # create missing rows as type 'edge'\n        new_rows = 0\n        for eid, _ in norm:\n            if eid not in self.entity_to_idx:\n                idx = self._num_entities\n                self.entity_to_idx[eid] = idx\n                self.idx_to_entity[idx] = eid\n                self.entity_types[eid] = \"edge\"\n                self._num_entities = idx + 1\n                new_rows += 1\n\n        if new_rows:\n            self._grow_rows_to(self._num_entities)\n\n        # layer membership\n        if layer not in self._layers:\n            self._layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n        self._layers[layer][\"vertices\"].update(eid for eid, _ in norm)\n\n        # attributes (edge-entities share vertex_attributes table)\n        self._ensure_vertex_table()\n        df = self.vertex_attributes\n        to_append, existing_ids = [], set()\n        try:\n            if df.height and \"vertex_id\" in df.columns:\n                existing_ids = set(df.get_column(\"vertex_id\").to_list())\n        except Exception:\n            pass\n\n        for eid, attrs in norm:\n            if df.is_empty() or eid not in existing_ids:\n                row = {c: None for c in df.columns} if not df.is_empty() else {\"vertex_id\": None}\n                row[\"vertex_id\"] = eid\n                for k, v in attrs.items():\n                    row[k] = v\n                to_append.append(row)\n\n        if to_append:\n            need_cols = {k for r in to_append for k in r if k != \"vertex_id\"}\n            if need_cols:\n                df = self._ensure_attr_columns(df, {k: None for k in need_cols})\n            add_df = pl.DataFrame(to_append)\n            for c in df.columns:\n                if c not in add_df.columns:\n                    add_df = add_df.with_columns(pl.lit(None).cast(df.schema[c]).alias(c))\n            for c in df.columns:\n                lc, rc = df.schema[c], add_df.schema[c]\n                if lc == pl.Null and rc != pl.Null:\n                    df = df.with_columns(pl.col(c).cast(rc))\n                elif rc == pl.Null and lc != pl.Null:\n                    add_df = add_df.with_columns(pl.col(c).cast(lc).alias(c))\n                elif lc != rc:\n                    df = df.with_columns(pl.col(c).cast(pl.Utf8))\n                    add_df = add_df.with_columns(pl.col(c).cast(pl.Utf8).alias(c))\n                if to_append:\n                    need_cols = {k for r in to_append for k in r if k != \"vertex_id\"}\n                    if need_cols:\n                        df = self._ensure_attr_columns(df, {k: None for k in need_cols})\n\n                    add_df = pl.DataFrame(to_append)\n\n                    # ensure all df columns exist on add_df\n                    for c in df.columns:\n                        if c not in add_df.columns:\n                            add_df = add_df.with_columns(pl.lit(None).cast(df.schema[c]).alias(c))\n\n                    # dtype reconciliation (same as before)\n                    for c in df.columns:\n                        lc, rc = df.schema[c], add_df.schema[c]\n                        if lc == pl.Null and rc != pl.Null:\n                            df = df.with_columns(pl.col(c).cast(rc))\n                        elif rc == pl.Null and lc != pl.Null:\n                            add_df = add_df.with_columns(pl.col(c).cast(lc).alias(c))\n                        elif lc != rc:\n                            df = df.with_columns(pl.col(c).cast(pl.Utf8))\n                            add_df = add_df.with_columns(pl.col(c).cast(pl.Utf8).alias(c))\n\n                    # reorder add_df columns to match df exactly\n                    add_df = add_df.select(df.columns)\n\n                    df = df.vstack(add_df)\n\n\n        for eid, attrs in norm:\n            if attrs and (df.is_empty() or (eid in existing_ids)):\n                df = self._upsert_row(df, eid, attrs)\n        self.vertex_attributes = df\n\n    # Remove / mutate down\n\n    def remove_edge(self, edge_id):\n        \"\"\"\n        Remove an edge (binary or hyperedge) from the graph.\n\n        Parameters\n        ----------\n        edge_id : str\n\n        Raises\n        ------\n        KeyError\n            If the edge is not found.\n\n        Notes\n        -----\n        - Physically removes the incidence column (no CSR round-trip).\n        - Cleans edge attributes, layer memberships, and per-layer entries.\n        \"\"\"\n        if edge_id not in self.edge_to_idx:\n            raise KeyError(f\"Edge {edge_id} not found\")\n\n        col_idx = self.edge_to_idx[edge_id]\n\n        # column removal without CSR (single pass over nonzeros)\n        M_old = self._matrix\n        rows, cols = M_old.shape\n        new_cols = cols - 1\n        # Rebuild DOK with columns &gt; col_idx shifted left by 1\n        M_new = sp.dok_matrix((rows, new_cols), dtype=M_old.dtype)\n        for (r, c), v in M_old.items():\n            if c == col_idx:\n                continue  # drop this column\n            elif c &gt; col_idx:\n                M_new[r, c - 1] = v\n            else:\n                M_new[r, c] = v\n        self._matrix = M_new\n\n        # mappings (preserve relative order of remaining edges)\n        # Remove the deleted edge id\n        del self.edge_to_idx[edge_id]\n        # Shift indices for edges after the removed column\n        for old_idx in range(col_idx + 1, self._num_edges):\n            eid = self.idx_to_edge.pop(old_idx)\n            self.idx_to_edge[old_idx - 1] = eid\n            self.edge_to_idx[eid] = old_idx - 1\n        # Drop the last stale entry (now shifted)\n        self.idx_to_edge.pop(self._num_edges - 1, None)\n        self._num_edges -= 1\n\n        # Metadata cleanup\n        # Edge definitions / weights / directedness\n        self.edge_definitions.pop(edge_id, None)\n        self.edge_weights.pop(edge_id, None)\n        if edge_id in self.edge_directed:\n            self.edge_directed.pop(edge_id, None)\n\n        # Remove from edge attributes\n        if (\n            isinstance(self.edge_attributes, pl.DataFrame)\n            and self.edge_attributes.height &gt; 0\n            and \"edge_id\" in self.edge_attributes.columns\n        ):\n            self.edge_attributes = self.edge_attributes.filter(pl.col(\"edge_id\") != edge_id)\n\n        # Remove from per-layer membership\n        for layer_data in self._layers.values():\n            layer_data[\"edges\"].discard(edge_id)\n\n        # Remove from edge-layer attributes\n        if (\n            isinstance(self.edge_layer_attributes, pl.DataFrame)\n            and self.edge_layer_attributes.height &gt; 0\n            and \"edge_id\" in self.edge_layer_attributes.columns\n        ):\n            self.edge_layer_attributes = self.edge_layer_attributes.filter(pl.col(\"edge_id\") != edge_id)\n\n        # Legacy / auxiliary dicts\n        for d in self.layer_edge_weights.values():\n            d.pop(edge_id, None)\n\n        self.edge_kind.pop(edge_id, None)\n        self.hyperedge_definitions.pop(edge_id, None)\n\n    def remove_vertex(self, vertex_id):\n        \"\"\"\n        Remove a vertex and all incident edges (binary + hyperedges).\n\n        Parameters\n        ----------\n        vertex_id : str\n\n        Raises\n        ------\n        KeyError\n            If the vertex is not found.\n\n        Notes\n        -----\n        - Rebuilds entity indexing and shrinks the incidence matrix accordingly.\n        \"\"\"\n        if vertex_id not in self.entity_to_idx:\n            raise KeyError(f\"vertex {vertex_id} not found\")\n\n        entity_idx = self.entity_to_idx[vertex_id]\n\n        # Collect incident edges (set to avoid duplicates)\n        edges_to_remove = set()\n\n        # Binary edges: edge_definitions {eid: (source, target, ...)}\n        for eid, edef in list(self.edge_definitions.items()):\n            try:\n                source, target = edef[0], edef[1]\n            except Exception:\n                source, target = edef.get(\"source\"), edef.get(\"target\")\n            if source == vertex_id or target == vertex_id:\n                edges_to_remove.add(eid)\n\n        # Hyperedges: hyperedge_definitions {eid: {\"head\":[...], \"tail\":[...]}} or {\"members\":[...]}\n        def _vertex_in_hyperdef(hdef: dict, vertex: str) -&gt; bool:\n            # Common keys first\n            for key in (\"head\", \"tail\", \"members\", \"vertices\", \"vertices\"):\n                seq = hdef.get(key)\n                if isinstance(seq, (list, tuple, set)) and vertex in seq:\n                    return True\n            # Safety net: scan any list/tuple/set values\n            for v in hdef.values():\n                if isinstance(v, (list, tuple, set)) and vertex in v:\n                    return True\n            return False\n\n        hdefs = getattr(self, \"hyperedge_definitions\", {})\n        if isinstance(hdefs, dict):\n            for heid, hdef in list(hdefs.items()):\n                if isinstance(hdef, dict) and _vertex_in_hyperdef(hdef, vertex_id):\n                    edges_to_remove.add(heid)\n\n        # Remove all collected edges\n        for eid in edges_to_remove:\n            self.remove_edge(eid)\n\n        # row removal without CSR: rebuild DOK with rows-1 and shift indices\n        M_old = self._matrix\n        rows, cols = M_old.shape\n        new_rows = rows - 1\n        M_new = sp.dok_matrix((new_rows, cols), dtype=M_old.dtype)\n        for (r, c), v in M_old.items():\n            if r == entity_idx:\n                continue  # drop this row\n            elif r &gt; entity_idx:\n                M_new[r - 1, c] = v\n            else:\n                M_new[r, c] = v\n        self._matrix = M_new\n\n        # Update entity mappings\n        del self.entity_to_idx[vertex_id]\n        del self.entity_types[vertex_id]\n\n        # Shift indices for entities after the removed row; preserve relative order\n        for old_idx in range(entity_idx + 1, self._num_entities):\n            ent_id = self.idx_to_entity.pop(old_idx)\n            self.idx_to_entity[old_idx - 1] = ent_id\n            self.entity_to_idx[ent_id] = old_idx - 1\n        # Drop last stale entry and shrink count\n        self.idx_to_entity.pop(self._num_entities - 1, None)\n        self._num_entities -= 1\n\n        # Remove from vertex attributes\n        if isinstance(self.vertex_attributes, pl.DataFrame):\n            if self.vertex_attributes.height &gt; 0 and \"vertex_id\" in self.vertex_attributes.columns:\n                self.vertex_attributes = self.vertex_attributes.filter(pl.col(\"vertex_id\") != vertex_id)\n\n        # Remove from per-layer membership\n        for layer_data in self._layers.values():\n            layer_data[\"vertices\"].discard(vertex_id)\n\n    def remove_layer(self, layer_id):\n        \"\"\"\n        Remove a non-default layer and its per-layer attributes.\n\n        Parameters\n        ----------\n        layer_id : str\n\n        Raises\n        ------\n        ValueError\n            If attempting to remove the internal default layer.\n        KeyError\n            If the layer does not exist.\n\n        Notes\n        -----\n        - Does not delete vertices/edges globally; only membership and layer metadata.\n        \"\"\"\n        if layer_id == self._default_layer:\n            raise ValueError(\"Cannot remove default layer\")\n        if layer_id not in self._layers:\n            raise KeyError(f\"Layer {layer_id} not found\")\n\n        # Purge per-layer attributes\n        ela = getattr(self, \"edge_layer_attributes\", None)\n        if isinstance(ela, pl.DataFrame) and ela.height &gt; 0 and \"layer_id\" in ela.columns:\n            # Keep everything not matching the layer_id\n            self.edge_layer_attributes = ela.filter(pl.col(\"layer_id\") != layer_id)\n\n        # Drop legacy dict slice if present\n        if isinstance(getattr(self, \"layer_edge_weights\", None), dict):\n            self.layer_edge_weights.pop(layer_id, None)\n\n        # Remove the layer and reset current if needed\n        del self._layers[layer_id]\n        if self._current_layer == layer_id:\n            self._current_layer = self._default_layer\n\n    # Bulk remove / mutate down\n\n    def remove_edges(self, edge_ids):\n        \"\"\"Remove many edges in one pass (much faster than looping).\"\"\"\n        to_drop = [eid for eid in edge_ids if eid in self.edge_to_idx]\n        if not to_drop:\n            return\n        self._remove_edges_bulk(to_drop)\n\n    def remove_vertices(self, vertex_ids):\n        \"\"\"Remove many vertices (and all their incident edges) in one pass.\"\"\"\n        to_drop = [vid for vid in vertex_ids if vid in self.entity_to_idx]\n        if not to_drop:\n            return\n        self._remove_vertices_bulk(to_drop)\n\n    def _remove_edges_bulk(self, edge_ids):\n        drop = set(edge_ids)\n        if not drop:\n            return\n\n        # Columns to keep, old-&gt;new remap\n        keep_pairs = sorted(((idx, eid) for eid, idx in self.edge_to_idx.items() if eid not in drop))\n        old_to_new = {old: new for new, (old, _eid) in enumerate(((old, eid) for old, eid in keep_pairs))}\n        new_cols = len(keep_pairs)\n\n        # Rebuild matrix once\n        M_old = self._matrix  # DOK\n        rows, _cols = M_old.shape\n        M_new = sp.dok_matrix((rows, new_cols), dtype=M_old.dtype)\n        for (r, c), v in M_old.items():\n            if c in old_to_new:\n                M_new[r, old_to_new[c]] = v\n        self._matrix = M_new\n\n        # Rebuild edge mappings\n        self.idx_to_edge.clear()\n        self.edge_to_idx.clear()\n        for new_idx, (old_idx, eid) in enumerate(keep_pairs):\n            self.idx_to_edge[new_idx] = eid\n            self.edge_to_idx[eid] = new_idx\n        self._num_edges = new_cols\n\n        # Metadata cleanup (vectorized)\n        # Dicts\n        for eid in drop:\n            self.edge_definitions.pop(eid, None)\n            self.edge_weights.pop(eid, None)\n            self.edge_directed.pop(eid, None)\n            self.edge_kind.pop(eid, None)\n            self.hyperedge_definitions.pop(eid, None)\n        for layer_data in self._layers.values():\n            layer_data[\"edges\"].difference_update(drop)\n        for d in self.layer_edge_weights.values():\n            for eid in drop:\n                d.pop(eid, None)\n\n        # DataFrames\n        if isinstance(self.edge_attributes, pl.DataFrame) and self.edge_attributes.height:\n            if \"edge_id\" in self.edge_attributes.columns:\n                self.edge_attributes = self.edge_attributes.filter(~pl.col(\"edge_id\").is_in(list(drop)))\n        if isinstance(self.edge_layer_attributes, pl.DataFrame) and self.edge_layer_attributes.height:\n            cols = set(self.edge_layer_attributes.columns)\n            if {\"edge_id\"}.issubset(cols):\n                self.edge_layer_attributes = self.edge_layer_attributes.filter(~pl.col(\"edge_id\").is_in(list(drop)))\n\n    def _remove_vertices_bulk(self, vertex_ids):\n        drop_vs = set(vertex_ids)\n        if not drop_vs:\n            return\n\n        # 1) Collect incident edges (binary + hyper)\n        drop_es = set()\n        for eid, (s, t, _typ) in list(self.edge_definitions.items()):\n            if s in drop_vs or t in drop_vs:\n                drop_es.add(eid)\n        for eid, hdef in list(self.hyperedge_definitions.items()):\n            if hdef.get(\"members\"):\n                if drop_vs &amp; set(hdef[\"members\"]):\n                    drop_es.add(eid)\n            else:\n                if (drop_vs &amp; set(hdef.get(\"head\", ()))) or (drop_vs &amp; set(hdef.get(\"tail\", ()))):  # directed\n                    drop_es.add(eid)\n\n        # 2) Drop all those edges in one pass\n        if drop_es:\n            self._remove_edges_bulk(drop_es)\n\n        # 3) Build row keep list and old-&gt;new map\n        keep_idx = []\n        for idx in range(self._num_entities):\n            ent = self.idx_to_entity[idx]\n            if ent not in drop_vs:\n                keep_idx.append(idx)\n        old_to_new = {old: new for new, old in enumerate(keep_idx)}\n        new_rows = len(keep_idx)\n\n        # 4) Rebuild matrix rows once\n        M_old = self._matrix  # DOK\n        _rows, cols = M_old.shape\n        M_new = sp.dok_matrix((new_rows, cols), dtype=M_old.dtype)\n        for (r, c), v in M_old.items():\n            if r in old_to_new:\n                M_new[old_to_new[r], c] = v\n        self._matrix = M_new\n\n        # 5) Rebuild entity mappings\n        new_entity_to_idx = {}\n        new_idx_to_entity = {}\n        for new_i, old_i in enumerate(keep_idx):\n            ent = self.idx_to_entity[old_i]\n            new_entity_to_idx[ent] = new_i\n            new_idx_to_entity[new_i] = ent\n        self.entity_to_idx = new_entity_to_idx\n        self.idx_to_entity = new_idx_to_entity\n        # types: drop removed\n        for vid in drop_vs:\n            self.entity_types.pop(vid, None)\n        self._num_entities = new_rows\n\n        # 6) Clean vertex attributes and layer memberships\n        if isinstance(self.vertex_attributes, pl.DataFrame) and self.vertex_attributes.height:\n            if \"vertex_id\" in self.vertex_attributes.columns:\n                self.vertex_attributes = self.vertex_attributes.filter(~pl.col(\"vertex_id\").is_in(list(drop_vs)))\n        for layer_data in self._layers.values():\n            layer_data[\"vertices\"].difference_update(drop_vs)\n\n\n    # Attributes &amp; weights\n\n    def set_graph_attribute(self, key, value):\n        \"\"\"\n        Set a graph-level attribute.\n\n        Parameters\n        ----------\n        key : str\n        value : Any\n        \"\"\"\n        self.graph_attributes[key] = value\n\n    def get_graph_attribute(self, key, default=None):\n        \"\"\"\n        Get a graph-level attribute.\n\n        Parameters\n        ----------\n        key : str\n        default : Any, optional\n\n        Returns\n        -------\n        Any\n        \"\"\"\n        return self.graph_attributes.get(key, default)\n\n    def set_vertex_attrs(self, vertex_id, **attrs):\n        \"\"\"\n        Upsert pure vertex attributes (non-structural) into the vertex DF.\n\n        Parameters\n        ----------\n        vertex_id : str\n        **attrs\n            Key/value attributes. Structural keys are ignored.\n        \"\"\"\n        # keep attributes table pure\n        clean = {k: v for k, v in attrs.items() if k not in self._vertex_RESERVED}\n        if clean:\n            self.vertex_attributes = self._upsert_row(self.vertex_attributes, vertex_id, clean)\n\n    def get_attr_vertex(self, vertex_id, key, default=None):\n        \"\"\"\n        Get a single vertex attribute (scalar) or default if missing.\n\n        Parameters\n        ----------\n        vertex_id : str\n        key : str\n        default : Any, optional\n\n        Returns\n        -------\n        Any\n        \"\"\"\n        df = self.vertex_attributes\n        if key not in df.columns:\n            return default\n        rows = df.filter(pl.col(\"vertex_id\") == vertex_id)\n        if rows.height == 0:\n            return default\n        val = rows.select(pl.col(key)).to_series()[0]\n        return default if val is None else val\n\n    def get_vertex_attribute(self, vertex_id, attribute): #legacy alias\n        \"\"\"\n        (Legacy alias) Get a single vertex attribute from the Polars DF [DataFrame].\n\n        Parameters\n        ----------\n        vertex_id : str\n        attribute : str or enum.Enum\n            Column name or Enum with ``.value``.\n\n        Returns\n        -------\n        Any or None\n            Scalar value if present, else ``None``.\n\n        See Also\n        --------\n        get_attr_vertex\n        \"\"\"\n        # allow Attr enums\n        attribute = getattr(attribute, \"value\", attribute)\n\n        df = self.vertex_attributes\n        if not isinstance(df, pl.DataFrame):\n            return None\n        if df.height == 0 or \"vertex_id\" not in df.columns or attribute not in df.columns:\n            return None\n\n        rows = df.filter(pl.col(\"vertex_id\") == vertex_id)\n        if rows.height == 0:\n            return None\n\n        s = rows.get_column(attribute)\n        return s.item(0) if s.len() else None\n\n    def set_edge_attrs(self, edge_id, **attrs):\n        \"\"\"\n        Upsert pure edge attributes (non-structural) into the edge DF.\n\n        Parameters\n        ----------\n        edge_id : str\n        **attrs\n            Key/value attributes. Structural keys are ignored.\n        \"\"\"\n        # keep attributes table pure: strip structural keys\n        clean = {k: v for k, v in attrs.items() if k not in self._EDGE_RESERVED}\n        if clean:\n            self.edge_attributes = self._upsert_row(self.edge_attributes, edge_id, clean)\n\n    def get_attr_edge(self, edge_id, key, default=None):\n        \"\"\"\n        Get a single edge attribute (scalar) or default if missing.\n\n        Parameters\n        ----------\n        edge_id : str\n        key : str\n        default : Any, optional\n\n        Returns\n        -------\n        Any\n        \"\"\"\n        df = self.edge_attributes\n        if key not in df.columns:\n            return default\n        rows = df.filter(pl.col(\"edge_id\") == edge_id)\n        if rows.height == 0:\n            return default\n        val = rows.select(pl.col(key)).to_series()[0]\n        return default if val is None else val\n\n    def get_edge_attribute(self, edge_id, attribute): #legacy alias\n        \"\"\"\n        (Legacy alias) Get a single edge attribute from the Polars DF [DataFrame].\n\n        Parameters\n        ----------\n        edge_id : str\n        attribute : str or enum.Enum\n            Column name or Enum with ``.value``.\n\n        Returns\n        -------\n        Any or None\n            Scalar value if present, else ``None``.\n\n        See Also\n        --------\n        get_attr_edge\n        \"\"\"\n        # allow Attr enums\n        attribute = getattr(attribute, \"value\", attribute)\n\n        df = self.edge_attributes\n        if not isinstance(df, pl.DataFrame):\n            return None\n        if df.height == 0 or \"edge_id\" not in df.columns or attribute not in df.columns:\n            return None\n\n        rows = df.filter(pl.col(\"edge_id\") == edge_id)\n        if rows.height == 0:\n            return None\n\n        s = rows.get_column(attribute)\n        return s.item(0) if s.len() else None\n\n    def set_layer_attrs(self, layer_id, **attrs):\n        \"\"\"\n        Upsert pure layer attributes.\n\n        Parameters\n        ----------\n        layer_id : str\n        **attrs\n            Key/value attributes. Structural keys are ignored.\n        \"\"\"\n        clean = {k: v for k, v in attrs.items() if k not in self._LAYER_RESERVED}\n        if clean:\n            self.layer_attributes = self._upsert_row(self.layer_attributes, layer_id, clean)\n\n    def get_layer_attr(self, layer_id, key, default=None):\n        \"\"\"\n        Get a single layer attribute (scalar) or default if missing.\n\n        Parameters\n        ----------\n        layer_id : str\n        key : str\n        default : Any, optional\n\n        Returns\n        -------\n        Any\n        \"\"\"\n        df = self.layer_attributes\n        if key not in df.columns:\n            return default\n        rows = df.filter(pl.col(\"layer_id\") == layer_id)\n        if rows.height == 0:\n            return default\n        val = rows.select(pl.col(key)).to_series()[0]\n        return default if val is None else val\n\n    def set_edge_layer_attrs(self, layer_id, edge_id, **attrs):\n        \"\"\"\n        Upsert per-layer attributes for a specific edge.\n\n        Parameters\n        ----------\n        layer_id : str\n        edge_id : str\n        **attrs\n            Pure attributes. Structural keys are ignored (except 'weight', which is allowed here).\n        \"\"\"\n        # allow 'weight' through; keep ignoring true structural keys\n        clean = {k: v for k, v in attrs.items() if (k not in self._EDGE_RESERVED) or (k == \"weight\")}\n        if not clean:\n            return\n\n        # Normalize hot keys (intern) and avoid float dtype surprises for 'weight'\n        try:\n            import sys as _sys\n            if isinstance(layer_id, str): layer_id = _sys.intern(layer_id)\n            if isinstance(edge_id, str):  edge_id  = _sys.intern(edge_id)\n        except Exception:\n            pass\n        if \"weight\" in clean:\n            try:\n                # cast once to float to reduce dtype mismatch churn inside _upsert_row\n                clean[\"weight\"] = float(clean[\"weight\"])\n            except Exception:\n                # leave as-is if not coercible; behavior stays identical\n                pass\n\n        # Ensure edge_layer_attributes compares strings to strings (defensive against prior bad writes),\n        # but only cast when actually needed (skip no-op with_columns).\n        df = self.edge_layer_attributes\n        if isinstance(df, pl.DataFrame) and df.height &gt; 0:\n            to_cast = []\n            if \"layer_id\" in df.columns and df.schema[\"layer_id\"] != pl.Utf8:\n                to_cast.append(pl.col(\"layer_id\").cast(pl.Utf8))\n            if \"edge_id\" in df.columns and df.schema[\"edge_id\"] != pl.Utf8:\n                to_cast.append(pl.col(\"edge_id\").cast(pl.Utf8))\n            if to_cast:\n                df = df.with_columns(*to_cast)\n                self.edge_layer_attributes = df  # reassign only when changed\n\n        # Upsert via central helper (keeps exact behavior, schema handling, and caching)\n        self.edge_layer_attributes = self._upsert_row(\n            self.edge_layer_attributes, (layer_id, edge_id), clean\n        )\n\n    def get_edge_layer_attr(self, layer_id, edge_id, key, default=None):\n        \"\"\"\n        Get a per-layer attribute for an edge.\n\n        Parameters\n        ----------\n        layer_id : str\n        edge_id : str\n        key : str\n        default : Any, optional\n\n        Returns\n        -------\n        Any\n        \"\"\"\n        df = self.edge_layer_attributes\n        if key not in df.columns:\n            return default\n        rows = df.filter((pl.col(\"layer_id\") == layer_id) &amp; (pl.col(\"edge_id\") == edge_id))\n        if rows.height == 0:\n            return default\n        val = rows.select(pl.col(key)).to_series()[0]\n        return default if val is None else val\n\n    def set_layer_edge_weight(self, layer_id, edge_id, weight): #legacy weight helper\n        \"\"\"\n        Set a legacy per-layer weight override for an edge.\n\n        Parameters\n        ----------\n        layer_id : str\n        edge_id : str\n        weight : float\n\n        Raises\n        ------\n        KeyError\n            If the layer or edge does not exist.\n\n        See Also\n        --------\n        get_effective_edge_weight\n        \"\"\"\n        if layer_id not in self._layers:\n            raise KeyError(f\"Layer {layer_id} not found\")\n        if edge_id not in self.edge_to_idx:\n            raise KeyError(f\"Edge {edge_id} not found\")\n        self.layer_edge_weights[layer_id][edge_id] = float(weight)\n\n    def get_effective_edge_weight(self, edge_id, layer=None):\n        \"\"\"\n        Resolve the effective weight for an edge, optionally within a layer.\n\n        Parameters\n        ----------\n        edge_id : str\n        layer : str, optional\n            If provided, return the layer override if present; otherwise global weight.\n\n        Returns\n        -------\n        float\n            Effective weight.\n        \"\"\"\n        if layer is not None:\n            df = self.edge_layer_attributes\n            if (\n                isinstance(df, pl.DataFrame)\n                and df.height &gt; 0\n                and {\"layer_id\", \"edge_id\", \"weight\"} &lt;= set(df.columns)\n            ):\n                rows = df.filter(\n                    (pl.col(\"layer_id\") == layer) &amp; (pl.col(\"edge_id\") == edge_id)\n                ).select(\"weight\")\n                if rows.height &gt; 0:\n                    w = rows.to_series()[0]\n                    if w is not None and not (isinstance(w, float) and math.isnan(w)):\n                        return float(w)\n\n            # fallback to legacy dict if present\n            w2 = self.layer_edge_weights.get(layer, {}).get(edge_id, None)\n            if w2 is not None:\n                return float(w2)\n\n        return float(self.edge_weights[edge_id])\n\n    def audit_attributes(self):\n        \"\"\"\n        Audit attribute tables for extra/missing rows and invalid edge-layer pairs.\n\n        Returns\n        -------\n        dict\n            {\n            'extra_vertex_rows': list[str],\n            'extra_edge_rows': list[str],\n            'missing_vertex_rows': list[str],\n            'missing_edge_rows': list[str],\n            'invalid_edge_layer_rows': list[tuple[str, str]],\n            }\n        \"\"\"\n        vertex_ids = {eid for eid, t in self.entity_types.items() if t == \"vertex\"}\n        edge_ids = set(self.edge_to_idx.keys())\n\n        na = self.vertex_attributes\n        ea = self.edge_attributes\n        ela = self.edge_layer_attributes\n\n        vertex_attr_ids = (\n            set(na.select(\"vertex_id\").to_series().to_list())\n            if isinstance(na, pl.DataFrame) and na.height &gt; 0 and \"vertex_id\" in na.columns\n            else set()\n        )\n        edge_attr_ids = (\n            set(ea.select(\"edge_id\").to_series().to_list())\n            if isinstance(ea, pl.DataFrame) and ea.height &gt; 0 and \"edge_id\" in ea.columns\n            else set()\n        )\n\n        extra_vertex_rows = [i for i in vertex_attr_ids if i not in vertex_ids]\n        extra_edge_rows = [i for i in edge_attr_ids if i not in edge_ids]\n        missing_vertex_rows = [i for i in vertex_ids if i not in vertex_attr_ids]\n        missing_edge_rows = [i for i in edge_ids if i not in edge_attr_ids]\n\n        bad_edge_layer = []\n        if isinstance(ela, pl.DataFrame) and ela.height &gt; 0 and {\"layer_id\", \"edge_id\"} &lt;= set(ela.columns):\n            for lid, eid in ela.select([\"layer_id\", \"edge_id\"]).iter_rows():\n                if lid not in self._layers or eid not in edge_ids:\n                    bad_edge_layer.append((lid, eid))\n\n        return {\n            \"extra_vertex_rows\": extra_vertex_rows,\n            \"extra_edge_rows\": extra_edge_rows,\n            \"missing_vertex_rows\": missing_vertex_rows,\n            \"missing_edge_rows\": missing_edge_rows,\n            \"invalid_edge_layer_rows\": bad_edge_layer,\n        }\n\n    def _pl_dtype_for_value(self, v):\n        \"\"\"\n        INTERNAL: Infer an appropriate Polars dtype for a Python value.\n\n        Parameters\n        ----------\n        v : Any\n\n        Returns\n        -------\n        polars.datatypes.DataType\n            One of ``pl.Null``, ``pl.Boolean``, ``pl.Int64``, ``pl.Float64``,\n            ``pl.Utf8``, ``pl.Binary``, ``pl.Object``, or ``pl.List(inner)``.\n\n        Notes\n        -----\n        - Enums are mapped to ``pl.Object`` (useful for categorical enums).\n        - Lists/tuples infer inner dtype from the first element (defaults to ``Utf8``).\n        \"\"\"\n        import enum, polars as pl\n        if v is None: return pl.Null\n        if isinstance(v, bool): return pl.Boolean\n        if isinstance(v, int) and not isinstance(v, bool): return pl.Int64\n        if isinstance(v, float): return pl.Float64\n        if isinstance(v, enum.Enum): return pl.Object     # important for EdgeType\n        if isinstance(v, (bytes, bytearray)): return pl.Binary\n        if isinstance(v, (list, tuple)):\n            inner = self._pl_dtype_for_value(v[0]) if len(v) else pl.Utf8\n            return pl.List(pl.Utf8 if inner == pl.Null else inner)\n        if isinstance(v, dict): return pl.Object\n        return pl.Utf8\n\n    def _ensure_attr_columns(self, df: pl.DataFrame, attrs: dict) -&gt; pl.DataFrame:\n        \"\"\"\n        INTERNAL: Create/align attribute columns and dtypes to accept ``attrs``.\n\n        Parameters\n        ----------\n        df : polars.DataFrame\n            Existing attribute table.\n        attrs : dict\n            Incoming key/value pairs to upsert.\n\n        Returns\n        -------\n        polars.DataFrame\n            DataFrame with columns added/cast so inserts/updates won't hit ``Null`` dtypes.\n\n        Notes\n        -----\n        - New columns are created with the inferred dtype.\n        - If a column is ``Null`` and the incoming value is not, it is cast to the inferred dtype.\n        - If dtypes conflict (mixed over time), both sides upcast to ``Utf8`` to avoid schema errors.\n        \"\"\"\n        schema = df.schema\n        for col, val in attrs.items():\n            target = self._pl_dtype_for_value(val)\n            if col not in schema:\n                df = df.with_columns(pl.lit(None).cast(target).alias(col))\n            else:\n                cur = schema[col]\n                if cur == pl.Null and target != pl.Null:\n                    df = df.with_columns(pl.col(col).cast(target))\n                # if mixed types are expected over time, upcast to Utf8:\n                elif cur != target and target != pl.Null:\n                    # upcast both sides to Utf8 to avoid schema conflicts\n                    df = df.with_columns(pl.col(col).cast(pl.Utf8))\n        return df\n\n    def _upsert_row(self, df: pl.DataFrame, idx, attrs: dict) -&gt; pl.DataFrame:\n        \"\"\"\n        INTERNAL: Upsert a row in a Polars DF [DataFrame] using explicit key columns.\n\n        Keys\n        ----\n        - ``vertex_attributes``           \u2192 key: ``[\"vertex_id\"]``\n        - ``edge_attributes``             \u2192 key: ``[\"edge_id\"]``\n        - ``layer_attributes``            \u2192 key: ``[\"layer_id\"]``\n        - ``edge_layer_attributes``       \u2192 key: ``[\"layer_id\", \"edge_id\"]``\n        \"\"\"\n        if not isinstance(attrs, dict) or not attrs:\n            return df\n\n        cols = set(df.columns)\n\n        # Determine key columns + values\n        if {\"layer_id\", \"edge_id\"} &lt;= cols:\n            if not (isinstance(idx, tuple) and len(idx) == 2):\n                raise ValueError(\"idx must be a (layer_id, edge_id) tuple\")\n            key_cols = (\"layer_id\", \"edge_id\")\n            key_vals = {\"layer_id\": idx[0], \"edge_id\": idx[1]}\n            cache_name = \"_edge_layer_attr_keys\"   # set of (layer_id, edge_id)\n            df_id_name = \"_edge_layer_attr_df_id\"\n        elif \"vertex_id\" in cols:\n            key_cols = (\"vertex_id\",)\n            key_vals = {\"vertex_id\": idx}\n            cache_name = \"_vertex_attr_ids\"        # set of vertex_id\n            df_id_name = \"_vertex_attr_df_id\"\n        elif \"edge_id\" in cols:\n            key_cols = (\"edge_id\",)\n            key_vals = {\"edge_id\": idx}\n            cache_name = \"_edge_attr_ids\"          # set of edge_id\n            df_id_name = \"_edge_attr_df_id\"\n        elif \"layer_id\" in cols:\n            key_cols = (\"layer_id\",)\n            key_vals = {\"layer_id\": idx}\n            cache_name = \"_layer_attr_ids\"         # set of layer_id\n            df_id_name = \"_layer_attr_df_id\"\n        else:\n            raise ValueError(\"Cannot infer key columns from DataFrame schema\")\n\n        # Ensure attribute columns exist / are cast appropriately\n        df = self._ensure_attr_columns(df, attrs)\n\n        # Build the match condition (used later for updates)\n        cond = None\n        for k in key_cols:\n            v = key_vals[k]\n            c = (pl.col(k) == pl.lit(v))\n            cond = c if cond is None else (cond &amp; c)\n\n        # existence check via small per-table caches (no DF scan)\n        try:\n            key_cache = getattr(self, cache_name, None)\n            cached_df_id = getattr(self, df_id_name, None)\n            if key_cache is None or cached_df_id != id(df):\n                # Rebuild cache lazily for the current df object\n                if \"vertex_id\" in cols and key_cols == (\"vertex_id\",):\n                    series = df.get_column(\"vertex_id\") if df.height else pl.Series([])\n                    key_cache = set(series.to_list()) if df.height else set()\n                elif \"edge_id\" in cols and \"layer_id\" in cols and key_cols == (\"layer_id\", \"edge_id\"):\n                    if df.height:\n                        key_cache = set(zip(df.get_column(\"layer_id\").to_list(),\n                                            df.get_column(\"edge_id\").to_list()))\n                    else:\n                        key_cache = set()\n                elif \"edge_id\" in cols and key_cols == (\"edge_id\",):\n                    series = df.get_column(\"edge_id\") if df.height else pl.Series([])\n                    key_cache = set(series.to_list()) if df.height else set()\n                elif \"layer_id\" in cols and key_cols == (\"layer_id\",):\n                    series = df.get_column(\"layer_id\") if df.height else pl.Series([])\n                    key_cache = set(series.to_list()) if df.height else set()\n                else:\n                    key_cache = set()\n                setattr(self, cache_name, key_cache)\n                setattr(self, df_id_name, id(df))\n            # Decide existence from cache\n            cache_key = key_vals[key_cols[0]] if len(key_cols) == 1 else (key_vals[\"layer_id\"], key_vals[\"edge_id\"])\n            exists = cache_key in key_cache\n        except Exception:\n            # Fallback to original behavior if caching fails\n            exists = df.filter(cond).height &gt; 0\n            key_cache = None\n\n        if exists:\n            # cast literals to column dtypes; keep exact semantics\n            schema = df.schema\n            upds = []\n            for k, v in attrs.items():\n                tgt_dtype = schema[k]\n                upds.append(\n                    pl.when(cond)\n                    .then(pl.lit(v).cast(tgt_dtype))\n                    .otherwise(pl.col(k))\n                    .alias(k)\n                )\n            new_df = df.with_columns(upds)\n\n            # Keep cache pointers in sync with the new df object\n            try:\n                setattr(self, df_id_name, id(new_df))\n                # cache contents unchanged for updates\n            except Exception:\n                pass\n\n            return new_df\n\n        # build a single row aligned to df schema\n        schema = df.schema\n\n        # Start with None for all columns, fill keys and attrs\n        new_row = {c: None for c in df.columns}\n        new_row.update(key_vals)\n        new_row.update(attrs)\n\n        to_append = pl.DataFrame([new_row])\n\n        # 1) Ensure to_append has all df columns\n        for c in df.columns:\n            if c not in to_append.columns:\n                to_append = to_append.with_columns(pl.lit(None).cast(schema[c]).alias(c))\n\n        # 2) Resolve dtype mismatches:\n        #    - df Null + to_append non-Null -&gt; cast df to right\n        #    - to_append Null + df non-Null -&gt; cast to_append to left\n        #    - left != right -&gt; upcast both to Utf8\n        left_schema = schema\n        right_schema = to_append.schema\n        df_casts = []\n        app_casts = []\n        for c in df.columns:\n            left = left_schema[c]\n            right = right_schema[c]\n            if left == pl.Null and right != pl.Null:\n                df_casts.append(pl.col(c).cast(right))\n            elif right == pl.Null and left != pl.Null:\n                app_casts.append(pl.col(c).cast(left).alias(c))\n            elif left != right:\n                df_casts.append(pl.col(c).cast(pl.Utf8))\n                app_casts.append(pl.col(c).cast(pl.Utf8).alias(c))\n\n        if df_casts:\n            df = df.with_columns(df_casts)\n            left_schema = df.schema  # refresh for correctness\n        if app_casts:\n            to_append = to_append.with_columns(app_casts)\n\n        new_df = df.vstack(to_append)\n\n        # Update caches after insertion\n        try:\n            if key_cache is not None:\n                if len(key_cols) == 1:\n                    key_cache.add(cache_key)\n                else:\n                    key_cache.add(cache_key)\n            setattr(self, df_id_name, id(new_df))\n        except Exception:\n            pass\n\n        return new_df\n\n    ## Full attribute dict for a single entity\n\n    def get_edge_attrs(self, edge) -&gt; dict:\n        \"\"\"\n        Return the full attribute dict for a single edge.\n\n        Parameters\n        ----------\n        edge : int | str\n            Edge index (int) or edge id (str).\n\n        Returns\n        -------\n        dict\n            Attribute dictionary for that edge. {} if not found.\n        \"\"\"\n        # normalize to edge id\n        if isinstance(edge, int):\n            eid = self.idx_to_edge[edge]\n        else:\n            eid = edge\n\n        df = self.edge_attributes\n        # Polars-safe: iterate the (at most one) row as a dict\n        try:\n            import polars as pl  # noqa: F401\n            for row in df.filter(pl.col(\"edge_id\") == eid).iter_rows(named=True):\n                return dict(row)\n            return {}\n        except Exception:\n            # Fallback if df is pandas or dict-like\n            try:\n                row = df[df[\"edge_id\"] == eid].to_dict(orient=\"records\")\n                return row[0] if row else {}\n            except Exception:\n                return {}\n\n    def get_vertex_attrs(self, vertex) -&gt; dict:\n        \"\"\"\n        Return the full attribute dict for a single vertex.\n\n        Parameters\n        ----------\n        vertex : str\n            Vertex id.\n\n        Returns\n        -------\n        dict\n            Attribute dictionary for that vertex. {} if not found.\n        \"\"\"\n        df = self.vertex_attributes\n        try:\n            import polars as pl  # noqa: F401\n            for row in df.filter(pl.col(\"vertex_id\") == vertex).iter_rows(named=True):\n                return dict(row)\n            return {}\n        except Exception:\n            try:\n                row = df[df[\"vertex_id\"] == vertex].to_dict(orient=\"records\")\n                return row[0] if row else {}\n            except Exception:\n                return {}\n\n    ## Bulk attributes\n\n    def get_attr_edges(self, indexes=None) -&gt; dict:\n        \"\"\"\n        Retrieve edge attributes as a dictionary.\n\n        Parameters\n        ----------\n        indexes : Iterable[int] | None, optional\n            A list or iterable of edge indices to retrieve attributes for.\n            - If `None` (default), attributes for **all** edges are returned.\n            - If provided, only those edges will be included in the output.\n\n        Returns\n        -------\n        dict[str, dict]\n            A dictionary mapping `edge_id` \u2192 `attribute_dict`, where:\n            - `edge_id` is the unique string identifier of the edge.\n            - `attribute_dict` is a dictionary of attribute names and values.\n\n        Notes\n        -----\n        - This function reads directly from `self.edge_attributes`, which should be\n        a Polars DataFrame where each row corresponds to an edge.\n        - Useful for bulk inspection, serialization, or analytics without looping manually.\n        \"\"\"\n        df = self.edge_attributes\n        if indexes is not None:\n            df = df.filter(pl.col(\"edge_id\").is_in([self.idx_to_edge[i] for i in indexes]))\n        return {row[\"edge_id\"]: row.as_dict() for row in df.iter_rows(named=True)}\n\n    def get_attr_vertices(self, vertices=None) -&gt; dict:\n        \"\"\"\n        Retrieve vertex (vertex) attributes as a dictionary.\n\n        Parameters\n        ----------\n        vertices : Iterable[str] | None, optional\n            A list or iterable of vertex IDs to retrieve attributes for.\n            - If `None` (default), attributes for **all** verices are returned.\n            - If provided, only those verices will be included in the output.\n\n        Returns\n        -------\n        dict[str, dict]\n            A dictionary mapping `vertex_id` \u2192 `attribute_dict`, where:\n            - `vertex_id` is the unique string identifier of the vertex.\n            - `attribute_dict` is a dictionary of attribute names and values.\n\n        Notes\n        -----\n        - This reads from `self.vertex_attributes`, which stores per-vertex metadata.\n        - Use this for bulk data extraction instead of repeated single-vertex calls.\n        \"\"\"\n        df = self.vertex_attributes\n        if vertices is not None:\n            df = df.filter(pl.col(\"vertex_id\").is_in(vertices))\n        return {row[\"vertex_id\"]: row.as_dict() for row in df.iter_rows(named=True)}\n\n    def get_attr_from_edges(self, key: str, default=None) -&gt; dict:\n        \"\"\"\n        Extract a specific attribute column for all edges.\n\n        Parameters\n        ----------\n        key : str\n            Attribute column name to extract from `self.edge_attributes`.\n        default : Any, optional\n            Default value to use if the column does not exist or if an edge\n            does not have a value. Defaults to `None`.\n\n        Returns\n        -------\n        dict[str, Any]\n            A dictionary mapping `edge_id` \u2192 attribute value.\n\n        Notes\n        -----\n        - If the requested column is missing, all edges return `default`.\n        - This is useful for quick property lookups (e.g., weight, label, type).\n        \"\"\"\n        df = self.edge_attributes\n        if key not in df.columns:\n            return {row[\"edge_id\"]: default for row in df.iter_rows(named=True)}\n        return {row[\"edge_id\"]: row[key] if row[key] is not None else default for row in df.iter_rows(named=True)}\n\n    def get_edges_by_attr(self, key: str, value) -&gt; list:\n        \"\"\"\n        Retrieve all edges where a given attribute equals a specific value.\n\n        Parameters\n        ----------\n        key : str\n            Attribute column name to filter on.\n        value : Any\n            Value to match.\n\n        Returns\n        -------\n        list[str]\n            A list of edge IDs where the attribute `key` equals `value`.\n\n        Notes\n        -----\n        - If the attribute column does not exist, an empty list is returned.\n        - Comparison is exact; consider normalizing types before calling.\n        \"\"\"\n        df = self.edge_attributes\n        if key not in df.columns:\n            return []\n        return [row[\"edge_id\"] for row in df.iter_rows(named=True) if row[key] == value]\n\n    def get_graph_attributes(self) -&gt; dict:\n        \"\"\"\n        Return a shallow copy of the graph-level attributes dictionary.\n\n        Returns\n        -------\n        dict\n            A dictionary of global metadata describing the graph as a whole.\n            Typical keys might include:\n            - `\"name\"` : Graph name or label.\n            - `\"directed\"` : Boolean indicating directedness.\n            - `\"layers\"` : List of layers present in the graph.\n            - `\"created_at\"` : Timestamp of graph creation.\n\n        Notes\n        -----\n        - Returns a **shallow copy** to prevent external mutation of internal state.\n        - Graph-level attributes are meant to store metadata not tied to individual\n        verices or edges (e.g., versioning info, provenance, global labels).\n        \"\"\"\n        return dict(self.graph_attributes)\n\n    def set_edge_layer_attrs_bulk(self, layer_id, items):\n        \"\"\"\n        items: iterable of (edge_id, attrs_dict) or dict{edge_id: attrs_dict}\n        Upserts rows in edge_layer_attributes for one layer in bulk.\n        \"\"\"\n        import polars as pl\n\n        # normalize\n        rows = []\n        if isinstance(items, dict):\n            it = items.items()\n        else:\n            it = items\n        for eid, attrs in it:\n            if not isinstance(attrs, dict) or not attrs:\n                continue\n            r = {\"layer_id\": layer_id, \"edge_id\": eid}\n            r.update(attrs)\n            if \"weight\" in r:\n                try: r[\"weight\"] = float(r[\"weight\"])\n                except Exception: pass\n            rows.append(r)\n        if not rows:\n            return\n\n        # start from current DF\n        df = self.edge_layer_attributes\n        add_df = pl.DataFrame(rows)\n\n        # ensure required key cols exist/correct dtype on existing df\n        if not isinstance(df, pl.DataFrame) or df.is_empty():\n            # create from scratch with canonical dtypes\n            self.edge_layer_attributes = add_df\n            # legacy mirror\n            if \"weight\" in add_df.columns:\n                self.layer_edge_weights.setdefault(layer_id, {})\n                for r in add_df.iter_rows(named=True):\n                    w = r.get(\"weight\")\n                    if w is not None:\n                        self.layer_edge_weights[layer_id][r[\"edge_id\"]] = float(w)\n            return\n\n        # schema alignment using your _ensure_attr_columns + Utf8 upcast rule\n        need_cols = {c: None for c in add_df.columns if c not in df.columns}\n        if need_cols:\n            df = self._ensure_attr_columns(df, need_cols)  # adds missing columns to df\n        # add missing columns to add_df\n        for c in df.columns:\n            if c not in add_df.columns:\n                add_df = add_df.with_columns(pl.lit(None).cast(df.schema[c]).alias(c))\n        # reconcile dtype mismatches (Null/Null, mixed -&gt; Utf8), same policy as _upsert_row\n        for c in df.columns:\n            lc, rc = df.schema[c], add_df.schema[c]\n            if lc == pl.Null and rc != pl.Null:\n                df = df.with_columns(pl.col(c).cast(rc))\n            elif rc == pl.Null and lc != pl.Null:\n                add_df = add_df.with_columns(pl.col(c).cast(lc).alias(c))\n            elif lc != rc:\n                df = df.with_columns(pl.col(c).cast(pl.Utf8))\n                add_df = add_df.with_columns(pl.col(c).cast(pl.Utf8).alias(c))\n\n        # drop existing keys for (layer_id, edge_id) we are about to write; then vstack new rows\n        mask_keep = ~((pl.col(\"layer_id\") == layer_id) &amp; pl.col(\"edge_id\").is_in(add_df.get_column(\"edge_id\")))\n        df = df.filter(mask_keep)\n        df = df.vstack(add_df)\n        self.edge_layer_attributes = df\n\n        # legacy mirror\n        if \"weight\" in add_df.columns:\n            self.layer_edge_weights.setdefault(layer_id, {})\n            for r in add_df.iter_rows(named=True):\n                w = r.get(\"weight\")\n                if w is not None:\n                    self.layer_edge_weights[layer_id][r[\"edge_id\"]] = float(w)\n\n    # Basic queries &amp; metrics\n\n    def get_vertex(self, index: int) -&gt; str:\n        \"\"\"\n        Return the vertex ID corresponding to a given internal index.\n\n        Parameters\n        ----------\n        index : int\n            The internal vertex index.\n\n        Returns\n        -------\n        str\n            The vertex ID.\n        \"\"\"\n        return self.idx_to_entity[index]\n\n    def get_edge(self, index: int):\n        \"\"\"\n        Return edge endpoints in a canonical form.\n\n        Parameters\n        ----------\n        index : int\n            Internal edge index.\n\n        Returns\n        -------\n        tuple[frozenset, frozenset]\n            (S, T) where S and T are frozensets of vertex IDs.\n            - For directed binary edges: ({u}, {v})\n            - For undirected binary edges: (M, M)\n            - For directed hyperedges: (head_set, tail_set)\n            - For undirected hyperedges: (members, members)\n        \"\"\"\n        if isinstance(index, str):\n            eid = index\n            try:\n                index = self.edge_to_idx[eid]\n            except KeyError:\n                raise KeyError(f\"Unknown edge id: {eid}\") from None\n        else:\n            eid = self.idx_to_edge[index]\n\n        kind = self.edge_kind.get(eid)\n\n        eid = self.idx_to_edge[index]\n        kind = self.edge_kind.get(eid)\n\n        if kind == \"hyper\":\n            meta = self.hyperedge_definitions[eid]\n            if meta.get(\"directed\", False):\n                return (frozenset(meta[\"head\"]), frozenset(meta[\"tail\"]))\n            else:\n                M = frozenset(meta[\"members\"])\n                return (M, M)\n        else:\n            u, v, _etype = self.edge_definitions[eid]\n            directed = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n            if directed:\n                return (frozenset([u]), frozenset([v]))\n            else:\n                M = frozenset([u, v])\n                return (M, M)\n\n    def incident_edges(self, vertex_id) -&gt; list[int]:\n        \"\"\"\n        Return all edge indices incident to a given vertex.\n\n        Parameters\n        ----------\n        vertex_id : str\n            vertex identifier.\n\n        Returns\n        -------\n        list[int]\n            List of edge indices incident to the vertex.\n        \"\"\"\n        incident = []\n        # Fast path: direct matrix row lookup if available\n        if vertex_id in self.entity_to_idx:\n            row_idx = self.entity_to_idx[vertex_id]\n            try:\n                incident.extend(self._matrix.tocsr().getrow(row_idx).indices.tolist())\n                return incident\n            except Exception:\n                # fallback if matrix is not in CSR (compressed sparse row) format\n                pass\n\n        # Fallback: scan edge definitions\n        for j in range(self.number_of_edges()):\n            eid = self.idx_to_edge[j]\n            kind = self.edge_kind.get(eid)\n            if kind == \"hyper\":\n                meta = self.hyperedge_definitions[eid]\n                if (meta.get(\"directed\", False) and (vertex_id in meta[\"head\"] or vertex_id in meta[\"tail\"])) \\\n                or (not meta.get(\"directed\", False) and vertex_id in meta[\"members\"]):\n                    incident.append(j)\n            else:\n                u, v, _etype = self.edge_definitions[eid]\n                if vertex_id == u or vertex_id == v:\n                    incident.append(j)\n\n        return incident\n\n    def _is_directed_edge(self, edge_id):\n        \"\"\"\n        Check if an edge is directed (per-edge flag overrides graph default).\n\n        Parameters\n        ----------\n        edge_id : str\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return bool(self.edge_directed.get(edge_id, self.directed))\n\n    def has_edge(self, source, target, edge_id=None):\n        \"\"\"\n        Test for the existence of an edge.\n\n        Parameters\n        ----------\n        source : str\n        target : str\n        edge_id : str, optional\n            If provided, check for this specific ID.\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        if edge_id:\n            return edge_id in self.edge_to_idx\n\n        # Check any edge between source and target\n        for eid, (src, tgt, _) in self.edge_definitions.items():\n            if src == source and tgt == target:\n                return True\n        return False\n\n    def has_vertex(self, vertex_id: str) -&gt; bool:\n        \"\"\"\n        Test for the existence of a vertex.\n\n        Parameters\n        ----------\n        vertex_id : str\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return vertex_id in self.entity_to_idx and self.entity_types.get(vertex_id) == \"vertex\"\n\n\n    def get_edge_ids(self, source, target):\n        \"\"\"\n        List all edge IDs between two endpoints.\n\n        Parameters\n        ----------\n        source : str\n        target : str\n\n        Returns\n        -------\n        list[str]\n            Edge IDs (may be empty).\n        \"\"\"\n        edge_ids = []\n        for eid, (src, tgt, _) in self.edge_definitions.items():\n            if src == source and tgt == target:\n                edge_ids.append(eid)\n        return edge_ids\n\n    def degree(self, entity_id):\n        \"\"\"\n        Degree of a vertex or edge-entity (number of incident non-zero entries).\n\n        Parameters\n        ----------\n        entity_id : str\n\n        Returns\n        -------\n        int\n        \"\"\"\n        if entity_id not in self.entity_to_idx:\n            return 0\n\n        entity_idx = self.entity_to_idx[entity_id]\n        row = self._matrix.getrow(entity_idx)\n        return len(row.nonzero()[1])\n\n    def vertices(self):\n        \"\"\"\n        Get all vertex IDs (excluding edge-entities).\n\n        Returns\n        -------\n        list[str]\n        \"\"\"\n        return [eid for eid, etype in self.entity_types.items() if etype == 'vertex']\n\n    def edges(self):\n        \"\"\"\n        Get all edge IDs.\n\n        Returns\n        -------\n        list[str]\n        \"\"\"\n        return list(self.edge_to_idx.keys())\n\n    def edge_list(self):\n        \"\"\"\n        Materialize (source, target, edge_id, weight) for binary/vertex-edge edges.\n\n        Returns\n        -------\n        list[tuple[str, str, str, float]]\n        \"\"\"\n        edges = []\n        for edge_id, (source, target, edge_type) in self.edge_definitions.items():\n            weight = self.edge_weights[edge_id]\n            edges.append((source, target, edge_id, weight))\n        return edges\n\n    def get_directed_edges(self):\n        \"\"\"\n        List IDs of directed edges.\n\n        Returns\n        -------\n        list[str]\n        \"\"\"\n        default_dir = True if self.directed is None else self.directed\n        return [eid for eid in self.edge_to_idx.keys() \n                if self.edge_directed.get(eid, default_dir)]\n\n    def get_undirected_edges(self):\n        \"\"\"\n        List IDs of undirected edges.\n\n        Returns\n        -------\n        list[str]\n        \"\"\"\n        default_dir = True if self.directed is None else self.directed\n        return [eid for eid in self.edge_to_idx.keys() \n                if not self.edge_directed.get(eid, default_dir)]\n\n    def number_of_vertices(self):\n        \"\"\"\n        Count vertices (excluding edge-entities).\n\n        Returns\n        -------\n        int\n        \"\"\"\n        return len([e for e in self.entity_types.values() if e == 'vertex'])\n\n    def number_of_edges(self):\n        \"\"\"\n        Count edges (columns in the incidence matrix).\n\n        Returns\n        -------\n        int\n        \"\"\"\n        return self._num_edges\n\n    def global_entity_count(self):\n        \"\"\"\n        Count unique entities present across all layers (union of memberships).\n\n        Returns\n        -------\n        int\n        \"\"\"\n        all_vertices = set()\n        for layer_data in self._layers.values():\n            all_vertices.update(layer_data[\"vertices\"])\n        return len(all_vertices)\n\n    def global_edge_count(self):\n        \"\"\"\n        Count unique edges present across all layers (union of memberships).\n\n        Returns\n        -------\n        int\n        \"\"\"\n        all_edges = set()\n        for layer_data in self._layers.values():\n            all_edges.update(layer_data[\"edges\"])\n        return len(all_edges)\n\n    def in_edges(self, vertices):\n        \"\"\"\n        Iterate over all edges that are **incoming** to one or more vertices.\n\n        Parameters\n        ----------\n        vertices : str | Iterable[str]\n            A single vertex ID or an iterable of vertex IDs. All edges whose\n            **target set** intersects with this set will be yielded.\n\n        Yields\n        ------\n        tuple[int, tuple[frozenset, frozenset]]\n            Tuples of the form `(edge_index, (S, T))`, where:\n            - `edge_index` : int \u2014 internal integer index of the edge.\n            - `S` : frozenset[str] \u2014 set of source/head verices.\n            - `T` : frozenset[str] \u2014 set of target/tail verices.\n\n        Behavior\n        --------\n        - **Directed binary edges**: returned if any vertex is in the target (`T`).\n        - **Directed hyperedges**: returned if any vertex is in the tail set.\n        - **Undirected edges/hyperedges**: returned if any vertex is in\n        the edge's member set (`S \u222a T`).\n\n        Notes\n        -----\n        - Works with binary and hyperedges.\n        - Undirected edges appear in both `in_edges()` and `out_edges()`.\n        - The returned `(S, T)` is the canonical form from `get_edge()`.\n        \"\"\"\n        V = self._normalize_vertices_arg(vertices)\n        if not V:\n            return\n        for j in range(self.number_of_edges()):\n            S, T = self.get_edge(j)\n            eid = self.idx_to_edge[j]\n            directed = self._is_directed_edge(eid)\n            if directed:\n                if T &amp; V:\n                    yield j, (S, T)\n            else:\n                if (S | T) &amp; V:\n                    yield j, (S, T)\n\n    def out_edges(self, vertices):\n        \"\"\"\n        Iterate over all edges that are **outgoing** from one or more vertices.\n\n        Parameters\n        ----------\n        vertices : str | Iterable[str]\n            A single vertex ID or an iterable of vertex IDs. All edges whose\n            **source set** intersects with this set will be yielded.\n\n        Yields\n        ------\n        tuple[int, tuple[frozenset, frozenset]]\n            Tuples of the form `(edge_index, (S, T))`, where:\n            - `edge_index` : int \u2014 internal integer index of the edge.\n            - `S` : frozenset[str] \u2014 set of source/head verices.\n            - `T` : frozenset[str] \u2014 set of target/tail verices.\n\n        Behavior\n        --------\n        - **Directed binary edges**: returned if any vertex is in the source (`S`).\n        - **Directed hyperedges**: returned if any vertex is in the head set.\n        - **Undirected edges/hyperedges**: returned if any vertex is in\n        the edge's member set (`S \u222a T`).\n\n        Notes\n        -----\n        - Works with binary and hyperedges.\n        - Undirected edges appear in both `out_edges()` and `in_edges()`.\n        - The returned `(S, T)` is the canonical form from `get_edge()`.\n        \"\"\"\n        V = self._normalize_vertices_arg(vertices)\n        if not V:\n            return\n        for j in range(self.number_of_edges()):\n            S, T = self.get_edge(j)\n            eid = self.idx_to_edge[j]\n            directed = self._is_directed_edge(eid)\n            if directed:\n                if S &amp; V:\n                    yield j, (S, T)\n            else:\n                if (S | T) &amp; V:\n                    yield j, (S, T)\n\n    @property\n    def V(self):\n        \"\"\"\n        All vertices as a tuple.\n\n        Returns\n        -------\n        tuple\n            Tuple of all vertex IDs in the graph.\n        \"\"\"\n        return tuple(self.vertices())\n\n    @property\n    def E(self):\n        \"\"\"\n        All edges as a tuple.\n\n        Returns\n        -------\n        tuple\n            Tuple of all edge identifiers (whatever `self.edges()` yields).\n        \"\"\"\n        return tuple(self.edges())\n\n    @property\n    def num_vertices(self):\n        \"\"\"\n        Total number of vertices (vertices) in the graph.\n        \"\"\"\n        return self.number_of_vertices()\n\n    @property\n    def num_edges(self):\n        \"\"\"\n        Total number of edges in the graph.\n        \"\"\"\n        return self.number_of_edges()\n\n    @property\n    def nv(self):\n        \"\"\"\n        Shorthand for num_vertices.\n        \"\"\"\n        return self.num_vertices\n\n    @property\n    def ne(self):\n        \"\"\"\n        Shorthand for num_edges.\n        \"\"\"\n        return self.num_edges\n\n    @property\n    def shape(self):\n        \"\"\"\n        Graph shape as a tuple: (num_vertices, num_edges).\n        Useful for quick inspection.\n        \"\"\"\n        return (self.num_vertices, self.num_edges)\n\n    # Materialized views\n\n    def edges_view(self, layer=None, include_directed=True, include_weight=True, resolved_weight=True, copy=True):\n        \"\"\"\n        Build a Polars DF [DataFrame] view of edges with optional layer join.\n        Same columns/semantics as before, but vectorized (no per-edge DF scans).\n        \"\"\"\n        # Fast path: no edges\n        if not self.edge_to_idx:\n            return pl.DataFrame(schema={\"edge_id\": pl.Utf8, \"kind\": pl.Utf8})\n\n        eids = list(self.edge_to_idx.keys())\n        kinds = [self.edge_kind.get(eid, \"binary\") for eid in eids]\n\n        # columns we might need\n        need_global = include_weight or resolved_weight\n        global_w = [self.edge_weights.get(eid, None) for eid in eids] if need_global else None\n        dirs = [self.edge_directed.get(eid, True if self.directed is None else self.directed) for eid in eids] if include_directed else None\n\n        # endpoints / hyper metadata (one pass; no weight lookups)\n        src, tgt, etype = [], [], []\n        head, tail, members = [], [], []\n        for eid, k in zip(eids, kinds):\n            if k == \"hyper\":\n                # hyperedge: store sets in canonical sorted tuples\n                h = self.hyperedge_definitions[eid]\n                if h.get(\"directed\", False):\n                    head.append(tuple(sorted(h.get(\"head\", ()))))\n                    tail.append(tuple(sorted(h.get(\"tail\", ()))))\n                    members.append(None)\n                else:\n                    head.append(None)\n                    tail.append(None)\n                    members.append(tuple(sorted(h.get(\"members\", ()))))\n                src.append(None); tgt.append(None); etype.append(None)\n            else:\n                s, t, et = self.edge_definitions[eid]\n                src.append(s); tgt.append(t); etype.append(et)\n                head.append(None); tail.append(None); members.append(None)\n\n        # base frame\n        cols = {\"edge_id\": eids, \"kind\": kinds}\n        if include_directed: cols[\"directed\"] = dirs\n        if include_weight:   cols[\"global_weight\"] = global_w\n        # we still need global weight transiently to compute effective weight even if not displayed\n        if resolved_weight and not include_weight: cols[\"_gw_tmp\"] = global_w\n\n        base = pl.DataFrame(cols).with_columns(\n            pl.Series(\"source\", src, dtype=pl.Utf8),\n            pl.Series(\"target\", tgt, dtype=pl.Utf8),\n            pl.Series(\"edge_type\", etype, dtype=pl.Utf8),\n            pl.Series(\"head\", head, dtype=pl.List(pl.Utf8)),\n            pl.Series(\"tail\", tail, dtype=pl.List(pl.Utf8)),\n            pl.Series(\"members\", members, dtype=pl.List(pl.Utf8)),\n        )\n\n        # join pure edge attributes (left)\n        if isinstance(self.edge_attributes, pl.DataFrame) and self.edge_attributes.height &gt; 0:\n            out = base.join(self.edge_attributes, on=\"edge_id\", how=\"left\")\n        else:\n            out = base\n\n        # join layer-specific attributes once, then compute resolved weight vectorized\n        if layer is not None and isinstance(self.edge_layer_attributes, pl.DataFrame) and self.edge_layer_attributes.height &gt; 0:\n            layer_slice = (\n                self.edge_layer_attributes\n                .filter(pl.col(\"layer_id\") == layer)\n                .drop(\"layer_id\")\n            )\n            if layer_slice.height &gt; 0:\n                # prefix non-key columns -&gt; layer_*\n                rename_map = {c: f\"layer_{c}\" for c in layer_slice.columns if c not in {\"edge_id\"}}\n                if rename_map:\n                    layer_slice = layer_slice.rename(rename_map)\n                out = out.join(layer_slice, on=\"edge_id\", how=\"left\")\n\n        # add effective_weight without per-edge function calls\n        if resolved_weight:\n            gw_col = \"global_weight\" if include_weight else \"_gw_tmp\"\n            lw_col = \"layer_weight\" if (\"layer_weight\" in out.columns) else None\n            if lw_col:\n                out = out.with_columns(\n                    pl.coalesce([pl.col(lw_col), pl.col(gw_col)]).alias(\"effective_weight\")\n                )\n            else:\n                out = out.with_columns(pl.col(gw_col).alias(\"effective_weight\"))\n\n            # drop temp global if it wasn't requested explicitly\n            if not include_weight and \"_gw_tmp\" in out.columns:\n                out = out.drop(\"_gw_tmp\")\n\n        return out.clone() if copy else out\n\n    def vertices_view(self, copy=True):\n        \"\"\"\n        Read-only vertex attribute table.\n\n        Parameters\n        ----------\n        copy : bool, optional\n            Return a cloned DF.\n\n        Returns\n        -------\n        polars.DataFrame\n            Columns: ``vertex_id`` plus pure attributes (may be empty).\n        \"\"\"\n        df = self.vertex_attributes\n        if df.height == 0:\n            return pl.DataFrame(schema={\"vertex_id\": pl.Utf8})\n        return df.clone() if copy else df\n\n    def layers_view(self, copy=True):\n        \"\"\"\n        Read-only layer attribute table.\n\n        Parameters\n        ----------\n        copy : bool, optional\n            Return a cloned DF.\n\n        Returns\n        -------\n        polars.DataFrame\n            Columns: ``layer_id`` plus pure attributes (may be empty).\n        \"\"\"\n        df = self.layer_attributes\n        if df.height == 0:\n            return pl.DataFrame(schema={\"layer_id\": pl.Utf8})\n        return df.clone() if copy else df\n\n    # Layer set-ops &amp; cross-layer analytics\n\n    def get_layer_vertices(self, layer_id):\n        \"\"\"\n        vertices in a layer.\n\n        Parameters\n        ----------\n        layer_id : str\n\n        Returns\n        -------\n        set[str]\n        \"\"\"\n        return self._layers[layer_id][\"vertices\"].copy()\n\n    def get_layer_edges(self, layer_id):\n        \"\"\"\n        Edges in a layer.\n\n        Parameters\n        ----------\n        layer_id : str\n\n        Returns\n        -------\n        set[str]\n        \"\"\"\n        return self._layers[layer_id][\"edges\"].copy()\n\n    def layer_union(self, layer_ids):\n        \"\"\"\n        Union of multiple layers.\n\n        Parameters\n        ----------\n        layer_ids : Iterable[str]\n\n        Returns\n        -------\n        dict\n            ``{\"vertices\": set[str], \"edges\": set[str]}``\n        \"\"\"\n        if not layer_ids:\n            return {\"vertices\": set(), \"edges\": set()}\n\n        union_vertices = set()\n        union_edges = set()\n\n        for layer_id in layer_ids:\n            if layer_id in self._layers:\n                union_vertices.update(self._layers[layer_id][\"vertices\"])\n                union_edges.update(self._layers[layer_id][\"edges\"])\n\n        return {\"vertices\": union_vertices, \"edges\": union_edges}\n\n    def layer_intersection(self, layer_ids):\n        \"\"\"\n        Intersection of multiple layers.\n\n        Parameters\n        ----------\n        layer_ids : Iterable[str]\n\n        Returns\n        -------\n        dict\n            ``{\"vertices\": set[str], \"edges\": set[str]}``\n        \"\"\"\n        if not layer_ids:\n            return {\"vertices\": set(), \"edges\": set()}\n\n        if len(layer_ids) == 1:\n            layer_id = layer_ids[0]\n            return {\n                \"vertices\": self._layers[layer_id][\"vertices\"].copy(),\n                \"edges\": self._layers[layer_id][\"edges\"].copy()\n            }\n\n        # Start with first layer\n        common_vertices = self._layers[layer_ids[0]][\"vertices\"].copy()\n        common_edges = self._layers[layer_ids[0]][\"edges\"].copy()\n\n        # Intersect with remaining layers\n        for layer_id in layer_ids[1:]:\n            if layer_id in self._layers:\n                common_vertices &amp;= self._layers[layer_id][\"vertices\"]\n                common_edges &amp;= self._layers[layer_id][\"edges\"]\n            else:\n                # Layer doesn't exist, intersection is empty\n                return {\"vertices\": set(), \"edges\": set()}\n\n        return {\"vertices\": common_vertices, \"edges\": common_edges}\n\n    def layer_difference(self, layer1_id, layer2_id):\n        \"\"\"\n        Set difference: elements in ``layer1_id`` not in ``layer2_id``.\n\n        Parameters\n        ----------\n        layer1_id : str\n        layer2_id : str\n\n        Returns\n        -------\n        dict\n            ``{\"vertices\": set[str], \"edges\": set[str]}``\n\n        Raises\n        ------\n        KeyError\n            If either layer is missing.\n        \"\"\"\n        if layer1_id not in self._layers or layer2_id not in self._layers:\n            raise KeyError(\"One or both layers not found\")\n\n        layer1 = self._layers[layer1_id]\n        layer2 = self._layers[layer2_id]\n\n        return {\n            \"vertices\": layer1[\"vertices\"] - layer2[\"vertices\"],\n            \"edges\": layer1[\"edges\"] - layer2[\"edges\"]\n        }\n\n    def create_layer_from_operation(self, result_layer_id, operation_result, **attributes):\n        \"\"\"\n        Create a new layer from the result of a set operation.\n\n        Parameters\n        ----------\n        result_layer_id : str\n        operation_result : dict\n            Output of ``layer_union``/``layer_intersection``/``layer_difference``.\n        **attributes\n            Pure layer attributes.\n\n        Returns\n        -------\n        str\n            The created layer ID.\n\n        Raises\n        ------\n        ValueError\n            If the target layer already exists.\n        \"\"\"\n        if result_layer_id in self._layers:\n            raise ValueError(f\"Layer {result_layer_id} already exists\")\n\n        self._layers[result_layer_id] = {\n            \"vertices\": operation_result[\"vertices\"].copy(),\n            \"edges\": operation_result[\"edges\"].copy(), \n            \"attributes\": attributes\n        }\n\n        return result_layer_id\n\n    def edge_presence_across_layers(\n        self,\n        edge_id: str | None = None,\n        source: str | None = None,\n        target: str | None = None,\n        *,\n        include_default: bool = False,\n        undirected_match: bool | None = None\n    ):\n        \"\"\"\n        Locate where an edge exists across layers.\n\n        Parameters\n        ----------\n        edge_id : str, optional\n            If provided, match by ID (any kind: binary/vertex-edge/hyper).\n        source : str, optional\n            When used with ``target``, match only binary/vertex-edge edges by endpoints.\n        target : str, optional\n        include_default : bool, optional\n            Include the internal default layer in the search.\n        undirected_match : bool, optional\n            When endpoint matching, allow undirected symmetric matches.\n\n        Returns\n        -------\n        list[str] or dict[str, list[str]]\n            If ``edge_id`` given: list of layer IDs.\n            Else: ``{layer_id: [edge_id, ...]}``.\n\n        Raises\n        ------\n        ValueError\n            If both modes (ID and endpoints) are provided or neither is valid.\n        \"\"\"\n        has_id = edge_id is not None\n        has_pair = (source is not None) and (target is not None)\n        if has_id == has_pair:\n            raise ValueError(\"Provide either edge_id OR (source and target), but not both.\")\n\n        layers_view = self.get_layers_dict(include_default=include_default)\n\n        if has_id:\n            return [lid for lid, ldata in layers_view.items() if edge_id in ldata[\"edges\"]]\n\n        if undirected_match is None:\n            undirected_match = False\n\n        out: dict[str, list[str]] = {}\n        for lid, ldata in layers_view.items():\n            matches = []\n            for eid in ldata[\"edges\"]:\n                # skip hyper-edges for (source,target) mode\n                if self.edge_kind.get(eid) == \"hyper\":\n                    continue\n                s, t, _ = self.edge_definitions[eid]\n                edge_is_directed = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n                if s == source and t == target:\n                    matches.append(eid)\n                elif undirected_match and not edge_is_directed and s == target and t == source:\n                    matches.append(eid)\n            if matches:\n                out[lid] = matches\n        return out\n\n    def hyperedge_presence_across_layers(\n        self,\n        *,\n        members=None,\n        head=None,\n        tail=None,\n        include_default: bool = False,\n    ):\n        \"\"\"\n        Locate layers containing a hyperedge with exactly these sets.\n\n        Parameters\n        ----------\n        members : Iterable[str], optional\n            Undirected member set (exact match).\n        head : Iterable[str], optional\n            Directed head set (exact match).\n        tail : Iterable[str], optional\n            Directed tail set (exact match).\n        include_default : bool, optional\n\n        Returns\n        -------\n        dict[str, list[str]]\n            ``{layer_id: [edge_id, ...]}``.\n\n        Raises\n        ------\n        ValueError\n            For invalid combinations or empty sets.\n        \"\"\"\n        undirected = members is not None\n        if undirected and (head is not None or tail is not None):\n            raise ValueError(\"Use either members OR head+tail, not both.\")\n        if not undirected and (head is None or tail is None):\n            raise ValueError(\"Directed hyperedge query requires both head and tail.\")\n\n        if undirected:\n            members = set(members)\n            if not members:\n                raise ValueError(\"members must be non-empty.\")\n        else:\n            head = set(head)\n            tail = set(tail)\n            if not head or not tail:\n                raise ValueError(\"head and tail must be non-empty.\")\n            if head &amp; tail:\n                raise ValueError(\"head and tail must be disjoint.\")\n\n        layers_view = self.get_layers_dict(include_default=include_default)\n        out: dict[str, list[str]] = {}\n\n        for lid, ldata in layers_view.items():\n            matches = []\n            for eid in ldata[\"edges\"]:\n                if self.edge_kind.get(eid) != \"hyper\":\n                    continue\n                meta = self.hyperedge_definitions.get(eid, {})\n                if undirected and (not meta.get(\"directed\", False)):\n                    if set(meta.get(\"members\", ())) == members:\n                        matches.append(eid)\n                elif (not undirected) and meta.get(\"directed\", False):\n                    if set(meta.get(\"head\", ())) == head and set(meta.get(\"tail\", ())) == tail:\n                        matches.append(eid)\n            if matches:\n                out[lid] = matches\n        return out\n\n    def vertex_presence_across_layers(self, vertex_id, include_default: bool = False):\n        \"\"\"\n        List layers containing a specific vertex.\n\n        Parameters\n        ----------\n        vertex_id : str\n        include_default : bool, optional\n\n        Returns\n        -------\n        list[str]\n        \"\"\"\n        layers_with_vertex = []\n        for layer_id, layer_data in self.get_layers_dict(include_default=include_default).items():\n            if vertex_id in layer_data[\"vertices\"]:\n                layers_with_vertex.append(layer_id)\n        return layers_with_vertex\n\n    def conserved_edges(self, min_layers=2, include_default=False):\n        \"\"\"\n        Edges present in at least ``min_layers`` layers.\n\n        Parameters\n        ----------\n        min_layers : int, optional\n        include_default : bool, optional\n\n        Returns\n        -------\n        dict[str, int]\n            ``{edge_id: count}``.\n        \"\"\"\n        layers_to_check = self.get_layers_dict(include_default=include_default)  # hides 'default' by default\n        edge_counts = {}\n        for _, layer_data in layers_to_check.items():\n            for eid in layer_data[\"edges\"]:\n                edge_counts[eid] = edge_counts.get(eid, 0) + 1\n        return {eid: c for eid, c in edge_counts.items() if c &gt;= min_layers}\n\n    def layer_specific_edges(self, layer_id):\n        \"\"\"\n        Edges that appear **only** in the specified layer.\n\n        Parameters\n        ----------\n        layer_id : str\n\n        Returns\n        -------\n        set[str]\n\n        Raises\n        ------\n        KeyError\n            If the layer does not exist.\n        \"\"\"\n        if layer_id not in self._layers:\n            raise KeyError(f\"Layer {layer_id} not found\")\n\n        target_edges = self._layers[layer_id][\"edges\"]\n        specific_edges = set()\n\n        for edge_id in target_edges:\n            # Count how many layers contain this edge\n            count = sum(1 for layer_data in self._layers.values() \n                    if edge_id in layer_data[\"edges\"])\n            if count == 1:  # Only in target layer\n                specific_edges.add(edge_id)\n\n        return specific_edges\n\n    def temporal_dynamics(self, ordered_layers, metric='edge_change'):\n        \"\"\"\n        Compute changes between consecutive layers in a temporal sequence.\n\n        Parameters\n        ----------\n        ordered_layers : list[str]\n            Layer IDs in chronological order.\n        metric : {'edge_change', 'vertex_change'}, optional\n\n        Returns\n        -------\n        list[dict[str, int]]\n            Per-step dictionaries with keys: ``'added'``, ``'removed'``, ``'net_change'``.\n\n        Raises\n        ------\n        ValueError\n            If fewer than two layers are provided.\n        KeyError\n            If a referenced layer does not exist.\n        \"\"\"\n        if len(ordered_layers) &lt; 2:\n            raise ValueError(\"Need at least 2 layers for temporal analysis\")\n\n        changes = []\n\n        for i in range(len(ordered_layers) - 1):\n            current_id = ordered_layers[i]\n            next_id = ordered_layers[i + 1]\n\n            if current_id not in self._layers or next_id not in self._layers:\n                raise KeyError(\"One or more layers not found\")\n\n            current_data = self._layers[current_id]\n            next_data = self._layers[next_id]\n\n            if metric == 'edge_change':\n                added = len(next_data[\"edges\"] - current_data[\"edges\"])\n                removed = len(current_data[\"edges\"] - next_data[\"edges\"])\n                changes.append({'added': added, 'removed': removed, 'net_change': added - removed})\n\n            elif metric == 'vertex_change':\n                added = len(next_data[\"vertices\"] - current_data[\"vertices\"])\n                removed = len(current_data[\"vertices\"] - next_data[\"vertices\"])\n                changes.append({'added': added, 'removed': removed, 'net_change': added - removed})\n\n        return changes\n\n    def create_aggregated_layer(self, source_layer_ids, target_layer_id, method='union', \n                            weight_func=None, **attributes):\n        \"\"\"\n        Create a new layer by aggregating multiple source layers.\n\n        Parameters\n        ----------\n        source_layer_ids : list[str]\n        target_layer_id : str\n        method : {'union', 'intersection'}, optional\n        weight_func : callable, optional\n            Reserved for future weight merging logic (currently unused).\n        **attributes\n            Pure layer attributes.\n\n        Returns\n        -------\n        str\n            The created layer ID.\n\n        Raises\n        ------\n        ValueError\n            For unknown methods or missing source layers, or if target exists.\n        \"\"\"\n        if not source_layer_ids:\n            raise ValueError(\"Must specify at least one source layer\")\n\n        if target_layer_id in self._layers:\n            raise ValueError(f\"Target layer {target_layer_id} already exists\")\n\n        if method == 'union':\n            result = self.layer_union(source_layer_ids)\n        elif method == 'intersection':\n            result = self.layer_intersection(source_layer_ids)\n        else:\n            raise ValueError(f\"Unknown aggregation method: {method}\")\n\n        return self.create_layer_from_operation(target_layer_id, result, **attributes)\n\n    def layer_statistics(self, include_default: bool = False):\n        \"\"\"\n        Basic per-layer statistics.\n\n        Parameters\n        ----------\n        include_default : bool, optional\n\n        Returns\n        -------\n        dict[str, dict]\n            ``{layer_id: {'vertices': int, 'edges': int, 'attributes': dict}}``.\n        \"\"\"\n        stats = {}\n        for layer_id, layer_data in self.get_layers_dict(include_default=include_default).items():\n            stats[layer_id] = {\n                'vertices': len(layer_data[\"vertices\"]),\n                'edges': len(layer_data[\"edges\"]),\n                'attributes': layer_data[\"attributes\"]\n            }\n        return stats\n\n    # Traversal (neighbors)\n\n    def neighbors(self, entity_id):\n        \"\"\"\n        Neighbors of an entity (vertex or edge-entity).\n\n        Parameters\n        ----------\n        entity_id : str\n\n        Returns\n        -------\n        list[str]\n            Adjacent entities. For hyperedges, uses head/tail orientation.\n        \"\"\"        \n        if entity_id not in self.entity_to_idx:\n            return []\n        out = set()\n        for eid in self.edge_to_idx.keys():\n            kind = self.edge_kind.get(eid, None)\n            if kind == \"hyper\":\n                meta = self.hyperedge_definitions[eid]\n                if meta[\"directed\"]:\n                    if entity_id in meta[\"head\"]:\n                        out |= (meta[\"tail\"])\n                    elif entity_id in meta[\"tail\"]:\n                        out |= (meta[\"head\"])\n                else:\n                    if ((\"members\" in meta) and (entity_id in meta[\"members\"])):\n                        out |= (meta[\"members\"] - {entity_id})\n            else:\n                # binary / vertex_edge\n                s, t, _ = self.edge_definitions[eid]\n                edir = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n                if s == entity_id:\n                    out.add(t)\n                elif t == entity_id and (not edir or self.entity_types.get(entity_id) == 'edge'):\n                    out.add(s)\n        return list(out)\n\n    def out_neighbors(self, vertex_id):\n        \"\"\"\n        Out-neighbors of a vertex under directed semantics.\n\n        Parameters\n        ----------\n        vertex_id : str\n\n        Returns\n        -------\n        list[str]\n        \"\"\"\n        if vertex_id not in self.entity_to_idx:\n            return []\n        out = set()\n        for eid in self.edge_to_idx.keys():\n            kind = self.edge_kind.get(eid, None)\n            if kind == \"hyper\":\n                meta = self.hyperedge_definitions[eid]\n                if meta[\"directed\"]:\n                    if vertex_id in meta[\"head\"]:\n                        out |= (meta[\"tail\"])\n                else:\n                    if vertex_id in meta.get(\"members\", ()):\n                        out |= (meta[\"members\"] - {vertex_id})\n            else:\n                s, t, _ = self.edge_definitions[eid]\n                edir = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n                if s == vertex_id:\n                    out.add(t)\n                elif t == vertex_id and not edir:\n                    out.add(s)\n        return list(out)\n\n    def successors(self, vertex_id):\n        \"\"\"\n        successors of a vertex under directed semantics.\n\n        Parameters\n        ----------\n        vertex_id : str\n\n        Returns\n        -------\n        list[str]\n        \"\"\"\n        if vertex_id not in self.entity_to_idx:\n            return []\n        out = set()\n        for eid in self.edge_to_idx.keys():\n            kind = self.edge_kind.get(eid, None)\n            if kind == \"hyper\":\n                meta = self.hyperedge_definitions[eid]\n                if meta[\"directed\"]:\n                    if vertex_id in meta[\"head\"]:\n                        out |= (meta[\"tail\"])\n                else:\n                    if vertex_id in meta.get(\"members\", ()):\n                        out |= (meta[\"members\"] - {vertex_id})\n            else:\n                s, t, _ = self.edge_definitions[eid]\n                edir = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n                if s == vertex_id:\n                    out.add(t)\n                elif t == vertex_id and not edir:\n                    out.add(s)\n        return list(out)\n\n    def in_neighbors(self, vertex_id):\n        \"\"\"\n        In-neighbors of a vertex under directed semantics.\n\n        Parameters\n        ----------\n        vertex_id : str\n\n        Returns\n        -------\n        list[str]\n        \"\"\"        \n        if vertex_id not in self.entity_to_idx:\n            return []\n        inn = set()\n        for eid in self.edge_to_idx.keys():\n            kind = self.edge_kind.get(eid, None)\n            if kind == \"hyper\":\n                meta = self.hyperedge_definitions[eid]\n                if meta[\"directed\"]:\n                    if vertex_id in meta[\"tail\"]:\n                        inn |= (meta[\"head\"])\n                else:\n                    if vertex_id in meta.get(\"members\", ()):\n                        inn |= (meta[\"members\"] - {vertex_id})\n            else:\n                s, t, _ = self.edge_definitions[eid]\n                edir = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n                if t == vertex_id:\n                    inn.add(s)\n                elif s == vertex_id and not edir:\n                    inn.add(t)\n        return list(inn)\n\n    def predecessors(self, vertex_id):\n        \"\"\"\n        In-neighbors of a vertex under directed semantics.\n\n        Parameters\n        ----------\n        vertex_id : str\n\n        Returns\n        -------\n        list[str]\n        \"\"\"        \n        if vertex_id not in self.entity_to_idx:\n            return []\n        inn = set()\n        for eid in self.edge_to_idx.keys():\n            kind = self.edge_kind.get(eid, None)\n            if kind == \"hyper\":\n                meta = self.hyperedge_definitions[eid]\n                if meta[\"directed\"]:\n                    if vertex_id in meta[\"tail\"]:\n                        inn |= (meta[\"head\"])\n                else:\n                    if vertex_id in meta.get(\"members\", ()):\n                        inn |= (meta[\"members\"] - {vertex_id})\n            else:\n                s, t, _ = self.edge_definitions[eid]\n                edir = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n                if t == vertex_id:\n                    inn.add(s)\n                elif s == vertex_id and not edir:\n                    inn.add(t)\n        return list(inn)\n\n    # Slicing / copying / accounting\n\n\n    def edge_subgraph(self, edges) -&gt; \"Graph\":\n        \"\"\"\n        Create a new graph containing only a specified subset of edges.\n\n        Parameters\n        ----------\n        edges : Iterable[str] | Iterable[int]\n            Edge identifiers (strings) or edge indices (integers) to retain\n            in the subgraph.\n\n        Returns\n        -------\n        Graph\n            A new `Graph` instance containing only the selected edges and the\n            vertices incident to them.\n\n        Behavior\n        --------\n        - Copies the current graph and deletes all edges **not** in the provided set.\n        - Optionally, you can prune orphaned vertices (i.e., vertices not incident\n        to any remaining edge) \u2014 this is generally recommended for consistency.\n\n        Notes\n        -----\n        - Attributes associated with remaining edges and vertices are preserved.\n        - Hyperedges are supported: if a hyperedge is in the provided set, all\n        its members are retained.\n        - If `edges` is empty, the resulting graph will be empty except for\n        any isolated vertices that remain.\n        \"\"\"        \n        # normalize to edge_id set\n        if all(isinstance(e, int) for e in edges):\n            E = {self.idx_to_edge[e] for e in edges}\n        else:\n            E = set(edges)\n\n        # collect incident vertices and partition edges\n        V = set()\n        bin_payload, hyper_payload = [], []\n        for eid in E:\n            kind = self.edge_kind.get(eid, \"binary\")\n            if kind == \"hyper\":\n                h = self.hyperedge_definitions[eid]\n                if h.get(\"members\"):\n                    V.update(h[\"members\"])\n                    hyper_payload.append({\"members\": list(h[\"members\"]), \"edge_id\": eid,\n                                        \"weight\": self.edge_weights.get(eid, 1.0)})\n                else:\n                    V.update(h.get(\"head\", ())); V.update(h.get(\"tail\", ()))\n                    hyper_payload.append({\"head\": list(h.get(\"head\", ())),\n                                        \"tail\": list(h.get(\"tail\", ())),\n                                        \"edge_id\": eid, \"weight\": self.edge_weights.get(eid, 1.0)})\n            else:\n                s, t, etype = self.edge_definitions[eid]\n                V.add(s); V.add(t)\n                bin_payload.append({\"source\": s, \"target\": t, \"edge_id\": eid,\n                                    \"edge_type\": etype,\n                                    \"edge_directed\": self.edge_directed.get(eid, True if self.directed is None else self.directed),\n                                    \"weight\": self.edge_weights.get(eid, 1.0)})\n\n        # new graph prealloc\n        g = Graph(directed=self.directed, n=len(V), e=len(E))\n        # vertices with attrs\n        v_rows = [{\"vertex_id\": v, **(self._row_attrs(self.vertex_attributes, \"vertex_id\", v) or {})} for v in V]\n        g.add_vertices_bulk(v_rows, layer=g._default_layer)\n\n        # edges\n        if bin_payload:\n            g.add_edges_bulk(bin_payload, layer=g._default_layer)\n        if hyper_payload:\n            g.add_hyperedges_bulk(hyper_payload, layer=g._default_layer)\n\n        # copy layer memberships for retained edges &amp; incident vertices\n        for lid, meta in self._layers.items():\n            g.add_layer(lid, **meta[\"attributes\"])\n            kept_edges = set(meta[\"edges\"]) &amp; E\n            if kept_edges:\n                g.add_edges_to_layer_bulk(lid, kept_edges)\n\n        return g\n\n    def subgraph(self, vertices) -&gt; \"Graph\":\n        \"\"\"\n        Create a vertex-induced subgraph.\n\n        Parameters\n        ----------\n        vertices : Iterable[str]\n            A set or list of vertex identifiers to keep in the subgraph.\n\n        Returns\n        -------\n        Graph\n            A new `Graph` containing only the specified vertices and any edges\n            for which **all** endpoints are within this set.\n\n        Behavior\n        --------\n        - Copies the current graph and removes edges with any endpoint outside\n        the provided vertex set.\n        - Removes all vertices not listed in `vertices`.\n\n        Notes\n        -----\n        - For binary edges, both endpoints must be in `vertices` to be retained.\n        - For hyperedges, **all** member verices must be included to retain the edge.\n        - Attributes for retained verices and edges are preserved.\n        \"\"\"\n        V = set(vertices)\n\n        # collect edges fully inside V\n        E_bin, E_hyper_members, E_hyper_dir = [], [], []\n        for eid, (s, t, et) in self.edge_definitions.items():\n            if et == \"hyper\":\n                continue\n            if s in V and t in V:\n                E_bin.append(eid)\n        for eid, h in self.hyperedge_definitions.items():\n            if h.get(\"members\"):\n                if set(h[\"members\"]).issubset(V):\n                    E_hyper_members.append(eid)\n            else:\n                if set(h.get(\"head\", ())).issubset(V) and set(h.get(\"tail\", ())).issubset(V):\n                    E_hyper_dir.append(eid)\n\n        # payloads\n        v_rows = [{\"vertex_id\": v, **(self._row_attrs(self.vertex_attributes, \"vertex_id\", v) or {})} for v in V]\n\n        bin_payload = []\n        for eid in E_bin:\n            s, t, etype = self.edge_definitions[eid]\n            bin_payload.append({\"source\": s, \"target\": t, \"edge_id\": eid,\n                                \"edge_type\": etype,\n                                \"edge_directed\": self.edge_directed.get(eid, True if self.directed is None else self.directed),\n                                \"weight\": self.edge_weights.get(eid, 1.0)})\n\n        hyper_payload = []\n        for eid in E_hyper_members:\n            m = self.hyperedge_definitions[eid][\"members\"]\n            hyper_payload.append({\"members\": list(m), \"edge_id\": eid,\n                                \"weight\": self.edge_weights.get(eid, 1.0)})\n        for eid in E_hyper_dir:\n            h = self.hyperedge_definitions[eid]\n            hyper_payload.append({\"head\": list(h.get(\"head\", ())),\n                                \"tail\": list(h.get(\"tail\", ())),\n                                \"edge_id\": eid, \"weight\": self.edge_weights.get(eid, 1.0)})\n\n        # build new graph\n        g = Graph(directed=self.directed, n=len(V), e=len(E_bin)+len(E_hyper_members)+len(E_hyper_dir))\n        g.add_vertices_bulk(v_rows, layer=g._default_layer)\n        if bin_payload:\n            g.add_edges_bulk(bin_payload, layer=g._default_layer)\n        if hyper_payload:\n            g.add_hyperedges_bulk(hyper_payload, layer=g._default_layer)\n\n        # layer memberships restricted to V\n        for lid, meta in self._layers.items():\n            g.add_layer(lid, **meta[\"attributes\"])\n            keep = set()\n            for eid in meta[\"edges\"]:\n                kind = self.edge_kind.get(eid, \"binary\")\n                if kind == \"hyper\":\n                    h = self.hyperedge_definitions[eid]\n                    if h.get(\"members\"):\n                        if set(h[\"members\"]).issubset(V): keep.add(eid)\n                    else:\n                        if set(h.get(\"head\",())).issubset(V) and set(h.get(\"tail\",())).issubset(V): keep.add(eid)\n                else:\n                    s, t, _ = self.edge_definitions[eid]\n                    if s in V and t in V:\n                        keep.add(eid)\n            if keep:\n                g.add_edges_to_layer_bulk(lid, keep)\n\n        return g\n\n    def extract_subgraph(self, vertices=None, edges=None) -&gt; \"Graph\":\n\n        \"\"\"\n        Create a subgraph based on a combination of vertex and/or edge filters.\n\n        Parameters\n        ----------\n        vertices : Iterable[str] | None, optional\n            A set of vertex IDs to include. If provided, behaves like `subgraph()`.\n            If `None`, no vertex filtering is applied.\n        edges : Iterable[str] | Iterable[int] | None, optional\n            A set of edge IDs or indices to include. If provided, behaves like\n            `edge_subgraph()`. If `None`, no edge filtering is applied.\n\n        Returns\n        -------\n        Graph\n            A new `Graph` filtered according to the provided vertex and/or edge\n            sets.\n\n        Behavior\n        --------\n        - If both `vertices` and `edges` are provided, the resulting subgraph is\n        the intersection of the two filters.\n        - If only `vertices` is provided, equivalent to `subgraph(vertices)`.\n        - If only `edges` is provided, equivalent to `edge_subgraph(edges)`.\n        - If neither is provided, a full copy of the graph is returned.\n\n        Notes\n        -----\n        - This is a convenience method; it delegates to `subgraph()` and\n        `edge_subgraph()` internally.\n        \"\"\"    \n        if vertices is None and edges is None:\n            return self.copy()\n\n        if edges is not None:\n            if all(isinstance(e, int) for e in edges):\n                E = {self.idx_to_edge[e] for e in edges}\n            else:\n                E = set(edges)\n        else:\n            E = None\n\n        V = set(vertices) if vertices is not None else None\n\n        # If only one filter, delegate to optimized path\n        if V is not None and E is None:\n            return self.subgraph(V)\n        if V is None and E is not None:\n            return self.edge_subgraph(E)\n\n        # Both filters: keep only edges in E whose endpoints (or members) lie in V\n        kept_edges = set()\n        kept_vertices = set(V)\n        for eid in E:\n            kind = self.edge_kind.get(eid, \"binary\")\n            if kind == \"hyper\":\n                h = self.hyperedge_definitions[eid]\n                if h.get(\"members\"):\n                    if set(h[\"members\"]).issubset(V):\n                        kept_edges.add(eid)\n                else:\n                    if set(h.get(\"head\", ())).issubset(V) and set(h.get(\"tail\", ())).issubset(V):\n                        kept_edges.add(eid)\n            else:\n                s, t, _ = self.edge_definitions[eid]\n                if s in V and t in V:\n                    kept_edges.add(eid)\n\n        return self.edge_subgraph(kept_edges).subgraph(kept_vertices)\n\n    def reverse(self) -&gt; \"Graph\":\n        \"\"\"\n        Return a new graph with all directed edges reversed.\n\n        Returns\n        -------\n        Graph\n            A new `Graph` instance with reversed directionality where applicable.\n\n        Behavior\n        --------\n        - **Binary edges:** direction is flipped by swapping source and target.\n        - **Directed hyperedges:** `head` and `tail` sets are swapped.\n        - **Undirected edges/hyperedges:** unaffected.\n        - Edge attributes and metadata are preserved.\n\n        Notes\n        -----\n        - This operation does not modify the original graph.\n        - If the graph is undirected (`self.directed == False`), the result is\n        identical to the original.\n        - For mixed graphs (directed + undirected edges), only the directed\n        ones are reversed.\n        \"\"\"\n        g = self.copy()\n\n        for eid, defn in g.edge_definitions.items():\n            if not g._is_directed_edge(eid):\n                continue\n            # Binary edge: swap endpoints\n            u, v, etype = defn\n            g.edge_definitions[eid] = (v, u, etype)\n\n        for eid, meta in g.hyperedge_definitions.items():\n            if not meta.get(\"directed\", False):\n                continue\n            # Hyperedge: swap head and tail sets\n            meta[\"head\"], meta[\"tail\"] = meta[\"tail\"], meta[\"head\"]\n\n        return g\n\n    def subgraph_from_layer(self, layer_id, *, resolve_layer_weights=True):\n        if layer_id not in self._layers:\n            raise KeyError(f\"Layer {layer_id} not found\")\n\n        import polars as pl\n        layer_meta = self._layers[layer_id]\n        V = set(layer_meta[\"vertices\"])\n        E = set(layer_meta[\"edges\"])\n\n        g = Graph(directed=self.directed, n=len(V), e=len(E))\n        g.add_layer(layer_id, **layer_meta[\"attributes\"])\n        g.set_active_layer(layer_id)\n\n        # vertices with attrs (edge-entities share same table)\n        v_rows = [{\"vertex_id\": v, **(self._row_attrs(self.vertex_attributes, \"vertex_id\", v) or {})} for v in V]\n        g.add_vertices_bulk(v_rows, layer=layer_id)\n\n        # edge attrs\n        e_attrs = {}\n        if isinstance(self.edge_attributes, pl.DataFrame) and self.edge_attributes.height and \"edge_id\" in self.edge_attributes.columns:\n            for row in self.edge_attributes.filter(pl.col(\"edge_id\").is_in(list(E))).to_dicts():\n                d = dict(row); eid = d.pop(\"edge_id\", None)\n                if eid is not None: e_attrs[eid] = d\n\n        # weights\n        eff_w = {}\n        if resolve_layer_weights:\n            df = self.edge_layer_attributes\n            if isinstance(df, pl.DataFrame) and df.height and {\"layer_id\",\"edge_id\",\"weight\"}.issubset(df.columns):\n                for r in df.filter((pl.col(\"layer_id\")==layer_id) &amp; (pl.col(\"edge_id\").is_in(list(E)))).iter_rows(named=True):\n                    if r.get(\"weight\") is not None:\n                        eff_w[r[\"edge_id\"]] = float(r[\"weight\"])\n\n        # partition edges\n        bin_payload, hyper_payload = [], []\n        for eid in E:\n            w = eff_w.get(eid, self.edge_weights.get(eid, 1.0)) if resolve_layer_weights else self.edge_weights.get(eid, 1.0)\n            kind = self.edge_kind.get(eid, \"binary\")\n            attrs = e_attrs.get(eid, {})\n            if kind == \"hyper\":\n                h = self.hyperedge_definitions[eid]\n                if h.get(\"members\"):\n                    hyper_payload.append({\"members\": list(h[\"members\"]), \"edge_id\": eid, \"weight\": w, \"attributes\": attrs})\n                else:\n                    hyper_payload.append({\"head\": list(h.get(\"head\", ())), \"tail\": list(h.get(\"tail\", ())),\n                                        \"edge_id\": eid, \"weight\": w, \"attributes\": attrs})\n            else:\n                s, t, et = self.edge_definitions[eid]\n                bin_payload.append({\n                                    \"source\": s, \n                                    \"target\": t, \n                                    \"edge_id\": eid,\n                                    \"edge_type\": et,\n                                    \"edge_directed\": self.edge_directed.get(eid, True if self.directed is None else self.directed),\n                                    \"weight\": w, \n                                    \"attributes\": attrs\n                                })\n\n        if bin_payload:\n            g.add_edges_bulk(bin_payload, layer=layer_id)\n        if hyper_payload:\n            g.add_hyperedges_bulk(hyper_payload, layer=layer_id)\n\n        return g\n\n    def _row_attrs(self, df, key_col: str, key):\n        \"\"\"\n        INTERNAL: return a dict of attributes for the row in `df` where `key_col == key`,\n        excluding the key column itself. If not found or df empty, return {}.\n        Caches per (id(df), key_col) for speed; cache auto-refreshes when the df object changes.\n        \"\"\"\n        try:\n            import polars as pl\n        except Exception:\n            # If Polars isn't available for some reason, best-effort fallback\n            return {}\n\n        # Basic guards\n        if not isinstance(df, pl.DataFrame) or df.height == 0 or key_col not in df.columns:\n            return {}\n\n        # Cache setup\n        cache = getattr(self, \"_row_attr_cache\", None)\n        if cache is None:\n            cache = {}\n            setattr(self, \"_row_attr_cache\", cache)\n\n        cache_key = (id(df), key_col)\n        mapping = cache.get(cache_key)\n\n        # Build the mapping once per df object\n        if mapping is None:\n            mapping = {}\n            # Latest write should win if duplicates exist (matches your upsert semantics)\n            for row in df.iter_rows(named=True):\n                kval = row.get(key_col)\n                if kval is None:\n                    continue\n                d = dict(row)\n                d.pop(key_col, None)\n                mapping[kval] = d\n            cache[cache_key] = mapping\n\n        return mapping.get(key, {})\n\n    def copy(self):\n        \"\"\"\n        Deep copy the entire graph, including layers, edges, hyperedges, and attributes.\n        (Behavior preserved; uses preallocation + vectorized attr extraction.)\n        \"\"\"\n        import polars as pl\n\n        # Preallocate with current sizes\n        new_graph = Graph(directed=self.directed, n=self._num_entities, e=self._num_edges)\n\n        # Copy layers &amp; their pure attributes ----\n        for lid, meta in self._layers.items():\n            if lid != new_graph._default_layer:\n                new_graph.add_layer(lid, **meta[\"attributes\"])\n            else:\n                # default layer exists; mirror its attributes too\n                if meta[\"attributes\"]:\n                    new_graph.set_layer_attrs(lid, **meta[\"attributes\"])\n\n        # Build attribute rows once (no per-row filters)\n        if isinstance(self.vertex_attributes, pl.DataFrame) and self.vertex_attributes.height and \"vertex_id\" in self.vertex_attributes.columns:\n            vmap = {d.pop(\"vertex_id\"): d for d in self.vertex_attributes.to_dicts()}\n        else:\n            vmap = {}\n\n        # Split entities by type to preserve typing\n        vertex_rows = []\n        edge_entity_rows = []\n        for ent_id, etype in self.entity_types.items():\n            row = {\"vertex_id\": ent_id}\n            row.update(vmap.get(ent_id, {}))\n            if etype == \"vertex\":\n                vertex_rows.append(row)\n            else:\n                # entity_types[...] == \"edge\" \u2192 edge-entity\n                edge_entity_rows.append({\"edge_entity_id\": ent_id, **vmap.get(ent_id, {})})\n\n        # Add entities with correct type APIs (bulk)\n        if vertex_rows:\n            new_graph.add_vertices_bulk(vertex_rows, layer=new_graph._default_layer)\n        if edge_entity_rows:\n            # attributes for edge-entities live in the same vertex_attributes table\n            new_graph.add_edge_entities_bulk(edge_entity_rows, layer=new_graph._default_layer)\n\n        # Binary / vertex-edge edges\n        bin_payload = []\n        for edge_id, (source, target, edge_type) in self.edge_definitions.items():\n            if edge_type == \"hyper\":\n                continue\n            bin_payload.append({\n                \"source\": source, \"target\": target, \"edge_id\": edge_id,\n                \"edge_type\": edge_type,    # 'regular' or 'vertex_edge'\n                \"edge_directed\": self.edge_directed.get(edge_id, self.directed),\n                \"weight\": self.edge_weights.get(edge_id, 1.0),\n                \"attributes\": (self._row_attrs(self.edge_attributes, \"edge_id\", edge_id) or {}),\n            })\n        if bin_payload:\n            new_graph.add_edges_bulk(bin_payload, layer=new_graph._default_layer)\n\n        # Hyperedges\n        hyper_payload = []\n        for eid, hdef in self.hyperedge_definitions.items():\n            base = {\n                \"edge_id\": eid,\n                \"weight\": self.edge_weights.get(eid, 1.0),\n                \"attributes\": (self._row_attrs(self.edge_attributes, \"edge_id\", eid) or {}),\n            }\n            if hdef.get(\"members\"):\n                hyper_payload.append({**base, \"members\": list(hdef[\"members\"])})\n            else:\n                hyper_payload.append({**base, \"head\": list(hdef.get(\"head\", ())), \"tail\": list(hdef.get(\"tail\", ()))})\n        if hyper_payload:\n            new_graph.add_hyperedges_bulk(hyper_payload, layer=new_graph._default_layer)\n\n        # Copy layer memberships\n        for lid, meta in self._layers.items():\n            if lid not in new_graph._layers:\n                new_graph.add_layer(lid)\n            new_graph._layers[lid][\"vertices\"] = set(meta[\"vertices\"])\n            new_graph._layers[lid][\"edges\"] = set(meta[\"edges\"])\n\n        # Copy edge-layer attributes + legacy weight dict\n        if isinstance(self.edge_layer_attributes, pl.DataFrame):\n            new_graph.edge_layer_attributes = self.edge_layer_attributes.clone()\n        else:\n            new_graph.edge_layer_attributes = self.edge_layer_attributes\n\n        from collections import defaultdict\n        new_graph.layer_edge_weights = defaultdict(dict, {lid: dict(m) for lid, m in self.layer_edge_weights.items()})\n\n        return new_graph\n\n    def memory_usage(self):\n        \"\"\"\n        Approximate total memory usage in bytes.\n\n        Returns\n        -------\n        int\n            Estimated bytes for the incidence matrix, dictionaries, and attribute DFs.\n        \"\"\"        \n        # Approximate matrix memory: each non-zero entry stores row, col, and value (4 bytes each)\n        matrix_bytes = self._matrix.nnz * (4 + 4 + 4)\n        # Estimate dict memory: ~100 bytes per entry\n        dict_bytes = (len(self.entity_to_idx) + len(self.edge_to_idx) + len(self.edge_weights)) * 100\n\n        df_bytes = 0\n\n        # vertex attributes\n        if isinstance(self.vertex_attributes, pl.DataFrame):\n            # Polars provides a built-in estimate of total size in bytes\n            df_bytes += self.vertex_attributes.estimated_size()\n\n        # Edge attributes\n        if isinstance(self.edge_attributes, pl.DataFrame):\n            df_bytes += self.edge_attributes.estimated_size()\n\n        return matrix_bytes + dict_bytes + df_bytes\n\n    def get_vertex_incidence_matrix_as_lists(self, values: bool = False) -&gt; dict:\n        \"\"\"\n        Materialize the vertex\u2013edge incidence structure as Python lists.\n\n        Parameters\n        ----------\n        values : bool, optional (default=False)\n            - If `False`, returns edge indices incident to each vertex.\n            - If `True`, returns the **matrix values** (usually weights or 1/0) for\n            each incident edge instead of the indices.\n\n        Returns\n        -------\n        dict[str, list]\n            A mapping from `vertex_id` \u2192 list of incident edges (indices or values),\n            where:\n            - Keys are vertex IDs.\n            - Values are lists of edge indices (if `values=False`) or numeric values\n            from the incidence matrix (if `values=True`).\n\n        Notes\n        -----\n        - Internally uses the sparse incidence matrix `self._matrix`, which is stored\n        as a SciPy CSR (compressed sparse row) matrix or similar.\n        - The incidence matrix `M` is defined as:\n            - Rows: vertices\n            - Columns: edges\n            - Entry `M[i, j]` non-zero \u21e8 vertex `i` is incident to edge `j`.\n        - This is a convenient method when you want a native-Python structure for\n        downstream use (e.g., exporting, iterating, or visualization).\n        \"\"\"\n        result = {}\n        csr = self._matrix.tocsr()\n        for i in range(csr.shape[0]):\n            vertex_id = self.idx_to_entity[i]\n            row = csr.getrow(i)\n            if values:\n                result[vertex_id] = row.data.tolist()\n            else:\n                result[vertex_id] = row.indices.tolist()\n        return result\n\n    def vertex_incidence_matrix(self, values: bool = False, sparse: bool = False):\n        \"\"\"\n        Return the vertex\u2013edge incidence matrix in sparse or dense form.\n\n        Parameters\n        ----------\n        values : bool, optional (default=False)\n            If `True`, include the numeric values stored in the matrix\n            (e.g., weights or signed incidence values). If `False`, convert the\n            matrix to a binary mask (1 if incident, 0 if not).\n        sparse : bool, optional (default=False)\n            - If `True`, return the underlying sparse matrix (CSR).\n            - If `False`, return a dense NumPy ndarray.\n\n        Returns\n        -------\n        scipy.sparse.csr_matrix | numpy.ndarray\n            The vertex\u2013edge incidence matrix `M`:\n            - Rows correspond to vertices.\n            - Columns correspond to edges.\n            - `M[i, j]` \u2260 0 indicates that vertex `i` is incident to edge `j`.\n\n        Notes\n        -----\n        - If `values=False`, the returned matrix is binarized before returning.\n        - Use `sparse=True` for large graphs to avoid memory blowups.\n        - This is the canonical low-level structure that most algorithms (e.g.,\n        spectral clustering, Laplacian construction, hypergraph analytics) rely on.\n        \"\"\"\n        M = self._matrix.tocsr()\n\n        if not values:\n            # Convert to binary mask\n            M = M.copy()\n            M.data[:] = 1\n\n        if sparse:\n            return M\n        else:\n            return M.toarray()\n\n    def __hash__(self) -&gt; int:\n        \"\"\"\n        Return a stable hash representing the current graph structure and metadata.\n\n        Returns\n        -------\n        int\n            A hash value that uniquely (within high probability) identifies the graph\n            based on its topology and attributes.\n\n        Behavior\n        --------\n        - Includes the set of verices, edges, and directedness in the hash.\n        - Includes graph-level attributes (if any) to capture metadata changes.\n        - Does **not** depend on memory addresses or internal object IDs, so the same\n        graph serialized/deserialized or reconstructed with identical structure\n        will produce the same hash.\n\n        Notes\n        -----\n        - This method enables `Graph` objects to be used in hash-based containers\n        (like `set` or `dict` keys).\n        - If the graph is **mutated** after hashing (e.g., verices or edges are added\n        or removed), the hash will no longer reflect the new state.\n        - The method uses a deterministic representation: sorted vertex/edge sets\n        ensure that ordering does not affect the hash.\n        \"\"\"\n        # Core structural components\n        vertex_ids = tuple(sorted(self.verices()))\n        edge_defs = []\n\n        for j in range(self.number_of_edges()):\n            S, T = self.get_edge(j)\n            eid = self.idx_to_edge[j]\n            directed = self._is_directed_edge(eid)\n            edge_defs.append((eid, tuple(sorted(S)), tuple(sorted(T)), directed))\n\n        edge_defs = tuple(sorted(edge_defs))\n\n        # Include high-level metadata if available\n        graph_meta = tuple(sorted(self.graph_attributes.items())) if hasattr(self, \"graph_attributes\") else ()\n\n        return hash((vertex_ids, edge_defs, graph_meta))\n\n    # History and Timeline\n\n    def _utcnow_iso(self) -&gt; str:\n        return datetime.now(timezone.utc).isoformat(timespec=\"microseconds\").replace(\"+00:00\", \"Z\")\n\n    def _jsonify(self, x):\n        # Make args/return JSON-safe &amp; compact.\n        import numpy as np\n        if x is None or isinstance(x, (bool, int, float, str)):\n            return x\n        if isinstance(x, (set, frozenset)):\n            return sorted(self._jsonify(v) for v in x)\n        if isinstance(x, (list, tuple)):\n            return [self._jsonify(v) for v in x]\n        if isinstance(x, dict):\n            return {str(k): self._jsonify(v) for k, v in x.items()}\n        # NumPy scalars\n        if isinstance(x, (np.generic,)):\n            return x.item()\n        # Polars, SciPy, or other heavy objects -&gt; just a tag\n        t = type(x).__name__\n        return f\"&lt;&lt;{t}&gt;&gt;\"\n\n    def _log_event(self, op: str, **fields):\n        if not self._history_enabled:\n            return\n        self._version += 1\n        evt = {\n            \"version\": self._version,\n            \"ts_utc\": self._utcnow_iso(),                    # ISO-8601 with Z\n            \"mono_ns\": time.perf_counter_ns() - self._history_clock0,\n            \"op\": op,\n        }\n        # sanitize\n        for k, v in fields.items():\n            evt[k] = self._jsonify(v)\n        self._history.append(evt)\n\n    def _log_mutation(self, name=None):\n        def deco(fn):\n            op = name or fn.__name__\n            sig = inspect.signature(fn)\n            @wraps(fn)\n            def wrapper(*args, **kwargs):\n                bound = sig.bind(*args, **kwargs)\n                bound.apply_defaults()\n                result = fn(*args, **kwargs)\n                payload = {}\n                # record all call args except 'self'\n                for k, v in bound.arguments.items():\n                    if k != \"self\":\n                        payload[k] = v\n                payload[\"result\"] = result\n                self._log_event(op, **payload)\n                return result\n            return wrapper\n        return deco\n\n    def _install_history_hooks(self):\n        # Mutating methods to wrap. Add here if you add new mutators.\n        to_wrap = [\n            \"add_vertex\", \"add_edge_entity\", \"add_edge\", \"add_hyperedge\",\n            \"remove_edge\", \"remove_vertex\",\n            \"set_vertex_attrs\", \"set_edge_attrs\", \"set_layer_attrs\", \"set_edge_layer_attrs\",\n            \"register_layer\", \"unregister_layer\"\n        ]\n        for name in to_wrap:\n            if hasattr(self, name):\n                fn = getattr(self, name)\n                # Avoid double-wrapping\n                if getattr(fn, \"__wrapped__\", None) is None:\n                    setattr(self, name, self._log_mutation(name)(fn))\n\n    def history(self, as_df: bool = False):\n        \"\"\"\n        Return the append-only mutation history.\n\n        Parameters\n        ----------\n        as_df : bool, default False\n            If True, return a Polars DF [DataFrame]; otherwise return a list of dicts.\n\n        Returns\n        -------\n        list[dict] or polars.DataFrame\n            Each event includes: 'version', 'ts_utc' (UTC [Coordinated Universal Time]\n            ISO-8601 [International Organization for Standardization]), 'mono_ns'\n            (monotonic nanoseconds since logger start), 'op', call snapshot fields,\n            and 'result' when captured.\n\n        Notes\n        -----\n        Ordering is guaranteed by 'version' and 'mono_ns'. The log is in-memory until exported.\n        \"\"\"\n        return pl.DataFrame(self._history) if as_df else list(self._history)\n\n    def export_history(self, path: str):\n        \"\"\"\n        Write the mutation history to disk.\n\n        Parameters\n        ----------\n        path : str\n            Output path. Supported extensions: '.parquet', '.ndjson' (a.k.a. '.jsonl'),\n            '.json', '.csv'. Unknown extensions default to Parquet by appending '.parquet'.\n\n        Returns\n        -------\n        int\n            Number of events written. Returns 0 if the history is empty.\n\n        Raises\n        ------\n        OSError\n            If the file cannot be written.\n        \"\"\"\n        if not self._history:\n            return 0\n        df = pl.DataFrame(self._history)\n        p = path.lower()\n        if p.endswith(\".parquet\"):\n            df.write_parquet(path);  return len(df)\n        if p.endswith(\".ndjson\") or p.endswith(\".jsonl\"):\n            with open(path, \"w\", encoding=\"utf-8\") as f:\n                for r in df.iter_rows(named=True):\n                    import json\n                    f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n            return len(df)\n        if p.endswith(\".json\"):\n            import json\n            with open(path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(df.to_dicts(), f, ensure_ascii=False)\n            return len(df)\n        if p.endswith(\".csv\"):\n            df.write_csv(path); return len(df)\n        # Default to Parquet if unknown\n        df.write_parquet(path + \".parquet\"); return len(df)\n\n    def enable_history(self, flag: bool = True):\n        \"\"\"\n        Enable or disable in-memory mutation logging.\n\n        Parameters\n        ----------\n        flag : bool, default True\n            When True, start/continue logging; when False, pause logging.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self._history_enabled = bool(flag)\n\n    def clear_history(self):\n        \"\"\"\n        Clear the in-memory mutation log.\n\n        Returns\n        -------\n        None\n\n        Notes\n        -----\n        This does not delete any files previously exported.\n        \"\"\"\n        self._history.clear()\n\n    def mark(self, label: str):\n        \"\"\"\n        Insert a manual marker into the mutation history.\n\n        Parameters\n        ----------\n        label : str\n            Human-readable tag for the marker event.\n\n        Returns\n        -------\n        None\n\n        Notes\n        -----\n        The event is recorded with 'op'='mark' alongside standard fields\n        ('version', 'ts_utc', 'mono_ns'). Logging must be enabled for the\n        marker to be recorded.\n        \"\"\"\n        self._log_event(\"mark\", label=label)\n\n    # Lazy proxies\n    ## Lazy NX proxy\n\n    @property\n    def nx(self):\n        \"\"\"\n        Accessor for the lazy NX proxy.\n        Usage: G.nx.algorithm(); e.g: G.nx.louvain_communities(G), G.nx.shortest_path_length(G, weight=\"weight\")\n        \"\"\"\n        if not hasattr(self, \"_nx_proxy\"):\n            self._nx_proxy = self._LazyNXProxy(self)\n        return self._nx_proxy\n\n    class _LazyNXProxy:\n        \"\"\"\n        Lazy, cached NX (NetworkX) adapter:\n          - On-demand backend conversion (no persistent NX graph).\n          - Cache keyed by options until Graph._version changes.\n          - Selective edge attr exposure (weight/capacity only when needed).\n          - Clear warnings when conversion is lossy.\n          - Auto label\u2192ID mapping for node arguments (kwargs + positionals).\n          - NEW: _nx_simple to collapse Multi* \u2192 simple Graph/DiGraph for algos that need it.\n          - NEW: _nx_edge_aggs to control parallel-edge aggregation (e.g., {\"capacity\":\"sum\"}).\n        \"\"\"\n\n        # ------------------------------ init -----------------------------------\n        def __init__(self, owner: \"Graph\"):\n            self._G = owner\n            self._cache = {}  # key -&gt; {\"nxG\": nx.Graph, \"version\": int}\n            self.cache_enabled = True\n\n        # ---------------------------- public API --------------------------------\n        def clear(self):\n            \"\"\"Drop all cached NX graphs.\"\"\"\n            self._cache.clear()\n\n        def peek_nodes(self, k: int = 10):\n            \"\"\"Debug helper: return up to k node IDs visible to NX.\"\"\"\n            nxG = self._get_or_make_nx(\n                directed=True, hyperedge_mode=\"expand\", layer=None, layers=None, needed_attrs=set(),\n                simple=False, edge_aggs=None\n            )\n            out = []\n            it = iter(nxG.nodes())\n            for _ in range(max(0, int(k))):\n                try:\n                    out.append(next(it))\n                except StopIteration:\n                    break\n            return out\n\n        # ------------------------- dynamic dispatch -----------------------------\n                # Public helper: obtain the cached/backend NX graph directly\n        # Usage in tests: nxG = G.nx.backend(directed=False, simple=True)\n        def backend(\n            self,\n            *,\n            directed: bool = True,\n            hyperedge_mode: str = \"expand\",\n            layer=None,\n            layers=None,\n            needed_attrs=None,\n            simple: bool = False,\n            edge_aggs: dict | None = None,\n        ):\n            \"\"\"\n            Return the underlying NetworkX graph built with the same lazy/cached\n            machinery as normal calls.\n\n            Args:\n              directed: build DiGraph (True) or Graph (False) view\n              hyperedge_mode: \"skip\" | \"expand\"\n              layer/layers: layer selection if your Graph is multilayered\n              needed_attrs: set of edge attribute names to keep (default empty)\n              simple: if True, collapse Multi* -&gt; simple (Di)Graph\n              edge_aggs: how to aggregate parallel edge attrs when simple=True,\n                         e.g. {\"capacity\": \"sum\", \"weight\": \"min\"} or callables\n            \"\"\"\n            if needed_attrs is None:\n                needed_attrs = set()\n            return self._get_or_make_nx(\n                directed=directed,\n                hyperedge_mode=hyperedge_mode,\n                layer=layer,\n                layers=layers,\n                needed_attrs=needed_attrs,\n                simple=simple,\n                edge_aggs=edge_aggs,\n            )\n\n        def __getattr__(self, name: str):\n            nx_callable = self._resolve_nx_callable(name)\n\n            def wrapper(*args, **kwargs):\n                import inspect\n                import networkx as _nx\n\n                # Proxy-only knobs (consumed here; not forwarded to NX)\n                directed = bool(kwargs.pop(\"_nx_directed\", getattr(self, \"default_directed\", True)))\n                hyperedge_mode = kwargs.pop(\"_nx_hyperedge\", getattr(self, \"default_hyperedge_mode\", \"expand\"))  # \"skip\" | \"expand\"\n                layer = kwargs.pop(\"_nx_layer\", None)\n                layers = kwargs.pop(\"_nx_layers\", None)\n                label_field = kwargs.pop(\"_nx_label_field\", None)      # explicit label column\n                guess_labels = kwargs.pop(\"_nx_guess_labels\", True)    # try auto-infer when not provided\n\n                # force simple Graph/DiGraph and aggregation policy for parallel edges\n                simple = bool(kwargs.pop(\"_nx_simple\", getattr(self, \"default_simple\", False)))\n                edge_aggs = kwargs.pop(\"_nx_edge_aggs\", None)  # e.g. {\"weight\":\"min\",\"capacity\":\"sum\"} or callables\n\n                # Determine required edge attributes (keep graph skinny)\n                needed_edge_attrs = self._needed_edge_attrs(nx_callable, kwargs)\n\n                # Do NOT auto-inject G. Only convert/replace if the user passed our Graph.\n                args = list(args)\n                has_owner_graph = any(a is self._G for a in args) or any(v is self._G for v in kwargs.values())\n\n                # Build backend ONLY if we actually need to replace self._G\n                nxG = None\n                if has_owner_graph:\n                    nxG = self._get_or_make_nx(\n                        directed=directed,\n                        hyperedge_mode=hyperedge_mode,\n                        layer=layer,\n                        layers=layers,\n                        needed_attrs=needed_edge_attrs,\n                        simple=simple,\n                        edge_aggs=edge_aggs,\n                    )\n\n\n                # Replace any occurrence of our Graph with the NX backend\n                if nxG is not None:\n                    for i, v in enumerate(args):\n                        if v is self._G:\n                            args[i] = nxG\n                    for k, v in list(kwargs.items()):\n                        if v is self._G:\n                            kwargs[k] = nxG\n\n                # Bind to NX signature so we can coerce node args (no defaults!)\n                bound = None\n                try:\n                    sig = inspect.signature(nx_callable)\n                    bound = sig.bind_partial(*args, **kwargs)\n                except Exception:\n                    pass\n\n                # Coerce node args (labels/indices -&gt; vertex IDs)\n                try:\n                    # Determine default label field if not given\n                    if label_field is None and guess_labels:\n                        label_field = self._infer_label_field()\n\n                    if bound is not None and nxG is not None:\n                        self._coerce_nodes_in_bound(bound, nxG, label_field)\n                        # Reconstruct WITHOUT applying defaults (avoid flow_func=None, etc.)\n                        pargs = bound.args\n                        pkwargs = bound.kwargs\n                    else:\n                        # Fallback: best-effort coercion on kwargs only\n                        if nxG is not None:\n                            self._coerce_nodes_in_kwargs(kwargs, nxG, label_field)\n                        pargs, pkwargs = tuple(args), kwargs\n                except Exception:\n                    pargs, pkwargs = tuple(args), kwargs  # best effort; let NX raise if needed\n\n                # Never leak private knobs to NX\n                for k in list(pkwargs.keys()):\n                    if isinstance(k, str) and k.startswith(\"_nx_\"):\n                        pkwargs.pop(k, None)\n\n                try:\n                    return nx_callable(*pargs, **pkwargs)\n                except _nx.NodeNotFound as e:\n                    # Add actionable tip that actually tells how to fix it now.\n                    sample = self.peek_nodes(5)\n                    tip = (\n                        f\"{e}. Nodes must be your graph's vertex IDs.\\n\"\n                        f\"- If you passed labels, specify _nx_label_field=&lt;vertex label column&gt; \"\n                        f\"or rely on auto-guess (columns like 'name'/'label'/'title').\\n\"\n                        f\"- Example: G.nx.shortest_path_length(G, source='a', target='z', weight='weight', _nx_label_field='name')\\n\"\n                        f\"- A few node IDs NX sees: {sample}\"\n                    )\n                    raise _nx.NodeNotFound(tip) from e\n\n            return wrapper\n\n        # ------------------------------ internals -------------------------------\n        def _resolve_nx_callable(self, name: str):\n            import networkx as _nx\n            candidates = [\n                _nx,\n                getattr(_nx, \"algorithms\", None),\n                getattr(_nx.algorithms, \"community\", None) if hasattr(_nx, \"algorithms\") else None,\n                getattr(_nx.algorithms, \"approximation\", None) if hasattr(_nx, \"algorithms\") else None,\n                getattr(_nx.algorithms, \"centrality\", None) if hasattr(_nx, \"algorithms\") else None,\n                getattr(_nx.algorithms, \"shortest_paths\", None) if hasattr(_nx, \"algorithms\") else None,\n                getattr(_nx.algorithms, \"flow\", None) if hasattr(_nx, \"algorithms\") else None,\n                getattr(_nx.algorithms, \"components\", None) if hasattr(_nx, \"algorithms\") else None,\n                getattr(_nx.algorithms, \"traversal\", None) if hasattr(_nx, \"algorithms\") else None,\n                getattr(_nx.algorithms, \"bipartite\", None) if hasattr(_nx, \"algorithms\") else None,\n                getattr(_nx.algorithms, \"link_analysis\", None) if hasattr(_nx, \"algorithms\") else None,\n                getattr(_nx, \"classes\", None),\n                getattr(_nx.classes, \"function\", None) if hasattr(_nx, \"classes\") else None,\n            ]\n            for mod in (m for m in candidates if m is not None):\n                attr = getattr(mod, name, None)\n                if callable(attr):\n                    return attr\n            raise AttributeError(f\"networkx has no callable '{name}'\")\n\n        def _needed_edge_attrs(self, target, kwargs) -&gt; set:\n            import inspect\n            needed = set()\n            # weight\n            w_name = kwargs.get(\"weight\", \"weight\")\n            try:\n                sig = inspect.signature(target)\n                if \"weight\" in sig.parameters and w_name is not None:\n                    needed.add(str(w_name))\n            except Exception:\n                if \"weight\" in kwargs and w_name is not None:\n                    needed.add(str(w_name))\n            # capacity (flows)\n            c_name = kwargs.get(\"capacity\", \"capacity\")\n            try:\n                sig = inspect.signature(target)\n                if \"capacity\" in sig.parameters and c_name is not None:\n                    needed.add(str(c_name))\n            except Exception:\n                if \"capacity\" in kwargs and c_name is not None:\n                    needed.add(str(c_name))\n            return needed\n\n        def _convert_to_nx(self, *, directed: bool, hyperedge_mode: str, layer, layers,\n                           needed_attrs: set, simple: bool, edge_aggs: dict | None):\n            from ..adapters import networkx_adapter as _gg_nx  # graphglue.adapters.networkx_adapter\n            import networkx as _nx\n\n            nxG, manifest = _gg_nx.to_nx(\n                self._G,\n                directed=directed,\n                hyperedge_mode=hyperedge_mode,\n                layer=layer,\n                layers=layers,\n                public_only=True,\n            )\n            # Keep only needed edge attrs\n            if needed_attrs:\n                for _, _, _, d in nxG.edges(keys=True, data=True):\n                    for k in list(d.keys()):\n                        if k not in needed_attrs:\n                            d.pop(k, None)\n            else:\n                for _, _, _, d in nxG.edges(keys=True, data=True):\n                    d.clear()\n\n            # Collapse Multi* \u2192 simple Graph/DiGraph if requested\n            if simple and nxG.is_multigraph():\n                nxG = self._collapse_multiedges(nxG, directed=directed,\n                                                aggregations=edge_aggs, needed_attrs=needed_attrs)\n\n            self._warn_on_loss(hyperedge_mode=hyperedge_mode, layer=layer, layers=layers, manifest=manifest)\n            return nxG\n\n        def _get_or_make_nx(self, *, directed: bool, hyperedge_mode: str, layer, layers,\n                            needed_attrs: set, simple: bool, edge_aggs: dict | None):\n            key = (\n                bool(directed),\n                str(hyperedge_mode),\n                tuple(sorted(layers)) if layers else None,\n                str(layer) if layer is not None else None,\n                tuple(sorted(needed_attrs)) if needed_attrs else (),\n                bool(simple),\n                tuple(sorted(edge_aggs.items())) if isinstance(edge_aggs, dict) else None,\n            )\n            version = getattr(self._G, \"_version\", None)\n            entry = self._cache.get(key)\n            if (not self.cache_enabled) or (entry is None) or (version is not None and entry.get(\"version\") != version):\n                nxG = self._convert_to_nx(\n                    directed=directed,\n                    hyperedge_mode=hyperedge_mode,\n                    layer=layer,\n                    layers=layers,\n                    needed_attrs=needed_attrs,\n                    simple=simple,\n                    edge_aggs=edge_aggs,\n                )\n                if self.cache_enabled:\n                    self._cache[key] = {\"nxG\": nxG, \"version\": version}\n                return nxG\n            return entry[\"nxG\"]\n\n        def _warn_on_loss(self, *, hyperedge_mode, layer, layers, manifest):\n            import warnings\n            has_hyper = False\n            try:\n                ek = getattr(self._G, \"edge_kind\", {})  # dict[eid] -&gt; \"hyper\"/\"binary\"\n                if hasattr(ek, \"values\"):\n                    has_hyper = any(str(v).lower() == \"hyper\" for v in ek.values())\n            except Exception:\n                pass\n            msgs = []\n            if has_hyper and hyperedge_mode != \"expand\":\n                msgs.append(\"hyperedges dropped (hyperedge_mode='skip')\")\n            try:\n                layers_dict = getattr(self._G, \"_layers\", None)\n                if isinstance(layers_dict, dict) and len(layers_dict) &gt; 1 and (layer is None and not layers):\n                    msgs.append(\"multiple layers flattened into single NX graph\")\n            except Exception:\n                pass\n            if manifest is None:\n                msgs.append(\"no manifest provided; round-trip fidelity not guaranteed\")\n            if msgs:\n                warnings.warn(\n                    \"Graph\u2192NX conversion is lossy: \" + \"; \".join(msgs) + \".\",\n                    category=RuntimeWarning,\n                    stacklevel=3,\n                )\n\n        # ---------------------- label/ID mapping helpers ------------------------\n        def _infer_label_field(self) -&gt; str | None:\n            \"\"\"\n            Heuristic label column if user didn't specify:\n              1) Graph.default_label_field if present\n              2) first present in [\"name\",\"label\",\"title\",\"slug\",\"external_id\",\"string_id\"]\n            \"\"\"\n            try:\n                if hasattr(self._G, \"default_label_field\") and self._G.default_label_field:\n                    return self._G.default_label_field\n                va = getattr(self._G, \"vertex_attributes\", None)\n                cols = list(va.columns) if va is not None and hasattr(va, \"columns\") else []\n                for c in (\"name\", \"label\", \"title\", \"slug\", \"external_id\", \"string_id\"):\n                    if c in cols:\n                        return c\n            except Exception:\n                pass\n            return None\n\n        def _vertex_id_col(self) -&gt; str:\n            \"\"\"Best-effort to determine the vertex ID column name in vertex_attributes.\"\"\"\n            try:\n                va = self._G.vertex_attributes\n                cols = list(va.columns)\n                for k in (\"vertex_id\", \"id\", \"vid\"):\n                    if k in cols:\n                        return k\n            except Exception:\n                pass\n            return \"vertex_id\"\n\n        def _lookup_vertex_id_by_label(self, label_field: str, val):\n            \"\"\"Return vertex_id where vertex_attributes[label_field] == val, else None.\"\"\"\n            try:\n                va = self._G.vertex_attributes\n                if va is None or not hasattr(va, \"columns\") or label_field not in va.columns:\n                    return None\n                id_col = self._vertex_id_col()\n                # Prefer polars path\n                try:\n                    import polars as pl  # type: ignore\n                    matches = va.filter(pl.col(label_field) == val)\n                    if matches.height == 0:\n                        return None\n                    try:\n                        return matches.select(id_col).to_series().to_list()[0]\n                    except Exception:\n                        return matches.select(id_col).item(0, 0)\n                except Exception:\n                    # Fallback: convert to dicts (slower; fine for ad-hoc lookups)\n                    for row in va.to_dicts():\n                        if row.get(label_field) == val:\n                            return row.get(id_col)\n            except Exception:\n                return None\n            return None\n\n        def _coerce_node_id(self, x, nxG, label_field: str | None):\n            # If already a node ID present in the backend, keep it.\n            if x in nxG:\n                return x\n            # Internal index \u2192 vertex_id\n            try:\n                if isinstance(x, int) and x in getattr(self._G, \"idx_to_entity\", {}):\n                    cand = self._G.idx_to_entity[x]\n                    if getattr(self._G, \"entity_types\", {}).get(cand) == \"vertex\":\n                        return cand\n            except Exception:\n                pass\n            # Label mapping\n            if label_field:\n                cand = self._lookup_vertex_id_by_label(label_field, x)\n                if cand is not None:\n                    return cand\n            return x  # let NX decide (will raise NodeNotFound if still absent)\n\n        def _coerce_node_or_iter(self, obj, nxG, label_field: str | None):\n            if isinstance(obj, (list, tuple, set)):\n                coerced = [self._coerce_node_id(v, nxG, label_field) for v in obj]\n                return type(obj)(coerced) if not isinstance(obj, set) else set(coerced)\n            return self._coerce_node_id(obj, nxG, label_field)\n\n        def _coerce_nodes_in_kwargs(self, kwargs: dict, nxG, label_field: str | None):\n            node_keys = {\"source\", \"target\", \"u\", \"v\", \"node\", \"nodes\", \"nbunch\", \"center\", \"path\"}\n            for key in list(kwargs.keys()):\n                if key in node_keys:\n                    kwargs[key] = self._coerce_node_or_iter(kwargs[key], nxG, label_field)\n\n        def _coerce_nodes_in_bound(self, bound, nxG, label_field: str | None):\n            \"\"\"Coerce nodes in a BoundArguments object using common node parameter names.\"\"\"\n            node_keys = {\"source\", \"target\", \"u\", \"v\", \"node\", \"nodes\", \"nbunch\", \"center\", \"path\"}\n            for key in list(bound.arguments.keys()):\n                if key in node_keys:\n                    bound.arguments[key] = self._coerce_node_or_iter(bound.arguments[key], nxG, label_field)\n\n        # ---------------------- Multi* collapse helpers -------------------------\n        def _collapse_multiedges(self, nxG, *, directed: bool,\n                                 aggregations: dict | None, needed_attrs: set):\n            \"\"\"\n            Collapse parallel edges into a single edge with aggregated attributes.\n            Defaults: weight -&gt; min (good for shortest paths), capacity -&gt; sum (good for max-flow).\n            \"\"\"\n            import networkx as _nx\n            H = _nx.DiGraph() if directed else _nx.Graph()\n            H.add_nodes_from(nxG.nodes(data=True))\n\n            aggregations = aggregations or {}\n\n            def _agg_for(key):\n                agg = aggregations.get(key)\n                if callable(agg):\n                    return agg\n                if agg == \"sum\":\n                    return sum\n                if agg == \"min\":\n                    return min\n                if agg == \"max\":\n                    return max\n                # sensible defaults:\n                if key == \"capacity\":\n                    return sum\n                if key == \"weight\":\n                    return min\n                # fallback: first value\n                return lambda vals: next(iter(vals))\n\n            # Bucket parallel edges\n            bucket = {}  # (u,v) or sorted(u,v) -&gt; {attr: [values]}\n            for u, v, _, d in nxG.edges(keys=True, data=True):\n                key = (u, v) if directed else tuple(sorted((u, v)))\n                entry = bucket.setdefault(key, {})\n                for k, val in d.items():\n                    if needed_attrs and k not in needed_attrs:\n                        continue\n                    entry.setdefault(k, []).append(val)\n\n            # Aggregate per (u,v)\n            for (u, v), attrs in bucket.items():\n                out = {k: _agg_for(k)(vals) for k, vals in attrs.items()}\n                H.add_edge(u, v, **out)\n\n            return H\n\n    ## Lazy igraph proxy\n\n    @property\n    def ig(self):\n        \"\"\"\n        Accessor for the lazy igraph proxy.\n        Usage: G.ig.community_multilevel(G, weights=\"weight\"), G.ig.shortest_paths_dijkstra(G, source=\"a\", target=\"z\", weights=\"weight\")\n        (same idea as NX: pass G; proxy swaps it with the backend igraph.Graph lazily)\n        \"\"\"\n        if not hasattr(self, \"_ig_proxy\"):\n            self._ig_proxy = self._LazyIGProxy(self)\n        return self._ig_proxy\n\n    class _LazyIGProxy:\n\n        \"\"\"\n        Lazy, cached igraph adapter:\n          - On-demand backend conversion (no persistent igraph graph).\n          - Cache keyed by options until Graph._version changes.\n          - Selective edge-attr exposure (keep only needed weights/capacity).\n          - Clear warnings when conversion is lossy.\n          - Auto label\u2192ID mapping for node args (kwargs + positionals).\n          - _ig_simple=True collapses parallel edges to simple (Di)Graph.\n          - _ig_edge_aggs={\"weight\":\"min\",\"capacity\":\"sum\"} for parallel-edge aggregation.\n        \"\"\"\n\n        def __init__(self, owner: \"Graph\"):\n            self._G = owner\n            self._cache = {}   # key -&gt; {\"igG\": ig.Graph, \"version\": int}\n            self.cache_enabled = True\n\n        # ---------------------------- public API --------------------------------\n        def clear(self):\n            self._cache.clear()\n\n        def peek_vertices(self, k: int = 10):\n            igG = self._get_or_make_ig(directed=True, hyperedge_mode=\"skip\",\n                                       layer=None, layers=None, needed_attrs=set(),\n                                       simple=True, edge_aggs=None)\n            out = []\n            names = igG.vs[\"name\"] if \"name\" in igG.vs.attributes() else None\n            for i in range(min(max(0, int(k)), igG.vcount())):\n                out.append(names[i] if names else i)\n            return out\n\n        # public helper so tests don\u2019t touch private API\n        def backend(self, *,\n                    directed: bool = True,\n                    hyperedge_mode: str = \"skip\",\n                    layer=None,\n                    layers=None,\n                    needed_attrs=None,\n                    simple: bool = False,\n                    edge_aggs: dict | None = None):\n            needed_attrs = needed_attrs or set()\n            return self._get_or_make_ig(directed=directed, hyperedge_mode=hyperedge_mode,\n                                        layer=layer, layers=layers, needed_attrs=needed_attrs,\n                                        simple=simple, edge_aggs=edge_aggs)\n\n        # ------------------------- dynamic dispatch -----------------------------\n        def __getattr__(self, name: str):\n            def wrapper(*args, **kwargs):\n                import inspect\n                import igraph as _ig\n\n                # proxy-only knobs (consumed here)\n                directed = bool(kwargs.pop(\"_ig_directed\", True))\n                hyperedge_mode = kwargs.pop(\"_ig_hyperedge\", \"skip\")  # \"skip\" | \"expand\"\n                layer = kwargs.pop(\"_ig_layer\", None)\n                layers = kwargs.pop(\"_ig_layers\", None)\n                label_field = kwargs.pop(\"_ig_label_field\", None)\n                guess_labels = kwargs.pop(\"_ig_guess_labels\", True)\n                simple = bool(kwargs.pop(\"_ig_simple\", False))\n                edge_aggs = kwargs.pop(\"_ig_edge_aggs\", None)  # {\"weight\":\"min\",\"capacity\":\"sum\"} or callables\n\n                # keep only attributes actually needed by the called function\n                needed_edge_attrs = self._needed_edge_attrs_for_ig(name, kwargs)\n\n                # build/reuse backend\n                igG = self._get_or_make_ig(directed=directed, hyperedge_mode=hyperedge_mode,\n                                           layer=layer, layers=layers, needed_attrs=needed_edge_attrs,\n                                           simple=simple, edge_aggs=edge_aggs)\n\n                # replace any Graph instance with igG\n                args = list(args)\n                for i, v in enumerate(args):\n                    if v is self._G:\n                        args[i] = igG\n                for k, v in list(kwargs.items()):\n                    if v is self._G:\n                        kwargs[k] = igG\n\n                # resolve target callable: prefer bound Graph method, else module-level\n                target = getattr(igG, name, None)\n                if not callable(target):\n                    target = getattr(_ig, name, None)\n                if not callable(target):\n                    raise AttributeError(f\"igraph has no callable '{name}'. \"\n                                         f\"Use native igraph names, e.g. community_multilevel, pagerank, shortest_paths_dijkstra, components, etc.\")\n\n                # bind to signature (best effort) so we can coerce node args\n                try:\n                    sig = inspect.signature(target)\n                    bound = sig.bind_partial(*args, **kwargs)\n                except Exception:\n                    bound = None\n\n                try:\n                    if label_field is None and guess_labels:\n                        label_field = self._infer_label_field()\n\n                    if bound is not None:\n                        self._coerce_nodes_in_bound(bound, igG, label_field)\n                        bound.apply_defaults()\n                        pargs, pkwargs = list(bound.args), dict(bound.kwargs)\n                    else:\n                        self._coerce_nodes_in_kwargs(kwargs, igG, label_field)\n                        pargs, pkwargs = list(args), dict(kwargs)\n                except Exception:\n                    pargs, pkwargs = list(args), dict(kwargs)  # let igraph raise if invalid\n\n                try:\n                    return target(*pargs, **pkwargs)\n                except (KeyError, ValueError) as e:\n                    sample = self.peek_vertices(5)\n                    tip = (\n                        f\"{e}. Vertices must match this graph's vertex IDs.\\n\"\n                        f\"- If you passed labels, set _ig_label_field=&lt;vertex label column&gt; \"\n                        f\"or rely on auto-guess ('name'/'label'/'title').\\n\"\n                        f\"- Example: G.ig.shortest_paths_dijkstra(G, source='a', target='z', weights='weight', _ig_label_field='name')\\n\"\n                        f\"- A few vertex IDs igraph sees: {sample}\"\n                    )\n                    raise type(e)(tip) from e\n\n            return wrapper\n\n        # ------------------------------ internals -------------------------------\n        def _needed_edge_attrs_for_ig(self, func_name: str, kwargs: dict) -&gt; set:\n            \"\"\"\n            Heuristic: igraph uses `weights` (plural) for edge weights in most algos,\n            some accept both; flows use 'capacity' if you forward them to adapters.\n            \"\"\"\n            needed = set()\n            # weight(s)\n            w = kwargs.get(\"weights\", kwargs.get(\"weight\", None))\n            if w is None:\n                # sometimes user passes True to mean default \"weight\"\n                if \"weights\" in kwargs and kwargs[\"weights\"] is not None:\n                    needed.add(str(kwargs[\"weights\"]))\n            else:\n                needed.add(str(w))\n            # capacity (if you forward flow-like algos to ig backends)\n            if \"capacity\" in kwargs and kwargs[\"capacity\"] is not None:\n                needed.add(str(kwargs[\"capacity\"]))\n            return needed\n\n        def _convert_to_ig(self, *, directed: bool, hyperedge_mode: str, layer, layers,\n                           needed_attrs: set, simple: bool, edge_aggs: dict | None):\n            # try both adapter entry points: to_ig / to_igraph\n            from ..adapters import igraph_adapter as _gg_ig  # graphglue.adapters.igraph_adapter\n            import igraph as _ig\n\n            conv = None\n            for cand in (\"to_ig\", \"to_igraph\"):\n                conv = getattr(_gg_ig, cand, None) or conv\n            if conv is None:\n                raise RuntimeError(\"igraph adapter missing: expected adapters.igraph_adapter.to_ig(...) or .to_igraph(...).\")\n\n            igG, manifest = conv(\n                self._G,\n                directed=directed,\n                hyperedge_mode=hyperedge_mode,\n                layer=layer,\n                layers=layers,\n                public_only=True,\n            )\n\n            # keep only requested edge attrs (or none at all)\n            igG = self._prune_edge_attributes(igG, needed_attrs)\n\n            # igraph lacks is_multigraph(); always collapse when simple=True\n            if simple:\n                igG = self._collapse_multiedges(igG, directed=directed,\n                                                aggregations=edge_aggs, needed_attrs=needed_attrs)\n\n\n            self._warn_on_loss(hyperedge_mode=hyperedge_mode, layer=layer, layers=layers, manifest=manifest)\n            return igG\n\n        def _get_or_make_ig(self, *, directed: bool, hyperedge_mode: str, layer, layers,\n                            needed_attrs: set, simple: bool, edge_aggs: dict | None):\n            key = (\n                bool(directed),\n                str(hyperedge_mode),\n                tuple(sorted(layers)) if layers else None,\n                str(layer) if layer is not None else None,\n                tuple(sorted(needed_attrs)) if needed_attrs else (),\n                bool(simple),\n                tuple(sorted(edge_aggs.items())) if isinstance(edge_aggs, dict) else None,\n            )\n            version = getattr(self._G, \"_version\", None)\n            entry = self._cache.get(key)\n            if (not self.cache_enabled) or (entry is None) or (version is not None and entry.get(\"version\") != version):\n                igG = self._convert_to_ig(\n                    directed=directed,\n                    hyperedge_mode=hyperedge_mode,\n                    layer=layer,\n                    layers=layers,\n                    needed_attrs=needed_attrs,\n                    simple=simple,\n                    edge_aggs=edge_aggs,\n                )\n                if self.cache_enabled:\n                    self._cache[key] = {\"igG\": igG, \"version\": version}\n                return igG\n            return entry[\"igG\"]\n\n        def _warn_on_loss(self, *, hyperedge_mode, layer, layers, manifest):\n            import warnings\n            has_hyper = False\n            try:\n                ek = getattr(self._G, \"edge_kind\", {})\n                if hasattr(ek, \"values\"):\n                    has_hyper = any(str(v).lower() == \"hyper\" for v in ek.values())\n            except Exception:\n                pass\n            msgs = []\n            if has_hyper and hyperedge_mode != \"expand\":\n                msgs.append(\"hyperedges dropped (hyperedge_mode='skip')\")\n            try:\n                layers_dict = getattr(self._G, \"_layers\", None)\n                if isinstance(layers_dict, dict) and len(layers_dict) &gt; 1 and (layer is None and not layers):\n                    msgs.append(\"multiple layers flattened into single igraph graph\")\n            except Exception:\n                pass\n            if manifest is None:\n                msgs.append(\"no manifest provided; round-trip fidelity not guaranteed\")\n            if msgs:\n                warnings.warn(\n                    \"Graph\u2192igraph conversion is lossy: \" + \"; \".join(msgs) + \".\",\n                    category=RuntimeWarning,\n                    stacklevel=3,\n                )\n\n        # ---------------------- label/ID mapping helpers ------------------------\n        def _infer_label_field(self) -&gt; str | None:\n            try:\n                if hasattr(self._G, \"default_label_field\") and self._G.default_label_field:\n                    return self._G.default_label_field\n                va = getattr(self._G, \"vertex_attributes\", None)\n                cols = list(va.columns) if va is not None and hasattr(va, \"columns\") else []\n                for c in (\"name\", \"label\", \"title\", \"slug\", \"external_id\", \"string_id\"):\n                    if c in cols:\n                        return c\n            except Exception:\n                pass\n            return None\n\n        def _vertex_id_col(self) -&gt; str:\n            try:\n                va = self._G.vertex_attributes\n                cols = list(va.columns)\n                for k in (\"vertex_id\", \"id\", \"vid\"):\n                    if k in cols:\n                        return k\n            except Exception:\n                pass\n            return \"vertex_id\"\n\n        def _lookup_vertex_id_by_label(self, label_field: str, val):\n            try:\n                va = self._G.vertex_attributes\n                if va is None or not hasattr(va, \"columns\") or label_field not in va.columns:\n                    return None\n                id_col = self._vertex_id_col()\n                try:\n                    import polars as pl  # type: ignore\n                    matches = va.filter(pl.col(label_field) == val)\n                    if matches.height == 0:\n                        return None\n                    try:\n                        return matches.select(id_col).to_series().to_list()[0]\n                    except Exception:\n                        return matches.select(id_col).item(0, 0)\n                except Exception:\n                    for row in va.to_dicts():\n                        if row.get(label_field) == val:\n                            return row.get(id_col)\n            except Exception:\n                return None\n            return None\n\n        def _name_to_index_map(self, igG):\n            names = igG.vs[\"name\"] if \"name\" in igG.vs.attributes() else None\n            return {n: i for i, n in enumerate(names)} if names is not None else {}\n\n        def _coerce_vertex(self, x, igG, label_field: str | None):\n            # already an index?\n            if isinstance(x, int) and 0 &lt;= x &lt; igG.vcount():\n                return x\n            # graph-level mapping (label -&gt; vertex_id)\n            if label_field:\n                cand = self._lookup_vertex_id_by_label(label_field, x)\n                if cand is not None:\n                    x = cand\n            # igraph name -&gt; index\n            name_to_idx = self._name_to_index_map(igG)\n            if x in name_to_idx:\n                return name_to_idx[x]\n            # if user already passed internal vertex_id string, try treating it as name\n            if isinstance(x, str) and x in name_to_idx:\n                return name_to_idx[x]\n            return x  # let igraph validate/raise\n\n        def _coerce_node_or_iter(self, obj, igG, label_field: str | None):\n            if isinstance(obj, (list, tuple, set)):\n                coerced = [self._coerce_vertex(v, igG, label_field) for v in obj]\n                return type(obj)(coerced) if not isinstance(obj, set) else set(coerced)\n            return self._coerce_vertex(obj, igG, label_field)\n\n        def _coerce_nodes_in_kwargs(self, kwargs: dict, igG, label_field: str | None):\n            node_keys = {\n                \"source\", \"target\", \"u\", \"v\", \"vertex\", \"vertices\", \"vs\", \"to\", \"fr\",\n                \"root\", \"roots\", \"neighbors\", \"nbunch\", \"path\", \"cut\",\n            }\n            for key in list(kwargs.keys()):\n                if key in node_keys:\n                    kwargs[key] = self._coerce_node_or_iter(kwargs[key], igG, label_field)\n\n        def _coerce_nodes_in_bound(self, bound, igG, label_field: str | None):\n            node_keys = {\n                \"source\", \"target\", \"u\", \"v\", \"vertex\", \"vertices\", \"vs\", \"to\", \"fr\",\n                \"root\", \"roots\", \"neighbors\", \"nbunch\", \"path\", \"cut\",\n            }\n            for key in list(bound.arguments.keys()):\n                if key in node_keys:\n                    bound.arguments[key] = self._coerce_node_or_iter(bound.arguments[key], igG, label_field)\n\n        # ---------------------- edge-attr &amp; multiedge helpers -------------------\n        def _prune_edge_attributes(self, igG, needed_attrs: set):\n            import igraph as _ig\n            if not needed_attrs:\n                # keep only 'name' on vertices, drop all edge attrs quickly by rebuild\n                H = _ig.Graph(directed=igG.is_directed())\n                H.add_vertices(igG.vcount())\n                if \"name\" in igG.vs.attributes():\n                    H.vs[\"name\"] = igG.vs[\"name\"]\n                H.add_edges([e.tuple for e in igG.es])\n                return H\n            # keep only specific attrs\n            H = _ig.Graph(directed=igG.is_directed())\n            H.add_vertices(igG.vcount())\n            if \"name\" in igG.vs.attributes():\n                H.vs[\"name\"] = igG.vs[\"name\"]\n            edges = [e.tuple for e in igG.es]\n            H.add_edges(edges)\n            have = set(igG.es.attributes())\n            for k in needed_attrs:\n                if k in have:\n                    H.es[k] = igG.es[k]\n            return H\n\n        def _collapse_multiedges(self, igG, *, directed: bool,\n\n                                 aggregations: dict | None, needed_attrs: set):\n            import igraph as _ig\n            H = _ig.Graph(directed=directed)\n            H.add_vertices(igG.vcount())\n            if \"name\" in igG.vs.attributes():\n                H.vs[\"name\"] = igG.vs[\"name\"]\n\n            aggregations = aggregations or {}\n            def _agg_for(key):\n                agg = aggregations.get(key)\n                if callable(agg):\n                    return agg\n                if agg == \"sum\": return sum\n                if agg == \"min\": return min\n                if agg == \"max\": return max\n                if agg == \"mean\": \n                    return lambda vals: (sum(vals) / len(vals)) if vals else None\n                if key == \"capacity\": return sum\n                if key == \"weight\": return min\n                return lambda vals: next(iter(vals)) if vals else None\n\n            # bucket edges\n            buckets = {}  # (u,v) or sorted(u,v) -&gt; {attr: [vals]}\n            for e in igG.es:\n                u, v = e.tuple\n                key = (u, v) if directed else tuple(sorted((u, v)))\n                entry = buckets.setdefault(key, {})\n                for k, val in e.attributes().items():\n                    if needed_attrs and k not in needed_attrs:\n                        continue\n                    entry.setdefault(k, []).append(val)\n\n            edges = list(buckets.keys())\n            H.add_edges(edges)\n            # aggregate per attribute\n            all_attrs = set(k for _, attrs in buckets.items() for k in attrs.keys())\n            for k in all_attrs:\n                agg = _agg_for(k)\n                H.es[k] = [agg(buckets[edge].get(k, [])) for edge in edges]\n            return H\n\n    # For SBML Stoechiometry\n\n    def set_hyperedge_coeffs(self, edge_id: str, coeffs: dict[str, float]) -&gt; None:\n        \"\"\"Write per-vertex coefficients into the incidence column (DOK [dictionary of keys]).\"\"\"\n        col = self.edge_to_idx[edge_id]\n        for vid, coeff in coeffs.items():\n            row = self.entity_to_idx[vid]\n            self._matrix[row, col] = float(coeff)\n\n    # AnnNet API\n\n    def X(self): \n        \"\"\"Sparse incidence matrix.\"\"\"\n        return self._matrix\n\n    @property\n    def obs(self): \n        \"\"\"Node attribute table (observations).\"\"\"\n        return self.vertex_attributes\n\n    @property\n    def var(self): \n        \"\"\"Edge attribute table (variables).\"\"\"\n        return self.edge_attributes\n\n    @property\n    def uns(self): \n        \"\"\"Unstructured metadata.\"\"\"\n        return self.graph_attributes\n\n    @property\n    def layers(self):\n        \"\"\"Layer operations (add, remove, union, intersect).\"\"\"\n        if not hasattr(self, \"_layer_manager\"):\n            self._layer_manager = LayerManager(self)\n        return self._layer_manager\n\n    @property\n    def idx(self):\n        \"\"\"Index lookups (entity_id\u2194row, edge_id\u2194col).\"\"\"\n        if not hasattr(self, \"_index_manager\"):\n            self._index_manager = IndexManager(self)\n        return self._index_manager\n\n    @property\n    def cache(self):\n        \"\"\"Cache management (CSR/CSC materialization).\"\"\"\n        if not hasattr(self, \"_cache_manager\"):\n            self._cache_manager = CacheManager(self)\n        return self._cache_manager\n\n    # I/O\n    def write(self, path, **kwargs):\n        \"\"\"Save to .annnet format (zero loss).\"\"\"\n        from ..io.io_annnet import write\n        write(self, path, **kwargs)\n\n    @classmethod\n    def read(cls, path, **kwargs):\n        \"\"\"Load from .annnet format.\"\"\"\n        from ..io.io_annnet import read\n        return read(path, **kwargs)\n\n    # View API\n    def view(self, nodes=None, edges=None, layers=None, predicate=None):\n        \"\"\"Create lazy view/subgraph.\"\"\"\n        return GraphView(self, nodes, edges, layers, predicate)\n\n    # Audit\n    def snapshot(self, label=None):\n        \"\"\"\n        Create a named snapshot of current graph state.\n\n        Uses existing Graph attributes: entity_types, edge_to_idx, _layers, _version\n\n        Parameters\n        ----------\n        label : str, optional\n            Human-readable label for snapshot (auto-generated if None)\n\n        Returns\n        -------\n        dict\n            Snapshot metadata\n        \"\"\"\n        from datetime import datetime, timezone\n\n        if label is None:\n            label = f\"snapshot_{len(self._snapshots)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\n        snapshot = {\n            \"label\": label,\n            \"version\": self._version,\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"counts\": {\n                \"vertices\": self.number_of_vertices(),\n                \"edges\": self.number_of_edges(),\n                \"layers\": len(self._layers)\n            },\n            # Store minimal state for comparison (uses existing Graph attributes)\n            \"vertex_ids\": set(v for v, t in self.entity_types.items() if t == \"vertex\"),\n            \"edge_ids\": set(self.edge_to_idx.keys()),\n            \"layer_ids\": set(self._layers.keys()),\n        }\n\n        self._snapshots.append(snapshot)\n        return snapshot\n\n    def diff(self, a, b=None):\n        \"\"\"\n        Compare two snapshots or compare snapshot with current state.\n\n        Parameters\n        ----------\n        a : str | dict | Graph\n            First snapshot (label, snapshot dict, or Graph instance)\n        b : str | dict | Graph | None\n            Second snapshot. If None, compare with current state.\n\n        Returns\n        -------\n        GraphDiff\n            Difference object with added/removed entities\n        \"\"\"\n        snap_a = self._resolve_snapshot(a)\n        snap_b = self._resolve_snapshot(b) if b is not None else self._current_snapshot()\n\n        return GraphDiff(snap_a, snap_b)\n\n    def _resolve_snapshot(self, ref):\n        \"\"\"Resolve snapshot reference (label, dict, or Graph).\"\"\"\n        if isinstance(ref, dict):\n            return ref\n        elif isinstance(ref, str):\n            # Find by label\n            for snap in self._snapshots:\n                if snap[\"label\"] == ref:\n                    return snap\n            raise ValueError(f\"Snapshot '{ref}' not found\")\n        elif isinstance(ref, Graph):\n            # Create snapshot from another graph (uses Graph attributes)\n            return {\n                \"label\": \"external\",\n                \"version\": ref._version,\n                \"vertex_ids\": set(v for v, t in ref.entity_types.items() if t == \"vertex\"),\n                \"edge_ids\": set(ref.edge_to_idx.keys()),\n                \"layer_ids\": set(ref._layers.keys()),\n            }\n        else:\n            raise TypeError(f\"Invalid snapshot reference: {type(ref)}\")\n\n    def _current_snapshot(self):\n        \"\"\"Create snapshot of current state (uses Graph attributes).\"\"\"\n        return {\n            \"label\": \"current\",\n            \"version\": self._version,\n            \"vertex_ids\": set(v for v, t in self.entity_types.items() if t == \"vertex\"),\n            \"edge_ids\": set(self.edge_to_idx.keys()),\n            \"layer_ids\": set(self._layers.keys()),\n        }\n\n    def list_snapshots(self):\n        \"\"\"\n        List all snapshots.\n\n        Returns\n        -------\n        list[dict]\n            Snapshot metadata\n        \"\"\"\n        return [\n            {\n                \"label\": snap[\"label\"],\n                \"timestamp\": snap[\"timestamp\"],\n                \"version\": snap[\"version\"],\n                \"counts\": snap[\"counts\"]\n            }\n            for snap in self._snapshots\n        ]\n</code></pre>"},{"location":"reference/api/#graphglue.Graph-attributes","title":"Attributes","text":""},{"location":"reference/api/#graphglue.Graph.E","title":"<code>E</code>  <code>property</code>","text":"<p>All edges as a tuple.</p>"},{"location":"reference/api/#graphglue.Graph.E--returns","title":"Returns","text":"<p>tuple     Tuple of all edge identifiers (whatever <code>self.edges()</code> yields).</p>"},{"location":"reference/api/#graphglue.Graph.V","title":"<code>V</code>  <code>property</code>","text":"<p>All vertices as a tuple.</p>"},{"location":"reference/api/#graphglue.Graph.V--returns","title":"Returns","text":"<p>tuple     Tuple of all vertex IDs in the graph.</p>"},{"location":"reference/api/#graphglue.Graph.cache","title":"<code>cache</code>  <code>property</code>","text":"<p>Cache management (CSR/CSC materialization).</p>"},{"location":"reference/api/#graphglue.Graph.idx","title":"<code>idx</code>  <code>property</code>","text":"<p>Index lookups (entity_id\u2194row, edge_id\u2194col).</p>"},{"location":"reference/api/#graphglue.Graph.ig","title":"<code>ig</code>  <code>property</code>","text":"<p>Accessor for the lazy igraph proxy. Usage: G.ig.community_multilevel(G, weights=\"weight\"), G.ig.shortest_paths_dijkstra(G, source=\"a\", target=\"z\", weights=\"weight\") (same idea as NX: pass G; proxy swaps it with the backend igraph.Graph lazily)</p>"},{"location":"reference/api/#graphglue.Graph.layers","title":"<code>layers</code>  <code>property</code>","text":"<p>Layer operations (add, remove, union, intersect).</p>"},{"location":"reference/api/#graphglue.Graph.ne","title":"<code>ne</code>  <code>property</code>","text":"<p>Shorthand for num_edges.</p>"},{"location":"reference/api/#graphglue.Graph.num_edges","title":"<code>num_edges</code>  <code>property</code>","text":"<p>Total number of edges in the graph.</p>"},{"location":"reference/api/#graphglue.Graph.num_vertices","title":"<code>num_vertices</code>  <code>property</code>","text":"<p>Total number of vertices (vertices) in the graph.</p>"},{"location":"reference/api/#graphglue.Graph.nv","title":"<code>nv</code>  <code>property</code>","text":"<p>Shorthand for num_vertices.</p>"},{"location":"reference/api/#graphglue.Graph.nx","title":"<code>nx</code>  <code>property</code>","text":"<p>Accessor for the lazy NX proxy. Usage: G.nx.algorithm(); e.g: G.nx.louvain_communities(G), G.nx.shortest_path_length(G, weight=\"weight\")</p>"},{"location":"reference/api/#graphglue.Graph.obs","title":"<code>obs</code>  <code>property</code>","text":"<p>Node attribute table (observations).</p>"},{"location":"reference/api/#graphglue.Graph.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Graph shape as a tuple: (num_vertices, num_edges). Useful for quick inspection.</p>"},{"location":"reference/api/#graphglue.Graph.uns","title":"<code>uns</code>  <code>property</code>","text":"<p>Unstructured metadata.</p>"},{"location":"reference/api/#graphglue.Graph.var","title":"<code>var</code>  <code>property</code>","text":"<p>Edge attribute table (variables).</p>"},{"location":"reference/api/#graphglue.Graph-functions","title":"Functions","text":""},{"location":"reference/api/#graphglue.Graph.X","title":"<code>X()</code>","text":"<p>Sparse incidence matrix.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def X(self): \n    \"\"\"Sparse incidence matrix.\"\"\"\n    return self._matrix\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.__hash__","title":"<code>__hash__()</code>","text":"<p>Return a stable hash representing the current graph structure and metadata.</p>"},{"location":"reference/api/#graphglue.Graph.__hash__--returns","title":"Returns","text":"<p>int     A hash value that uniquely (within high probability) identifies the graph     based on its topology and attributes.</p>"},{"location":"reference/api/#graphglue.Graph.__hash__--behavior","title":"Behavior","text":"<ul> <li>Includes the set of verices, edges, and directedness in the hash.</li> <li>Includes graph-level attributes (if any) to capture metadata changes.</li> <li>Does not depend on memory addresses or internal object IDs, so the same graph serialized/deserialized or reconstructed with identical structure will produce the same hash.</li> </ul>"},{"location":"reference/api/#graphglue.Graph.__hash__--notes","title":"Notes","text":"<ul> <li>This method enables <code>Graph</code> objects to be used in hash-based containers (like <code>set</code> or <code>dict</code> keys).</li> <li>If the graph is mutated after hashing (e.g., verices or edges are added or removed), the hash will no longer reflect the new state.</li> <li>The method uses a deterministic representation: sorted vertex/edge sets ensure that ordering does not affect the hash.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"\n    Return a stable hash representing the current graph structure and metadata.\n\n    Returns\n    -------\n    int\n        A hash value that uniquely (within high probability) identifies the graph\n        based on its topology and attributes.\n\n    Behavior\n    --------\n    - Includes the set of verices, edges, and directedness in the hash.\n    - Includes graph-level attributes (if any) to capture metadata changes.\n    - Does **not** depend on memory addresses or internal object IDs, so the same\n    graph serialized/deserialized or reconstructed with identical structure\n    will produce the same hash.\n\n    Notes\n    -----\n    - This method enables `Graph` objects to be used in hash-based containers\n    (like `set` or `dict` keys).\n    - If the graph is **mutated** after hashing (e.g., verices or edges are added\n    or removed), the hash will no longer reflect the new state.\n    - The method uses a deterministic representation: sorted vertex/edge sets\n    ensure that ordering does not affect the hash.\n    \"\"\"\n    # Core structural components\n    vertex_ids = tuple(sorted(self.verices()))\n    edge_defs = []\n\n    for j in range(self.number_of_edges()):\n        S, T = self.get_edge(j)\n        eid = self.idx_to_edge[j]\n        directed = self._is_directed_edge(eid)\n        edge_defs.append((eid, tuple(sorted(S)), tuple(sorted(T)), directed))\n\n    edge_defs = tuple(sorted(edge_defs))\n\n    # Include high-level metadata if available\n    graph_meta = tuple(sorted(self.graph_attributes.items())) if hasattr(self, \"graph_attributes\") else ()\n\n    return hash((vertex_ids, edge_defs, graph_meta))\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.__init__","title":"<code>__init__(directed=None, n=0, e=0, **kwargs)</code>","text":"<p>Initialize an empty incidence-matrix graph.</p>"},{"location":"reference/api/#graphglue.Graph.__init__--parameters","title":"Parameters","text":"<p>directed : bool, optional     Global default for edge directionality. Individual edges can override this.</p>"},{"location":"reference/api/#graphglue.Graph.__init__--notes","title":"Notes","text":"<ul> <li>Stores entities (vertices and edge-entities), edges (including parallels), and an incidence matrix in DOK (Dictionary Of Keys) sparse format.</li> <li>Attribute tables are Polars DF (DataFrame) with canonical key columns: <code>vertex_attributes(vertex_id)</code>, <code>edge_attributes(edge_id)</code>, <code>layer_attributes(layer_id)</code>, and <code>edge_layer_attributes(layer_id, edge_id, weight)</code>.</li> <li>A <code>'default'</code> layer is created and set active.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def __init__(self, directed=None, n: int = 0, e: int = 0, **kwargs):\n    \"\"\"\n    Initialize an empty incidence-matrix graph.\n\n    Parameters\n    ----------\n    directed : bool, optional\n        Global default for edge directionality. Individual edges can override this.\n\n    Notes\n    -----\n    - Stores entities (vertices and edge-entities), edges (including parallels), and\n    an incidence matrix in DOK (Dictionary Of Keys) sparse format.\n    - Attribute tables are Polars DF (DataFrame) with canonical key columns:\n    ``vertex_attributes(vertex_id)``, ``edge_attributes(edge_id)``,\n    ``layer_attributes(layer_id)``, and\n    ``edge_layer_attributes(layer_id, edge_id, weight)``.\n    - A ``'default'`` layer is created and set active.\n    \"\"\"        \n    self.directed = directed\n\n    # Entity mappings (vertices + vertex-edge hybrids)\n    self.entity_to_idx = {}  # entity_id -&gt; row index\n    self.idx_to_entity = {}  # row index -&gt; entity_id\n    self.entity_types = {}   # entity_id -&gt; 'vertex' or 'edge'\n\n    # Edge mappings (supports parallel edges)\n    self.edge_to_idx = {}    # edge_id -&gt; column index\n    self.idx_to_edge = {}    # column index -&gt; edge_id\n    self.edge_definitions = {}  # edge_id -&gt; (source, target, edge_type)\n    self.edge_weights = {}   # edge_id -&gt; weight\n    self.edge_directed = {} # Per-edge directedness; edge_id -&gt; bool  (None = Mixed, True=directed, False=undirected)\n\n    # Sparse incidence matrix\n    self._matrix = sp.dok_matrix((0, 0), dtype=np.float32)\n    self._num_entities = 0\n    self._num_edges = 0\n\n    # Attribute storage using polars DataFrames\n    self.vertex_attributes = pl.DataFrame(schema={\"vertex_id\": pl.Utf8})\n    self.edge_attributes = pl.DataFrame(schema={\"edge_id\": pl.Utf8})\n    self.layer_attributes = pl.DataFrame(schema={\"layer_id\": pl.Utf8})\n    self.edge_layer_attributes = pl.DataFrame(\n        schema={\"layer_id\": pl.Utf8, \"edge_id\": pl.Utf8, \"weight\": pl.Float64}\n    )\n    self.edge_kind = {}\n    self.hyperedge_definitions = {}\n    self.graph_attributes = {}\n\n    # Edge ID counter for parallel edges\n    self._next_edge_id = 0\n\n    # Layer management - lightweight dict structure\n    self._layers = {}  # layer_id -&gt; {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n    self._current_layer = None\n    self._default_layer = 'default'\n    self.layer_edge_weights = defaultdict(dict)  # layer_id -&gt; {edge_id: weight}\n\n    # Initialize default layer\n    self._layers[self._default_layer] = {\n        \"vertices\": set(),\n        \"edges\": set(), \n        \"attributes\": {}\n    }\n    self._current_layer = self._default_layer\n\n    # counts stay logical (start empty)\n    self._num_entities = 0\n    self._num_edges = 0\n\n    # pre-size the incidence matrix to capacity (no zeros allocated in DOK)\n    n = int(n) if n and n &gt; 0 else 0\n    e = int(e) if e and e &gt; 0 else 0\n    self._matrix = sp.dok_matrix((n, e), dtype=np.float32)\n\n    # grow-only helpers to avoid per-insert exact resizes\n    def _grow_rows_to(target: int):\n        rows, cols = self._matrix.shape\n        if target &gt; rows:\n            # geometric bump; keeps behavior, reduces churn\n            new_rows = max(target, rows + max(8, rows &gt;&gt; 1))\n            self._matrix.resize((new_rows, cols))\n\n    def _grow_cols_to(target: int):\n        rows, cols = self._matrix.shape\n        if target &gt; cols:\n            new_cols = max(target, cols + max(8, cols &gt;&gt; 1))\n            self._matrix.resize((rows, new_cols))\n\n    # bind as privates\n    self._grow_rows_to = _grow_rows_to\n    self._grow_cols_to = _grow_cols_to\n\n    # History and Timeline\n    self._history_enabled = True\n    self._history = []           # list[dict]\n    self._version = 0\n    self._history_clock0 = time.perf_counter_ns()\n    self._install_history_hooks()  # wrap mutating methods\n    self._snapshots = []\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_edge","title":"<code>add_edge(source, target, layer=None, weight=1.0, edge_id=None, edge_type='regular', propagate='none', layer_weight=None, directed=None, edge_directed=None, **attributes)</code>","text":"<p>Add or update a binary edge between two entities.</p>"},{"location":"reference/api/#graphglue.Graph.add_edge--parameters","title":"Parameters","text":"<p>source : str     Source entity ID (vertex or edge-entity for vertex-edge mode). target : str     Target entity ID. layer : str, optional     Layer to place the edge into. Defaults to the active layer. weight : float, optional     Global edge weight stored in the incidence column (default 1.0). edge_id : str, optional     Explicit edge ID. If omitted, a fresh ID is generated. edge_type : {'regular', 'vertex_edge'}, optional     Edge kind. <code>'vertex_edge'</code> allows connecting to an edge-entity. propagate : {'none', 'shared', 'all'}, optional     Layer propagation:     - <code>'none'</code> : only the specified layer     - <code>'shared'</code> : all layers that already contain both endpoints     - <code>'all'</code> : all layers that contain either endpoint (and add the other) layer_weight : float, optional     Per-layer weight override for this edge (stored in edge-layer DF). edge_directed : bool, optional     Override default directedness for this edge. If None, uses graph default. **attributes     Pure edge attributes to upsert.</p>"},{"location":"reference/api/#graphglue.Graph.add_edge--returns","title":"Returns","text":"<p>str     The edge ID (new or updated).</p>"},{"location":"reference/api/#graphglue.Graph.add_edge--raises","title":"Raises","text":"<p>ValueError     If <code>propagate</code> or <code>edge_type</code> is invalid. TypeError     If <code>weight</code> is not numeric.</p>"},{"location":"reference/api/#graphglue.Graph.add_edge--notes","title":"Notes","text":"<ul> <li>Directed edges write <code>+weight</code> at source row and <code>-weight</code> at target row.</li> <li>Undirected edges write <code>+weight</code> at both endpoints.</li> <li>Updating an existing edge ID overwrites its matrix column and metadata.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_edge(\n    self,\n    source,\n    target,\n    layer=None,\n    weight=1.0,\n    edge_id=None,\n    edge_type=\"regular\",\n    propagate=\"none\",\n    layer_weight=None,\n    directed=None,\n    edge_directed=None,\n    **attributes,\n):\n    \"\"\"\n    Add or update a binary edge between two entities.\n\n    Parameters\n    ----------\n    source : str\n        Source entity ID (vertex or edge-entity for vertex-edge mode).\n    target : str\n        Target entity ID.\n    layer : str, optional\n        Layer to place the edge into. Defaults to the active layer.\n    weight : float, optional\n        Global edge weight stored in the incidence column (default 1.0).\n    edge_id : str, optional\n        Explicit edge ID. If omitted, a fresh ID is generated.\n    edge_type : {'regular', 'vertex_edge'}, optional\n        Edge kind. ``'vertex_edge'`` allows connecting to an edge-entity.\n    propagate : {'none', 'shared', 'all'}, optional\n        Layer propagation:\n        - ``'none'`` : only the specified layer\n        - ``'shared'`` : all layers that already contain **both** endpoints\n        - ``'all'`` : all layers that contain **either** endpoint (and add the other)\n    layer_weight : float, optional\n        Per-layer weight override for this edge (stored in edge-layer DF).\n    edge_directed : bool, optional\n        Override default directedness for this edge. If None, uses graph default.\n    **attributes\n        Pure edge attributes to upsert.\n\n    Returns\n    -------\n    str\n        The edge ID (new or updated).\n\n    Raises\n    ------\n    ValueError\n        If ``propagate`` or ``edge_type`` is invalid.\n    TypeError\n        If ``weight`` is not numeric.\n\n    Notes\n    -----\n    - Directed edges write ``+weight`` at source row and ``-weight`` at target row.\n    - Undirected edges write ``+weight`` at both endpoints.\n    - Updating an existing edge ID overwrites its matrix column and metadata.\n    \"\"\"\n    if edge_type is None:\n        edge_type = \"regular\"\n\n    # normalize endpoints: accept str OR iterable; route hyperedges\n    def _to_tuple(x):\n        if isinstance(x, (str, bytes)):\n            return (x,), False\n        try:\n            xs = tuple(x)\n        except TypeError:\n            return (x,), False\n        return xs, (len(xs) != 1)\n\n    S, src_multi = _to_tuple(source)\n    T, tgt_multi = _to_tuple(target)\n\n    # Hyperedge delegation\n    if src_multi or tgt_multi:\n        if edge_directed:\n            return self.add_hyperedge(\n                head=S, tail=T, edge_directed=True,\n                layer=layer, weight=weight, edge_id=edge_id, **attributes\n            )\n        else:\n            members = tuple(set(S) | set(T))\n            return self.add_hyperedge(\n                members=members, edge_directed=False,\n                layer=layer, weight=weight, edge_id=edge_id, **attributes\n            )\n\n    # Binary case: unwrap singletons to plain IDs\n    source, target = S[0], T[0]\n\n    # validate inputs\n    if propagate not in {\"none\", \"shared\", \"all\"}:\n        raise ValueError(f\"propagate must be one of 'none'|'shared'|'all', got {propagate!r}\")\n    if not isinstance(weight, (int, float)):\n        raise TypeError(f\"weight must be numeric, got {type(weight).__name__}\")\n    if edge_type not in {\"regular\", \"vertex_edge\"}:\n        raise ValueError(f\"edge_type must be 'regular' or 'vertex_edge', got {edge_type!r}\")\n\n    # resolve layer + whether to touch layering at all\n    layer = self._current_layer if layer is None else layer\n    touch_layer = layer is not None\n\n    # Intern common strings to speed up dict lookups\n    try:\n        import sys as _sys\n        if isinstance(source, str): source = _sys.intern(source)\n        if isinstance(target, str): target = _sys.intern(target)\n        if isinstance(layer, str):  layer  = _sys.intern(layer)\n        if isinstance(edge_id, str): edge_id = _sys.intern(edge_id)\n    except Exception:\n        pass\n\n    entity_to_idx = self.entity_to_idx\n    idx_to_edge = self.idx_to_edge\n    edge_to_idx = self.edge_to_idx\n    edge_defs = self.edge_definitions\n    edge_w = self.edge_weights\n    edge_dir = self.edge_directed\n    layers = self._layers\n    M = self._matrix  # DOK\n\n    # ensure vertices exist (global)\n    def _ensure_vertex_or_edge_entity(x):\n        if x in entity_to_idx:\n            return\n        if edge_type == \"vertex_edge\" and isinstance(x, str) and x.startswith(\"edge_\"):\n            self.add_edge_entity(x, layer=layer)\n        else:\n            self.add_vertex(x, layer=layer)\n\n    _ensure_vertex_or_edge_entity(source)\n    _ensure_vertex_or_edge_entity(target)\n\n    # indices (after potential vertex creation)\n    source_idx = entity_to_idx[source]\n    target_idx = entity_to_idx[target]\n\n    # edge id\n    if edge_id is None:\n        edge_id = self._get_next_edge_id()\n\n    # determine direction\n    if edge_directed is not None:\n        is_dir = bool(edge_directed)\n    elif self.directed is not None:\n        is_dir = self.directed\n    else:\n        is_dir = True\n\n    if edge_id in edge_to_idx:\n        # UPDATE existing column\n\n        col_idx = edge_to_idx[edge_id]\n\n        # allow explicit direction change; otherwise keep existing\n        if edge_directed is None:\n            is_dir = edge_dir.get(edge_id, is_dir)\n        edge_dir[edge_id] = is_dir\n\n        # keep edge_type attr write\n        self.set_edge_attrs(edge_id, edge_type=(EdgeType.DIRECTED if is_dir else EdgeType.UNDIRECTED))\n\n        # if source/target changed, update definition\n        old_src, old_tgt, old_type = edge_defs[edge_id]\n        edge_defs[edge_id] = (source, target, old_type)  # keep old_type by default\n\n        # ensure matrix has enough rows (in case vertices were added since creation)\n        self._grow_rows_to(self._num_entities)\n\n\n        # clear only the cells that were previously set, not the whole column\n        try:\n            old_src_idx = entity_to_idx[old_src]\n            M[old_src_idx, col_idx] = 0\n        except KeyError:\n            pass\n        if old_src != old_tgt:\n            try:\n                old_tgt_idx = entity_to_idx[old_tgt]\n                M[old_tgt_idx, col_idx] = 0\n            except KeyError:\n                pass\n\n        # write new endpoints\n        M[source_idx, col_idx] = weight\n        if source != target:\n            M[target_idx, col_idx] = (-weight if is_dir else weight)\n\n        edge_w[edge_id] = weight\n\n    else:\n        # CREATE new column\n\n        col_idx = self._num_edges\n        edge_to_idx[edge_id] = col_idx\n        idx_to_edge[col_idx] = edge_id\n        edge_defs[edge_id] = (source, target, edge_type)\n        edge_w[edge_id] = weight\n        edge_dir[edge_id] = is_dir\n        self._num_edges = col_idx + 1\n\n        # grow-only to current logical capacity\n        self._grow_rows_to(self._num_entities)\n        self._grow_cols_to(self._num_edges)\n        M[source_idx, col_idx] = weight\n        if source != target:\n            M[target_idx, col_idx] = (-weight if is_dir else weight)\n\n    # layer handling\n    if touch_layer:\n        if layer not in layers:\n            layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n        layers[layer][\"edges\"].add(edge_id)\n        layers[layer][\"vertices\"].update((source, target))\n\n        if layer_weight is not None:\n            w = float(layer_weight)\n            self.set_edge_layer_attrs(layer, edge_id, weight=w)\n            self.layer_edge_weights.setdefault(layer, {})[edge_id] = w\n\n    # propagation\n    if propagate == \"shared\":\n        self._propagate_to_shared_layers(edge_id, source, target)\n    elif propagate == \"all\":\n        self._propagate_to_all_layers(edge_id, source, target)\n\n    # attributes\n    if attributes:\n        self.set_edge_attrs(edge_id, **attributes)\n\n    return edge_id\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_edge_entities_bulk","title":"<code>add_edge_entities_bulk(items, layer=None)</code>","text":"<p>Bulk add edge-entities (vertex-edge hybrids). Accepts: - iterable of str IDs - iterable of (edge_entity_id, attrs_dict) - iterable of dicts with key 'edge_entity_id' (or 'id') Behavior: identical to calling add_edge_entity() for each, but grows rows once and batches attribute inserts.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_edge_entities_bulk(self, items, layer=None):\n    \"\"\"\n    Bulk add edge-entities (vertex-edge hybrids). Accepts:\n    - iterable of str IDs\n    - iterable of (edge_entity_id, attrs_dict)\n    - iterable of dicts with key 'edge_entity_id' (or 'id')\n    Behavior: identical to calling add_edge_entity() for each, but grows rows once\n    and batches attribute inserts.\n    \"\"\"\n    layer = layer or self._current_layer\n\n    # normalize -&gt; [(eid, attrs)]\n    norm = []\n    for it in items:\n        if isinstance(it, dict):\n            eid = it.get(\"edge_entity_id\") or it.get(\"id\")\n            if eid is None: continue\n            a = {k: v for k, v in it.items() if k not in (\"edge_entity_id\",\"id\")}\n            norm.append((eid, a))\n        elif isinstance(it, (tuple, list)) and it:\n            eid = it[0]; a = (it[1] if len(it) &gt; 1 and isinstance(it[1], dict) else {})\n            norm.append((eid, a))\n        else:\n            norm.append((it, {}))\n    if not norm:\n        return\n\n    # intern hot strings\n    try:\n        import sys as _sys\n        norm = [(_sys.intern(eid) if isinstance(eid, str) else eid, attrs) for eid, attrs in norm]\n        if isinstance(layer, str): layer = _sys.intern(layer)\n    except Exception:\n        pass\n\n    # create missing rows as type 'edge'\n    new_rows = 0\n    for eid, _ in norm:\n        if eid not in self.entity_to_idx:\n            idx = self._num_entities\n            self.entity_to_idx[eid] = idx\n            self.idx_to_entity[idx] = eid\n            self.entity_types[eid] = \"edge\"\n            self._num_entities = idx + 1\n            new_rows += 1\n\n    if new_rows:\n        self._grow_rows_to(self._num_entities)\n\n    # layer membership\n    if layer not in self._layers:\n        self._layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n    self._layers[layer][\"vertices\"].update(eid for eid, _ in norm)\n\n    # attributes (edge-entities share vertex_attributes table)\n    self._ensure_vertex_table()\n    df = self.vertex_attributes\n    to_append, existing_ids = [], set()\n    try:\n        if df.height and \"vertex_id\" in df.columns:\n            existing_ids = set(df.get_column(\"vertex_id\").to_list())\n    except Exception:\n        pass\n\n    for eid, attrs in norm:\n        if df.is_empty() or eid not in existing_ids:\n            row = {c: None for c in df.columns} if not df.is_empty() else {\"vertex_id\": None}\n            row[\"vertex_id\"] = eid\n            for k, v in attrs.items():\n                row[k] = v\n            to_append.append(row)\n\n    if to_append:\n        need_cols = {k for r in to_append for k in r if k != \"vertex_id\"}\n        if need_cols:\n            df = self._ensure_attr_columns(df, {k: None for k in need_cols})\n        add_df = pl.DataFrame(to_append)\n        for c in df.columns:\n            if c not in add_df.columns:\n                add_df = add_df.with_columns(pl.lit(None).cast(df.schema[c]).alias(c))\n        for c in df.columns:\n            lc, rc = df.schema[c], add_df.schema[c]\n            if lc == pl.Null and rc != pl.Null:\n                df = df.with_columns(pl.col(c).cast(rc))\n            elif rc == pl.Null and lc != pl.Null:\n                add_df = add_df.with_columns(pl.col(c).cast(lc).alias(c))\n            elif lc != rc:\n                df = df.with_columns(pl.col(c).cast(pl.Utf8))\n                add_df = add_df.with_columns(pl.col(c).cast(pl.Utf8).alias(c))\n            if to_append:\n                need_cols = {k for r in to_append for k in r if k != \"vertex_id\"}\n                if need_cols:\n                    df = self._ensure_attr_columns(df, {k: None for k in need_cols})\n\n                add_df = pl.DataFrame(to_append)\n\n                # ensure all df columns exist on add_df\n                for c in df.columns:\n                    if c not in add_df.columns:\n                        add_df = add_df.with_columns(pl.lit(None).cast(df.schema[c]).alias(c))\n\n                # dtype reconciliation (same as before)\n                for c in df.columns:\n                    lc, rc = df.schema[c], add_df.schema[c]\n                    if lc == pl.Null and rc != pl.Null:\n                        df = df.with_columns(pl.col(c).cast(rc))\n                    elif rc == pl.Null and lc != pl.Null:\n                        add_df = add_df.with_columns(pl.col(c).cast(lc).alias(c))\n                    elif lc != rc:\n                        df = df.with_columns(pl.col(c).cast(pl.Utf8))\n                        add_df = add_df.with_columns(pl.col(c).cast(pl.Utf8).alias(c))\n\n                # reorder add_df columns to match df exactly\n                add_df = add_df.select(df.columns)\n\n                df = df.vstack(add_df)\n\n\n    for eid, attrs in norm:\n        if attrs and (df.is_empty() or (eid in existing_ids)):\n            df = self._upsert_row(df, eid, attrs)\n    self.vertex_attributes = df\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_edge_entity","title":"<code>add_edge_entity(edge_entity_id, layer=None, **attributes)</code>","text":"<p>Add an edge entity (vertex-edge hybrid) that can connect to vertices/edges.</p>"},{"location":"reference/api/#graphglue.Graph.add_edge_entity--parameters","title":"Parameters","text":"<p>edge_entity_id : str     Entity ID to register as type <code>'edge'</code> in the entity set. layer : str, optional     Target layer. Defaults to the active layer. **attributes     Attributes stored in the vertex attribute DF (treated like vertices).</p>"},{"location":"reference/api/#graphglue.Graph.add_edge_entity--returns","title":"Returns","text":"<p>str     The edge-entity ID.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_edge_entity(self, edge_entity_id, layer=None, **attributes):\n    \"\"\"\n    Add an **edge entity** (vertex-edge hybrid) that can connect to vertices/edges.\n\n    Parameters\n    ----------\n    edge_entity_id : str\n        Entity ID to register as type ``'edge'`` in the entity set.\n    layer : str, optional\n        Target layer. Defaults to the active layer.\n    **attributes\n        Attributes stored in the vertex attribute DF (treated like vertices).\n\n    Returns\n    -------\n    str\n        The edge-entity ID.\n    \"\"\"\n    # Resolve layer default and intern hot strings\n    layer = layer or self._current_layer\n    try:\n        import sys as _sys\n        if isinstance(edge_entity_id, str):\n            edge_entity_id = _sys.intern(edge_entity_id)\n        if isinstance(layer, str):\n            layer = _sys.intern(layer)\n    except Exception:\n        pass\n\n    entity_to_idx = self.entity_to_idx\n    layers = self._layers\n\n    # Add to global superset if new (delegate to existing helper)\n    if edge_entity_id not in entity_to_idx:\n        self._add_edge_entity(edge_entity_id)\n\n    # Add to specified layer\n    if layer not in layers:\n        layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n    layers[layer][\"vertices\"].add(edge_entity_id)\n\n    # Add attributes (treat edge entities like vertices for attributes)\n    if attributes:\n        self.set_vertex_attrs(edge_entity_id, **attributes)\n\n    return edge_entity_id\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_edge_to_layer","title":"<code>add_edge_to_layer(lid, eid)</code>","text":"<p>Attach an existing edge to a layer (no weight changes).</p>"},{"location":"reference/api/#graphglue.Graph.add_edge_to_layer--parameters","title":"Parameters","text":"<p>lid : str     Layer ID. eid : str     Edge ID.</p>"},{"location":"reference/api/#graphglue.Graph.add_edge_to_layer--raises","title":"Raises","text":"<p>KeyError     If the layer does not exist.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_edge_to_layer(self, lid, eid):\n    \"\"\"\n    Attach an existing edge to a layer (no weight changes).\n\n    Parameters\n    ----------\n    lid : str\n        Layer ID.\n    eid : str\n        Edge ID.\n\n    Raises\n    ------\n    KeyError\n        If the layer does not exist.\n    \"\"\"\n    if lid not in self._layers:\n        raise KeyError(f\"Layer {lid} does not exist\")\n    self._layers[lid][\"edges\"].add(eid)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_edges_bulk","title":"<code>add_edges_bulk(edges, *, layer=None, default_weight=1.0, default_edge_type='regular', default_propagate='none', default_layer_weight=None, default_edge_directed=None)</code>","text":"<p>Bulk add/update binary (and vertex-edge) edges. Accepts each item as: - (src, tgt) - (src, tgt, weight) - dict with keys: source, target, [weight, edge_id, edge_type, propagate, layer_weight, edge_directed, attributes] Behavior: identical to calling add_edge() per item (same propagation/layer/attrs), but grows columns once and avoids full-column wipes.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_edges_bulk(\n    self,\n    edges,\n    *,\n    layer=None,\n    default_weight=1.0,\n    default_edge_type=\"regular\",\n    default_propagate=\"none\",\n    default_layer_weight=None,\n    default_edge_directed=None,\n):\n    \"\"\"\n    Bulk add/update *binary* (and vertex-edge) edges.\n    Accepts each item as:\n    - (src, tgt)\n    - (src, tgt, weight)\n    - dict with keys: source, target, [weight, edge_id, edge_type, propagate, layer_weight, edge_directed, attributes]\n    Behavior: identical to calling add_edge() per item (same propagation/layer/attrs), but grows columns once and avoids full-column wipes.\n    \"\"\"\n    layer = self._current_layer if layer is None else layer\n\n    # Normalize into dicts\n    norm = []\n    for it in edges:\n        if isinstance(it, dict):\n            d = dict(it)\n        elif isinstance(it, (tuple, list)):\n            if len(it) == 2:\n                d = {\"source\": it[0], \"target\": it[1], \"weight\": default_weight}\n            else:\n                d = {\"source\": it[0], \"target\": it[1], \"weight\": it[2]}\n        else:\n            continue\n        d.setdefault(\"weight\", default_weight)\n        d.setdefault(\"edge_type\", default_edge_type)\n        d.setdefault(\"propagate\", default_propagate)\n        if \"layer\" not in d:\n            d[\"layer\"] = layer\n        if \"edge_directed\" not in d:\n            d[\"edge_directed\"] = default_edge_directed\n        norm.append(d)\n\n    if not norm:\n        return []\n\n    # Intern hot strings &amp; coerce weights\n    try:\n        import sys as _sys\n        for d in norm:\n            s, t = d[\"source\"], d[\"target\"]\n            if isinstance(s, str): d[\"source\"] = _sys.intern(s)\n            if isinstance(t, str): d[\"target\"] = _sys.intern(t)\n            lid = d.get(\"layer\")\n            if isinstance(lid, str): d[\"layer\"] = _sys.intern(lid)\n            eid = d.get(\"edge_id\")\n            if isinstance(eid, str): d[\"edge_id\"] = _sys.intern(eid)\n            try:\n                d[\"weight\"] = float(d[\"weight\"])\n            except Exception:\n                pass\n    except Exception:\n        pass\n\n    entity_to_idx = self.entity_to_idx\n    M = self._matrix\n    # 1) Ensure endpoints exist (global); we\u2019ll rely on layer handling below to add membership.\n    for d in norm:\n        s, t = d[\"source\"], d[\"target\"]\n        et = d.get(\"edge_type\", \"regular\")\n        if s not in entity_to_idx:\n            # vertex or edge-entity depending on mode?\n            if et == \"vertex_edge\" and isinstance(s, str) and s.startswith(\"edge_\"):\n                self._add_edge_entity(s)\n            else:\n                # bare global insert (no layer side-effects; membership handled later)\n                idx = self._num_entities\n                self.entity_to_idx[s] = idx\n                self.idx_to_entity[idx] = s\n                self.entity_types[s] = \"vertex\"\n                self._num_entities = idx + 1\n        if t not in entity_to_idx:\n            if et == \"vertex_edge\" and isinstance(t, str) and t.startswith(\"edge_\"):\n                self._add_edge_entity(t)\n            else:\n                idx = self._num_entities\n                self.entity_to_idx[t] = idx\n                self.idx_to_entity[idx] = t\n                self.entity_types[t] = \"vertex\"\n                self._num_entities = idx + 1\n\n    # Grow rows once if needed\n    self._grow_rows_to(self._num_entities)\n\n    # 2) Pre-size columns for new edges\n    new_count = sum(1 for d in norm if d.get(\"edge_id\") not in self.edge_to_idx)\n    if new_count:\n        self._grow_cols_to(self._num_edges + new_count)\n\n    # 3) Create/update columns\n    out_ids = []\n    for d in norm:\n        s, t = d[\"source\"], d[\"target\"]\n        w = d[\"weight\"]\n        etype = d.get(\"edge_type\", \"regular\")\n        prop = d.get(\"propagate\", default_propagate)\n        layer_local = d.get(\"layer\", layer)\n        layer_w = d.get(\"layer_weight\", default_layer_weight)\n        e_dir = d.get(\"edge_directed\", default_edge_directed)\n        edge_id = d.get(\"edge_id\")\n\n        if e_dir is not None:\n            is_dir = bool(e_dir)\n        elif self.directed is not None:\n            is_dir = self.directed\n        else:\n            is_dir = True\n        s_idx = self.entity_to_idx[s]; t_idx = self.entity_to_idx[t]\n\n        if edge_id is None:\n            edge_id = self._get_next_edge_id()\n\n        # update vs create\n        if edge_id in self.edge_to_idx:\n            col = self.edge_to_idx[edge_id]\n            # keep old_type on update (mimic add_edge)\n            old_s, old_t, old_type = self.edge_definitions[edge_id]\n            # clear only previous cells (no full column wipe)\n            try:\n                M[self.entity_to_idx[old_s], col] = 0\n            except Exception:\n                pass\n            if old_t is not None and old_t != old_s:\n                try:\n                    M[self.entity_to_idx[old_t], col] = 0\n                except Exception:\n                    pass\n            # write new\n            M[s_idx, col] = w\n            if s != t:\n                M[t_idx, col] = (-w if is_dir else w)\n            self.edge_definitions[edge_id] = (s, t, old_type)\n            self.edge_weights[edge_id] = w\n            self.edge_directed[edge_id] = is_dir\n            # keep attribute side-effect for directedness flag\n            self.set_edge_attrs(edge_id, edge_type=(EdgeType.DIRECTED if is_dir else EdgeType.UNDIRECTED))\n        else:\n            col = self._num_edges\n            self.edge_to_idx[edge_id] = col\n            self.idx_to_edge[col] = edge_id\n            self.edge_definitions[edge_id] = (s, t, etype)\n            self.edge_weights[edge_id] = w\n            self.edge_directed[edge_id] = is_dir\n            self._num_edges = col + 1\n            # write cells\n            M[s_idx, col] = w\n            if s != t:\n                M[t_idx, col] = (-w if is_dir else w)\n\n        # layer membership + optional per-layer weight\n        if layer_local is not None:\n            if layer_local not in self._layers:\n                self._layers[layer_local] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n            self._layers[layer_local][\"edges\"].add(edge_id)\n            self._layers[layer_local][\"vertices\"].update((s, t))\n            if layer_w is not None:\n                self.set_edge_layer_attrs(layer_local, edge_id, weight=float(layer_w))\n                self.layer_edge_weights.setdefault(layer_local, {})[edge_id] = float(layer_w)\n\n        # propagation\n        if prop == \"shared\":\n            self._propagate_to_shared_layers(edge_id, s, t)\n        elif prop == \"all\":\n            self._propagate_to_all_layers(edge_id, s, t)\n\n        # per-edge extra attributes\n        attrs = d.get(\"attributes\") or d.get(\"attrs\") or {}\n        if attrs:\n            self.set_edge_attrs(edge_id, **attrs)\n\n        out_ids.append(edge_id)\n\n    return out_ids\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_edges_to_layer_bulk","title":"<code>add_edges_to_layer_bulk(layer_id, edge_ids)</code>","text":"<p>Bulk version of add_edge_to_layer: add many edges to a layer and attach all incident vertices. No weights are changed here.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_edges_to_layer_bulk(self, layer_id, edge_ids):\n    \"\"\"\n    Bulk version of add_edge_to_layer: add many edges to a layer and attach\n    all incident vertices. No weights are changed here.\n    \"\"\"\n    layer = layer_id if layer_id is not None else self._current_layer\n    if layer not in self._layers:\n        self._layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n    L = self._layers[layer]\n\n    add_edges = {eid for eid in edge_ids if eid in self.edge_to_idx}\n    if not add_edges:\n        return\n\n    L[\"edges\"].update(add_edges)\n\n    verts = set()\n    for eid in add_edges:\n        kind = self.edge_kind.get(eid, \"binary\")\n        if kind == \"hyper\":\n            h = self.hyperedge_definitions[eid]\n            if h.get(\"members\") is not None:\n                verts.update(h[\"members\"])\n            else:\n                verts.update(h.get(\"head\", ()))\n                verts.update(h.get(\"tail\", ()))\n        else:\n            s, t, _ = self.edge_definitions[eid]\n            verts.add(s); verts.add(t)\n\n    L[\"vertices\"].update(verts)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_hyperedge","title":"<code>add_hyperedge(*, members=None, head=None, tail=None, layer=None, weight=1.0, edge_id=None, edge_directed=None, **attributes)</code>","text":"<p>Create a k-ary hyperedge as a single incidence column.</p>"},{"location":"reference/api/#graphglue.Graph.add_hyperedge--modes","title":"Modes","text":"<ul> <li>Undirected: pass <code>members</code> (&gt;=2). Each member gets <code>+weight</code>.</li> <li>Directed: pass <code>head</code> and <code>tail</code> (both non-empty, disjoint). Head gets <code>+weight</code>; tail gets <code>-weight</code>.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_hyperedge(\n    self,\n    *,\n    members=None,\n    head=None,\n    tail=None,\n    layer=None,\n    weight=1.0,\n    edge_id=None,\n    edge_directed=None,   # bool or None (None -&gt; infer from params)\n    **attributes,\n):\n    \"\"\"\n    Create a k-ary hyperedge as a single incidence column.\n\n    Modes\n    -----\n    - **Undirected**: pass ``members`` (&gt;=2). Each member gets ``+weight``.\n    - **Directed**: pass ``head`` and ``tail`` (both non-empty, disjoint).\n    Head gets ``+weight``; tail gets ``-weight``.\n    \"\"\"\n    # validate form\n    if members is None and (head is None or tail is None):\n        raise ValueError(\"Provide members (undirected) OR head+tail (directed).\")\n    if members is not None and (head is not None or tail is not None):\n        raise ValueError(\"Use either members OR head+tail, not both.\")\n\n    if members is not None:\n        members = list(members)\n        if len(members) &lt; 2:\n            raise ValueError(\"Hyperedge needs &gt;=2 members.\")\n        directed = False if edge_directed is None else bool(edge_directed)\n        if directed:\n            raise ValueError(\"Directed=True requires head+tail, not members.\")\n    else:\n        head = list(head)\n        tail = list(tail)\n        if not head or not tail:\n            raise ValueError(\"Directed hyperedge needs non-empty head and tail.\")\n        if set(head) &amp; set(tail):\n            raise ValueError(\"head and tail must be disjoint.\")\n        directed = True if edge_directed is None else bool(edge_directed)\n        if not directed:\n            raise ValueError(\"Undirected=False conflicts with head/tail.\")\n\n    # set layer\n    layer = self._current_layer if layer is None else layer\n\n    # Intern frequently-used strings for cheaper dict ops\n    try:\n        import sys as _sys\n        if isinstance(layer, str): layer = _sys.intern(layer)\n        if isinstance(edge_id, str): edge_id = _sys.intern(edge_id)\n        if members is not None:\n            members = [ _sys.intern(u) if isinstance(u, str) else u for u in members ]\n        else:\n            head  = [ _sys.intern(u) if isinstance(u, str) else u for u in head ]\n            tail  = [ _sys.intern(v) if isinstance(v, str) else v for v in tail ]\n    except Exception:\n        pass\n\n    # locals for hot paths\n    entity_to_idx = self.entity_to_idx\n    layers = self._layers\n    M = self._matrix  # DOK\n\n    # ensure participants exist globally\n    def _ensure_entity(x):\n        if x in entity_to_idx:\n            return\n        if isinstance(x, str) and x.startswith(\"edge_\") and x in self.entity_types and self.entity_types[x] == \"edge\":\n            return\n        self.add_vertex(x, layer=layer)\n\n    if members is not None:\n        for u in members:\n            _ensure_entity(u)\n    else:\n        for u in head:\n            _ensure_entity(u)\n        for v in tail:\n            _ensure_entity(v)\n\n    # allocate edge id + column\n    if edge_id is None:\n        edge_id = self._get_next_edge_id()\n\n    is_new = edge_id not in self.edge_to_idx\n    if is_new:\n        col_idx = self._num_edges\n        self.edge_to_idx[edge_id] = col_idx\n        self.idx_to_edge[col_idx] = edge_id\n        self._num_edges += 1\n        self._grow_rows_to(self._num_entities)\n        self._grow_cols_to(self._num_edges)\n    else:\n        col_idx = self.edge_to_idx[edge_id]\n        # clear: delete only previously set cells instead of zeroing whole column\n        # handle prior hyperedge or binary edge reuse\n        prev_h = self.hyperedge_definitions.get(edge_id)\n        if prev_h is not None:\n            if prev_h.get(\"directed\", False):\n                rows_to_clear = prev_h[\"head\"] | prev_h[\"tail\"]\n            else:\n                rows_to_clear = prev_h[\"members\"]\n            for vid in rows_to_clear:\n                try:\n                    M[entity_to_idx[vid], col_idx] = 0\n                except KeyError:\n                    # vertex may not exist anymore; ignore\n                    pass\n        else:\n            # maybe it was a binary edge before\n            prev = self.edge_definitions.get(edge_id)\n            if prev is not None:\n                src, tgt, _ = prev\n                if src is not None:\n                    try:\n                        M[entity_to_idx[src], col_idx] = 0\n                    except KeyError:\n                        pass\n                if tgt is not None and tgt != src:\n                    try:\n                        M[entity_to_idx[tgt], col_idx] = 0\n                    except KeyError:\n                        pass\n\n    self._grow_rows_to(self._num_entities)\n\n    # write column entries\n    w = float(weight)\n    if members is not None:\n        # undirected: +w at each member\n        for u in members:\n            M[entity_to_idx[u], col_idx] = w\n        self.hyperedge_definitions[edge_id] = {\n            \"directed\": False,\n            \"members\": set(members),\n        }\n    else:\n        # directed: +w on head, -w on tail\n        for u in head:\n            M[entity_to_idx[u], col_idx] = w\n        mw = -w\n        for v in tail:\n            M[entity_to_idx[v], col_idx] = mw\n        self.hyperedge_definitions[edge_id] = {\n            \"directed\": True,\n            \"head\": set(head),\n            \"tail\": set(tail),\n        }\n\n    # bookkeeping shared with binary edges\n    self.edge_weights[edge_id] = w\n    self.edge_directed[edge_id] = bool(directed)\n    self.edge_kind[edge_id] = \"hyper\"\n    # keep a sentinel in edge_definitions so old code won't crash\n    self.edge_definitions[edge_id] = (None, None, \"hyper\")\n\n    # layer membership + per-layer vertices\n    if layer is not None:\n        if layer not in layers:\n            layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n        layers[layer][\"edges\"].add(edge_id)\n        if members is not None:\n            layers[layer][\"vertices\"].update(members)\n        else:\n            layers[layer][\"vertices\"].update(self.hyperedge_definitions[edge_id][\"head\"])\n            layers[layer][\"vertices\"].update(self.hyperedge_definitions[edge_id][\"tail\"])\n\n    # attributes\n    if attributes:\n        self.set_edge_attrs(edge_id, **attributes)\n\n    return edge_id\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_hyperedges_bulk","title":"<code>add_hyperedges_bulk(hyperedges, *, layer=None, default_weight=1.0, default_edge_directed=None)</code>","text":"<p>Bulk add/update hyperedges. Each item can be: - {'members': [...], 'edge_id': ..., 'weight': ..., 'layer': ..., 'attributes': {...}} - {'head': [...], 'tail': [...], ...} Behavior: identical to calling add_hyperedge() per item, but grows columns once and avoids full-column wipes.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_hyperedges_bulk(\n    self,\n    hyperedges,\n    *,\n    layer=None,\n    default_weight=1.0,\n    default_edge_directed=None,\n):\n    \"\"\"\n    Bulk add/update hyperedges.\n    Each item can be:\n    - {'members': [...], 'edge_id': ..., 'weight': ..., 'layer': ..., 'attributes': {...}}\n    - {'head': [...], 'tail': [...], ...}\n    Behavior: identical to calling add_hyperedge() per item, but grows columns once and avoids full-column wipes.\n    \"\"\"\n    layer = self._current_layer if layer is None else layer\n\n    items = []\n    for it in hyperedges:\n        if not isinstance(it, dict):\n            continue\n        d = dict(it)\n        d.setdefault(\"weight\", default_weight)\n        if \"layer\" not in d:\n            d[\"layer\"] = layer\n        if \"edge_directed\" not in d:\n            d[\"edge_directed\"] = default_edge_directed\n        items.append(d)\n\n    if not items:\n        return []\n\n    # Intern + coerce\n    try:\n        import sys as _sys\n        for d in items:\n            if \"members\" in d and d[\"members\"] is not None:\n                d[\"members\"] = [ _sys.intern(x) if isinstance(x, str) else x for x in d[\"members\"] ]\n            else:\n                d[\"head\"] = [ _sys.intern(x) if isinstance(x, str) else x for x in d.get(\"head\", []) ]\n                d[\"tail\"] = [ _sys.intern(x) if isinstance(x, str) else x for x in d.get(\"tail\", []) ]\n            lid = d.get(\"layer\")\n            if isinstance(lid, str): d[\"layer\"] = _sys.intern(lid)\n            eid = d.get(\"edge_id\")\n            if isinstance(eid, str): d[\"edge_id\"] = _sys.intern(eid)\n            try:\n                d[\"weight\"] = float(d[\"weight\"])\n            except Exception:\n                pass\n    except Exception:\n        pass\n\n    # Ensure participants exist (global)\n    for d in items:\n        if \"members\" in d and d[\"members\"] is not None:\n            for u in d[\"members\"]:\n                if u not in self.entity_to_idx:\n                    idx = self._num_entities\n                    self.entity_to_idx[u] = idx\n                    self.idx_to_entity[idx] = u\n                    self.entity_types[u] = \"vertex\"\n                    self._num_entities = idx + 1\n        else:\n            for u in d.get(\"head\", []):\n                if u not in self.entity_to_idx:\n                    idx = self._num_entities\n                    self.entity_to_idx[u] = idx\n                    self.idx_to_entity[idx] = u\n                    self.entity_types[u] = \"vertex\"\n                    self._num_entities = idx + 1\n            for v in d.get(\"tail\", []):\n                if v not in self.entity_to_idx:\n                    idx = self._num_entities\n                    self.entity_to_idx[v] = idx\n                    self.entity_types[v] = \"vertex\"\n                    self.idx_to_entity[idx] = v\n                    self._num_entities = idx + 1\n\n    # Grow rows once\n    self._grow_rows_to(self._num_entities)\n\n    # Pre-size columns\n    new_count = sum(1 for d in items if d.get(\"edge_id\") not in self.edge_to_idx)\n    if new_count:\n        self._grow_cols_to(self._num_edges + new_count)\n\n    M = self._matrix\n    out_ids = []\n\n    for d in items:\n        members = d.get(\"members\")\n        head = d.get(\"head\")\n        tail = d.get(\"tail\")\n        layer_local = d.get(\"layer\", layer)\n        w = float(d.get(\"weight\", default_weight))\n        e_id = d.get(\"edge_id\")\n\n        # Decide directedness from form unless forced\n        directed = d.get(\"edge_directed\")\n        if directed is None:\n            directed = (members is None)\n\n        # allocate/update column\n        if e_id is None:\n            e_id = self._get_next_edge_id()\n\n        if e_id in self.edge_to_idx:\n            col = self.edge_to_idx[e_id]\n            # clear old cells (binary or hyper)\n            if e_id in self.hyperedge_definitions:\n                h = self.hyperedge_definitions[e_id]\n                if h.get(\"members\"):\n                    rows = h[\"members\"]\n                else:\n                    rows = set(h.get(\"head\", ())) | set(h.get(\"tail\", ()))\n                for vid in rows:\n                    try:\n                        M[self.entity_to_idx[vid], col] = 0\n                    except Exception:\n                        pass\n            else:\n                old = self.edge_definitions.get(e_id)\n                if old is not None:\n                    os, ot, _ = old\n                    try:\n                        M[self.entity_to_idx[os], col] = 0\n                    except Exception:\n                        pass\n                    if ot is not None and ot != os:\n                        try:\n                            M[self.entity_to_idx[ot], col] = 0\n                        except Exception:\n                            pass\n        else:\n            col = self._num_edges\n            self.edge_to_idx[e_id] = col\n            self.idx_to_edge[col] = e_id\n            self._num_edges = col + 1\n\n        # write new column values + metadata\n        if members is not None:\n            for u in members:\n                M[self.entity_to_idx[u], col] = w\n            self.hyperedge_definitions[e_id] = {\"directed\": False, \"members\": set(members)}\n            self.edge_directed[e_id] = False\n            self.edge_kind[e_id] = \"hyper\"\n            self.edge_definitions[e_id] = (None, None, \"hyper\")\n        else:\n            for u in head:\n                M[self.entity_to_idx[u], col] = w\n            for v in tail:\n                M[self.entity_to_idx[v], col] = -w\n            self.hyperedge_definitions[e_id] = {\"directed\": True, \"head\": set(head), \"tail\": set(tail)}\n            self.edge_directed[e_id] = True\n            self.edge_kind[e_id] = \"hyper\"\n            self.edge_definitions[e_id] = (None, None, \"hyper\")\n\n        self.edge_weights[e_id] = w\n\n        # layer membership\n        if layer_local is not None:\n            if layer_local not in self._layers:\n                self._layers[layer_local] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n            self._layers[layer_local][\"edges\"].add(e_id)\n            if members is not None:\n                self._layers[layer_local][\"vertices\"].update(members)\n            else:\n                self._layers[layer_local][\"vertices\"].update(head)\n                self._layers[layer_local][\"vertices\"].update(tail)\n\n        # per-edge attributes (optional)\n        attrs = d.get(\"attributes\") or d.get(\"attrs\") or {}\n        if attrs:\n            self.set_edge_attrs(e_id, **attrs)\n\n        out_ids.append(e_id)\n\n    return out_ids\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_layer","title":"<code>add_layer(layer_id, **attributes)</code>","text":"<p>Create a new empty layer.</p>"},{"location":"reference/api/#graphglue.Graph.add_layer--parameters","title":"Parameters","text":"<p>layer_id : str     New layer identifier (ID). **attributes     Pure layer attributes to store (non-structural).</p>"},{"location":"reference/api/#graphglue.Graph.add_layer--returns","title":"Returns","text":"<p>str     The created layer ID.</p>"},{"location":"reference/api/#graphglue.Graph.add_layer--raises","title":"Raises","text":"<p>ValueError     If the layer already exists.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_layer(self, layer_id, **attributes):\n    \"\"\"\n    Create a new empty layer.\n\n    Parameters\n    ----------\n    layer_id : str\n        New layer identifier (ID).\n    **attributes\n        Pure layer attributes to store (non-structural).\n\n    Returns\n    -------\n    str\n        The created layer ID.\n\n    Raises\n    ------\n    ValueError\n        If the layer already exists.\n    \"\"\"\n    if layer_id in self._layers and layer_id != \"default\":\n        raise ValueError(f\"Layer {layer_id} already exists\")\n\n    self._layers[layer_id] = {\n        \"vertices\": set(),\n        \"edges\": set(),\n        \"attributes\": attributes\n    }\n    # Persist layer metadata to DF (pure attributes, upsert)\n    if attributes:\n        self.set_layer_attrs(layer_id, **attributes)\n    return layer_id\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_parallel_edge","title":"<code>add_parallel_edge(source, target, weight=1.0, **attributes)</code>","text":"<p>Add a parallel edge (same endpoints, different ID).</p>"},{"location":"reference/api/#graphglue.Graph.add_parallel_edge--parameters","title":"Parameters","text":"<p>source : str target : str weight : float, optional **attributes     Pure edge attributes.</p>"},{"location":"reference/api/#graphglue.Graph.add_parallel_edge--returns","title":"Returns","text":"<p>str     The new edge ID.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_parallel_edge(self, source, target, weight=1.0, **attributes):\n    \"\"\"\n    Add a parallel edge (same endpoints, different ID).\n\n    Parameters\n    ----------\n    source : str\n    target : str\n    weight : float, optional\n    **attributes\n        Pure edge attributes.\n\n    Returns\n    -------\n    str\n        The new edge ID.\n    \"\"\"\n    try:\n        import sys as _sys\n        if isinstance(source, str): source = _sys.intern(source)\n        if isinstance(target, str): target = _sys.intern(target)\n    except Exception:\n        pass\n\n    _add_edge = self.add_edge\n    return _add_edge(source, target, weight=weight, edge_id=None, **attributes)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_vertex","title":"<code>add_vertex(vertex_id, layer=None, **attributes)</code>","text":"<p>Add (or upsert) a vertex and optionally attach it to a layer.</p>"},{"location":"reference/api/#graphglue.Graph.add_vertex--parameters","title":"Parameters","text":"<p>vertex_id : str     vertex ID (must be unique across entities). layer : str, optional     Target layer. Defaults to the active layer. **attributes     Pure vertex attributes to store.</p>"},{"location":"reference/api/#graphglue.Graph.add_vertex--returns","title":"Returns","text":"<p>str     The vertex ID (echoed).</p>"},{"location":"reference/api/#graphglue.Graph.add_vertex--notes","title":"Notes","text":"<ul> <li>Ensures a row exists in the Polars DF [DataFrame] for attributes.</li> <li>Resizes the incidence matrix if needed.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_vertex(self, vertex_id, layer=None, **attributes):\n    \"\"\"\n    Add (or upsert) a vertex and optionally attach it to a layer.\n\n    Parameters\n    ----------\n    vertex_id : str\n        vertex ID (must be unique across entities).\n    layer : str, optional\n        Target layer. Defaults to the active layer.\n    **attributes\n        Pure vertex attributes to store.\n\n    Returns\n    -------\n    str\n        The vertex ID (echoed).\n\n    Notes\n    -----\n    - Ensures a row exists in the Polars DF [DataFrame] for attributes.\n    - Resizes the incidence matrix if needed.\n    \"\"\"\n    # Fast normalize to cut hashing/dup costs in dicts.\n    try:\n        import sys as _sys\n        if isinstance(vertex_id, str):\n            vertex_id = _sys.intern(vertex_id)\n        if layer is None:\n            layer = self._current_layer\n        elif isinstance(layer, str):\n            layer = _sys.intern(layer)\n    except Exception:\n        layer = layer or self._current_layer\n\n    entity_to_idx = self.entity_to_idx\n    idx_to_entity = self.idx_to_entity\n    entity_types = self.entity_types\n    M = self._matrix  # DOK\n\n    # Add to global superset if new\n    if vertex_id not in entity_to_idx:\n        idx = self._num_entities\n        entity_to_idx[vertex_id] = idx\n        idx_to_entity[idx] = vertex_id\n        entity_types[vertex_id] = \"vertex\"\n        self._num_entities = idx + 1\n\n        rows, cols = M.shape\n        if self._num_entities &gt; rows:\n            # geometric growth (\u22481.5x), minimum step 8 to avoid frequent resizes\n            new_rows = max(self._num_entities, rows + max(8, rows &gt;&gt; 1))\n            M.resize((new_rows, cols))\n\n    # Add to specified layer (create if needed)\n    layers = self._layers\n    if layer not in layers:\n        layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n    layers[layer][\"vertices\"].add(vertex_id)\n\n    # Ensure vertex_attributes has a row for this vertex (even with no attrs)\n    self._ensure_vertex_table()\n    self._ensure_vertex_row(vertex_id)\n\n    # Upsert passed attributes (if any)\n    if attributes:\n        self.vertex_attributes = self._upsert_row(self.vertex_attributes, vertex_id, attributes)\n\n    return vertex_id\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.add_vertices_bulk","title":"<code>add_vertices_bulk(vertices, layer=None)</code>","text":"<p>Bulk add vertices (and edge-entities if prefixed externally). Accepts: iterable of str  OR  iterable of (vertex_id, attrs_dict)  OR iterable of dicts with keys {'vertex_id', ...attrs} Behavior: identical to calling add_vertex() for each, but resizes once and batches attribute inserts.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def add_vertices_bulk(self, vertices, layer=None):\n    \"\"\"\n    Bulk add vertices (and edge-entities if prefixed externally).\n    Accepts: iterable of str  OR  iterable of (vertex_id, attrs_dict)  OR iterable of dicts with keys {'vertex_id', ...attrs}\n    Behavior: identical to calling add_vertex() for each, but resizes once and batches attribute inserts.\n    \"\"\"\n    import polars as pl\n\n    layer = layer or self._current_layer\n\n    # Normalize items -&gt; [(vid, attrs_dict), ...]\n    norm = []\n    for it in vertices:\n        if isinstance(it, dict):\n            vid = it.get(\"vertex_id\") or it.get(\"id\") or it.get(\"name\")\n            if vid is None:\n                continue\n            a = {k: v for k, v in it.items() if k not in (\"vertex_id\", \"id\", \"name\")}\n            norm.append((vid, a))\n        elif isinstance(it, (tuple, list)) and it:\n            vid = it[0]\n            a = (it[1] if len(it) &gt; 1 and isinstance(it[1], dict) else {})\n            norm.append((vid, a))\n        else:\n            norm.append((it, {}))\n\n    if not norm:\n        return\n\n    # Intern hot strings\n    try:\n        import sys as _sys\n        norm = [(_sys.intern(vid) if isinstance(vid, str) else vid, attrs) for vid, attrs in norm]\n        if isinstance(layer, str):\n            layer = _sys.intern(layer)\n    except Exception:\n        pass\n\n    # Create missing vertices without per-item resize thrash\n    new_rows = 0\n    for vid, _ in norm:\n        if vid not in self.entity_to_idx:\n            idx = self._num_entities\n            self.entity_to_idx[vid] = idx\n            self.idx_to_entity[idx] = vid\n            self.entity_types[vid] = \"vertex\"\n            self._num_entities = idx + 1\n            new_rows += 1\n\n    # Grow rows once if needed\n    if new_rows:\n        self._grow_rows_to(self._num_entities)\n\n    # Layer membership (same semantics as add_vertex)\n    if layer not in self._layers:\n        self._layers[layer] = {\"vertices\": set(), \"edges\": set(), \"attributes\": {}}\n    self._layers[layer][\"vertices\"].update(vid for vid, _ in norm)\n\n    # Vertex attributes (batch insert for new ones, upsert for existing with attrs)\n    self._ensure_vertex_table()\n    df = self.vertex_attributes\n\n    # Collect existing ids (if any)\n    existing_ids = set()\n    try:\n        if isinstance(df, pl.DataFrame) and df.height and \"vertex_id\" in df.columns:\n            existing_ids = set(df.get_column(\"vertex_id\").to_list())\n    except Exception:\n        pass\n\n    # Rows to append for ids missing in DF\n    to_append = []\n    for vid, attrs in norm:\n        if df.is_empty() or vid not in existing_ids:\n            row = {c: None for c in df.columns} if not df.is_empty() else {\"vertex_id\": None}\n            row[\"vertex_id\"] = vid\n            for k, v in attrs.items():\n                row[k] = v\n            to_append.append(row)\n\n    if to_append:\n        # Ensure df has any new columns first\n        need_cols = {k for row in to_append for k in row.keys() if k != \"vertex_id\"}\n        if need_cols:\n            df = self._ensure_attr_columns(df, {k: None for k in need_cols})\n\n        # Build add_df with full inference over the whole batch to avoid ComputeError\n        add_df = pl.DataFrame(\n            to_append,\n            infer_schema_length=len(to_append),\n            nan_to_null=True,\n            strict=False,\n        )\n\n        # Make sure all df columns exist on add_df\n        for c in df.columns:\n            if c not in add_df.columns:\n                add_df = add_df.with_columns(pl.lit(None).cast(df.schema[c]).alias(c))\n\n        # Dtype reconciliation (mirror _upsert_row semantics)\n        for c in df.columns:\n            lc, rc = df.schema[c], add_df.schema[c]\n            if lc == pl.Null and rc != pl.Null:\n                df = df.with_columns(pl.col(c).cast(rc))\n            elif rc == pl.Null and lc != pl.Null:\n                add_df = add_df.with_columns(pl.col(c).cast(lc).alias(c))\n            elif lc != rc:\n                # resolve mismatches by upcasting both to Utf8 (UTF-8 string)\n                df = df.with_columns(pl.col(c).cast(pl.Utf8))\n                add_df = add_df.with_columns(pl.col(c).cast(pl.Utf8).alias(c))\n\n        # Reorder columns EXACTLY to match df before vstack\n        add_df = add_df.select(df.columns)\n\n        df = df.vstack(add_df)\n\n    # Upsert attrs for existing ids (vector of updates via helper)\n    for vid, attrs in norm:\n        if attrs and (df.is_empty() or (vid in existing_ids)):\n            df = self._upsert_row(df, vid, attrs)\n\n    self.vertex_attributes = df\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.audit_attributes","title":"<code>audit_attributes()</code>","text":"<p>Audit attribute tables for extra/missing rows and invalid edge-layer pairs.</p>"},{"location":"reference/api/#graphglue.Graph.audit_attributes--returns","title":"Returns","text":"<p>dict     {     'extra_vertex_rows': list[str],     'extra_edge_rows': list[str],     'missing_vertex_rows': list[str],     'missing_edge_rows': list[str],     'invalid_edge_layer_rows': list[tuple[str, str]],     }</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def audit_attributes(self):\n    \"\"\"\n    Audit attribute tables for extra/missing rows and invalid edge-layer pairs.\n\n    Returns\n    -------\n    dict\n        {\n        'extra_vertex_rows': list[str],\n        'extra_edge_rows': list[str],\n        'missing_vertex_rows': list[str],\n        'missing_edge_rows': list[str],\n        'invalid_edge_layer_rows': list[tuple[str, str]],\n        }\n    \"\"\"\n    vertex_ids = {eid for eid, t in self.entity_types.items() if t == \"vertex\"}\n    edge_ids = set(self.edge_to_idx.keys())\n\n    na = self.vertex_attributes\n    ea = self.edge_attributes\n    ela = self.edge_layer_attributes\n\n    vertex_attr_ids = (\n        set(na.select(\"vertex_id\").to_series().to_list())\n        if isinstance(na, pl.DataFrame) and na.height &gt; 0 and \"vertex_id\" in na.columns\n        else set()\n    )\n    edge_attr_ids = (\n        set(ea.select(\"edge_id\").to_series().to_list())\n        if isinstance(ea, pl.DataFrame) and ea.height &gt; 0 and \"edge_id\" in ea.columns\n        else set()\n    )\n\n    extra_vertex_rows = [i for i in vertex_attr_ids if i not in vertex_ids]\n    extra_edge_rows = [i for i in edge_attr_ids if i not in edge_ids]\n    missing_vertex_rows = [i for i in vertex_ids if i not in vertex_attr_ids]\n    missing_edge_rows = [i for i in edge_ids if i not in edge_attr_ids]\n\n    bad_edge_layer = []\n    if isinstance(ela, pl.DataFrame) and ela.height &gt; 0 and {\"layer_id\", \"edge_id\"} &lt;= set(ela.columns):\n        for lid, eid in ela.select([\"layer_id\", \"edge_id\"]).iter_rows():\n            if lid not in self._layers or eid not in edge_ids:\n                bad_edge_layer.append((lid, eid))\n\n    return {\n        \"extra_vertex_rows\": extra_vertex_rows,\n        \"extra_edge_rows\": extra_edge_rows,\n        \"missing_vertex_rows\": missing_vertex_rows,\n        \"missing_edge_rows\": missing_edge_rows,\n        \"invalid_edge_layer_rows\": bad_edge_layer,\n    }\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.clear_history","title":"<code>clear_history()</code>","text":"<p>Clear the in-memory mutation log.</p>"},{"location":"reference/api/#graphglue.Graph.clear_history--returns","title":"Returns","text":"<p>None</p>"},{"location":"reference/api/#graphglue.Graph.clear_history--notes","title":"Notes","text":"<p>This does not delete any files previously exported.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def clear_history(self):\n    \"\"\"\n    Clear the in-memory mutation log.\n\n    Returns\n    -------\n    None\n\n    Notes\n    -----\n    This does not delete any files previously exported.\n    \"\"\"\n    self._history.clear()\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.conserved_edges","title":"<code>conserved_edges(min_layers=2, include_default=False)</code>","text":"<p>Edges present in at least <code>min_layers</code> layers.</p>"},{"location":"reference/api/#graphglue.Graph.conserved_edges--parameters","title":"Parameters","text":"<p>min_layers : int, optional include_default : bool, optional</p>"},{"location":"reference/api/#graphglue.Graph.conserved_edges--returns","title":"Returns","text":"<p>dict[str, int]     <code>{edge_id: count}</code>.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def conserved_edges(self, min_layers=2, include_default=False):\n    \"\"\"\n    Edges present in at least ``min_layers`` layers.\n\n    Parameters\n    ----------\n    min_layers : int, optional\n    include_default : bool, optional\n\n    Returns\n    -------\n    dict[str, int]\n        ``{edge_id: count}``.\n    \"\"\"\n    layers_to_check = self.get_layers_dict(include_default=include_default)  # hides 'default' by default\n    edge_counts = {}\n    for _, layer_data in layers_to_check.items():\n        for eid in layer_data[\"edges\"]:\n            edge_counts[eid] = edge_counts.get(eid, 0) + 1\n    return {eid: c for eid, c in edge_counts.items() if c &gt;= min_layers}\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.copy","title":"<code>copy()</code>","text":"<p>Deep copy the entire graph, including layers, edges, hyperedges, and attributes. (Behavior preserved; uses preallocation + vectorized attr extraction.)</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def copy(self):\n    \"\"\"\n    Deep copy the entire graph, including layers, edges, hyperedges, and attributes.\n    (Behavior preserved; uses preallocation + vectorized attr extraction.)\n    \"\"\"\n    import polars as pl\n\n    # Preallocate with current sizes\n    new_graph = Graph(directed=self.directed, n=self._num_entities, e=self._num_edges)\n\n    # Copy layers &amp; their pure attributes ----\n    for lid, meta in self._layers.items():\n        if lid != new_graph._default_layer:\n            new_graph.add_layer(lid, **meta[\"attributes\"])\n        else:\n            # default layer exists; mirror its attributes too\n            if meta[\"attributes\"]:\n                new_graph.set_layer_attrs(lid, **meta[\"attributes\"])\n\n    # Build attribute rows once (no per-row filters)\n    if isinstance(self.vertex_attributes, pl.DataFrame) and self.vertex_attributes.height and \"vertex_id\" in self.vertex_attributes.columns:\n        vmap = {d.pop(\"vertex_id\"): d for d in self.vertex_attributes.to_dicts()}\n    else:\n        vmap = {}\n\n    # Split entities by type to preserve typing\n    vertex_rows = []\n    edge_entity_rows = []\n    for ent_id, etype in self.entity_types.items():\n        row = {\"vertex_id\": ent_id}\n        row.update(vmap.get(ent_id, {}))\n        if etype == \"vertex\":\n            vertex_rows.append(row)\n        else:\n            # entity_types[...] == \"edge\" \u2192 edge-entity\n            edge_entity_rows.append({\"edge_entity_id\": ent_id, **vmap.get(ent_id, {})})\n\n    # Add entities with correct type APIs (bulk)\n    if vertex_rows:\n        new_graph.add_vertices_bulk(vertex_rows, layer=new_graph._default_layer)\n    if edge_entity_rows:\n        # attributes for edge-entities live in the same vertex_attributes table\n        new_graph.add_edge_entities_bulk(edge_entity_rows, layer=new_graph._default_layer)\n\n    # Binary / vertex-edge edges\n    bin_payload = []\n    for edge_id, (source, target, edge_type) in self.edge_definitions.items():\n        if edge_type == \"hyper\":\n            continue\n        bin_payload.append({\n            \"source\": source, \"target\": target, \"edge_id\": edge_id,\n            \"edge_type\": edge_type,    # 'regular' or 'vertex_edge'\n            \"edge_directed\": self.edge_directed.get(edge_id, self.directed),\n            \"weight\": self.edge_weights.get(edge_id, 1.0),\n            \"attributes\": (self._row_attrs(self.edge_attributes, \"edge_id\", edge_id) or {}),\n        })\n    if bin_payload:\n        new_graph.add_edges_bulk(bin_payload, layer=new_graph._default_layer)\n\n    # Hyperedges\n    hyper_payload = []\n    for eid, hdef in self.hyperedge_definitions.items():\n        base = {\n            \"edge_id\": eid,\n            \"weight\": self.edge_weights.get(eid, 1.0),\n            \"attributes\": (self._row_attrs(self.edge_attributes, \"edge_id\", eid) or {}),\n        }\n        if hdef.get(\"members\"):\n            hyper_payload.append({**base, \"members\": list(hdef[\"members\"])})\n        else:\n            hyper_payload.append({**base, \"head\": list(hdef.get(\"head\", ())), \"tail\": list(hdef.get(\"tail\", ()))})\n    if hyper_payload:\n        new_graph.add_hyperedges_bulk(hyper_payload, layer=new_graph._default_layer)\n\n    # Copy layer memberships\n    for lid, meta in self._layers.items():\n        if lid not in new_graph._layers:\n            new_graph.add_layer(lid)\n        new_graph._layers[lid][\"vertices\"] = set(meta[\"vertices\"])\n        new_graph._layers[lid][\"edges\"] = set(meta[\"edges\"])\n\n    # Copy edge-layer attributes + legacy weight dict\n    if isinstance(self.edge_layer_attributes, pl.DataFrame):\n        new_graph.edge_layer_attributes = self.edge_layer_attributes.clone()\n    else:\n        new_graph.edge_layer_attributes = self.edge_layer_attributes\n\n    from collections import defaultdict\n    new_graph.layer_edge_weights = defaultdict(dict, {lid: dict(m) for lid, m in self.layer_edge_weights.items()})\n\n    return new_graph\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.create_aggregated_layer","title":"<code>create_aggregated_layer(source_layer_ids, target_layer_id, method='union', weight_func=None, **attributes)</code>","text":"<p>Create a new layer by aggregating multiple source layers.</p>"},{"location":"reference/api/#graphglue.Graph.create_aggregated_layer--parameters","title":"Parameters","text":"<p>source_layer_ids : list[str] target_layer_id : str method : {'union', 'intersection'}, optional weight_func : callable, optional     Reserved for future weight merging logic (currently unused). **attributes     Pure layer attributes.</p>"},{"location":"reference/api/#graphglue.Graph.create_aggregated_layer--returns","title":"Returns","text":"<p>str     The created layer ID.</p>"},{"location":"reference/api/#graphglue.Graph.create_aggregated_layer--raises","title":"Raises","text":"<p>ValueError     For unknown methods or missing source layers, or if target exists.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def create_aggregated_layer(self, source_layer_ids, target_layer_id, method='union', \n                        weight_func=None, **attributes):\n    \"\"\"\n    Create a new layer by aggregating multiple source layers.\n\n    Parameters\n    ----------\n    source_layer_ids : list[str]\n    target_layer_id : str\n    method : {'union', 'intersection'}, optional\n    weight_func : callable, optional\n        Reserved for future weight merging logic (currently unused).\n    **attributes\n        Pure layer attributes.\n\n    Returns\n    -------\n    str\n        The created layer ID.\n\n    Raises\n    ------\n    ValueError\n        For unknown methods or missing source layers, or if target exists.\n    \"\"\"\n    if not source_layer_ids:\n        raise ValueError(\"Must specify at least one source layer\")\n\n    if target_layer_id in self._layers:\n        raise ValueError(f\"Target layer {target_layer_id} already exists\")\n\n    if method == 'union':\n        result = self.layer_union(source_layer_ids)\n    elif method == 'intersection':\n        result = self.layer_intersection(source_layer_ids)\n    else:\n        raise ValueError(f\"Unknown aggregation method: {method}\")\n\n    return self.create_layer_from_operation(target_layer_id, result, **attributes)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.create_layer_from_operation","title":"<code>create_layer_from_operation(result_layer_id, operation_result, **attributes)</code>","text":"<p>Create a new layer from the result of a set operation.</p>"},{"location":"reference/api/#graphglue.Graph.create_layer_from_operation--parameters","title":"Parameters","text":"<p>result_layer_id : str operation_result : dict     Output of <code>layer_union</code>/<code>layer_intersection</code>/<code>layer_difference</code>. **attributes     Pure layer attributes.</p>"},{"location":"reference/api/#graphglue.Graph.create_layer_from_operation--returns","title":"Returns","text":"<p>str     The created layer ID.</p>"},{"location":"reference/api/#graphglue.Graph.create_layer_from_operation--raises","title":"Raises","text":"<p>ValueError     If the target layer already exists.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def create_layer_from_operation(self, result_layer_id, operation_result, **attributes):\n    \"\"\"\n    Create a new layer from the result of a set operation.\n\n    Parameters\n    ----------\n    result_layer_id : str\n    operation_result : dict\n        Output of ``layer_union``/``layer_intersection``/``layer_difference``.\n    **attributes\n        Pure layer attributes.\n\n    Returns\n    -------\n    str\n        The created layer ID.\n\n    Raises\n    ------\n    ValueError\n        If the target layer already exists.\n    \"\"\"\n    if result_layer_id in self._layers:\n        raise ValueError(f\"Layer {result_layer_id} already exists\")\n\n    self._layers[result_layer_id] = {\n        \"vertices\": operation_result[\"vertices\"].copy(),\n        \"edges\": operation_result[\"edges\"].copy(), \n        \"attributes\": attributes\n    }\n\n    return result_layer_id\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.degree","title":"<code>degree(entity_id)</code>","text":"<p>Degree of a vertex or edge-entity (number of incident non-zero entries).</p>"},{"location":"reference/api/#graphglue.Graph.degree--parameters","title":"Parameters","text":"<p>entity_id : str</p>"},{"location":"reference/api/#graphglue.Graph.degree--returns","title":"Returns","text":"<p>int</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def degree(self, entity_id):\n    \"\"\"\n    Degree of a vertex or edge-entity (number of incident non-zero entries).\n\n    Parameters\n    ----------\n    entity_id : str\n\n    Returns\n    -------\n    int\n    \"\"\"\n    if entity_id not in self.entity_to_idx:\n        return 0\n\n    entity_idx = self.entity_to_idx[entity_id]\n    row = self._matrix.getrow(entity_idx)\n    return len(row.nonzero()[1])\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.diff","title":"<code>diff(a, b=None)</code>","text":"<p>Compare two snapshots or compare snapshot with current state.</p>"},{"location":"reference/api/#graphglue.Graph.diff--parameters","title":"Parameters","text":"<p>a : str | dict | Graph     First snapshot (label, snapshot dict, or Graph instance) b : str | dict | Graph | None     Second snapshot. If None, compare with current state.</p>"},{"location":"reference/api/#graphglue.Graph.diff--returns","title":"Returns","text":"<p>GraphDiff     Difference object with added/removed entities</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def diff(self, a, b=None):\n    \"\"\"\n    Compare two snapshots or compare snapshot with current state.\n\n    Parameters\n    ----------\n    a : str | dict | Graph\n        First snapshot (label, snapshot dict, or Graph instance)\n    b : str | dict | Graph | None\n        Second snapshot. If None, compare with current state.\n\n    Returns\n    -------\n    GraphDiff\n        Difference object with added/removed entities\n    \"\"\"\n    snap_a = self._resolve_snapshot(a)\n    snap_b = self._resolve_snapshot(b) if b is not None else self._current_snapshot()\n\n    return GraphDiff(snap_a, snap_b)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.edge_list","title":"<code>edge_list()</code>","text":"<p>Materialize (source, target, edge_id, weight) for binary/vertex-edge edges.</p>"},{"location":"reference/api/#graphglue.Graph.edge_list--returns","title":"Returns","text":"<p>list[tuple[str, str, str, float]]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def edge_list(self):\n    \"\"\"\n    Materialize (source, target, edge_id, weight) for binary/vertex-edge edges.\n\n    Returns\n    -------\n    list[tuple[str, str, str, float]]\n    \"\"\"\n    edges = []\n    for edge_id, (source, target, edge_type) in self.edge_definitions.items():\n        weight = self.edge_weights[edge_id]\n        edges.append((source, target, edge_id, weight))\n    return edges\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.edge_presence_across_layers","title":"<code>edge_presence_across_layers(edge_id=None, source=None, target=None, *, include_default=False, undirected_match=None)</code>","text":"<p>Locate where an edge exists across layers.</p>"},{"location":"reference/api/#graphglue.Graph.edge_presence_across_layers--parameters","title":"Parameters","text":"<p>edge_id : str, optional     If provided, match by ID (any kind: binary/vertex-edge/hyper). source : str, optional     When used with <code>target</code>, match only binary/vertex-edge edges by endpoints. target : str, optional include_default : bool, optional     Include the internal default layer in the search. undirected_match : bool, optional     When endpoint matching, allow undirected symmetric matches.</p>"},{"location":"reference/api/#graphglue.Graph.edge_presence_across_layers--returns","title":"Returns","text":"<p>list[str] or dict[str, list[str]]     If <code>edge_id</code> given: list of layer IDs.     Else: <code>{layer_id: [edge_id, ...]}</code>.</p>"},{"location":"reference/api/#graphglue.Graph.edge_presence_across_layers--raises","title":"Raises","text":"<p>ValueError     If both modes (ID and endpoints) are provided or neither is valid.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def edge_presence_across_layers(\n    self,\n    edge_id: str | None = None,\n    source: str | None = None,\n    target: str | None = None,\n    *,\n    include_default: bool = False,\n    undirected_match: bool | None = None\n):\n    \"\"\"\n    Locate where an edge exists across layers.\n\n    Parameters\n    ----------\n    edge_id : str, optional\n        If provided, match by ID (any kind: binary/vertex-edge/hyper).\n    source : str, optional\n        When used with ``target``, match only binary/vertex-edge edges by endpoints.\n    target : str, optional\n    include_default : bool, optional\n        Include the internal default layer in the search.\n    undirected_match : bool, optional\n        When endpoint matching, allow undirected symmetric matches.\n\n    Returns\n    -------\n    list[str] or dict[str, list[str]]\n        If ``edge_id`` given: list of layer IDs.\n        Else: ``{layer_id: [edge_id, ...]}``.\n\n    Raises\n    ------\n    ValueError\n        If both modes (ID and endpoints) are provided or neither is valid.\n    \"\"\"\n    has_id = edge_id is not None\n    has_pair = (source is not None) and (target is not None)\n    if has_id == has_pair:\n        raise ValueError(\"Provide either edge_id OR (source and target), but not both.\")\n\n    layers_view = self.get_layers_dict(include_default=include_default)\n\n    if has_id:\n        return [lid for lid, ldata in layers_view.items() if edge_id in ldata[\"edges\"]]\n\n    if undirected_match is None:\n        undirected_match = False\n\n    out: dict[str, list[str]] = {}\n    for lid, ldata in layers_view.items():\n        matches = []\n        for eid in ldata[\"edges\"]:\n            # skip hyper-edges for (source,target) mode\n            if self.edge_kind.get(eid) == \"hyper\":\n                continue\n            s, t, _ = self.edge_definitions[eid]\n            edge_is_directed = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n            if s == source and t == target:\n                matches.append(eid)\n            elif undirected_match and not edge_is_directed and s == target and t == source:\n                matches.append(eid)\n        if matches:\n            out[lid] = matches\n    return out\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.edge_subgraph","title":"<code>edge_subgraph(edges)</code>","text":"<p>Create a new graph containing only a specified subset of edges.</p>"},{"location":"reference/api/#graphglue.Graph.edge_subgraph--parameters","title":"Parameters","text":"<p>edges : Iterable[str] | Iterable[int]     Edge identifiers (strings) or edge indices (integers) to retain     in the subgraph.</p>"},{"location":"reference/api/#graphglue.Graph.edge_subgraph--returns","title":"Returns","text":"<p>Graph     A new <code>Graph</code> instance containing only the selected edges and the     vertices incident to them.</p>"},{"location":"reference/api/#graphglue.Graph.edge_subgraph--behavior","title":"Behavior","text":"<ul> <li>Copies the current graph and deletes all edges not in the provided set.</li> <li>Optionally, you can prune orphaned vertices (i.e., vertices not incident to any remaining edge) \u2014 this is generally recommended for consistency.</li> </ul>"},{"location":"reference/api/#graphglue.Graph.edge_subgraph--notes","title":"Notes","text":"<ul> <li>Attributes associated with remaining edges and vertices are preserved.</li> <li>Hyperedges are supported: if a hyperedge is in the provided set, all its members are retained.</li> <li>If <code>edges</code> is empty, the resulting graph will be empty except for any isolated vertices that remain.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def edge_subgraph(self, edges) -&gt; \"Graph\":\n    \"\"\"\n    Create a new graph containing only a specified subset of edges.\n\n    Parameters\n    ----------\n    edges : Iterable[str] | Iterable[int]\n        Edge identifiers (strings) or edge indices (integers) to retain\n        in the subgraph.\n\n    Returns\n    -------\n    Graph\n        A new `Graph` instance containing only the selected edges and the\n        vertices incident to them.\n\n    Behavior\n    --------\n    - Copies the current graph and deletes all edges **not** in the provided set.\n    - Optionally, you can prune orphaned vertices (i.e., vertices not incident\n    to any remaining edge) \u2014 this is generally recommended for consistency.\n\n    Notes\n    -----\n    - Attributes associated with remaining edges and vertices are preserved.\n    - Hyperedges are supported: if a hyperedge is in the provided set, all\n    its members are retained.\n    - If `edges` is empty, the resulting graph will be empty except for\n    any isolated vertices that remain.\n    \"\"\"        \n    # normalize to edge_id set\n    if all(isinstance(e, int) for e in edges):\n        E = {self.idx_to_edge[e] for e in edges}\n    else:\n        E = set(edges)\n\n    # collect incident vertices and partition edges\n    V = set()\n    bin_payload, hyper_payload = [], []\n    for eid in E:\n        kind = self.edge_kind.get(eid, \"binary\")\n        if kind == \"hyper\":\n            h = self.hyperedge_definitions[eid]\n            if h.get(\"members\"):\n                V.update(h[\"members\"])\n                hyper_payload.append({\"members\": list(h[\"members\"]), \"edge_id\": eid,\n                                    \"weight\": self.edge_weights.get(eid, 1.0)})\n            else:\n                V.update(h.get(\"head\", ())); V.update(h.get(\"tail\", ()))\n                hyper_payload.append({\"head\": list(h.get(\"head\", ())),\n                                    \"tail\": list(h.get(\"tail\", ())),\n                                    \"edge_id\": eid, \"weight\": self.edge_weights.get(eid, 1.0)})\n        else:\n            s, t, etype = self.edge_definitions[eid]\n            V.add(s); V.add(t)\n            bin_payload.append({\"source\": s, \"target\": t, \"edge_id\": eid,\n                                \"edge_type\": etype,\n                                \"edge_directed\": self.edge_directed.get(eid, True if self.directed is None else self.directed),\n                                \"weight\": self.edge_weights.get(eid, 1.0)})\n\n    # new graph prealloc\n    g = Graph(directed=self.directed, n=len(V), e=len(E))\n    # vertices with attrs\n    v_rows = [{\"vertex_id\": v, **(self._row_attrs(self.vertex_attributes, \"vertex_id\", v) or {})} for v in V]\n    g.add_vertices_bulk(v_rows, layer=g._default_layer)\n\n    # edges\n    if bin_payload:\n        g.add_edges_bulk(bin_payload, layer=g._default_layer)\n    if hyper_payload:\n        g.add_hyperedges_bulk(hyper_payload, layer=g._default_layer)\n\n    # copy layer memberships for retained edges &amp; incident vertices\n    for lid, meta in self._layers.items():\n        g.add_layer(lid, **meta[\"attributes\"])\n        kept_edges = set(meta[\"edges\"]) &amp; E\n        if kept_edges:\n            g.add_edges_to_layer_bulk(lid, kept_edges)\n\n    return g\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.edges","title":"<code>edges()</code>","text":"<p>Get all edge IDs.</p>"},{"location":"reference/api/#graphglue.Graph.edges--returns","title":"Returns","text":"<p>list[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def edges(self):\n    \"\"\"\n    Get all edge IDs.\n\n    Returns\n    -------\n    list[str]\n    \"\"\"\n    return list(self.edge_to_idx.keys())\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.edges_view","title":"<code>edges_view(layer=None, include_directed=True, include_weight=True, resolved_weight=True, copy=True)</code>","text":"<p>Build a Polars DF [DataFrame] view of edges with optional layer join. Same columns/semantics as before, but vectorized (no per-edge DF scans).</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def edges_view(self, layer=None, include_directed=True, include_weight=True, resolved_weight=True, copy=True):\n    \"\"\"\n    Build a Polars DF [DataFrame] view of edges with optional layer join.\n    Same columns/semantics as before, but vectorized (no per-edge DF scans).\n    \"\"\"\n    # Fast path: no edges\n    if not self.edge_to_idx:\n        return pl.DataFrame(schema={\"edge_id\": pl.Utf8, \"kind\": pl.Utf8})\n\n    eids = list(self.edge_to_idx.keys())\n    kinds = [self.edge_kind.get(eid, \"binary\") for eid in eids]\n\n    # columns we might need\n    need_global = include_weight or resolved_weight\n    global_w = [self.edge_weights.get(eid, None) for eid in eids] if need_global else None\n    dirs = [self.edge_directed.get(eid, True if self.directed is None else self.directed) for eid in eids] if include_directed else None\n\n    # endpoints / hyper metadata (one pass; no weight lookups)\n    src, tgt, etype = [], [], []\n    head, tail, members = [], [], []\n    for eid, k in zip(eids, kinds):\n        if k == \"hyper\":\n            # hyperedge: store sets in canonical sorted tuples\n            h = self.hyperedge_definitions[eid]\n            if h.get(\"directed\", False):\n                head.append(tuple(sorted(h.get(\"head\", ()))))\n                tail.append(tuple(sorted(h.get(\"tail\", ()))))\n                members.append(None)\n            else:\n                head.append(None)\n                tail.append(None)\n                members.append(tuple(sorted(h.get(\"members\", ()))))\n            src.append(None); tgt.append(None); etype.append(None)\n        else:\n            s, t, et = self.edge_definitions[eid]\n            src.append(s); tgt.append(t); etype.append(et)\n            head.append(None); tail.append(None); members.append(None)\n\n    # base frame\n    cols = {\"edge_id\": eids, \"kind\": kinds}\n    if include_directed: cols[\"directed\"] = dirs\n    if include_weight:   cols[\"global_weight\"] = global_w\n    # we still need global weight transiently to compute effective weight even if not displayed\n    if resolved_weight and not include_weight: cols[\"_gw_tmp\"] = global_w\n\n    base = pl.DataFrame(cols).with_columns(\n        pl.Series(\"source\", src, dtype=pl.Utf8),\n        pl.Series(\"target\", tgt, dtype=pl.Utf8),\n        pl.Series(\"edge_type\", etype, dtype=pl.Utf8),\n        pl.Series(\"head\", head, dtype=pl.List(pl.Utf8)),\n        pl.Series(\"tail\", tail, dtype=pl.List(pl.Utf8)),\n        pl.Series(\"members\", members, dtype=pl.List(pl.Utf8)),\n    )\n\n    # join pure edge attributes (left)\n    if isinstance(self.edge_attributes, pl.DataFrame) and self.edge_attributes.height &gt; 0:\n        out = base.join(self.edge_attributes, on=\"edge_id\", how=\"left\")\n    else:\n        out = base\n\n    # join layer-specific attributes once, then compute resolved weight vectorized\n    if layer is not None and isinstance(self.edge_layer_attributes, pl.DataFrame) and self.edge_layer_attributes.height &gt; 0:\n        layer_slice = (\n            self.edge_layer_attributes\n            .filter(pl.col(\"layer_id\") == layer)\n            .drop(\"layer_id\")\n        )\n        if layer_slice.height &gt; 0:\n            # prefix non-key columns -&gt; layer_*\n            rename_map = {c: f\"layer_{c}\" for c in layer_slice.columns if c not in {\"edge_id\"}}\n            if rename_map:\n                layer_slice = layer_slice.rename(rename_map)\n            out = out.join(layer_slice, on=\"edge_id\", how=\"left\")\n\n    # add effective_weight without per-edge function calls\n    if resolved_weight:\n        gw_col = \"global_weight\" if include_weight else \"_gw_tmp\"\n        lw_col = \"layer_weight\" if (\"layer_weight\" in out.columns) else None\n        if lw_col:\n            out = out.with_columns(\n                pl.coalesce([pl.col(lw_col), pl.col(gw_col)]).alias(\"effective_weight\")\n            )\n        else:\n            out = out.with_columns(pl.col(gw_col).alias(\"effective_weight\"))\n\n        # drop temp global if it wasn't requested explicitly\n        if not include_weight and \"_gw_tmp\" in out.columns:\n            out = out.drop(\"_gw_tmp\")\n\n    return out.clone() if copy else out\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.enable_history","title":"<code>enable_history(flag=True)</code>","text":"<p>Enable or disable in-memory mutation logging.</p>"},{"location":"reference/api/#graphglue.Graph.enable_history--parameters","title":"Parameters","text":"<p>flag : bool, default True     When True, start/continue logging; when False, pause logging.</p>"},{"location":"reference/api/#graphglue.Graph.enable_history--returns","title":"Returns","text":"<p>None</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def enable_history(self, flag: bool = True):\n    \"\"\"\n    Enable or disable in-memory mutation logging.\n\n    Parameters\n    ----------\n    flag : bool, default True\n        When True, start/continue logging; when False, pause logging.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    self._history_enabled = bool(flag)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.export_history","title":"<code>export_history(path)</code>","text":"<p>Write the mutation history to disk.</p>"},{"location":"reference/api/#graphglue.Graph.export_history--parameters","title":"Parameters","text":"<p>path : str     Output path. Supported extensions: '.parquet', '.ndjson' (a.k.a. '.jsonl'),     '.json', '.csv'. Unknown extensions default to Parquet by appending '.parquet'.</p>"},{"location":"reference/api/#graphglue.Graph.export_history--returns","title":"Returns","text":"<p>int     Number of events written. Returns 0 if the history is empty.</p>"},{"location":"reference/api/#graphglue.Graph.export_history--raises","title":"Raises","text":"<p>OSError     If the file cannot be written.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def export_history(self, path: str):\n    \"\"\"\n    Write the mutation history to disk.\n\n    Parameters\n    ----------\n    path : str\n        Output path. Supported extensions: '.parquet', '.ndjson' (a.k.a. '.jsonl'),\n        '.json', '.csv'. Unknown extensions default to Parquet by appending '.parquet'.\n\n    Returns\n    -------\n    int\n        Number of events written. Returns 0 if the history is empty.\n\n    Raises\n    ------\n    OSError\n        If the file cannot be written.\n    \"\"\"\n    if not self._history:\n        return 0\n    df = pl.DataFrame(self._history)\n    p = path.lower()\n    if p.endswith(\".parquet\"):\n        df.write_parquet(path);  return len(df)\n    if p.endswith(\".ndjson\") or p.endswith(\".jsonl\"):\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            for r in df.iter_rows(named=True):\n                import json\n                f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n        return len(df)\n    if p.endswith(\".json\"):\n        import json\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(df.to_dicts(), f, ensure_ascii=False)\n        return len(df)\n    if p.endswith(\".csv\"):\n        df.write_csv(path); return len(df)\n    # Default to Parquet if unknown\n    df.write_parquet(path + \".parquet\"); return len(df)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.extract_subgraph","title":"<code>extract_subgraph(vertices=None, edges=None)</code>","text":"<p>Create a subgraph based on a combination of vertex and/or edge filters.</p>"},{"location":"reference/api/#graphglue.Graph.extract_subgraph--parameters","title":"Parameters","text":"<p>vertices : Iterable[str] | None, optional     A set of vertex IDs to include. If provided, behaves like <code>subgraph()</code>.     If <code>None</code>, no vertex filtering is applied. edges : Iterable[str] | Iterable[int] | None, optional     A set of edge IDs or indices to include. If provided, behaves like     <code>edge_subgraph()</code>. If <code>None</code>, no edge filtering is applied.</p>"},{"location":"reference/api/#graphglue.Graph.extract_subgraph--returns","title":"Returns","text":"<p>Graph     A new <code>Graph</code> filtered according to the provided vertex and/or edge     sets.</p>"},{"location":"reference/api/#graphglue.Graph.extract_subgraph--behavior","title":"Behavior","text":"<ul> <li>If both <code>vertices</code> and <code>edges</code> are provided, the resulting subgraph is the intersection of the two filters.</li> <li>If only <code>vertices</code> is provided, equivalent to <code>subgraph(vertices)</code>.</li> <li>If only <code>edges</code> is provided, equivalent to <code>edge_subgraph(edges)</code>.</li> <li>If neither is provided, a full copy of the graph is returned.</li> </ul>"},{"location":"reference/api/#graphglue.Graph.extract_subgraph--notes","title":"Notes","text":"<ul> <li>This is a convenience method; it delegates to <code>subgraph()</code> and <code>edge_subgraph()</code> internally.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def extract_subgraph(self, vertices=None, edges=None) -&gt; \"Graph\":\n\n    \"\"\"\n    Create a subgraph based on a combination of vertex and/or edge filters.\n\n    Parameters\n    ----------\n    vertices : Iterable[str] | None, optional\n        A set of vertex IDs to include. If provided, behaves like `subgraph()`.\n        If `None`, no vertex filtering is applied.\n    edges : Iterable[str] | Iterable[int] | None, optional\n        A set of edge IDs or indices to include. If provided, behaves like\n        `edge_subgraph()`. If `None`, no edge filtering is applied.\n\n    Returns\n    -------\n    Graph\n        A new `Graph` filtered according to the provided vertex and/or edge\n        sets.\n\n    Behavior\n    --------\n    - If both `vertices` and `edges` are provided, the resulting subgraph is\n    the intersection of the two filters.\n    - If only `vertices` is provided, equivalent to `subgraph(vertices)`.\n    - If only `edges` is provided, equivalent to `edge_subgraph(edges)`.\n    - If neither is provided, a full copy of the graph is returned.\n\n    Notes\n    -----\n    - This is a convenience method; it delegates to `subgraph()` and\n    `edge_subgraph()` internally.\n    \"\"\"    \n    if vertices is None and edges is None:\n        return self.copy()\n\n    if edges is not None:\n        if all(isinstance(e, int) for e in edges):\n            E = {self.idx_to_edge[e] for e in edges}\n        else:\n            E = set(edges)\n    else:\n        E = None\n\n    V = set(vertices) if vertices is not None else None\n\n    # If only one filter, delegate to optimized path\n    if V is not None and E is None:\n        return self.subgraph(V)\n    if V is None and E is not None:\n        return self.edge_subgraph(E)\n\n    # Both filters: keep only edges in E whose endpoints (or members) lie in V\n    kept_edges = set()\n    kept_vertices = set(V)\n    for eid in E:\n        kind = self.edge_kind.get(eid, \"binary\")\n        if kind == \"hyper\":\n            h = self.hyperedge_definitions[eid]\n            if h.get(\"members\"):\n                if set(h[\"members\"]).issubset(V):\n                    kept_edges.add(eid)\n            else:\n                if set(h.get(\"head\", ())).issubset(V) and set(h.get(\"tail\", ())).issubset(V):\n                    kept_edges.add(eid)\n        else:\n            s, t, _ = self.edge_definitions[eid]\n            if s in V and t in V:\n                kept_edges.add(eid)\n\n    return self.edge_subgraph(kept_edges).subgraph(kept_vertices)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_active_layer","title":"<code>get_active_layer()</code>","text":"<p>Get the currently active layer ID.</p>"},{"location":"reference/api/#graphglue.Graph.get_active_layer--returns","title":"Returns","text":"<p>str     Active layer ID.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_active_layer(self):\n    \"\"\"\n    Get the currently active layer ID.\n\n    Returns\n    -------\n    str\n        Active layer ID.\n    \"\"\"\n    return self._current_layer\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_attr_edge","title":"<code>get_attr_edge(edge_id, key, default=None)</code>","text":"<p>Get a single edge attribute (scalar) or default if missing.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_edge--parameters","title":"Parameters","text":"<p>edge_id : str key : str default : Any, optional</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_edge--returns","title":"Returns","text":"<p>Any</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_attr_edge(self, edge_id, key, default=None):\n    \"\"\"\n    Get a single edge attribute (scalar) or default if missing.\n\n    Parameters\n    ----------\n    edge_id : str\n    key : str\n    default : Any, optional\n\n    Returns\n    -------\n    Any\n    \"\"\"\n    df = self.edge_attributes\n    if key not in df.columns:\n        return default\n    rows = df.filter(pl.col(\"edge_id\") == edge_id)\n    if rows.height == 0:\n        return default\n    val = rows.select(pl.col(key)).to_series()[0]\n    return default if val is None else val\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_attr_edges","title":"<code>get_attr_edges(indexes=None)</code>","text":"<p>Retrieve edge attributes as a dictionary.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_edges--parameters","title":"Parameters","text":"<p>indexes : Iterable[int] | None, optional     A list or iterable of edge indices to retrieve attributes for.     - If <code>None</code> (default), attributes for all edges are returned.     - If provided, only those edges will be included in the output.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_edges--returns","title":"Returns","text":"<p>dict[str, dict]     A dictionary mapping <code>edge_id</code> \u2192 <code>attribute_dict</code>, where:     - <code>edge_id</code> is the unique string identifier of the edge.     - <code>attribute_dict</code> is a dictionary of attribute names and values.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_edges--notes","title":"Notes","text":"<ul> <li>This function reads directly from <code>self.edge_attributes</code>, which should be a Polars DataFrame where each row corresponds to an edge.</li> <li>Useful for bulk inspection, serialization, or analytics without looping manually.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_attr_edges(self, indexes=None) -&gt; dict:\n    \"\"\"\n    Retrieve edge attributes as a dictionary.\n\n    Parameters\n    ----------\n    indexes : Iterable[int] | None, optional\n        A list or iterable of edge indices to retrieve attributes for.\n        - If `None` (default), attributes for **all** edges are returned.\n        - If provided, only those edges will be included in the output.\n\n    Returns\n    -------\n    dict[str, dict]\n        A dictionary mapping `edge_id` \u2192 `attribute_dict`, where:\n        - `edge_id` is the unique string identifier of the edge.\n        - `attribute_dict` is a dictionary of attribute names and values.\n\n    Notes\n    -----\n    - This function reads directly from `self.edge_attributes`, which should be\n    a Polars DataFrame where each row corresponds to an edge.\n    - Useful for bulk inspection, serialization, or analytics without looping manually.\n    \"\"\"\n    df = self.edge_attributes\n    if indexes is not None:\n        df = df.filter(pl.col(\"edge_id\").is_in([self.idx_to_edge[i] for i in indexes]))\n    return {row[\"edge_id\"]: row.as_dict() for row in df.iter_rows(named=True)}\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_attr_from_edges","title":"<code>get_attr_from_edges(key, default=None)</code>","text":"<p>Extract a specific attribute column for all edges.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_from_edges--parameters","title":"Parameters","text":"<p>key : str     Attribute column name to extract from <code>self.edge_attributes</code>. default : Any, optional     Default value to use if the column does not exist or if an edge     does not have a value. Defaults to <code>None</code>.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_from_edges--returns","title":"Returns","text":"<p>dict[str, Any]     A dictionary mapping <code>edge_id</code> \u2192 attribute value.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_from_edges--notes","title":"Notes","text":"<ul> <li>If the requested column is missing, all edges return <code>default</code>.</li> <li>This is useful for quick property lookups (e.g., weight, label, type).</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_attr_from_edges(self, key: str, default=None) -&gt; dict:\n    \"\"\"\n    Extract a specific attribute column for all edges.\n\n    Parameters\n    ----------\n    key : str\n        Attribute column name to extract from `self.edge_attributes`.\n    default : Any, optional\n        Default value to use if the column does not exist or if an edge\n        does not have a value. Defaults to `None`.\n\n    Returns\n    -------\n    dict[str, Any]\n        A dictionary mapping `edge_id` \u2192 attribute value.\n\n    Notes\n    -----\n    - If the requested column is missing, all edges return `default`.\n    - This is useful for quick property lookups (e.g., weight, label, type).\n    \"\"\"\n    df = self.edge_attributes\n    if key not in df.columns:\n        return {row[\"edge_id\"]: default for row in df.iter_rows(named=True)}\n    return {row[\"edge_id\"]: row[key] if row[key] is not None else default for row in df.iter_rows(named=True)}\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_attr_vertex","title":"<code>get_attr_vertex(vertex_id, key, default=None)</code>","text":"<p>Get a single vertex attribute (scalar) or default if missing.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_vertex--parameters","title":"Parameters","text":"<p>vertex_id : str key : str default : Any, optional</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_vertex--returns","title":"Returns","text":"<p>Any</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_attr_vertex(self, vertex_id, key, default=None):\n    \"\"\"\n    Get a single vertex attribute (scalar) or default if missing.\n\n    Parameters\n    ----------\n    vertex_id : str\n    key : str\n    default : Any, optional\n\n    Returns\n    -------\n    Any\n    \"\"\"\n    df = self.vertex_attributes\n    if key not in df.columns:\n        return default\n    rows = df.filter(pl.col(\"vertex_id\") == vertex_id)\n    if rows.height == 0:\n        return default\n    val = rows.select(pl.col(key)).to_series()[0]\n    return default if val is None else val\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_attr_vertices","title":"<code>get_attr_vertices(vertices=None)</code>","text":"<p>Retrieve vertex (vertex) attributes as a dictionary.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_vertices--parameters","title":"Parameters","text":"<p>vertices : Iterable[str] | None, optional     A list or iterable of vertex IDs to retrieve attributes for.     - If <code>None</code> (default), attributes for all verices are returned.     - If provided, only those verices will be included in the output.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_vertices--returns","title":"Returns","text":"<p>dict[str, dict]     A dictionary mapping <code>vertex_id</code> \u2192 <code>attribute_dict</code>, where:     - <code>vertex_id</code> is the unique string identifier of the vertex.     - <code>attribute_dict</code> is a dictionary of attribute names and values.</p>"},{"location":"reference/api/#graphglue.Graph.get_attr_vertices--notes","title":"Notes","text":"<ul> <li>This reads from <code>self.vertex_attributes</code>, which stores per-vertex metadata.</li> <li>Use this for bulk data extraction instead of repeated single-vertex calls.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_attr_vertices(self, vertices=None) -&gt; dict:\n    \"\"\"\n    Retrieve vertex (vertex) attributes as a dictionary.\n\n    Parameters\n    ----------\n    vertices : Iterable[str] | None, optional\n        A list or iterable of vertex IDs to retrieve attributes for.\n        - If `None` (default), attributes for **all** verices are returned.\n        - If provided, only those verices will be included in the output.\n\n    Returns\n    -------\n    dict[str, dict]\n        A dictionary mapping `vertex_id` \u2192 `attribute_dict`, where:\n        - `vertex_id` is the unique string identifier of the vertex.\n        - `attribute_dict` is a dictionary of attribute names and values.\n\n    Notes\n    -----\n    - This reads from `self.vertex_attributes`, which stores per-vertex metadata.\n    - Use this for bulk data extraction instead of repeated single-vertex calls.\n    \"\"\"\n    df = self.vertex_attributes\n    if vertices is not None:\n        df = df.filter(pl.col(\"vertex_id\").is_in(vertices))\n    return {row[\"vertex_id\"]: row.as_dict() for row in df.iter_rows(named=True)}\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_directed_edges","title":"<code>get_directed_edges()</code>","text":"<p>List IDs of directed edges.</p>"},{"location":"reference/api/#graphglue.Graph.get_directed_edges--returns","title":"Returns","text":"<p>list[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_directed_edges(self):\n    \"\"\"\n    List IDs of directed edges.\n\n    Returns\n    -------\n    list[str]\n    \"\"\"\n    default_dir = True if self.directed is None else self.directed\n    return [eid for eid in self.edge_to_idx.keys() \n            if self.edge_directed.get(eid, default_dir)]\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_edge","title":"<code>get_edge(index)</code>","text":"<p>Return edge endpoints in a canonical form.</p>"},{"location":"reference/api/#graphglue.Graph.get_edge--parameters","title":"Parameters","text":"<p>index : int     Internal edge index.</p>"},{"location":"reference/api/#graphglue.Graph.get_edge--returns","title":"Returns","text":"<p>tuple[frozenset, frozenset]     (S, T) where S and T are frozensets of vertex IDs.     - For directed binary edges: ({u}, {v})     - For undirected binary edges: (M, M)     - For directed hyperedges: (head_set, tail_set)     - For undirected hyperedges: (members, members)</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_edge(self, index: int):\n    \"\"\"\n    Return edge endpoints in a canonical form.\n\n    Parameters\n    ----------\n    index : int\n        Internal edge index.\n\n    Returns\n    -------\n    tuple[frozenset, frozenset]\n        (S, T) where S and T are frozensets of vertex IDs.\n        - For directed binary edges: ({u}, {v})\n        - For undirected binary edges: (M, M)\n        - For directed hyperedges: (head_set, tail_set)\n        - For undirected hyperedges: (members, members)\n    \"\"\"\n    if isinstance(index, str):\n        eid = index\n        try:\n            index = self.edge_to_idx[eid]\n        except KeyError:\n            raise KeyError(f\"Unknown edge id: {eid}\") from None\n    else:\n        eid = self.idx_to_edge[index]\n\n    kind = self.edge_kind.get(eid)\n\n    eid = self.idx_to_edge[index]\n    kind = self.edge_kind.get(eid)\n\n    if kind == \"hyper\":\n        meta = self.hyperedge_definitions[eid]\n        if meta.get(\"directed\", False):\n            return (frozenset(meta[\"head\"]), frozenset(meta[\"tail\"]))\n        else:\n            M = frozenset(meta[\"members\"])\n            return (M, M)\n    else:\n        u, v, _etype = self.edge_definitions[eid]\n        directed = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n        if directed:\n            return (frozenset([u]), frozenset([v]))\n        else:\n            M = frozenset([u, v])\n            return (M, M)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_edge_attribute","title":"<code>get_edge_attribute(edge_id, attribute)</code>","text":"<p>(Legacy alias) Get a single edge attribute from the Polars DF [DataFrame].</p>"},{"location":"reference/api/#graphglue.Graph.get_edge_attribute--parameters","title":"Parameters","text":"<p>edge_id : str attribute : str or enum.Enum     Column name or Enum with <code>.value</code>.</p>"},{"location":"reference/api/#graphglue.Graph.get_edge_attribute--returns","title":"Returns","text":"<p>Any or None     Scalar value if present, else <code>None</code>.</p>"},{"location":"reference/api/#graphglue.Graph.get_edge_attribute--see-also","title":"See Also","text":"<p>get_attr_edge</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_edge_attribute(self, edge_id, attribute): #legacy alias\n    \"\"\"\n    (Legacy alias) Get a single edge attribute from the Polars DF [DataFrame].\n\n    Parameters\n    ----------\n    edge_id : str\n    attribute : str or enum.Enum\n        Column name or Enum with ``.value``.\n\n    Returns\n    -------\n    Any or None\n        Scalar value if present, else ``None``.\n\n    See Also\n    --------\n    get_attr_edge\n    \"\"\"\n    # allow Attr enums\n    attribute = getattr(attribute, \"value\", attribute)\n\n    df = self.edge_attributes\n    if not isinstance(df, pl.DataFrame):\n        return None\n    if df.height == 0 or \"edge_id\" not in df.columns or attribute not in df.columns:\n        return None\n\n    rows = df.filter(pl.col(\"edge_id\") == edge_id)\n    if rows.height == 0:\n        return None\n\n    s = rows.get_column(attribute)\n    return s.item(0) if s.len() else None\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_edge_attrs","title":"<code>get_edge_attrs(edge)</code>","text":"<p>Return the full attribute dict for a single edge.</p>"},{"location":"reference/api/#graphglue.Graph.get_edge_attrs--parameters","title":"Parameters","text":"<p>edge : int | str     Edge index (int) or edge id (str).</p>"},{"location":"reference/api/#graphglue.Graph.get_edge_attrs--returns","title":"Returns","text":"<p>dict     Attribute dictionary for that edge. {} if not found.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_edge_attrs(self, edge) -&gt; dict:\n    \"\"\"\n    Return the full attribute dict for a single edge.\n\n    Parameters\n    ----------\n    edge : int | str\n        Edge index (int) or edge id (str).\n\n    Returns\n    -------\n    dict\n        Attribute dictionary for that edge. {} if not found.\n    \"\"\"\n    # normalize to edge id\n    if isinstance(edge, int):\n        eid = self.idx_to_edge[edge]\n    else:\n        eid = edge\n\n    df = self.edge_attributes\n    # Polars-safe: iterate the (at most one) row as a dict\n    try:\n        import polars as pl  # noqa: F401\n        for row in df.filter(pl.col(\"edge_id\") == eid).iter_rows(named=True):\n            return dict(row)\n        return {}\n    except Exception:\n        # Fallback if df is pandas or dict-like\n        try:\n            row = df[df[\"edge_id\"] == eid].to_dict(orient=\"records\")\n            return row[0] if row else {}\n        except Exception:\n            return {}\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_edge_ids","title":"<code>get_edge_ids(source, target)</code>","text":"<p>List all edge IDs between two endpoints.</p>"},{"location":"reference/api/#graphglue.Graph.get_edge_ids--parameters","title":"Parameters","text":"<p>source : str target : str</p>"},{"location":"reference/api/#graphglue.Graph.get_edge_ids--returns","title":"Returns","text":"<p>list[str]     Edge IDs (may be empty).</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_edge_ids(self, source, target):\n    \"\"\"\n    List all edge IDs between two endpoints.\n\n    Parameters\n    ----------\n    source : str\n    target : str\n\n    Returns\n    -------\n    list[str]\n        Edge IDs (may be empty).\n    \"\"\"\n    edge_ids = []\n    for eid, (src, tgt, _) in self.edge_definitions.items():\n        if src == source and tgt == target:\n            edge_ids.append(eid)\n    return edge_ids\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_edge_layer_attr","title":"<code>get_edge_layer_attr(layer_id, edge_id, key, default=None)</code>","text":"<p>Get a per-layer attribute for an edge.</p>"},{"location":"reference/api/#graphglue.Graph.get_edge_layer_attr--parameters","title":"Parameters","text":"<p>layer_id : str edge_id : str key : str default : Any, optional</p>"},{"location":"reference/api/#graphglue.Graph.get_edge_layer_attr--returns","title":"Returns","text":"<p>Any</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_edge_layer_attr(self, layer_id, edge_id, key, default=None):\n    \"\"\"\n    Get a per-layer attribute for an edge.\n\n    Parameters\n    ----------\n    layer_id : str\n    edge_id : str\n    key : str\n    default : Any, optional\n\n    Returns\n    -------\n    Any\n    \"\"\"\n    df = self.edge_layer_attributes\n    if key not in df.columns:\n        return default\n    rows = df.filter((pl.col(\"layer_id\") == layer_id) &amp; (pl.col(\"edge_id\") == edge_id))\n    if rows.height == 0:\n        return default\n    val = rows.select(pl.col(key)).to_series()[0]\n    return default if val is None else val\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_edges_by_attr","title":"<code>get_edges_by_attr(key, value)</code>","text":"<p>Retrieve all edges where a given attribute equals a specific value.</p>"},{"location":"reference/api/#graphglue.Graph.get_edges_by_attr--parameters","title":"Parameters","text":"<p>key : str     Attribute column name to filter on. value : Any     Value to match.</p>"},{"location":"reference/api/#graphglue.Graph.get_edges_by_attr--returns","title":"Returns","text":"<p>list[str]     A list of edge IDs where the attribute <code>key</code> equals <code>value</code>.</p>"},{"location":"reference/api/#graphglue.Graph.get_edges_by_attr--notes","title":"Notes","text":"<ul> <li>If the attribute column does not exist, an empty list is returned.</li> <li>Comparison is exact; consider normalizing types before calling.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_edges_by_attr(self, key: str, value) -&gt; list:\n    \"\"\"\n    Retrieve all edges where a given attribute equals a specific value.\n\n    Parameters\n    ----------\n    key : str\n        Attribute column name to filter on.\n    value : Any\n        Value to match.\n\n    Returns\n    -------\n    list[str]\n        A list of edge IDs where the attribute `key` equals `value`.\n\n    Notes\n    -----\n    - If the attribute column does not exist, an empty list is returned.\n    - Comparison is exact; consider normalizing types before calling.\n    \"\"\"\n    df = self.edge_attributes\n    if key not in df.columns:\n        return []\n    return [row[\"edge_id\"] for row in df.iter_rows(named=True) if row[key] == value]\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_effective_edge_weight","title":"<code>get_effective_edge_weight(edge_id, layer=None)</code>","text":"<p>Resolve the effective weight for an edge, optionally within a layer.</p>"},{"location":"reference/api/#graphglue.Graph.get_effective_edge_weight--parameters","title":"Parameters","text":"<p>edge_id : str layer : str, optional     If provided, return the layer override if present; otherwise global weight.</p>"},{"location":"reference/api/#graphglue.Graph.get_effective_edge_weight--returns","title":"Returns","text":"<p>float     Effective weight.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_effective_edge_weight(self, edge_id, layer=None):\n    \"\"\"\n    Resolve the effective weight for an edge, optionally within a layer.\n\n    Parameters\n    ----------\n    edge_id : str\n    layer : str, optional\n        If provided, return the layer override if present; otherwise global weight.\n\n    Returns\n    -------\n    float\n        Effective weight.\n    \"\"\"\n    if layer is not None:\n        df = self.edge_layer_attributes\n        if (\n            isinstance(df, pl.DataFrame)\n            and df.height &gt; 0\n            and {\"layer_id\", \"edge_id\", \"weight\"} &lt;= set(df.columns)\n        ):\n            rows = df.filter(\n                (pl.col(\"layer_id\") == layer) &amp; (pl.col(\"edge_id\") == edge_id)\n            ).select(\"weight\")\n            if rows.height &gt; 0:\n                w = rows.to_series()[0]\n                if w is not None and not (isinstance(w, float) and math.isnan(w)):\n                    return float(w)\n\n        # fallback to legacy dict if present\n        w2 = self.layer_edge_weights.get(layer, {}).get(edge_id, None)\n        if w2 is not None:\n            return float(w2)\n\n    return float(self.edge_weights[edge_id])\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_graph_attribute","title":"<code>get_graph_attribute(key, default=None)</code>","text":"<p>Get a graph-level attribute.</p>"},{"location":"reference/api/#graphglue.Graph.get_graph_attribute--parameters","title":"Parameters","text":"<p>key : str default : Any, optional</p>"},{"location":"reference/api/#graphglue.Graph.get_graph_attribute--returns","title":"Returns","text":"<p>Any</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_graph_attribute(self, key, default=None):\n    \"\"\"\n    Get a graph-level attribute.\n\n    Parameters\n    ----------\n    key : str\n    default : Any, optional\n\n    Returns\n    -------\n    Any\n    \"\"\"\n    return self.graph_attributes.get(key, default)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_graph_attributes","title":"<code>get_graph_attributes()</code>","text":"<p>Return a shallow copy of the graph-level attributes dictionary.</p>"},{"location":"reference/api/#graphglue.Graph.get_graph_attributes--returns","title":"Returns","text":"<p>dict     A dictionary of global metadata describing the graph as a whole.     Typical keys might include:     - <code>\"name\"</code> : Graph name or label.     - <code>\"directed\"</code> : Boolean indicating directedness.     - <code>\"layers\"</code> : List of layers present in the graph.     - <code>\"created_at\"</code> : Timestamp of graph creation.</p>"},{"location":"reference/api/#graphglue.Graph.get_graph_attributes--notes","title":"Notes","text":"<ul> <li>Returns a shallow copy to prevent external mutation of internal state.</li> <li>Graph-level attributes are meant to store metadata not tied to individual verices or edges (e.g., versioning info, provenance, global labels).</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_graph_attributes(self) -&gt; dict:\n    \"\"\"\n    Return a shallow copy of the graph-level attributes dictionary.\n\n    Returns\n    -------\n    dict\n        A dictionary of global metadata describing the graph as a whole.\n        Typical keys might include:\n        - `\"name\"` : Graph name or label.\n        - `\"directed\"` : Boolean indicating directedness.\n        - `\"layers\"` : List of layers present in the graph.\n        - `\"created_at\"` : Timestamp of graph creation.\n\n    Notes\n    -----\n    - Returns a **shallow copy** to prevent external mutation of internal state.\n    - Graph-level attributes are meant to store metadata not tied to individual\n    verices or edges (e.g., versioning info, provenance, global labels).\n    \"\"\"\n    return dict(self.graph_attributes)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_layer_attr","title":"<code>get_layer_attr(layer_id, key, default=None)</code>","text":"<p>Get a single layer attribute (scalar) or default if missing.</p>"},{"location":"reference/api/#graphglue.Graph.get_layer_attr--parameters","title":"Parameters","text":"<p>layer_id : str key : str default : Any, optional</p>"},{"location":"reference/api/#graphglue.Graph.get_layer_attr--returns","title":"Returns","text":"<p>Any</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_layer_attr(self, layer_id, key, default=None):\n    \"\"\"\n    Get a single layer attribute (scalar) or default if missing.\n\n    Parameters\n    ----------\n    layer_id : str\n    key : str\n    default : Any, optional\n\n    Returns\n    -------\n    Any\n    \"\"\"\n    df = self.layer_attributes\n    if key not in df.columns:\n        return default\n    rows = df.filter(pl.col(\"layer_id\") == layer_id)\n    if rows.height == 0:\n        return default\n    val = rows.select(pl.col(key)).to_series()[0]\n    return default if val is None else val\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_layer_edges","title":"<code>get_layer_edges(layer_id)</code>","text":"<p>Edges in a layer.</p>"},{"location":"reference/api/#graphglue.Graph.get_layer_edges--parameters","title":"Parameters","text":"<p>layer_id : str</p>"},{"location":"reference/api/#graphglue.Graph.get_layer_edges--returns","title":"Returns","text":"<p>set[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_layer_edges(self, layer_id):\n    \"\"\"\n    Edges in a layer.\n\n    Parameters\n    ----------\n    layer_id : str\n\n    Returns\n    -------\n    set[str]\n    \"\"\"\n    return self._layers[layer_id][\"edges\"].copy()\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_layer_info","title":"<code>get_layer_info(layer_id)</code>","text":"<p>Get a layer's metadata snapshot.</p>"},{"location":"reference/api/#graphglue.Graph.get_layer_info--parameters","title":"Parameters","text":"<p>layer_id : str</p>"},{"location":"reference/api/#graphglue.Graph.get_layer_info--returns","title":"Returns","text":"<p>dict     Copy of <code>{\"vertices\": set, \"edges\": set, \"attributes\": dict}</code>.</p>"},{"location":"reference/api/#graphglue.Graph.get_layer_info--raises","title":"Raises","text":"<p>KeyError     If the layer does not exist.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_layer_info(self, layer_id):\n    \"\"\"\n    Get a layer's metadata snapshot.\n\n    Parameters\n    ----------\n    layer_id : str\n\n    Returns\n    -------\n    dict\n        Copy of ``{\"vertices\": set, \"edges\": set, \"attributes\": dict}``.\n\n    Raises\n    ------\n    KeyError\n        If the layer does not exist.\n    \"\"\"\n    if layer_id not in self._layers:\n        raise KeyError(f\"Layer {layer_id} not found\")\n    return self._layers[layer_id].copy()\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_layer_vertices","title":"<code>get_layer_vertices(layer_id)</code>","text":"<p>vertices in a layer.</p>"},{"location":"reference/api/#graphglue.Graph.get_layer_vertices--parameters","title":"Parameters","text":"<p>layer_id : str</p>"},{"location":"reference/api/#graphglue.Graph.get_layer_vertices--returns","title":"Returns","text":"<p>set[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_layer_vertices(self, layer_id):\n    \"\"\"\n    vertices in a layer.\n\n    Parameters\n    ----------\n    layer_id : str\n\n    Returns\n    -------\n    set[str]\n    \"\"\"\n    return self._layers[layer_id][\"vertices\"].copy()\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_layers_dict","title":"<code>get_layers_dict(include_default=False)</code>","text":"<p>Get a mapping of layer IDs to their metadata.</p>"},{"location":"reference/api/#graphglue.Graph.get_layers_dict--parameters","title":"Parameters","text":"<p>include_default : bool, optional     Include the internal <code>'default'</code> layer if True.</p>"},{"location":"reference/api/#graphglue.Graph.get_layers_dict--returns","title":"Returns","text":"<p>dict[str, dict]     <code>{layer_id: {\"vertices\": set, \"edges\": set, \"attributes\": dict}}</code>.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_layers_dict(self, include_default: bool = False):\n    \"\"\"\n    Get a mapping of layer IDs to their metadata.\n\n    Parameters\n    ----------\n    include_default : bool, optional\n        Include the internal ``'default'`` layer if True.\n\n    Returns\n    -------\n    dict[str, dict]\n        ``{layer_id: {\"vertices\": set, \"edges\": set, \"attributes\": dict}}``.\n    \"\"\"\n    if include_default:\n        return self._layers\n    return {k: v for k, v in self._layers.items() if k != self._default_layer}\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_undirected_edges","title":"<code>get_undirected_edges()</code>","text":"<p>List IDs of undirected edges.</p>"},{"location":"reference/api/#graphglue.Graph.get_undirected_edges--returns","title":"Returns","text":"<p>list[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_undirected_edges(self):\n    \"\"\"\n    List IDs of undirected edges.\n\n    Returns\n    -------\n    list[str]\n    \"\"\"\n    default_dir = True if self.directed is None else self.directed\n    return [eid for eid in self.edge_to_idx.keys() \n            if not self.edge_directed.get(eid, default_dir)]\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_vertex","title":"<code>get_vertex(index)</code>","text":"<p>Return the vertex ID corresponding to a given internal index.</p>"},{"location":"reference/api/#graphglue.Graph.get_vertex--parameters","title":"Parameters","text":"<p>index : int     The internal vertex index.</p>"},{"location":"reference/api/#graphglue.Graph.get_vertex--returns","title":"Returns","text":"<p>str     The vertex ID.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_vertex(self, index: int) -&gt; str:\n    \"\"\"\n    Return the vertex ID corresponding to a given internal index.\n\n    Parameters\n    ----------\n    index : int\n        The internal vertex index.\n\n    Returns\n    -------\n    str\n        The vertex ID.\n    \"\"\"\n    return self.idx_to_entity[index]\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_vertex_attribute","title":"<code>get_vertex_attribute(vertex_id, attribute)</code>","text":"<p>(Legacy alias) Get a single vertex attribute from the Polars DF [DataFrame].</p>"},{"location":"reference/api/#graphglue.Graph.get_vertex_attribute--parameters","title":"Parameters","text":"<p>vertex_id : str attribute : str or enum.Enum     Column name or Enum with <code>.value</code>.</p>"},{"location":"reference/api/#graphglue.Graph.get_vertex_attribute--returns","title":"Returns","text":"<p>Any or None     Scalar value if present, else <code>None</code>.</p>"},{"location":"reference/api/#graphglue.Graph.get_vertex_attribute--see-also","title":"See Also","text":"<p>get_attr_vertex</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_vertex_attribute(self, vertex_id, attribute): #legacy alias\n    \"\"\"\n    (Legacy alias) Get a single vertex attribute from the Polars DF [DataFrame].\n\n    Parameters\n    ----------\n    vertex_id : str\n    attribute : str or enum.Enum\n        Column name or Enum with ``.value``.\n\n    Returns\n    -------\n    Any or None\n        Scalar value if present, else ``None``.\n\n    See Also\n    --------\n    get_attr_vertex\n    \"\"\"\n    # allow Attr enums\n    attribute = getattr(attribute, \"value\", attribute)\n\n    df = self.vertex_attributes\n    if not isinstance(df, pl.DataFrame):\n        return None\n    if df.height == 0 or \"vertex_id\" not in df.columns or attribute not in df.columns:\n        return None\n\n    rows = df.filter(pl.col(\"vertex_id\") == vertex_id)\n    if rows.height == 0:\n        return None\n\n    s = rows.get_column(attribute)\n    return s.item(0) if s.len() else None\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_vertex_attrs","title":"<code>get_vertex_attrs(vertex)</code>","text":"<p>Return the full attribute dict for a single vertex.</p>"},{"location":"reference/api/#graphglue.Graph.get_vertex_attrs--parameters","title":"Parameters","text":"<p>vertex : str     Vertex id.</p>"},{"location":"reference/api/#graphglue.Graph.get_vertex_attrs--returns","title":"Returns","text":"<p>dict     Attribute dictionary for that vertex. {} if not found.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_vertex_attrs(self, vertex) -&gt; dict:\n    \"\"\"\n    Return the full attribute dict for a single vertex.\n\n    Parameters\n    ----------\n    vertex : str\n        Vertex id.\n\n    Returns\n    -------\n    dict\n        Attribute dictionary for that vertex. {} if not found.\n    \"\"\"\n    df = self.vertex_attributes\n    try:\n        import polars as pl  # noqa: F401\n        for row in df.filter(pl.col(\"vertex_id\") == vertex).iter_rows(named=True):\n            return dict(row)\n        return {}\n    except Exception:\n        try:\n            row = df[df[\"vertex_id\"] == vertex].to_dict(orient=\"records\")\n            return row[0] if row else {}\n        except Exception:\n            return {}\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.get_vertex_incidence_matrix_as_lists","title":"<code>get_vertex_incidence_matrix_as_lists(values=False)</code>","text":"<p>Materialize the vertex\u2013edge incidence structure as Python lists.</p>"},{"location":"reference/api/#graphglue.Graph.get_vertex_incidence_matrix_as_lists--parameters","title":"Parameters","text":"<p>values : bool, optional (default=False)     - If <code>False</code>, returns edge indices incident to each vertex.     - If <code>True</code>, returns the matrix values (usually weights or 1/0) for     each incident edge instead of the indices.</p>"},{"location":"reference/api/#graphglue.Graph.get_vertex_incidence_matrix_as_lists--returns","title":"Returns","text":"<p>dict[str, list]     A mapping from <code>vertex_id</code> \u2192 list of incident edges (indices or values),     where:     - Keys are vertex IDs.     - Values are lists of edge indices (if <code>values=False</code>) or numeric values     from the incidence matrix (if <code>values=True</code>).</p>"},{"location":"reference/api/#graphglue.Graph.get_vertex_incidence_matrix_as_lists--notes","title":"Notes","text":"<ul> <li>Internally uses the sparse incidence matrix <code>self._matrix</code>, which is stored as a SciPy CSR (compressed sparse row) matrix or similar.</li> <li>The incidence matrix <code>M</code> is defined as:<ul> <li>Rows: vertices</li> <li>Columns: edges</li> <li>Entry <code>M[i, j]</code> non-zero \u21e8 vertex <code>i</code> is incident to edge <code>j</code>.</li> </ul> </li> <li>This is a convenient method when you want a native-Python structure for downstream use (e.g., exporting, iterating, or visualization).</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def get_vertex_incidence_matrix_as_lists(self, values: bool = False) -&gt; dict:\n    \"\"\"\n    Materialize the vertex\u2013edge incidence structure as Python lists.\n\n    Parameters\n    ----------\n    values : bool, optional (default=False)\n        - If `False`, returns edge indices incident to each vertex.\n        - If `True`, returns the **matrix values** (usually weights or 1/0) for\n        each incident edge instead of the indices.\n\n    Returns\n    -------\n    dict[str, list]\n        A mapping from `vertex_id` \u2192 list of incident edges (indices or values),\n        where:\n        - Keys are vertex IDs.\n        - Values are lists of edge indices (if `values=False`) or numeric values\n        from the incidence matrix (if `values=True`).\n\n    Notes\n    -----\n    - Internally uses the sparse incidence matrix `self._matrix`, which is stored\n    as a SciPy CSR (compressed sparse row) matrix or similar.\n    - The incidence matrix `M` is defined as:\n        - Rows: vertices\n        - Columns: edges\n        - Entry `M[i, j]` non-zero \u21e8 vertex `i` is incident to edge `j`.\n    - This is a convenient method when you want a native-Python structure for\n    downstream use (e.g., exporting, iterating, or visualization).\n    \"\"\"\n    result = {}\n    csr = self._matrix.tocsr()\n    for i in range(csr.shape[0]):\n        vertex_id = self.idx_to_entity[i]\n        row = csr.getrow(i)\n        if values:\n            result[vertex_id] = row.data.tolist()\n        else:\n            result[vertex_id] = row.indices.tolist()\n    return result\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.global_edge_count","title":"<code>global_edge_count()</code>","text":"<p>Count unique edges present across all layers (union of memberships).</p>"},{"location":"reference/api/#graphglue.Graph.global_edge_count--returns","title":"Returns","text":"<p>int</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def global_edge_count(self):\n    \"\"\"\n    Count unique edges present across all layers (union of memberships).\n\n    Returns\n    -------\n    int\n    \"\"\"\n    all_edges = set()\n    for layer_data in self._layers.values():\n        all_edges.update(layer_data[\"edges\"])\n    return len(all_edges)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.global_entity_count","title":"<code>global_entity_count()</code>","text":"<p>Count unique entities present across all layers (union of memberships).</p>"},{"location":"reference/api/#graphglue.Graph.global_entity_count--returns","title":"Returns","text":"<p>int</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def global_entity_count(self):\n    \"\"\"\n    Count unique entities present across all layers (union of memberships).\n\n    Returns\n    -------\n    int\n    \"\"\"\n    all_vertices = set()\n    for layer_data in self._layers.values():\n        all_vertices.update(layer_data[\"vertices\"])\n    return len(all_vertices)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.has_edge","title":"<code>has_edge(source, target, edge_id=None)</code>","text":"<p>Test for the existence of an edge.</p>"},{"location":"reference/api/#graphglue.Graph.has_edge--parameters","title":"Parameters","text":"<p>source : str target : str edge_id : str, optional     If provided, check for this specific ID.</p>"},{"location":"reference/api/#graphglue.Graph.has_edge--returns","title":"Returns","text":"<p>bool</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def has_edge(self, source, target, edge_id=None):\n    \"\"\"\n    Test for the existence of an edge.\n\n    Parameters\n    ----------\n    source : str\n    target : str\n    edge_id : str, optional\n        If provided, check for this specific ID.\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    if edge_id:\n        return edge_id in self.edge_to_idx\n\n    # Check any edge between source and target\n    for eid, (src, tgt, _) in self.edge_definitions.items():\n        if src == source and tgt == target:\n            return True\n    return False\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.has_layer","title":"<code>has_layer(layer_id)</code>","text":"<p>Check whether a layer exists.</p>"},{"location":"reference/api/#graphglue.Graph.has_layer--parameters","title":"Parameters","text":"<p>layer_id : str</p>"},{"location":"reference/api/#graphglue.Graph.has_layer--returns","title":"Returns","text":"<p>bool</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def has_layer(self, layer_id):\n    \"\"\"\n    Check whether a layer exists.\n\n    Parameters\n    ----------\n    layer_id : str\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return layer_id in self._layers\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.has_vertex","title":"<code>has_vertex(vertex_id)</code>","text":"<p>Test for the existence of a vertex.</p>"},{"location":"reference/api/#graphglue.Graph.has_vertex--parameters","title":"Parameters","text":"<p>vertex_id : str</p>"},{"location":"reference/api/#graphglue.Graph.has_vertex--returns","title":"Returns","text":"<p>bool</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def has_vertex(self, vertex_id: str) -&gt; bool:\n    \"\"\"\n    Test for the existence of a vertex.\n\n    Parameters\n    ----------\n    vertex_id : str\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return vertex_id in self.entity_to_idx and self.entity_types.get(vertex_id) == \"vertex\"\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.history","title":"<code>history(as_df=False)</code>","text":"<p>Return the append-only mutation history.</p>"},{"location":"reference/api/#graphglue.Graph.history--parameters","title":"Parameters","text":"<p>as_df : bool, default False     If True, return a Polars DF [DataFrame]; otherwise return a list of dicts.</p>"},{"location":"reference/api/#graphglue.Graph.history--returns","title":"Returns","text":"<p>list[dict] or polars.DataFrame     Each event includes: 'version', 'ts_utc' (UTC [Coordinated Universal Time]     ISO-8601 [International Organization for Standardization]), 'mono_ns'     (monotonic nanoseconds since logger start), 'op', call snapshot fields,     and 'result' when captured.</p>"},{"location":"reference/api/#graphglue.Graph.history--notes","title":"Notes","text":"<p>Ordering is guaranteed by 'version' and 'mono_ns'. The log is in-memory until exported.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def history(self, as_df: bool = False):\n    \"\"\"\n    Return the append-only mutation history.\n\n    Parameters\n    ----------\n    as_df : bool, default False\n        If True, return a Polars DF [DataFrame]; otherwise return a list of dicts.\n\n    Returns\n    -------\n    list[dict] or polars.DataFrame\n        Each event includes: 'version', 'ts_utc' (UTC [Coordinated Universal Time]\n        ISO-8601 [International Organization for Standardization]), 'mono_ns'\n        (monotonic nanoseconds since logger start), 'op', call snapshot fields,\n        and 'result' when captured.\n\n    Notes\n    -----\n    Ordering is guaranteed by 'version' and 'mono_ns'. The log is in-memory until exported.\n    \"\"\"\n    return pl.DataFrame(self._history) if as_df else list(self._history)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.hyperedge_presence_across_layers","title":"<code>hyperedge_presence_across_layers(*, members=None, head=None, tail=None, include_default=False)</code>","text":"<p>Locate layers containing a hyperedge with exactly these sets.</p>"},{"location":"reference/api/#graphglue.Graph.hyperedge_presence_across_layers--parameters","title":"Parameters","text":"<p>members : Iterable[str], optional     Undirected member set (exact match). head : Iterable[str], optional     Directed head set (exact match). tail : Iterable[str], optional     Directed tail set (exact match). include_default : bool, optional</p>"},{"location":"reference/api/#graphglue.Graph.hyperedge_presence_across_layers--returns","title":"Returns","text":"<p>dict[str, list[str]]     <code>{layer_id: [edge_id, ...]}</code>.</p>"},{"location":"reference/api/#graphglue.Graph.hyperedge_presence_across_layers--raises","title":"Raises","text":"<p>ValueError     For invalid combinations or empty sets.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def hyperedge_presence_across_layers(\n    self,\n    *,\n    members=None,\n    head=None,\n    tail=None,\n    include_default: bool = False,\n):\n    \"\"\"\n    Locate layers containing a hyperedge with exactly these sets.\n\n    Parameters\n    ----------\n    members : Iterable[str], optional\n        Undirected member set (exact match).\n    head : Iterable[str], optional\n        Directed head set (exact match).\n    tail : Iterable[str], optional\n        Directed tail set (exact match).\n    include_default : bool, optional\n\n    Returns\n    -------\n    dict[str, list[str]]\n        ``{layer_id: [edge_id, ...]}``.\n\n    Raises\n    ------\n    ValueError\n        For invalid combinations or empty sets.\n    \"\"\"\n    undirected = members is not None\n    if undirected and (head is not None or tail is not None):\n        raise ValueError(\"Use either members OR head+tail, not both.\")\n    if not undirected and (head is None or tail is None):\n        raise ValueError(\"Directed hyperedge query requires both head and tail.\")\n\n    if undirected:\n        members = set(members)\n        if not members:\n            raise ValueError(\"members must be non-empty.\")\n    else:\n        head = set(head)\n        tail = set(tail)\n        if not head or not tail:\n            raise ValueError(\"head and tail must be non-empty.\")\n        if head &amp; tail:\n            raise ValueError(\"head and tail must be disjoint.\")\n\n    layers_view = self.get_layers_dict(include_default=include_default)\n    out: dict[str, list[str]] = {}\n\n    for lid, ldata in layers_view.items():\n        matches = []\n        for eid in ldata[\"edges\"]:\n            if self.edge_kind.get(eid) != \"hyper\":\n                continue\n            meta = self.hyperedge_definitions.get(eid, {})\n            if undirected and (not meta.get(\"directed\", False)):\n                if set(meta.get(\"members\", ())) == members:\n                    matches.append(eid)\n            elif (not undirected) and meta.get(\"directed\", False):\n                if set(meta.get(\"head\", ())) == head and set(meta.get(\"tail\", ())) == tail:\n                    matches.append(eid)\n        if matches:\n            out[lid] = matches\n    return out\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.in_edges","title":"<code>in_edges(vertices)</code>","text":"<p>Iterate over all edges that are incoming to one or more vertices.</p>"},{"location":"reference/api/#graphglue.Graph.in_edges--parameters","title":"Parameters","text":"<p>vertices : str | Iterable[str]     A single vertex ID or an iterable of vertex IDs. All edges whose     target set intersects with this set will be yielded.</p>"},{"location":"reference/api/#graphglue.Graph.in_edges--yields","title":"Yields","text":"<p>tuple[int, tuple[frozenset, frozenset]]     Tuples of the form <code>(edge_index, (S, T))</code>, where:     - <code>edge_index</code> : int \u2014 internal integer index of the edge.     - <code>S</code> : frozenset[str] \u2014 set of source/head verices.     - <code>T</code> : frozenset[str] \u2014 set of target/tail verices.</p>"},{"location":"reference/api/#graphglue.Graph.in_edges--behavior","title":"Behavior","text":"<ul> <li>Directed binary edges: returned if any vertex is in the target (<code>T</code>).</li> <li>Directed hyperedges: returned if any vertex is in the tail set.</li> <li>Undirected edges/hyperedges: returned if any vertex is in the edge's member set (<code>S \u222a T</code>).</li> </ul>"},{"location":"reference/api/#graphglue.Graph.in_edges--notes","title":"Notes","text":"<ul> <li>Works with binary and hyperedges.</li> <li>Undirected edges appear in both <code>in_edges()</code> and <code>out_edges()</code>.</li> <li>The returned <code>(S, T)</code> is the canonical form from <code>get_edge()</code>.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def in_edges(self, vertices):\n    \"\"\"\n    Iterate over all edges that are **incoming** to one or more vertices.\n\n    Parameters\n    ----------\n    vertices : str | Iterable[str]\n        A single vertex ID or an iterable of vertex IDs. All edges whose\n        **target set** intersects with this set will be yielded.\n\n    Yields\n    ------\n    tuple[int, tuple[frozenset, frozenset]]\n        Tuples of the form `(edge_index, (S, T))`, where:\n        - `edge_index` : int \u2014 internal integer index of the edge.\n        - `S` : frozenset[str] \u2014 set of source/head verices.\n        - `T` : frozenset[str] \u2014 set of target/tail verices.\n\n    Behavior\n    --------\n    - **Directed binary edges**: returned if any vertex is in the target (`T`).\n    - **Directed hyperedges**: returned if any vertex is in the tail set.\n    - **Undirected edges/hyperedges**: returned if any vertex is in\n    the edge's member set (`S \u222a T`).\n\n    Notes\n    -----\n    - Works with binary and hyperedges.\n    - Undirected edges appear in both `in_edges()` and `out_edges()`.\n    - The returned `(S, T)` is the canonical form from `get_edge()`.\n    \"\"\"\n    V = self._normalize_vertices_arg(vertices)\n    if not V:\n        return\n    for j in range(self.number_of_edges()):\n        S, T = self.get_edge(j)\n        eid = self.idx_to_edge[j]\n        directed = self._is_directed_edge(eid)\n        if directed:\n            if T &amp; V:\n                yield j, (S, T)\n        else:\n            if (S | T) &amp; V:\n                yield j, (S, T)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.in_neighbors","title":"<code>in_neighbors(vertex_id)</code>","text":"<p>In-neighbors of a vertex under directed semantics.</p>"},{"location":"reference/api/#graphglue.Graph.in_neighbors--parameters","title":"Parameters","text":"<p>vertex_id : str</p>"},{"location":"reference/api/#graphglue.Graph.in_neighbors--returns","title":"Returns","text":"<p>list[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def in_neighbors(self, vertex_id):\n    \"\"\"\n    In-neighbors of a vertex under directed semantics.\n\n    Parameters\n    ----------\n    vertex_id : str\n\n    Returns\n    -------\n    list[str]\n    \"\"\"        \n    if vertex_id not in self.entity_to_idx:\n        return []\n    inn = set()\n    for eid in self.edge_to_idx.keys():\n        kind = self.edge_kind.get(eid, None)\n        if kind == \"hyper\":\n            meta = self.hyperedge_definitions[eid]\n            if meta[\"directed\"]:\n                if vertex_id in meta[\"tail\"]:\n                    inn |= (meta[\"head\"])\n            else:\n                if vertex_id in meta.get(\"members\", ()):\n                    inn |= (meta[\"members\"] - {vertex_id})\n        else:\n            s, t, _ = self.edge_definitions[eid]\n            edir = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n            if t == vertex_id:\n                inn.add(s)\n            elif s == vertex_id and not edir:\n                inn.add(t)\n    return list(inn)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.incident_edges","title":"<code>incident_edges(vertex_id)</code>","text":"<p>Return all edge indices incident to a given vertex.</p>"},{"location":"reference/api/#graphglue.Graph.incident_edges--parameters","title":"Parameters","text":"<p>vertex_id : str     vertex identifier.</p>"},{"location":"reference/api/#graphglue.Graph.incident_edges--returns","title":"Returns","text":"<p>list[int]     List of edge indices incident to the vertex.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def incident_edges(self, vertex_id) -&gt; list[int]:\n    \"\"\"\n    Return all edge indices incident to a given vertex.\n\n    Parameters\n    ----------\n    vertex_id : str\n        vertex identifier.\n\n    Returns\n    -------\n    list[int]\n        List of edge indices incident to the vertex.\n    \"\"\"\n    incident = []\n    # Fast path: direct matrix row lookup if available\n    if vertex_id in self.entity_to_idx:\n        row_idx = self.entity_to_idx[vertex_id]\n        try:\n            incident.extend(self._matrix.tocsr().getrow(row_idx).indices.tolist())\n            return incident\n        except Exception:\n            # fallback if matrix is not in CSR (compressed sparse row) format\n            pass\n\n    # Fallback: scan edge definitions\n    for j in range(self.number_of_edges()):\n        eid = self.idx_to_edge[j]\n        kind = self.edge_kind.get(eid)\n        if kind == \"hyper\":\n            meta = self.hyperedge_definitions[eid]\n            if (meta.get(\"directed\", False) and (vertex_id in meta[\"head\"] or vertex_id in meta[\"tail\"])) \\\n            or (not meta.get(\"directed\", False) and vertex_id in meta[\"members\"]):\n                incident.append(j)\n        else:\n            u, v, _etype = self.edge_definitions[eid]\n            if vertex_id == u or vertex_id == v:\n                incident.append(j)\n\n    return incident\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.layer_count","title":"<code>layer_count()</code>","text":"<p>Get the number of layers (including the internal default).</p>"},{"location":"reference/api/#graphglue.Graph.layer_count--returns","title":"Returns","text":"<p>int</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def layer_count(self):\n    \"\"\"\n    Get the number of layers (including the internal default).\n\n    Returns\n    -------\n    int\n    \"\"\"\n    return len(self._layers)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.layer_difference","title":"<code>layer_difference(layer1_id, layer2_id)</code>","text":"<p>Set difference: elements in <code>layer1_id</code> not in <code>layer2_id</code>.</p>"},{"location":"reference/api/#graphglue.Graph.layer_difference--parameters","title":"Parameters","text":"<p>layer1_id : str layer2_id : str</p>"},{"location":"reference/api/#graphglue.Graph.layer_difference--returns","title":"Returns","text":"<p>dict     <code>{\"vertices\": set[str], \"edges\": set[str]}</code></p>"},{"location":"reference/api/#graphglue.Graph.layer_difference--raises","title":"Raises","text":"<p>KeyError     If either layer is missing.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def layer_difference(self, layer1_id, layer2_id):\n    \"\"\"\n    Set difference: elements in ``layer1_id`` not in ``layer2_id``.\n\n    Parameters\n    ----------\n    layer1_id : str\n    layer2_id : str\n\n    Returns\n    -------\n    dict\n        ``{\"vertices\": set[str], \"edges\": set[str]}``\n\n    Raises\n    ------\n    KeyError\n        If either layer is missing.\n    \"\"\"\n    if layer1_id not in self._layers or layer2_id not in self._layers:\n        raise KeyError(\"One or both layers not found\")\n\n    layer1 = self._layers[layer1_id]\n    layer2 = self._layers[layer2_id]\n\n    return {\n        \"vertices\": layer1[\"vertices\"] - layer2[\"vertices\"],\n        \"edges\": layer1[\"edges\"] - layer2[\"edges\"]\n    }\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.layer_intersection","title":"<code>layer_intersection(layer_ids)</code>","text":"<p>Intersection of multiple layers.</p>"},{"location":"reference/api/#graphglue.Graph.layer_intersection--parameters","title":"Parameters","text":"<p>layer_ids : Iterable[str]</p>"},{"location":"reference/api/#graphglue.Graph.layer_intersection--returns","title":"Returns","text":"<p>dict     <code>{\"vertices\": set[str], \"edges\": set[str]}</code></p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def layer_intersection(self, layer_ids):\n    \"\"\"\n    Intersection of multiple layers.\n\n    Parameters\n    ----------\n    layer_ids : Iterable[str]\n\n    Returns\n    -------\n    dict\n        ``{\"vertices\": set[str], \"edges\": set[str]}``\n    \"\"\"\n    if not layer_ids:\n        return {\"vertices\": set(), \"edges\": set()}\n\n    if len(layer_ids) == 1:\n        layer_id = layer_ids[0]\n        return {\n            \"vertices\": self._layers[layer_id][\"vertices\"].copy(),\n            \"edges\": self._layers[layer_id][\"edges\"].copy()\n        }\n\n    # Start with first layer\n    common_vertices = self._layers[layer_ids[0]][\"vertices\"].copy()\n    common_edges = self._layers[layer_ids[0]][\"edges\"].copy()\n\n    # Intersect with remaining layers\n    for layer_id in layer_ids[1:]:\n        if layer_id in self._layers:\n            common_vertices &amp;= self._layers[layer_id][\"vertices\"]\n            common_edges &amp;= self._layers[layer_id][\"edges\"]\n        else:\n            # Layer doesn't exist, intersection is empty\n            return {\"vertices\": set(), \"edges\": set()}\n\n    return {\"vertices\": common_vertices, \"edges\": common_edges}\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.layer_specific_edges","title":"<code>layer_specific_edges(layer_id)</code>","text":"<p>Edges that appear only in the specified layer.</p>"},{"location":"reference/api/#graphglue.Graph.layer_specific_edges--parameters","title":"Parameters","text":"<p>layer_id : str</p>"},{"location":"reference/api/#graphglue.Graph.layer_specific_edges--returns","title":"Returns","text":"<p>set[str]</p>"},{"location":"reference/api/#graphglue.Graph.layer_specific_edges--raises","title":"Raises","text":"<p>KeyError     If the layer does not exist.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def layer_specific_edges(self, layer_id):\n    \"\"\"\n    Edges that appear **only** in the specified layer.\n\n    Parameters\n    ----------\n    layer_id : str\n\n    Returns\n    -------\n    set[str]\n\n    Raises\n    ------\n    KeyError\n        If the layer does not exist.\n    \"\"\"\n    if layer_id not in self._layers:\n        raise KeyError(f\"Layer {layer_id} not found\")\n\n    target_edges = self._layers[layer_id][\"edges\"]\n    specific_edges = set()\n\n    for edge_id in target_edges:\n        # Count how many layers contain this edge\n        count = sum(1 for layer_data in self._layers.values() \n                if edge_id in layer_data[\"edges\"])\n        if count == 1:  # Only in target layer\n            specific_edges.add(edge_id)\n\n    return specific_edges\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.layer_statistics","title":"<code>layer_statistics(include_default=False)</code>","text":"<p>Basic per-layer statistics.</p>"},{"location":"reference/api/#graphglue.Graph.layer_statistics--parameters","title":"Parameters","text":"<p>include_default : bool, optional</p>"},{"location":"reference/api/#graphglue.Graph.layer_statistics--returns","title":"Returns","text":"<p>dict[str, dict]     <code>{layer_id: {'vertices': int, 'edges': int, 'attributes': dict}}</code>.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def layer_statistics(self, include_default: bool = False):\n    \"\"\"\n    Basic per-layer statistics.\n\n    Parameters\n    ----------\n    include_default : bool, optional\n\n    Returns\n    -------\n    dict[str, dict]\n        ``{layer_id: {'vertices': int, 'edges': int, 'attributes': dict}}``.\n    \"\"\"\n    stats = {}\n    for layer_id, layer_data in self.get_layers_dict(include_default=include_default).items():\n        stats[layer_id] = {\n            'vertices': len(layer_data[\"vertices\"]),\n            'edges': len(layer_data[\"edges\"]),\n            'attributes': layer_data[\"attributes\"]\n        }\n    return stats\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.layer_union","title":"<code>layer_union(layer_ids)</code>","text":"<p>Union of multiple layers.</p>"},{"location":"reference/api/#graphglue.Graph.layer_union--parameters","title":"Parameters","text":"<p>layer_ids : Iterable[str]</p>"},{"location":"reference/api/#graphglue.Graph.layer_union--returns","title":"Returns","text":"<p>dict     <code>{\"vertices\": set[str], \"edges\": set[str]}</code></p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def layer_union(self, layer_ids):\n    \"\"\"\n    Union of multiple layers.\n\n    Parameters\n    ----------\n    layer_ids : Iterable[str]\n\n    Returns\n    -------\n    dict\n        ``{\"vertices\": set[str], \"edges\": set[str]}``\n    \"\"\"\n    if not layer_ids:\n        return {\"vertices\": set(), \"edges\": set()}\n\n    union_vertices = set()\n    union_edges = set()\n\n    for layer_id in layer_ids:\n        if layer_id in self._layers:\n            union_vertices.update(self._layers[layer_id][\"vertices\"])\n            union_edges.update(self._layers[layer_id][\"edges\"])\n\n    return {\"vertices\": union_vertices, \"edges\": union_edges}\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.layers_view","title":"<code>layers_view(copy=True)</code>","text":"<p>Read-only layer attribute table.</p>"},{"location":"reference/api/#graphglue.Graph.layers_view--parameters","title":"Parameters","text":"<p>copy : bool, optional     Return a cloned DF.</p>"},{"location":"reference/api/#graphglue.Graph.layers_view--returns","title":"Returns","text":"<p>polars.DataFrame     Columns: <code>layer_id</code> plus pure attributes (may be empty).</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def layers_view(self, copy=True):\n    \"\"\"\n    Read-only layer attribute table.\n\n    Parameters\n    ----------\n    copy : bool, optional\n        Return a cloned DF.\n\n    Returns\n    -------\n    polars.DataFrame\n        Columns: ``layer_id`` plus pure attributes (may be empty).\n    \"\"\"\n    df = self.layer_attributes\n    if df.height == 0:\n        return pl.DataFrame(schema={\"layer_id\": pl.Utf8})\n    return df.clone() if copy else df\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.list_layers","title":"<code>list_layers(include_default=False)</code>","text":"<p>List layer IDs.</p>"},{"location":"reference/api/#graphglue.Graph.list_layers--parameters","title":"Parameters","text":"<p>include_default : bool, optional     Include the internal <code>'default'</code> layer if True.</p>"},{"location":"reference/api/#graphglue.Graph.list_layers--returns","title":"Returns","text":"<p>list[str]     Layer IDs.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def list_layers(self, include_default: bool = False):\n    \"\"\"\n    List layer IDs.\n\n    Parameters\n    ----------\n    include_default : bool, optional\n        Include the internal ``'default'`` layer if True.\n\n    Returns\n    -------\n    list[str]\n        Layer IDs.\n    \"\"\"\n    return list(self.get_layers_dict(include_default=include_default).keys())\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.list_snapshots","title":"<code>list_snapshots()</code>","text":"<p>List all snapshots.</p>"},{"location":"reference/api/#graphglue.Graph.list_snapshots--returns","title":"Returns","text":"<p>list[dict]     Snapshot metadata</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def list_snapshots(self):\n    \"\"\"\n    List all snapshots.\n\n    Returns\n    -------\n    list[dict]\n        Snapshot metadata\n    \"\"\"\n    return [\n        {\n            \"label\": snap[\"label\"],\n            \"timestamp\": snap[\"timestamp\"],\n            \"version\": snap[\"version\"],\n            \"counts\": snap[\"counts\"]\n        }\n        for snap in self._snapshots\n    ]\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.mark","title":"<code>mark(label)</code>","text":"<p>Insert a manual marker into the mutation history.</p>"},{"location":"reference/api/#graphglue.Graph.mark--parameters","title":"Parameters","text":"<p>label : str     Human-readable tag for the marker event.</p>"},{"location":"reference/api/#graphglue.Graph.mark--returns","title":"Returns","text":"<p>None</p>"},{"location":"reference/api/#graphglue.Graph.mark--notes","title":"Notes","text":"<p>The event is recorded with 'op'='mark' alongside standard fields ('version', 'ts_utc', 'mono_ns'). Logging must be enabled for the marker to be recorded.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def mark(self, label: str):\n    \"\"\"\n    Insert a manual marker into the mutation history.\n\n    Parameters\n    ----------\n    label : str\n        Human-readable tag for the marker event.\n\n    Returns\n    -------\n    None\n\n    Notes\n    -----\n    The event is recorded with 'op'='mark' alongside standard fields\n    ('version', 'ts_utc', 'mono_ns'). Logging must be enabled for the\n    marker to be recorded.\n    \"\"\"\n    self._log_event(\"mark\", label=label)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.memory_usage","title":"<code>memory_usage()</code>","text":"<p>Approximate total memory usage in bytes.</p>"},{"location":"reference/api/#graphglue.Graph.memory_usage--returns","title":"Returns","text":"<p>int     Estimated bytes for the incidence matrix, dictionaries, and attribute DFs.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def memory_usage(self):\n    \"\"\"\n    Approximate total memory usage in bytes.\n\n    Returns\n    -------\n    int\n        Estimated bytes for the incidence matrix, dictionaries, and attribute DFs.\n    \"\"\"        \n    # Approximate matrix memory: each non-zero entry stores row, col, and value (4 bytes each)\n    matrix_bytes = self._matrix.nnz * (4 + 4 + 4)\n    # Estimate dict memory: ~100 bytes per entry\n    dict_bytes = (len(self.entity_to_idx) + len(self.edge_to_idx) + len(self.edge_weights)) * 100\n\n    df_bytes = 0\n\n    # vertex attributes\n    if isinstance(self.vertex_attributes, pl.DataFrame):\n        # Polars provides a built-in estimate of total size in bytes\n        df_bytes += self.vertex_attributes.estimated_size()\n\n    # Edge attributes\n    if isinstance(self.edge_attributes, pl.DataFrame):\n        df_bytes += self.edge_attributes.estimated_size()\n\n    return matrix_bytes + dict_bytes + df_bytes\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.neighbors","title":"<code>neighbors(entity_id)</code>","text":"<p>Neighbors of an entity (vertex or edge-entity).</p>"},{"location":"reference/api/#graphglue.Graph.neighbors--parameters","title":"Parameters","text":"<p>entity_id : str</p>"},{"location":"reference/api/#graphglue.Graph.neighbors--returns","title":"Returns","text":"<p>list[str]     Adjacent entities. For hyperedges, uses head/tail orientation.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def neighbors(self, entity_id):\n    \"\"\"\n    Neighbors of an entity (vertex or edge-entity).\n\n    Parameters\n    ----------\n    entity_id : str\n\n    Returns\n    -------\n    list[str]\n        Adjacent entities. For hyperedges, uses head/tail orientation.\n    \"\"\"        \n    if entity_id not in self.entity_to_idx:\n        return []\n    out = set()\n    for eid in self.edge_to_idx.keys():\n        kind = self.edge_kind.get(eid, None)\n        if kind == \"hyper\":\n            meta = self.hyperedge_definitions[eid]\n            if meta[\"directed\"]:\n                if entity_id in meta[\"head\"]:\n                    out |= (meta[\"tail\"])\n                elif entity_id in meta[\"tail\"]:\n                    out |= (meta[\"head\"])\n            else:\n                if ((\"members\" in meta) and (entity_id in meta[\"members\"])):\n                    out |= (meta[\"members\"] - {entity_id})\n        else:\n            # binary / vertex_edge\n            s, t, _ = self.edge_definitions[eid]\n            edir = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n            if s == entity_id:\n                out.add(t)\n            elif t == entity_id and (not edir or self.entity_types.get(entity_id) == 'edge'):\n                out.add(s)\n    return list(out)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.number_of_edges","title":"<code>number_of_edges()</code>","text":"<p>Count edges (columns in the incidence matrix).</p>"},{"location":"reference/api/#graphglue.Graph.number_of_edges--returns","title":"Returns","text":"<p>int</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def number_of_edges(self):\n    \"\"\"\n    Count edges (columns in the incidence matrix).\n\n    Returns\n    -------\n    int\n    \"\"\"\n    return self._num_edges\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.number_of_vertices","title":"<code>number_of_vertices()</code>","text":"<p>Count vertices (excluding edge-entities).</p>"},{"location":"reference/api/#graphglue.Graph.number_of_vertices--returns","title":"Returns","text":"<p>int</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def number_of_vertices(self):\n    \"\"\"\n    Count vertices (excluding edge-entities).\n\n    Returns\n    -------\n    int\n    \"\"\"\n    return len([e for e in self.entity_types.values() if e == 'vertex'])\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.out_edges","title":"<code>out_edges(vertices)</code>","text":"<p>Iterate over all edges that are outgoing from one or more vertices.</p>"},{"location":"reference/api/#graphglue.Graph.out_edges--parameters","title":"Parameters","text":"<p>vertices : str | Iterable[str]     A single vertex ID or an iterable of vertex IDs. All edges whose     source set intersects with this set will be yielded.</p>"},{"location":"reference/api/#graphglue.Graph.out_edges--yields","title":"Yields","text":"<p>tuple[int, tuple[frozenset, frozenset]]     Tuples of the form <code>(edge_index, (S, T))</code>, where:     - <code>edge_index</code> : int \u2014 internal integer index of the edge.     - <code>S</code> : frozenset[str] \u2014 set of source/head verices.     - <code>T</code> : frozenset[str] \u2014 set of target/tail verices.</p>"},{"location":"reference/api/#graphglue.Graph.out_edges--behavior","title":"Behavior","text":"<ul> <li>Directed binary edges: returned if any vertex is in the source (<code>S</code>).</li> <li>Directed hyperedges: returned if any vertex is in the head set.</li> <li>Undirected edges/hyperedges: returned if any vertex is in the edge's member set (<code>S \u222a T</code>).</li> </ul>"},{"location":"reference/api/#graphglue.Graph.out_edges--notes","title":"Notes","text":"<ul> <li>Works with binary and hyperedges.</li> <li>Undirected edges appear in both <code>out_edges()</code> and <code>in_edges()</code>.</li> <li>The returned <code>(S, T)</code> is the canonical form from <code>get_edge()</code>.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def out_edges(self, vertices):\n    \"\"\"\n    Iterate over all edges that are **outgoing** from one or more vertices.\n\n    Parameters\n    ----------\n    vertices : str | Iterable[str]\n        A single vertex ID or an iterable of vertex IDs. All edges whose\n        **source set** intersects with this set will be yielded.\n\n    Yields\n    ------\n    tuple[int, tuple[frozenset, frozenset]]\n        Tuples of the form `(edge_index, (S, T))`, where:\n        - `edge_index` : int \u2014 internal integer index of the edge.\n        - `S` : frozenset[str] \u2014 set of source/head verices.\n        - `T` : frozenset[str] \u2014 set of target/tail verices.\n\n    Behavior\n    --------\n    - **Directed binary edges**: returned if any vertex is in the source (`S`).\n    - **Directed hyperedges**: returned if any vertex is in the head set.\n    - **Undirected edges/hyperedges**: returned if any vertex is in\n    the edge's member set (`S \u222a T`).\n\n    Notes\n    -----\n    - Works with binary and hyperedges.\n    - Undirected edges appear in both `out_edges()` and `in_edges()`.\n    - The returned `(S, T)` is the canonical form from `get_edge()`.\n    \"\"\"\n    V = self._normalize_vertices_arg(vertices)\n    if not V:\n        return\n    for j in range(self.number_of_edges()):\n        S, T = self.get_edge(j)\n        eid = self.idx_to_edge[j]\n        directed = self._is_directed_edge(eid)\n        if directed:\n            if S &amp; V:\n                yield j, (S, T)\n        else:\n            if (S | T) &amp; V:\n                yield j, (S, T)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.out_neighbors","title":"<code>out_neighbors(vertex_id)</code>","text":"<p>Out-neighbors of a vertex under directed semantics.</p>"},{"location":"reference/api/#graphglue.Graph.out_neighbors--parameters","title":"Parameters","text":"<p>vertex_id : str</p>"},{"location":"reference/api/#graphglue.Graph.out_neighbors--returns","title":"Returns","text":"<p>list[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def out_neighbors(self, vertex_id):\n    \"\"\"\n    Out-neighbors of a vertex under directed semantics.\n\n    Parameters\n    ----------\n    vertex_id : str\n\n    Returns\n    -------\n    list[str]\n    \"\"\"\n    if vertex_id not in self.entity_to_idx:\n        return []\n    out = set()\n    for eid in self.edge_to_idx.keys():\n        kind = self.edge_kind.get(eid, None)\n        if kind == \"hyper\":\n            meta = self.hyperedge_definitions[eid]\n            if meta[\"directed\"]:\n                if vertex_id in meta[\"head\"]:\n                    out |= (meta[\"tail\"])\n            else:\n                if vertex_id in meta.get(\"members\", ()):\n                    out |= (meta[\"members\"] - {vertex_id})\n        else:\n            s, t, _ = self.edge_definitions[eid]\n            edir = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n            if s == vertex_id:\n                out.add(t)\n            elif t == vertex_id and not edir:\n                out.add(s)\n    return list(out)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.predecessors","title":"<code>predecessors(vertex_id)</code>","text":"<p>In-neighbors of a vertex under directed semantics.</p>"},{"location":"reference/api/#graphglue.Graph.predecessors--parameters","title":"Parameters","text":"<p>vertex_id : str</p>"},{"location":"reference/api/#graphglue.Graph.predecessors--returns","title":"Returns","text":"<p>list[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def predecessors(self, vertex_id):\n    \"\"\"\n    In-neighbors of a vertex under directed semantics.\n\n    Parameters\n    ----------\n    vertex_id : str\n\n    Returns\n    -------\n    list[str]\n    \"\"\"        \n    if vertex_id not in self.entity_to_idx:\n        return []\n    inn = set()\n    for eid in self.edge_to_idx.keys():\n        kind = self.edge_kind.get(eid, None)\n        if kind == \"hyper\":\n            meta = self.hyperedge_definitions[eid]\n            if meta[\"directed\"]:\n                if vertex_id in meta[\"tail\"]:\n                    inn |= (meta[\"head\"])\n            else:\n                if vertex_id in meta.get(\"members\", ()):\n                    inn |= (meta[\"members\"] - {vertex_id})\n        else:\n            s, t, _ = self.edge_definitions[eid]\n            edir = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n            if t == vertex_id:\n                inn.add(s)\n            elif s == vertex_id and not edir:\n                inn.add(t)\n    return list(inn)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.read","title":"<code>read(path, **kwargs)</code>  <code>classmethod</code>","text":"<p>Load from .annnet format.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>@classmethod\ndef read(cls, path, **kwargs):\n    \"\"\"Load from .annnet format.\"\"\"\n    from ..io.io_annnet import read\n    return read(path, **kwargs)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.remove_edge","title":"<code>remove_edge(edge_id)</code>","text":"<p>Remove an edge (binary or hyperedge) from the graph.</p>"},{"location":"reference/api/#graphglue.Graph.remove_edge--parameters","title":"Parameters","text":"<p>edge_id : str</p>"},{"location":"reference/api/#graphglue.Graph.remove_edge--raises","title":"Raises","text":"<p>KeyError     If the edge is not found.</p>"},{"location":"reference/api/#graphglue.Graph.remove_edge--notes","title":"Notes","text":"<ul> <li>Physically removes the incidence column (no CSR round-trip).</li> <li>Cleans edge attributes, layer memberships, and per-layer entries.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def remove_edge(self, edge_id):\n    \"\"\"\n    Remove an edge (binary or hyperedge) from the graph.\n\n    Parameters\n    ----------\n    edge_id : str\n\n    Raises\n    ------\n    KeyError\n        If the edge is not found.\n\n    Notes\n    -----\n    - Physically removes the incidence column (no CSR round-trip).\n    - Cleans edge attributes, layer memberships, and per-layer entries.\n    \"\"\"\n    if edge_id not in self.edge_to_idx:\n        raise KeyError(f\"Edge {edge_id} not found\")\n\n    col_idx = self.edge_to_idx[edge_id]\n\n    # column removal without CSR (single pass over nonzeros)\n    M_old = self._matrix\n    rows, cols = M_old.shape\n    new_cols = cols - 1\n    # Rebuild DOK with columns &gt; col_idx shifted left by 1\n    M_new = sp.dok_matrix((rows, new_cols), dtype=M_old.dtype)\n    for (r, c), v in M_old.items():\n        if c == col_idx:\n            continue  # drop this column\n        elif c &gt; col_idx:\n            M_new[r, c - 1] = v\n        else:\n            M_new[r, c] = v\n    self._matrix = M_new\n\n    # mappings (preserve relative order of remaining edges)\n    # Remove the deleted edge id\n    del self.edge_to_idx[edge_id]\n    # Shift indices for edges after the removed column\n    for old_idx in range(col_idx + 1, self._num_edges):\n        eid = self.idx_to_edge.pop(old_idx)\n        self.idx_to_edge[old_idx - 1] = eid\n        self.edge_to_idx[eid] = old_idx - 1\n    # Drop the last stale entry (now shifted)\n    self.idx_to_edge.pop(self._num_edges - 1, None)\n    self._num_edges -= 1\n\n    # Metadata cleanup\n    # Edge definitions / weights / directedness\n    self.edge_definitions.pop(edge_id, None)\n    self.edge_weights.pop(edge_id, None)\n    if edge_id in self.edge_directed:\n        self.edge_directed.pop(edge_id, None)\n\n    # Remove from edge attributes\n    if (\n        isinstance(self.edge_attributes, pl.DataFrame)\n        and self.edge_attributes.height &gt; 0\n        and \"edge_id\" in self.edge_attributes.columns\n    ):\n        self.edge_attributes = self.edge_attributes.filter(pl.col(\"edge_id\") != edge_id)\n\n    # Remove from per-layer membership\n    for layer_data in self._layers.values():\n        layer_data[\"edges\"].discard(edge_id)\n\n    # Remove from edge-layer attributes\n    if (\n        isinstance(self.edge_layer_attributes, pl.DataFrame)\n        and self.edge_layer_attributes.height &gt; 0\n        and \"edge_id\" in self.edge_layer_attributes.columns\n    ):\n        self.edge_layer_attributes = self.edge_layer_attributes.filter(pl.col(\"edge_id\") != edge_id)\n\n    # Legacy / auxiliary dicts\n    for d in self.layer_edge_weights.values():\n        d.pop(edge_id, None)\n\n    self.edge_kind.pop(edge_id, None)\n    self.hyperedge_definitions.pop(edge_id, None)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.remove_edges","title":"<code>remove_edges(edge_ids)</code>","text":"<p>Remove many edges in one pass (much faster than looping).</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def remove_edges(self, edge_ids):\n    \"\"\"Remove many edges in one pass (much faster than looping).\"\"\"\n    to_drop = [eid for eid in edge_ids if eid in self.edge_to_idx]\n    if not to_drop:\n        return\n    self._remove_edges_bulk(to_drop)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.remove_layer","title":"<code>remove_layer(layer_id)</code>","text":"<p>Remove a non-default layer and its per-layer attributes.</p>"},{"location":"reference/api/#graphglue.Graph.remove_layer--parameters","title":"Parameters","text":"<p>layer_id : str</p>"},{"location":"reference/api/#graphglue.Graph.remove_layer--raises","title":"Raises","text":"<p>ValueError     If attempting to remove the internal default layer. KeyError     If the layer does not exist.</p>"},{"location":"reference/api/#graphglue.Graph.remove_layer--notes","title":"Notes","text":"<ul> <li>Does not delete vertices/edges globally; only membership and layer metadata.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def remove_layer(self, layer_id):\n    \"\"\"\n    Remove a non-default layer and its per-layer attributes.\n\n    Parameters\n    ----------\n    layer_id : str\n\n    Raises\n    ------\n    ValueError\n        If attempting to remove the internal default layer.\n    KeyError\n        If the layer does not exist.\n\n    Notes\n    -----\n    - Does not delete vertices/edges globally; only membership and layer metadata.\n    \"\"\"\n    if layer_id == self._default_layer:\n        raise ValueError(\"Cannot remove default layer\")\n    if layer_id not in self._layers:\n        raise KeyError(f\"Layer {layer_id} not found\")\n\n    # Purge per-layer attributes\n    ela = getattr(self, \"edge_layer_attributes\", None)\n    if isinstance(ela, pl.DataFrame) and ela.height &gt; 0 and \"layer_id\" in ela.columns:\n        # Keep everything not matching the layer_id\n        self.edge_layer_attributes = ela.filter(pl.col(\"layer_id\") != layer_id)\n\n    # Drop legacy dict slice if present\n    if isinstance(getattr(self, \"layer_edge_weights\", None), dict):\n        self.layer_edge_weights.pop(layer_id, None)\n\n    # Remove the layer and reset current if needed\n    del self._layers[layer_id]\n    if self._current_layer == layer_id:\n        self._current_layer = self._default_layer\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.remove_vertex","title":"<code>remove_vertex(vertex_id)</code>","text":"<p>Remove a vertex and all incident edges (binary + hyperedges).</p>"},{"location":"reference/api/#graphglue.Graph.remove_vertex--parameters","title":"Parameters","text":"<p>vertex_id : str</p>"},{"location":"reference/api/#graphglue.Graph.remove_vertex--raises","title":"Raises","text":"<p>KeyError     If the vertex is not found.</p>"},{"location":"reference/api/#graphglue.Graph.remove_vertex--notes","title":"Notes","text":"<ul> <li>Rebuilds entity indexing and shrinks the incidence matrix accordingly.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def remove_vertex(self, vertex_id):\n    \"\"\"\n    Remove a vertex and all incident edges (binary + hyperedges).\n\n    Parameters\n    ----------\n    vertex_id : str\n\n    Raises\n    ------\n    KeyError\n        If the vertex is not found.\n\n    Notes\n    -----\n    - Rebuilds entity indexing and shrinks the incidence matrix accordingly.\n    \"\"\"\n    if vertex_id not in self.entity_to_idx:\n        raise KeyError(f\"vertex {vertex_id} not found\")\n\n    entity_idx = self.entity_to_idx[vertex_id]\n\n    # Collect incident edges (set to avoid duplicates)\n    edges_to_remove = set()\n\n    # Binary edges: edge_definitions {eid: (source, target, ...)}\n    for eid, edef in list(self.edge_definitions.items()):\n        try:\n            source, target = edef[0], edef[1]\n        except Exception:\n            source, target = edef.get(\"source\"), edef.get(\"target\")\n        if source == vertex_id or target == vertex_id:\n            edges_to_remove.add(eid)\n\n    # Hyperedges: hyperedge_definitions {eid: {\"head\":[...], \"tail\":[...]}} or {\"members\":[...]}\n    def _vertex_in_hyperdef(hdef: dict, vertex: str) -&gt; bool:\n        # Common keys first\n        for key in (\"head\", \"tail\", \"members\", \"vertices\", \"vertices\"):\n            seq = hdef.get(key)\n            if isinstance(seq, (list, tuple, set)) and vertex in seq:\n                return True\n        # Safety net: scan any list/tuple/set values\n        for v in hdef.values():\n            if isinstance(v, (list, tuple, set)) and vertex in v:\n                return True\n        return False\n\n    hdefs = getattr(self, \"hyperedge_definitions\", {})\n    if isinstance(hdefs, dict):\n        for heid, hdef in list(hdefs.items()):\n            if isinstance(hdef, dict) and _vertex_in_hyperdef(hdef, vertex_id):\n                edges_to_remove.add(heid)\n\n    # Remove all collected edges\n    for eid in edges_to_remove:\n        self.remove_edge(eid)\n\n    # row removal without CSR: rebuild DOK with rows-1 and shift indices\n    M_old = self._matrix\n    rows, cols = M_old.shape\n    new_rows = rows - 1\n    M_new = sp.dok_matrix((new_rows, cols), dtype=M_old.dtype)\n    for (r, c), v in M_old.items():\n        if r == entity_idx:\n            continue  # drop this row\n        elif r &gt; entity_idx:\n            M_new[r - 1, c] = v\n        else:\n            M_new[r, c] = v\n    self._matrix = M_new\n\n    # Update entity mappings\n    del self.entity_to_idx[vertex_id]\n    del self.entity_types[vertex_id]\n\n    # Shift indices for entities after the removed row; preserve relative order\n    for old_idx in range(entity_idx + 1, self._num_entities):\n        ent_id = self.idx_to_entity.pop(old_idx)\n        self.idx_to_entity[old_idx - 1] = ent_id\n        self.entity_to_idx[ent_id] = old_idx - 1\n    # Drop last stale entry and shrink count\n    self.idx_to_entity.pop(self._num_entities - 1, None)\n    self._num_entities -= 1\n\n    # Remove from vertex attributes\n    if isinstance(self.vertex_attributes, pl.DataFrame):\n        if self.vertex_attributes.height &gt; 0 and \"vertex_id\" in self.vertex_attributes.columns:\n            self.vertex_attributes = self.vertex_attributes.filter(pl.col(\"vertex_id\") != vertex_id)\n\n    # Remove from per-layer membership\n    for layer_data in self._layers.values():\n        layer_data[\"vertices\"].discard(vertex_id)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.remove_vertices","title":"<code>remove_vertices(vertex_ids)</code>","text":"<p>Remove many vertices (and all their incident edges) in one pass.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def remove_vertices(self, vertex_ids):\n    \"\"\"Remove many vertices (and all their incident edges) in one pass.\"\"\"\n    to_drop = [vid for vid in vertex_ids if vid in self.entity_to_idx]\n    if not to_drop:\n        return\n    self._remove_vertices_bulk(to_drop)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.reverse","title":"<code>reverse()</code>","text":"<p>Return a new graph with all directed edges reversed.</p>"},{"location":"reference/api/#graphglue.Graph.reverse--returns","title":"Returns","text":"<p>Graph     A new <code>Graph</code> instance with reversed directionality where applicable.</p>"},{"location":"reference/api/#graphglue.Graph.reverse--behavior","title":"Behavior","text":"<ul> <li>Binary edges: direction is flipped by swapping source and target.</li> <li>Directed hyperedges: <code>head</code> and <code>tail</code> sets are swapped.</li> <li>Undirected edges/hyperedges: unaffected.</li> <li>Edge attributes and metadata are preserved.</li> </ul>"},{"location":"reference/api/#graphglue.Graph.reverse--notes","title":"Notes","text":"<ul> <li>This operation does not modify the original graph.</li> <li>If the graph is undirected (<code>self.directed == False</code>), the result is identical to the original.</li> <li>For mixed graphs (directed + undirected edges), only the directed ones are reversed.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def reverse(self) -&gt; \"Graph\":\n    \"\"\"\n    Return a new graph with all directed edges reversed.\n\n    Returns\n    -------\n    Graph\n        A new `Graph` instance with reversed directionality where applicable.\n\n    Behavior\n    --------\n    - **Binary edges:** direction is flipped by swapping source and target.\n    - **Directed hyperedges:** `head` and `tail` sets are swapped.\n    - **Undirected edges/hyperedges:** unaffected.\n    - Edge attributes and metadata are preserved.\n\n    Notes\n    -----\n    - This operation does not modify the original graph.\n    - If the graph is undirected (`self.directed == False`), the result is\n    identical to the original.\n    - For mixed graphs (directed + undirected edges), only the directed\n    ones are reversed.\n    \"\"\"\n    g = self.copy()\n\n    for eid, defn in g.edge_definitions.items():\n        if not g._is_directed_edge(eid):\n            continue\n        # Binary edge: swap endpoints\n        u, v, etype = defn\n        g.edge_definitions[eid] = (v, u, etype)\n\n    for eid, meta in g.hyperedge_definitions.items():\n        if not meta.get(\"directed\", False):\n            continue\n        # Hyperedge: swap head and tail sets\n        meta[\"head\"], meta[\"tail\"] = meta[\"tail\"], meta[\"head\"]\n\n    return g\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.set_active_layer","title":"<code>set_active_layer(layer_id)</code>","text":"<p>Set the active layer for subsequent operations.</p>"},{"location":"reference/api/#graphglue.Graph.set_active_layer--parameters","title":"Parameters","text":"<p>layer_id : str     Existing layer ID.</p>"},{"location":"reference/api/#graphglue.Graph.set_active_layer--raises","title":"Raises","text":"<p>KeyError     If the layer does not exist.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def set_active_layer(self, layer_id):\n    \"\"\"\n    Set the active layer for subsequent operations.\n\n    Parameters\n    ----------\n    layer_id : str\n        Existing layer ID.\n\n    Raises\n    ------\n    KeyError\n        If the layer does not exist.\n    \"\"\"\n    if layer_id not in self._layers:\n        raise KeyError(f\"Layer {layer_id} not found\")\n    self._current_layer = layer_id\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.set_edge_attrs","title":"<code>set_edge_attrs(edge_id, **attrs)</code>","text":"<p>Upsert pure edge attributes (non-structural) into the edge DF.</p>"},{"location":"reference/api/#graphglue.Graph.set_edge_attrs--parameters","title":"Parameters","text":"<p>edge_id : str **attrs     Key/value attributes. Structural keys are ignored.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def set_edge_attrs(self, edge_id, **attrs):\n    \"\"\"\n    Upsert pure edge attributes (non-structural) into the edge DF.\n\n    Parameters\n    ----------\n    edge_id : str\n    **attrs\n        Key/value attributes. Structural keys are ignored.\n    \"\"\"\n    # keep attributes table pure: strip structural keys\n    clean = {k: v for k, v in attrs.items() if k not in self._EDGE_RESERVED}\n    if clean:\n        self.edge_attributes = self._upsert_row(self.edge_attributes, edge_id, clean)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.set_edge_layer_attrs","title":"<code>set_edge_layer_attrs(layer_id, edge_id, **attrs)</code>","text":"<p>Upsert per-layer attributes for a specific edge.</p>"},{"location":"reference/api/#graphglue.Graph.set_edge_layer_attrs--parameters","title":"Parameters","text":"<p>layer_id : str edge_id : str **attrs     Pure attributes. Structural keys are ignored (except 'weight', which is allowed here).</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def set_edge_layer_attrs(self, layer_id, edge_id, **attrs):\n    \"\"\"\n    Upsert per-layer attributes for a specific edge.\n\n    Parameters\n    ----------\n    layer_id : str\n    edge_id : str\n    **attrs\n        Pure attributes. Structural keys are ignored (except 'weight', which is allowed here).\n    \"\"\"\n    # allow 'weight' through; keep ignoring true structural keys\n    clean = {k: v for k, v in attrs.items() if (k not in self._EDGE_RESERVED) or (k == \"weight\")}\n    if not clean:\n        return\n\n    # Normalize hot keys (intern) and avoid float dtype surprises for 'weight'\n    try:\n        import sys as _sys\n        if isinstance(layer_id, str): layer_id = _sys.intern(layer_id)\n        if isinstance(edge_id, str):  edge_id  = _sys.intern(edge_id)\n    except Exception:\n        pass\n    if \"weight\" in clean:\n        try:\n            # cast once to float to reduce dtype mismatch churn inside _upsert_row\n            clean[\"weight\"] = float(clean[\"weight\"])\n        except Exception:\n            # leave as-is if not coercible; behavior stays identical\n            pass\n\n    # Ensure edge_layer_attributes compares strings to strings (defensive against prior bad writes),\n    # but only cast when actually needed (skip no-op with_columns).\n    df = self.edge_layer_attributes\n    if isinstance(df, pl.DataFrame) and df.height &gt; 0:\n        to_cast = []\n        if \"layer_id\" in df.columns and df.schema[\"layer_id\"] != pl.Utf8:\n            to_cast.append(pl.col(\"layer_id\").cast(pl.Utf8))\n        if \"edge_id\" in df.columns and df.schema[\"edge_id\"] != pl.Utf8:\n            to_cast.append(pl.col(\"edge_id\").cast(pl.Utf8))\n        if to_cast:\n            df = df.with_columns(*to_cast)\n            self.edge_layer_attributes = df  # reassign only when changed\n\n    # Upsert via central helper (keeps exact behavior, schema handling, and caching)\n    self.edge_layer_attributes = self._upsert_row(\n        self.edge_layer_attributes, (layer_id, edge_id), clean\n    )\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.set_edge_layer_attrs_bulk","title":"<code>set_edge_layer_attrs_bulk(layer_id, items)</code>","text":"<p>items: iterable of (edge_id, attrs_dict) or dict{edge_id: attrs_dict} Upserts rows in edge_layer_attributes for one layer in bulk.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def set_edge_layer_attrs_bulk(self, layer_id, items):\n    \"\"\"\n    items: iterable of (edge_id, attrs_dict) or dict{edge_id: attrs_dict}\n    Upserts rows in edge_layer_attributes for one layer in bulk.\n    \"\"\"\n    import polars as pl\n\n    # normalize\n    rows = []\n    if isinstance(items, dict):\n        it = items.items()\n    else:\n        it = items\n    for eid, attrs in it:\n        if not isinstance(attrs, dict) or not attrs:\n            continue\n        r = {\"layer_id\": layer_id, \"edge_id\": eid}\n        r.update(attrs)\n        if \"weight\" in r:\n            try: r[\"weight\"] = float(r[\"weight\"])\n            except Exception: pass\n        rows.append(r)\n    if not rows:\n        return\n\n    # start from current DF\n    df = self.edge_layer_attributes\n    add_df = pl.DataFrame(rows)\n\n    # ensure required key cols exist/correct dtype on existing df\n    if not isinstance(df, pl.DataFrame) or df.is_empty():\n        # create from scratch with canonical dtypes\n        self.edge_layer_attributes = add_df\n        # legacy mirror\n        if \"weight\" in add_df.columns:\n            self.layer_edge_weights.setdefault(layer_id, {})\n            for r in add_df.iter_rows(named=True):\n                w = r.get(\"weight\")\n                if w is not None:\n                    self.layer_edge_weights[layer_id][r[\"edge_id\"]] = float(w)\n        return\n\n    # schema alignment using your _ensure_attr_columns + Utf8 upcast rule\n    need_cols = {c: None for c in add_df.columns if c not in df.columns}\n    if need_cols:\n        df = self._ensure_attr_columns(df, need_cols)  # adds missing columns to df\n    # add missing columns to add_df\n    for c in df.columns:\n        if c not in add_df.columns:\n            add_df = add_df.with_columns(pl.lit(None).cast(df.schema[c]).alias(c))\n    # reconcile dtype mismatches (Null/Null, mixed -&gt; Utf8), same policy as _upsert_row\n    for c in df.columns:\n        lc, rc = df.schema[c], add_df.schema[c]\n        if lc == pl.Null and rc != pl.Null:\n            df = df.with_columns(pl.col(c).cast(rc))\n        elif rc == pl.Null and lc != pl.Null:\n            add_df = add_df.with_columns(pl.col(c).cast(lc).alias(c))\n        elif lc != rc:\n            df = df.with_columns(pl.col(c).cast(pl.Utf8))\n            add_df = add_df.with_columns(pl.col(c).cast(pl.Utf8).alias(c))\n\n    # drop existing keys for (layer_id, edge_id) we are about to write; then vstack new rows\n    mask_keep = ~((pl.col(\"layer_id\") == layer_id) &amp; pl.col(\"edge_id\").is_in(add_df.get_column(\"edge_id\")))\n    df = df.filter(mask_keep)\n    df = df.vstack(add_df)\n    self.edge_layer_attributes = df\n\n    # legacy mirror\n    if \"weight\" in add_df.columns:\n        self.layer_edge_weights.setdefault(layer_id, {})\n        for r in add_df.iter_rows(named=True):\n            w = r.get(\"weight\")\n            if w is not None:\n                self.layer_edge_weights[layer_id][r[\"edge_id\"]] = float(w)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.set_graph_attribute","title":"<code>set_graph_attribute(key, value)</code>","text":"<p>Set a graph-level attribute.</p>"},{"location":"reference/api/#graphglue.Graph.set_graph_attribute--parameters","title":"Parameters","text":"<p>key : str value : Any</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def set_graph_attribute(self, key, value):\n    \"\"\"\n    Set a graph-level attribute.\n\n    Parameters\n    ----------\n    key : str\n    value : Any\n    \"\"\"\n    self.graph_attributes[key] = value\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.set_hyperedge_coeffs","title":"<code>set_hyperedge_coeffs(edge_id, coeffs)</code>","text":"<p>Write per-vertex coefficients into the incidence column (DOK [dictionary of keys]).</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def set_hyperedge_coeffs(self, edge_id: str, coeffs: dict[str, float]) -&gt; None:\n    \"\"\"Write per-vertex coefficients into the incidence column (DOK [dictionary of keys]).\"\"\"\n    col = self.edge_to_idx[edge_id]\n    for vid, coeff in coeffs.items():\n        row = self.entity_to_idx[vid]\n        self._matrix[row, col] = float(coeff)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.set_layer_attrs","title":"<code>set_layer_attrs(layer_id, **attrs)</code>","text":"<p>Upsert pure layer attributes.</p>"},{"location":"reference/api/#graphglue.Graph.set_layer_attrs--parameters","title":"Parameters","text":"<p>layer_id : str **attrs     Key/value attributes. Structural keys are ignored.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def set_layer_attrs(self, layer_id, **attrs):\n    \"\"\"\n    Upsert pure layer attributes.\n\n    Parameters\n    ----------\n    layer_id : str\n    **attrs\n        Key/value attributes. Structural keys are ignored.\n    \"\"\"\n    clean = {k: v for k, v in attrs.items() if k not in self._LAYER_RESERVED}\n    if clean:\n        self.layer_attributes = self._upsert_row(self.layer_attributes, layer_id, clean)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.set_layer_edge_weight","title":"<code>set_layer_edge_weight(layer_id, edge_id, weight)</code>","text":"<p>Set a legacy per-layer weight override for an edge.</p>"},{"location":"reference/api/#graphglue.Graph.set_layer_edge_weight--parameters","title":"Parameters","text":"<p>layer_id : str edge_id : str weight : float</p>"},{"location":"reference/api/#graphglue.Graph.set_layer_edge_weight--raises","title":"Raises","text":"<p>KeyError     If the layer or edge does not exist.</p>"},{"location":"reference/api/#graphglue.Graph.set_layer_edge_weight--see-also","title":"See Also","text":"<p>get_effective_edge_weight</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def set_layer_edge_weight(self, layer_id, edge_id, weight): #legacy weight helper\n    \"\"\"\n    Set a legacy per-layer weight override for an edge.\n\n    Parameters\n    ----------\n    layer_id : str\n    edge_id : str\n    weight : float\n\n    Raises\n    ------\n    KeyError\n        If the layer or edge does not exist.\n\n    See Also\n    --------\n    get_effective_edge_weight\n    \"\"\"\n    if layer_id not in self._layers:\n        raise KeyError(f\"Layer {layer_id} not found\")\n    if edge_id not in self.edge_to_idx:\n        raise KeyError(f\"Edge {edge_id} not found\")\n    self.layer_edge_weights[layer_id][edge_id] = float(weight)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.set_vertex_attrs","title":"<code>set_vertex_attrs(vertex_id, **attrs)</code>","text":"<p>Upsert pure vertex attributes (non-structural) into the vertex DF.</p>"},{"location":"reference/api/#graphglue.Graph.set_vertex_attrs--parameters","title":"Parameters","text":"<p>vertex_id : str **attrs     Key/value attributes. Structural keys are ignored.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def set_vertex_attrs(self, vertex_id, **attrs):\n    \"\"\"\n    Upsert pure vertex attributes (non-structural) into the vertex DF.\n\n    Parameters\n    ----------\n    vertex_id : str\n    **attrs\n        Key/value attributes. Structural keys are ignored.\n    \"\"\"\n    # keep attributes table pure\n    clean = {k: v for k, v in attrs.items() if k not in self._vertex_RESERVED}\n    if clean:\n        self.vertex_attributes = self._upsert_row(self.vertex_attributes, vertex_id, clean)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.snapshot","title":"<code>snapshot(label=None)</code>","text":"<p>Create a named snapshot of current graph state.</p> <p>Uses existing Graph attributes: entity_types, edge_to_idx, _layers, _version</p>"},{"location":"reference/api/#graphglue.Graph.snapshot--parameters","title":"Parameters","text":"<p>label : str, optional     Human-readable label for snapshot (auto-generated if None)</p>"},{"location":"reference/api/#graphglue.Graph.snapshot--returns","title":"Returns","text":"<p>dict     Snapshot metadata</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def snapshot(self, label=None):\n    \"\"\"\n    Create a named snapshot of current graph state.\n\n    Uses existing Graph attributes: entity_types, edge_to_idx, _layers, _version\n\n    Parameters\n    ----------\n    label : str, optional\n        Human-readable label for snapshot (auto-generated if None)\n\n    Returns\n    -------\n    dict\n        Snapshot metadata\n    \"\"\"\n    from datetime import datetime, timezone\n\n    if label is None:\n        label = f\"snapshot_{len(self._snapshots)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\n    snapshot = {\n        \"label\": label,\n        \"version\": self._version,\n        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n        \"counts\": {\n            \"vertices\": self.number_of_vertices(),\n            \"edges\": self.number_of_edges(),\n            \"layers\": len(self._layers)\n        },\n        # Store minimal state for comparison (uses existing Graph attributes)\n        \"vertex_ids\": set(v for v, t in self.entity_types.items() if t == \"vertex\"),\n        \"edge_ids\": set(self.edge_to_idx.keys()),\n        \"layer_ids\": set(self._layers.keys()),\n    }\n\n    self._snapshots.append(snapshot)\n    return snapshot\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.subgraph","title":"<code>subgraph(vertices)</code>","text":"<p>Create a vertex-induced subgraph.</p>"},{"location":"reference/api/#graphglue.Graph.subgraph--parameters","title":"Parameters","text":"<p>vertices : Iterable[str]     A set or list of vertex identifiers to keep in the subgraph.</p>"},{"location":"reference/api/#graphglue.Graph.subgraph--returns","title":"Returns","text":"<p>Graph     A new <code>Graph</code> containing only the specified vertices and any edges     for which all endpoints are within this set.</p>"},{"location":"reference/api/#graphglue.Graph.subgraph--behavior","title":"Behavior","text":"<ul> <li>Copies the current graph and removes edges with any endpoint outside the provided vertex set.</li> <li>Removes all vertices not listed in <code>vertices</code>.</li> </ul>"},{"location":"reference/api/#graphglue.Graph.subgraph--notes","title":"Notes","text":"<ul> <li>For binary edges, both endpoints must be in <code>vertices</code> to be retained.</li> <li>For hyperedges, all member verices must be included to retain the edge.</li> <li>Attributes for retained verices and edges are preserved.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def subgraph(self, vertices) -&gt; \"Graph\":\n    \"\"\"\n    Create a vertex-induced subgraph.\n\n    Parameters\n    ----------\n    vertices : Iterable[str]\n        A set or list of vertex identifiers to keep in the subgraph.\n\n    Returns\n    -------\n    Graph\n        A new `Graph` containing only the specified vertices and any edges\n        for which **all** endpoints are within this set.\n\n    Behavior\n    --------\n    - Copies the current graph and removes edges with any endpoint outside\n    the provided vertex set.\n    - Removes all vertices not listed in `vertices`.\n\n    Notes\n    -----\n    - For binary edges, both endpoints must be in `vertices` to be retained.\n    - For hyperedges, **all** member verices must be included to retain the edge.\n    - Attributes for retained verices and edges are preserved.\n    \"\"\"\n    V = set(vertices)\n\n    # collect edges fully inside V\n    E_bin, E_hyper_members, E_hyper_dir = [], [], []\n    for eid, (s, t, et) in self.edge_definitions.items():\n        if et == \"hyper\":\n            continue\n        if s in V and t in V:\n            E_bin.append(eid)\n    for eid, h in self.hyperedge_definitions.items():\n        if h.get(\"members\"):\n            if set(h[\"members\"]).issubset(V):\n                E_hyper_members.append(eid)\n        else:\n            if set(h.get(\"head\", ())).issubset(V) and set(h.get(\"tail\", ())).issubset(V):\n                E_hyper_dir.append(eid)\n\n    # payloads\n    v_rows = [{\"vertex_id\": v, **(self._row_attrs(self.vertex_attributes, \"vertex_id\", v) or {})} for v in V]\n\n    bin_payload = []\n    for eid in E_bin:\n        s, t, etype = self.edge_definitions[eid]\n        bin_payload.append({\"source\": s, \"target\": t, \"edge_id\": eid,\n                            \"edge_type\": etype,\n                            \"edge_directed\": self.edge_directed.get(eid, True if self.directed is None else self.directed),\n                            \"weight\": self.edge_weights.get(eid, 1.0)})\n\n    hyper_payload = []\n    for eid in E_hyper_members:\n        m = self.hyperedge_definitions[eid][\"members\"]\n        hyper_payload.append({\"members\": list(m), \"edge_id\": eid,\n                            \"weight\": self.edge_weights.get(eid, 1.0)})\n    for eid in E_hyper_dir:\n        h = self.hyperedge_definitions[eid]\n        hyper_payload.append({\"head\": list(h.get(\"head\", ())),\n                            \"tail\": list(h.get(\"tail\", ())),\n                            \"edge_id\": eid, \"weight\": self.edge_weights.get(eid, 1.0)})\n\n    # build new graph\n    g = Graph(directed=self.directed, n=len(V), e=len(E_bin)+len(E_hyper_members)+len(E_hyper_dir))\n    g.add_vertices_bulk(v_rows, layer=g._default_layer)\n    if bin_payload:\n        g.add_edges_bulk(bin_payload, layer=g._default_layer)\n    if hyper_payload:\n        g.add_hyperedges_bulk(hyper_payload, layer=g._default_layer)\n\n    # layer memberships restricted to V\n    for lid, meta in self._layers.items():\n        g.add_layer(lid, **meta[\"attributes\"])\n        keep = set()\n        for eid in meta[\"edges\"]:\n            kind = self.edge_kind.get(eid, \"binary\")\n            if kind == \"hyper\":\n                h = self.hyperedge_definitions[eid]\n                if h.get(\"members\"):\n                    if set(h[\"members\"]).issubset(V): keep.add(eid)\n                else:\n                    if set(h.get(\"head\",())).issubset(V) and set(h.get(\"tail\",())).issubset(V): keep.add(eid)\n            else:\n                s, t, _ = self.edge_definitions[eid]\n                if s in V and t in V:\n                    keep.add(eid)\n        if keep:\n            g.add_edges_to_layer_bulk(lid, keep)\n\n    return g\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.successors","title":"<code>successors(vertex_id)</code>","text":"<p>successors of a vertex under directed semantics.</p>"},{"location":"reference/api/#graphglue.Graph.successors--parameters","title":"Parameters","text":"<p>vertex_id : str</p>"},{"location":"reference/api/#graphglue.Graph.successors--returns","title":"Returns","text":"<p>list[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def successors(self, vertex_id):\n    \"\"\"\n    successors of a vertex under directed semantics.\n\n    Parameters\n    ----------\n    vertex_id : str\n\n    Returns\n    -------\n    list[str]\n    \"\"\"\n    if vertex_id not in self.entity_to_idx:\n        return []\n    out = set()\n    for eid in self.edge_to_idx.keys():\n        kind = self.edge_kind.get(eid, None)\n        if kind == \"hyper\":\n            meta = self.hyperedge_definitions[eid]\n            if meta[\"directed\"]:\n                if vertex_id in meta[\"head\"]:\n                    out |= (meta[\"tail\"])\n            else:\n                if vertex_id in meta.get(\"members\", ()):\n                    out |= (meta[\"members\"] - {vertex_id})\n        else:\n            s, t, _ = self.edge_definitions[eid]\n            edir = self.edge_directed.get(eid, True if self.directed is None else self.directed)\n            if s == vertex_id:\n                out.add(t)\n            elif t == vertex_id and not edir:\n                out.add(s)\n    return list(out)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.temporal_dynamics","title":"<code>temporal_dynamics(ordered_layers, metric='edge_change')</code>","text":"<p>Compute changes between consecutive layers in a temporal sequence.</p>"},{"location":"reference/api/#graphglue.Graph.temporal_dynamics--parameters","title":"Parameters","text":"<p>ordered_layers : list[str]     Layer IDs in chronological order. metric : {'edge_change', 'vertex_change'}, optional</p>"},{"location":"reference/api/#graphglue.Graph.temporal_dynamics--returns","title":"Returns","text":"<p>list[dict[str, int]]     Per-step dictionaries with keys: <code>'added'</code>, <code>'removed'</code>, <code>'net_change'</code>.</p>"},{"location":"reference/api/#graphglue.Graph.temporal_dynamics--raises","title":"Raises","text":"<p>ValueError     If fewer than two layers are provided. KeyError     If a referenced layer does not exist.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def temporal_dynamics(self, ordered_layers, metric='edge_change'):\n    \"\"\"\n    Compute changes between consecutive layers in a temporal sequence.\n\n    Parameters\n    ----------\n    ordered_layers : list[str]\n        Layer IDs in chronological order.\n    metric : {'edge_change', 'vertex_change'}, optional\n\n    Returns\n    -------\n    list[dict[str, int]]\n        Per-step dictionaries with keys: ``'added'``, ``'removed'``, ``'net_change'``.\n\n    Raises\n    ------\n    ValueError\n        If fewer than two layers are provided.\n    KeyError\n        If a referenced layer does not exist.\n    \"\"\"\n    if len(ordered_layers) &lt; 2:\n        raise ValueError(\"Need at least 2 layers for temporal analysis\")\n\n    changes = []\n\n    for i in range(len(ordered_layers) - 1):\n        current_id = ordered_layers[i]\n        next_id = ordered_layers[i + 1]\n\n        if current_id not in self._layers or next_id not in self._layers:\n            raise KeyError(\"One or more layers not found\")\n\n        current_data = self._layers[current_id]\n        next_data = self._layers[next_id]\n\n        if metric == 'edge_change':\n            added = len(next_data[\"edges\"] - current_data[\"edges\"])\n            removed = len(current_data[\"edges\"] - next_data[\"edges\"])\n            changes.append({'added': added, 'removed': removed, 'net_change': added - removed})\n\n        elif metric == 'vertex_change':\n            added = len(next_data[\"vertices\"] - current_data[\"vertices\"])\n            removed = len(current_data[\"vertices\"] - next_data[\"vertices\"])\n            changes.append({'added': added, 'removed': removed, 'net_change': added - removed})\n\n    return changes\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.vertex_incidence_matrix","title":"<code>vertex_incidence_matrix(values=False, sparse=False)</code>","text":"<p>Return the vertex\u2013edge incidence matrix in sparse or dense form.</p>"},{"location":"reference/api/#graphglue.Graph.vertex_incidence_matrix--parameters","title":"Parameters","text":"<p>values : bool, optional (default=False)     If <code>True</code>, include the numeric values stored in the matrix     (e.g., weights or signed incidence values). If <code>False</code>, convert the     matrix to a binary mask (1 if incident, 0 if not). sparse : bool, optional (default=False)     - If <code>True</code>, return the underlying sparse matrix (CSR).     - If <code>False</code>, return a dense NumPy ndarray.</p>"},{"location":"reference/api/#graphglue.Graph.vertex_incidence_matrix--returns","title":"Returns","text":"<p>scipy.sparse.csr_matrix | numpy.ndarray     The vertex\u2013edge incidence matrix <code>M</code>:     - Rows correspond to vertices.     - Columns correspond to edges.     - <code>M[i, j]</code> \u2260 0 indicates that vertex <code>i</code> is incident to edge <code>j</code>.</p>"},{"location":"reference/api/#graphglue.Graph.vertex_incidence_matrix--notes","title":"Notes","text":"<ul> <li>If <code>values=False</code>, the returned matrix is binarized before returning.</li> <li>Use <code>sparse=True</code> for large graphs to avoid memory blowups.</li> <li>This is the canonical low-level structure that most algorithms (e.g., spectral clustering, Laplacian construction, hypergraph analytics) rely on.</li> </ul> Source code in <code>graphglue/core/graph.py</code> <pre><code>def vertex_incidence_matrix(self, values: bool = False, sparse: bool = False):\n    \"\"\"\n    Return the vertex\u2013edge incidence matrix in sparse or dense form.\n\n    Parameters\n    ----------\n    values : bool, optional (default=False)\n        If `True`, include the numeric values stored in the matrix\n        (e.g., weights or signed incidence values). If `False`, convert the\n        matrix to a binary mask (1 if incident, 0 if not).\n    sparse : bool, optional (default=False)\n        - If `True`, return the underlying sparse matrix (CSR).\n        - If `False`, return a dense NumPy ndarray.\n\n    Returns\n    -------\n    scipy.sparse.csr_matrix | numpy.ndarray\n        The vertex\u2013edge incidence matrix `M`:\n        - Rows correspond to vertices.\n        - Columns correspond to edges.\n        - `M[i, j]` \u2260 0 indicates that vertex `i` is incident to edge `j`.\n\n    Notes\n    -----\n    - If `values=False`, the returned matrix is binarized before returning.\n    - Use `sparse=True` for large graphs to avoid memory blowups.\n    - This is the canonical low-level structure that most algorithms (e.g.,\n    spectral clustering, Laplacian construction, hypergraph analytics) rely on.\n    \"\"\"\n    M = self._matrix.tocsr()\n\n    if not values:\n        # Convert to binary mask\n        M = M.copy()\n        M.data[:] = 1\n\n    if sparse:\n        return M\n    else:\n        return M.toarray()\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.vertex_presence_across_layers","title":"<code>vertex_presence_across_layers(vertex_id, include_default=False)</code>","text":"<p>List layers containing a specific vertex.</p>"},{"location":"reference/api/#graphglue.Graph.vertex_presence_across_layers--parameters","title":"Parameters","text":"<p>vertex_id : str include_default : bool, optional</p>"},{"location":"reference/api/#graphglue.Graph.vertex_presence_across_layers--returns","title":"Returns","text":"<p>list[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def vertex_presence_across_layers(self, vertex_id, include_default: bool = False):\n    \"\"\"\n    List layers containing a specific vertex.\n\n    Parameters\n    ----------\n    vertex_id : str\n    include_default : bool, optional\n\n    Returns\n    -------\n    list[str]\n    \"\"\"\n    layers_with_vertex = []\n    for layer_id, layer_data in self.get_layers_dict(include_default=include_default).items():\n        if vertex_id in layer_data[\"vertices\"]:\n            layers_with_vertex.append(layer_id)\n    return layers_with_vertex\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.vertices","title":"<code>vertices()</code>","text":"<p>Get all vertex IDs (excluding edge-entities).</p>"},{"location":"reference/api/#graphglue.Graph.vertices--returns","title":"Returns","text":"<p>list[str]</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def vertices(self):\n    \"\"\"\n    Get all vertex IDs (excluding edge-entities).\n\n    Returns\n    -------\n    list[str]\n    \"\"\"\n    return [eid for eid, etype in self.entity_types.items() if etype == 'vertex']\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.vertices_view","title":"<code>vertices_view(copy=True)</code>","text":"<p>Read-only vertex attribute table.</p>"},{"location":"reference/api/#graphglue.Graph.vertices_view--parameters","title":"Parameters","text":"<p>copy : bool, optional     Return a cloned DF.</p>"},{"location":"reference/api/#graphglue.Graph.vertices_view--returns","title":"Returns","text":"<p>polars.DataFrame     Columns: <code>vertex_id</code> plus pure attributes (may be empty).</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def vertices_view(self, copy=True):\n    \"\"\"\n    Read-only vertex attribute table.\n\n    Parameters\n    ----------\n    copy : bool, optional\n        Return a cloned DF.\n\n    Returns\n    -------\n    polars.DataFrame\n        Columns: ``vertex_id`` plus pure attributes (may be empty).\n    \"\"\"\n    df = self.vertex_attributes\n    if df.height == 0:\n        return pl.DataFrame(schema={\"vertex_id\": pl.Utf8})\n    return df.clone() if copy else df\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.view","title":"<code>view(nodes=None, edges=None, layers=None, predicate=None)</code>","text":"<p>Create lazy view/subgraph.</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def view(self, nodes=None, edges=None, layers=None, predicate=None):\n    \"\"\"Create lazy view/subgraph.\"\"\"\n    return GraphView(self, nodes, edges, layers, predicate)\n</code></pre>"},{"location":"reference/api/#graphglue.Graph.write","title":"<code>write(path, **kwargs)</code>","text":"<p>Save to .annnet format (zero loss).</p> Source code in <code>graphglue/core/graph.py</code> <pre><code>def write(self, path, **kwargs):\n    \"\"\"Save to .annnet format (zero loss).\"\"\"\n    from ..io.io_annnet import write\n    write(self, path, **kwargs)\n</code></pre>"},{"location":"reference/source/graphglue/_metadata-docs/","title":"_metadata","text":""},{"location":"reference/source/graphglue/_metadata-docs/#description","title":"Description","text":"<p>The <code>_metadata.py</code> file defines the structures and logic for handling metadata associated with cached items in the <code>graphglue</code> package. It provides classes and helper functions to manage, store, and retrieve metadata fields, ensuring that each cache entry can be enriched with flexible, structured, and queryable information. This enables advanced search, filtering, and organization of cached data based on user-defined or system-generated metadata.</p>"},{"location":"reference/source/graphglue/_metadata-docs/#main-components","title":"Main Components","text":"<ul> <li>Metadata Function:   Encapsulates the metadata for a cache item, providing methods to set, get, update, and validate metadata fields.</li> </ul> <p>Package metadata (version, authors, etc).</p>"},{"location":"reference/source/graphglue/_metadata-docs/#graphglue._metadata-functions","title":"Functions","text":""},{"location":"reference/source/graphglue/_metadata-docs/#graphglue._metadata.get_metadata","title":"<code>get_metadata()</code>","text":"<p>Basic package metadata.</p> <p>Retrieves package metadata from the current project directory or from the installed package.</p> Source code in <code>graphglue/_metadata.py</code> <pre><code>def get_metadata() -&gt; dict:\n    \"\"\"Basic package metadata.\n\n    Retrieves package metadata from the current project directory or from\n    the installed package.\n    \"\"\"\n\n    here = pathlib.Path(__file__).parent\n    pyproj_toml = 'pyproject.toml'\n    meta = {}\n\n    for project_dir in (here, here.parent):\n\n        toml_path = str(project_dir.joinpath(pyproj_toml).absolute())\n\n        if os.path.exists(toml_path):\n\n            pyproject = toml.load(toml_path)\n\n            meta = {\n                'name': pyproject['tool']['poetry']['name'],\n                'version': pyproject['tool']['poetry']['version'],\n                'author': pyproject['tool']['poetry']['authors'],\n                'license': pyproject['tool']['poetry']['license'],\n                'full_metadata': pyproject,\n            }\n\n            break\n\n    if not meta:\n\n        try:\n\n            meta = {\n                k.lower():\n                v for k, v in\n                importlib.metadata.metadata(here.name).items()\n            }\n\n        except importlib.metadata.PackageNotFoundError:\n\n            pass\n\n    meta['version'] = meta.get('version', None) or _VERSION\n\n    return meta\n</code></pre>"},{"location":"source/conf/","title":"Conf","text":"<p>Configuration file for the Sphinx documentation builder.</p> <p>For the full list of built-in configuration values, see the documentation: https://www.sphinx-doc.org/en/master/usage/configuration.html</p> In\u00a0[\u00a0]: Copied! <pre>import os\nimport sys\nsys.path.insert(0, os.path.abspath('.'))\nsys.path.insert(0, os.path.abspath(os.path.join('..', '..')))\nsys.path.insert(0, os.path.abspath('../../src/graphglue'))\nsys.path.insert(0, os.path.abspath('../../src/graphglue/demo'))\n</pre> import os import sys sys.path.insert(0, os.path.abspath('.')) sys.path.insert(0, os.path.abspath(os.path.join('..', '..'))) sys.path.insert(0, os.path.abspath('../../src/graphglue')) sys.path.insert(0, os.path.abspath('../../src/graphglue/demo')) <p>-- Project information ----------------------------------------------------- https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information</p> In\u00a0[\u00a0]: Copied! <pre>project = 'GraphGlue'\ncopyright = '2025, Bottazzi Daniele'\nauthor = 'Bottazzi Daniele'\nrelease = '0.0.1'\n</pre> project = 'GraphGlue' copyright = '2025, Bottazzi Daniele' author = 'Bottazzi Daniele' release = '0.0.1' <p>-- General configuration --------------------------------------------------- https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration</p> In\u00a0[\u00a0]: Copied! <pre>extensions = [\n    'sphinx.ext.autodoc',\n    'sphinx.ext.autosectionlabel',\n    'sphinx.ext.napoleon',\n    'sphinx.ext.autosummary',\n    'sphinx.ext.doctest',\n    'sphinx.ext.viewcode',\n    'sphinx.ext.mathjax',\n]\n</pre> extensions = [     'sphinx.ext.autodoc',     'sphinx.ext.autosectionlabel',     'sphinx.ext.napoleon',     'sphinx.ext.autosummary',     'sphinx.ext.doctest',     'sphinx.ext.viewcode',     'sphinx.ext.mathjax', ] In\u00a0[\u00a0]: Copied! <pre>autosectionlabel_prefix_document = True\n</pre> autosectionlabel_prefix_document = True In\u00a0[\u00a0]: Copied! <pre>autodoc_default_options = {\n    'members': True,\n    'undoc-members': True,\n    'private-members': False,\n    'special-members': '__init__',\n    'inherited-members': True,\n    'show-inheritance': True,\n}\n</pre> autodoc_default_options = {     'members': True,     'undoc-members': True,     'private-members': False,     'special-members': '__init__',     'inherited-members': True,     'show-inheritance': True, } In\u00a0[\u00a0]: Copied! <pre>#bibtex_bibfiles = ['refs.bib']\nbibtex_default_style = 'plain'\ntemplates_path = ['_templates']\nexclude_patterns = []\n</pre> #bibtex_bibfiles = ['refs.bib'] bibtex_default_style = 'plain' templates_path = ['_templates'] exclude_patterns = [] <p>-- Options for HTML output ------------------------------------------------- https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output</p> In\u00a0[\u00a0]: Copied! <pre>html_theme = 'sphinx_rtd_theme'\nhtml_theme_options = {\n    \"sidebarwidth\": '25%',\n}\n</pre> html_theme = 'sphinx_rtd_theme' html_theme_options = {     \"sidebarwidth\": '25%', } In\u00a0[\u00a0]: Copied! <pre>templates_path = ['_templates']\n</pre> templates_path = ['_templates'] In\u00a0[\u00a0]: Copied! <pre>html_static_path = ['_static']\n</pre> html_static_path = ['_static'] In\u00a0[\u00a0]: Copied! <pre>def skip_member(app, what, name, obj, skip, options):\n    if name == \"CustomArgumentParser\":\n        return True\n    return skip\n</pre> def skip_member(app, what, name, obj, skip, options):     if name == \"CustomArgumentParser\":         return True     return skip In\u00a0[\u00a0]: Copied! <pre>def setup(app):\n    app.connect(\"autodoc-skip-member\", skip_member)\n</pre> def setup(app):     app.connect(\"autodoc-skip-member\", skip_member)"}]}