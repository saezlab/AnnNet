{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c12b598-c9e1-41a3-abb0-737ddce14b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\")) \n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from graphglue.core.graph import Graph\n",
    "from graphglue.adapters.sbml_adapter import from_sbml, BOUNDARY_SOURCE, BOUNDARY_SINK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9583333-0495-46bf-9370-0dbe7d6a8716",
   "metadata": {},
   "source": [
    "# SBML adapter (Elowitz repressilator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e890d3-c708-4e5c-826b-5e739987e56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model does not contain SBML fbc package information.\n",
      "SBML package 'layout' not supported by cobrapy, information is not parsed\n",
      "SBML package 'render' not supported by cobrapy, information is not parsed\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction1 \"degradation of LacI transcripts\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction1 \"degradation of LacI transcripts\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction2 \"degradation of TetR transcripts\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction2 \"degradation of TetR transcripts\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction3 \"degradation of CI transcripts\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction3 \"degradation of CI transcripts\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction4 \"translation of LacI\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction4 \"translation of LacI\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction5 \"translation of TetR\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction5 \"translation of TetR\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction6 \"translation of CI\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction6 \"translation of CI\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction7 \"degradation of LacI\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction7 \"degradation of LacI\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction8 \"degradation of TetR\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction8 \"degradation of TetR\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction9 \"degradation of CI\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction9 \"degradation of CI\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction10 \"transcription of LacI\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction10 \"transcription of LacI\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction11 \"transcription of TetR\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction11 \"transcription of TetR\">'\n",
      "Missing lower flux bound set to '-1000.0' for reaction: '<Reaction Reaction12 \"transcription of CI\">'\n",
      "Missing upper flux bound set to '1000.0' for reaction: '<Reaction Reaction12 \"transcription of CI\">'\n",
      "No objective coefficients in model. Unclear what should be optimized\n",
      "Missing flux bounds on reactions set to default bounds.As best practise and to avoid confusion flux bounds should be set explicitly on all reactions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertices: 8\n",
      "edges: 12\n",
      "boundary nodes: True True\n",
      "sample edges: ['Reaction1', 'Reaction2', 'Reaction3', 'Reaction4', 'Reaction5']\n"
     ]
    }
   ],
   "source": [
    "G = from_sbml(\"Elowitz.sbml.xml\", graph=Graph(directed=True), preserve_stoichiometry=True)\n",
    "\n",
    "print(\"vertices:\", G.num_vertices)      # expect 8 (6 real + 2 boundary)\n",
    "print(\"edges:\", G.num_edges)            # expect 12\n",
    "print(\"boundary nodes:\", BOUNDARY_SOURCE in G.entity_to_idx, BOUNDARY_SINK in G.entity_to_idx)\n",
    "print(\"sample edges:\", list(G.edge_to_idx)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11048c69-82f3-4b0e-91cd-bf88becb1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Reaction1]\n",
      "  head (products): ['__BOUNDARY_SINK__']\n",
      "  tail (reactants): ['X']\n",
      "[Reaction4]\n",
      "  head (products): ['PX']\n",
      "  tail (reactants): ['__BOUNDARY_SOURCE__']\n"
     ]
    }
   ],
   "source": [
    "def show_reaction(eid: str):\n",
    "    if eid not in G.edge_to_idx:\n",
    "        print(\"no such edge:\", eid); return\n",
    "    h = G.hyperedge_definitions[eid]\n",
    "    attrs = G.get_edge_attrs(eid)\n",
    "    sto = attrs.get(\"stoich\")  # present if you didn't add set_hyperedge_coeffs OR adapter stored it anyway\n",
    "    print(f\"[{eid}]\")\n",
    "    print(\"  head (products):\", sorted(h[\"head\"]))\n",
    "    print(\"  tail (reactants):\", sorted(h[\"tail\"]))\n",
    "    if sto:\n",
    "        # filter zeros if any\n",
    "        sto = {k: float(v) for k, v in sto.items() if abs(float(v)) > 1e-12}\n",
    "        print(\"  stoich map:\", sto)\n",
    "\n",
    "# examples\n",
    "show_reaction(\"Reaction1\")\n",
    "show_reaction(\"Reaction4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f2a65b-34b9-4f71-ac35-341ddccb2320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PX  produced_in=1  consumed_in=1\n",
      "  PY  produced_in=1  consumed_in=1\n",
      "  PZ  produced_in=1  consumed_in=1\n",
      "   X  produced_in=1  consumed_in=1\n",
      "   Y  produced_in=1  consumed_in=1\n",
      "   Z  produced_in=1  consumed_in=1\n"
     ]
    }
   ],
   "source": [
    "BOUNDARY = {BOUNDARY_SOURCE, BOUNDARY_SINK}\n",
    "\n",
    "produced = {v:0 for v in G.entity_to_idx}\n",
    "consumed = {v:0 for v in G.entity_to_idx}\n",
    "\n",
    "for eid in G.edge_to_idx:\n",
    "    h = G.hyperedge_definitions[eid]\n",
    "    for v in h[\"head\"]: produced[v] += 1\n",
    "    for v in h[\"tail\"]: consumed[v] += 1\n",
    "\n",
    "real_species = [v for v in G.entity_to_idx if v not in BOUNDARY]\n",
    "stats = [(v, produced[v], consumed[v]) for v in real_species]\n",
    "stats.sort(key=lambda t: (t[1], t[2]), reverse=True)\n",
    "for v,p,c in stats:\n",
    "    print(f\"{v:>4}  produced_in={p}  consumed_in={c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fc74446-5135-4491-87fa-fb892b2d97e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PX\n",
      "  as product : ['Reaction4']\n",
      "  as reactant: ['Reaction7']\n",
      "\n",
      "PY\n",
      "  as product : ['Reaction5']\n",
      "  as reactant: ['Reaction8']\n",
      "\n",
      "PZ\n",
      "  as product : ['Reaction6']\n",
      "  as reactant: ['Reaction9']\n",
      "\n",
      "X\n",
      "  as product : ['Reaction10']\n",
      "  as reactant: ['Reaction1']\n",
      "\n",
      "Y\n",
      "  as product : ['Reaction11']\n",
      "  as reactant: ['Reaction2']\n",
      "\n",
      "Z\n",
      "  as product : ['Reaction12']\n",
      "  as reactant: ['Reaction3']\n"
     ]
    }
   ],
   "source": [
    "species_to_reactions = {v: {\"as_product\": [], \"as_reactant\": []} for v in G.entity_to_idx}\n",
    "\n",
    "for eid in G.edge_to_idx:\n",
    "    h = G.hyperedge_definitions[eid]\n",
    "    for v in h[\"head\"]:\n",
    "        species_to_reactions[v][\"as_product\"].append(eid)\n",
    "    for v in h[\"tail\"]:\n",
    "        species_to_reactions[v][\"as_reactant\"].append(eid)\n",
    "\n",
    "# example: show for each real species\n",
    "for v in real_species:\n",
    "    rp = species_to_reactions[v][\"as_product\"]\n",
    "    rr = species_to_reactions[v][\"as_reactant\"]\n",
    "    print(f\"\\n{v}\")\n",
    "    print(\"  as product :\", rp)\n",
    "    print(\"  as reactant:\", rr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29a1d7f7-32f0-4165-b44b-3dca2178ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signs consistent (based on available attrs): True\n",
      "columns balanced (based on available attrs): True\n"
     ]
    }
   ],
   "source": [
    "# signs: by definition head=products (+), tail=reactants (−)\n",
    "def signs_consistent(eid):\n",
    "    h = G.hyperedge_definitions[eid]\n",
    "    attrs = G.get_edge_attrs(eid)\n",
    "    sto = attrs.get(\"stoich\")\n",
    "    if not sto:\n",
    "        # no per-vertex coeffs exposed via attrs; just check sets are present\n",
    "        return bool(h[\"head\"] or h[\"tail\"])\n",
    "    # if stoich map exists, check sign consistency vs head/tail sets\n",
    "    ok = True\n",
    "    for v, coeff in sto.items():\n",
    "        coeff = float(coeff)\n",
    "        if v in h[\"head\"]: ok &= coeff > 0\n",
    "        if v in h[\"tail\"]: ok &= coeff < 0\n",
    "    return ok\n",
    "\n",
    "sign_ok_all = all(signs_consistent(e) for e in G.edge_to_idx)\n",
    "print(\"signs consistent (based on available attrs):\", sign_ok_all)\n",
    "\n",
    "# balance: if stoich map exists, sum should be ~0 including boundary nodes\n",
    "def balanced(eid):\n",
    "    attrs = G.get_edge_attrs(eid)\n",
    "    sto = attrs.get(\"stoich\")\n",
    "    if not sto: return True  # can't check without exposed coeffs; treat as pass\n",
    "    s = sum(float(v) for v in sto.values())\n",
    "    return abs(s) < 1e-9\n",
    "\n",
    "bal_ok_all = all(balanced(e) for e in G.edge_to_idx)\n",
    "print(\"columns balanced (based on available attrs):\", bal_ok_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2946759-f0dd-4245-99e3-53402a51af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nx nodes: 8  nx edges: 12\n",
      "top-degree nodes: [('__BOUNDARY_SOURCE__', 6), ('__BOUNDARY_SINK__', 6), ('PX', 2), ('PY', 2), ('PZ', 2), ('X', 2), ('Y', 2), ('Z', 2)]\n",
      "shortest_path failed: No path between X and PX.\n",
      "cycles(count): 0\n",
      "sample cycles: []\n",
      "neighbors(X): ['__BOUNDARY_SOURCE__']\n",
      "weakly components: 1\n",
      "largest component size: 8\n",
      "top degree_centrality: [('__BOUNDARY_SOURCE__', 0.8571428571428571), ('__BOUNDARY_SINK__', 0.8571428571428571), ('PX', 0.2857142857142857), ('PY', 0.2857142857142857), ('PZ', 0.2857142857142857)]\n",
      "species-subgraph nodes: 6 edges: 0\n"
     ]
    }
   ],
   "source": [
    "# degrees on your underlying NX projection (pass G explicitly)\n",
    "deg = dict(G.nx.degree(G=G))\n",
    "print(\"nx nodes:\", G.nx.number_of_nodes(G=G), \" nx edges:\", G.nx.number_of_edges(G=G))\n",
    "print(\"top-degree nodes:\", sorted(deg.items(), key=lambda kv: kv[1], reverse=True)[:10])\n",
    "\n",
    "# simple paths (between two species if connected in your projection)\n",
    "try:\n",
    "    path = G.nx.shortest_path(G=G, source=\"X\", target=\"PX\")  # tweak names if different\n",
    "    print(\"shortest path X→PX:\", path)\n",
    "except Exception as e:\n",
    "    print(\"shortest_path failed:\", e)\n",
    "\n",
    "# cycles (directed projection)\n",
    "try:\n",
    "    cyc = list(G.nx.simple_cycles(G=G))\n",
    "    print(\"cycles(count):\", len(cyc))\n",
    "    print(\"sample cycles:\", cyc[:3])\n",
    "except Exception as e:\n",
    "    print(\"simple_cycles failed:\", e)\n",
    "\n",
    "# neighbors / predecessors / successors\n",
    "try:\n",
    "    print(\"neighbors(X):\", list(G.nx.neighbors(G=G, n=\"X\")))\n",
    "except Exception as e:\n",
    "    print(\"neighbors failed:\", e)\n",
    "\n",
    "try:\n",
    "    print(\"successors(X):\", list(G.nx.successors(G=G, n=\"X\")))\n",
    "    print(\"predecessors(X):\", list(G.nx.predecessors(G=G, n=\"X\")))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# connected components (weakly for directed; else undirected)\n",
    "try:\n",
    "    comps = list(G.nx.weakly_connected_components(G=G))\n",
    "    print(\"weakly components:\", len(comps))\n",
    "    print(\"largest component size:\", max(len(c) for c in comps))\n",
    "except Exception:\n",
    "    try:\n",
    "        comps = list(G.nx.connected_components(G=G))\n",
    "        print(\"connected components:\", len(comps))\n",
    "        print(\"largest component size:\", max(len(c) for c in comps))\n",
    "    except Exception as e:\n",
    "        print(\"components failed:\", e)\n",
    "\n",
    "# degree centrality (works the same way)\n",
    "try:\n",
    "    dc = G.nx.degree_centrality(G=G)\n",
    "    print(\"top degree_centrality:\", sorted(dc.items(), key=lambda kv: kv[1], reverse=True)[:5])\n",
    "except Exception as e:\n",
    "    print(\"degree_centrality failed:\", e)\n",
    "\n",
    "# species-only subgraph with the proxy (filters out boundary nodes)\n",
    "BOUNDARY = {\"__BOUNDARY_SOURCE__\", \"__BOUNDARY_SINK__\"}\n",
    "try:\n",
    "    species = [n for n in G.nx.nodes(G=G) if n not in BOUNDARY]\n",
    "    SG = G.nx.subgraph(G=G, nbunch=species)  # returns an NX graph\n",
    "    print(\"species-subgraph nodes:\", SG.number_of_nodes(), \"edges:\", SG.number_of_edges())\n",
    "except Exception as e:\n",
    "    print(\"subgraph failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3bde9e-4fab-4923-8567-f4ebe5db22c5",
   "metadata": {},
   "source": [
    "# AnnNet API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa04d33d-41e0-499e-b644-49434f8b4b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING MULTI-LAYER TEMPORAL GRAPH\n",
      "============================================================\n",
      "\n",
      "✓ Created 4 layers\n",
      "  Layers: ['2022', '2023', '2024']\n"
     ]
    }
   ],
   "source": [
    "# Create graph\n",
    "G = Graph(directed=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CREATING MULTI-LAYER TEMPORAL GRAPH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Add layers\n",
    "G.layers.add(\"2022\", year=2022, description=\"Year 2022\")\n",
    "G.layers.add(\"2023\", year=2023, description=\"Year 2023\")\n",
    "G.layers.add(\"2024\", year=2024, description=\"Year 2024\")\n",
    "\n",
    "print(f\"\\n✓ Created {G.layers.count()} layers\")\n",
    "print(f\"  Layers: {G.layers.list()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e9d9289-b009-4395-85ac-3d44d9e596ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LAYER 2022: Adding nodes\n",
      "============================================================\n",
      "\n",
      "✓ Layer 2022:\n",
      "  Vertices: 4\n",
      "  Edges: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LAYER 2022: Adding nodes\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "G.layers.active = \"2022\"\n",
    "\n",
    "# Add people\n",
    "people_2022 = {\n",
    "    \"alice\": {\"name\": \"Alice\", \"age\": 25, \"role\": \"engineer\", \"salary\": 80000},\n",
    "    \"bob\": {\"name\": \"Bob\", \"age\": 30, \"role\": \"manager\", \"salary\": 95000},\n",
    "    \"charlie\": {\"name\": \"Charlie\", \"age\": 28, \"role\": \"engineer\", \"salary\": 85000},\n",
    "    \"diana\": {\"name\": \"Diana\", \"age\": 35, \"role\": \"director\", \"salary\": 120000},\n",
    "}\n",
    "\n",
    "for vid, attrs in people_2022.items():\n",
    "    G.add_vertex(vid, **attrs)\n",
    "\n",
    "# Add collaborations (edges)\n",
    "collaborations_2022 = [\n",
    "    (\"alice\", \"bob\", 0.8, {\"project\": \"ProjectX\", \"hours\": 120}),\n",
    "    (\"alice\", \"charlie\", 0.9, {\"project\": \"ProjectX\", \"hours\": 150}),\n",
    "    (\"bob\", \"diana\", 0.7, {\"project\": \"Management\", \"hours\": 80}),\n",
    "    (\"charlie\", \"diana\", 0.6, {\"project\": \"ProjectY\", \"hours\": 60}),\n",
    "]\n",
    "\n",
    "for source, target, weight, attrs in collaborations_2022:\n",
    "    G.add_edge(source, target, weight=weight, **attrs)\n",
    "\n",
    "print(f\"\\n✓ Layer 2022:\")\n",
    "print(f\"  Vertices: {G.number_of_vertices()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cd61063-777e-4d7d-9366-446ac1f6f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LAYER 2023: Adding nodes and edges\n",
      "============================================================\n",
      "\n",
      "✓ Layer 2023:\n",
      "  Total vertices: 5\n",
      "  Edges in layer: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LAYER 2023: Adding nodes and edges\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "G.layers.active = \"2023\"\n",
    "\n",
    "# Add existing people (some with updated attributes)\n",
    "people_2023 = {\n",
    "    \"alice\": {\"name\": \"Alice\", \"age\": 26, \"role\": \"senior_engineer\", \"salary\": 92000},\n",
    "    \"bob\": {\"name\": \"Bob\", \"age\": 31, \"role\": \"senior_manager\", \"salary\": 105000},\n",
    "    \"charlie\": {\"name\": \"Charlie\", \"age\": 29, \"role\": \"engineer\", \"salary\": 88000},\n",
    "    \"diana\": {\"name\": \"Diana\", \"age\": 36, \"role\": \"director\", \"salary\": 125000},\n",
    "    \"eve\": {\"name\": \"Eve\", \"age\": 27, \"role\": \"engineer\", \"salary\": 83000},  # New hire\n",
    "}\n",
    "\n",
    "for vid, attrs in people_2023.items():\n",
    "    if not G.has_vertex(vid):\n",
    "        G.add_vertex(vid, **attrs)\n",
    "\n",
    "# New collaborations\n",
    "collaborations_2023 = [\n",
    "    (\"alice\", \"bob\", 0.85, {\"project\": \"ProjectZ\", \"hours\": 140}),\n",
    "    (\"alice\", \"eve\", 0.95, {\"project\": \"ProjectZ\", \"hours\": 180}),  # New collaboration\n",
    "    (\"bob\", \"diana\", 0.75, {\"project\": \"Management\", \"hours\": 90}),\n",
    "    (\"charlie\", \"eve\", 0.8, {\"project\": \"ProjectW\", \"hours\": 100}),\n",
    "    (\"eve\", \"diana\", 0.7, {\"project\": \"ProjectW\", \"hours\": 70}),\n",
    "]\n",
    "\n",
    "for source, target, weight, attrs in collaborations_2023:\n",
    "    G.add_edge(source, target, weight=weight, **attrs)\n",
    "\n",
    "print(f\"\\n✓ Layer 2023:\")\n",
    "print(f\"  Total vertices: {G.number_of_vertices()}\")\n",
    "print(f\"  Edges in layer: {len(G.layers.edges('2023'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ff21352-787c-4a4f-b2e9-069fe5286d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LAYER 2024: Adding nodes and edges\n",
      "============================================================\n",
      "\n",
      "✓ Layer 2024:\n",
      "  Total vertices: 6\n",
      "  Edges in layer: 5\n",
      "\n",
      "============================================================\n",
      "GRAPH SUMMARY\n",
      "============================================================\n",
      "Total unique vertices: 6\n",
      "Total unique edges: 14\n",
      "Layers: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LAYER 2024: Adding nodes and edges\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "G.layers.active = \"2024\"\n",
    "\n",
    "# 2024 people (Bob left, Frank joined)\n",
    "people_2024 = {\n",
    "    \"alice\": {\"name\": \"Alice\", \"age\": 27, \"role\": \"tech_lead\", \"salary\": 110000},\n",
    "    \"charlie\": {\"name\": \"Charlie\", \"age\": 30, \"role\": \"senior_engineer\", \"salary\": 98000},\n",
    "    \"diana\": {\"name\": \"Diana\", \"age\": 37, \"role\": \"vp\", \"salary\": 150000},\n",
    "    \"eve\": {\"name\": \"Eve\", \"age\": 28, \"role\": \"senior_engineer\", \"salary\": 95000},\n",
    "    \"frank\": {\"name\": \"Frank\", \"age\": 32, \"role\": \"manager\", \"salary\": 100000},  # Replaced Bob\n",
    "}\n",
    "\n",
    "for vid, attrs in people_2024.items():\n",
    "    if not G.has_vertex(vid):\n",
    "        G.add_vertex(vid, **attrs)\n",
    "\n",
    "# 2024 collaborations\n",
    "collaborations_2024 = [\n",
    "    (\"alice\", \"frank\", 0.9, {\"project\": \"NextGen\", \"hours\": 160}),\n",
    "    (\"alice\", \"eve\", 0.92, {\"project\": \"NextGen\", \"hours\": 170}),\n",
    "    (\"charlie\", \"eve\", 0.85, {\"project\": \"NextGen\", \"hours\": 120}),\n",
    "    (\"frank\", \"diana\", 0.8, {\"project\": \"Strategy\", \"hours\": 100}),\n",
    "    (\"eve\", \"diana\", 0.75, {\"project\": \"Strategy\", \"hours\": 80}),\n",
    "]\n",
    "\n",
    "for source, target, weight, attrs in collaborations_2024:\n",
    "    G.add_edge(source, target, weight=weight, **attrs)\n",
    "\n",
    "print(f\"\\n✓ Layer 2024:\")\n",
    "print(f\"  Total vertices: {G.number_of_vertices()}\")\n",
    "print(f\"  Edges in layer: {len(G.layers.edges('2024'))}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"GRAPH SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total unique vertices: {G.number_of_vertices()}\")\n",
    "print(f\"Total unique edges: {G.number_of_edges()}\")\n",
    "print(f\"Layers: {G.layers.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c109bfa-0a46-4356-b12a-8d809c05a4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING ANNNET PROPERTIES\n",
      "============================================================\n",
      "\n",
      "1. obs (vertex attributes):\n",
      "shape: (6, 5)\n",
      "┌───────────┬─────────┬─────┬──────────┬────────┐\n",
      "│ vertex_id ┆ name    ┆ age ┆ role     ┆ salary │\n",
      "│ ---       ┆ ---     ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str       ┆ str     ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═══════════╪═════════╪═════╪══════════╪════════╡\n",
      "│ alice     ┆ Alice   ┆ 25  ┆ engineer ┆ 80000  │\n",
      "│ bob       ┆ Bob     ┆ 30  ┆ manager  ┆ 95000  │\n",
      "│ charlie   ┆ Charlie ┆ 28  ┆ engineer ┆ 85000  │\n",
      "│ diana     ┆ Diana   ┆ 35  ┆ director ┆ 120000 │\n",
      "│ eve       ┆ Eve     ┆ 27  ┆ engineer ┆ 83000  │\n",
      "│ frank     ┆ Frank   ┆ 32  ┆ manager  ┆ 100000 │\n",
      "└───────────┴─────────┴─────┴──────────┴────────┘\n",
      "\n",
      "   Shape: (6, 5)\n",
      "   Columns: ['vertex_id', 'name', 'age', 'role', 'salary']\n",
      "\n",
      "2. var (edge attributes):\n",
      "shape: (5, 3)\n",
      "┌─────────┬────────────┬───────┐\n",
      "│ edge_id ┆ project    ┆ hours │\n",
      "│ ---     ┆ ---        ┆ ---   │\n",
      "│ str     ┆ str        ┆ i64   │\n",
      "╞═════════╪════════════╪═══════╡\n",
      "│ edge_0  ┆ ProjectX   ┆ 120   │\n",
      "│ edge_1  ┆ ProjectX   ┆ 150   │\n",
      "│ edge_2  ┆ Management ┆ 80    │\n",
      "│ edge_3  ┆ ProjectY   ┆ 60    │\n",
      "│ edge_4  ┆ ProjectZ   ┆ 140   │\n",
      "└─────────┴────────────┴───────┘\n",
      "\n",
      "   Shape: (14, 3)\n",
      "   Columns: ['edge_id', 'project', 'hours']\n",
      "\n",
      "3. X (incidence matrix):\n",
      "   Type: <class 'scipy.sparse._dok.dok_matrix'>\n",
      "   Shape: (8, 16)\n",
      "   Non-zero entries: 28\n",
      "   Density: 0.2188\n",
      "\n",
      "4. uns (unstructured metadata):\n",
      "   {'dataset_name': 'Company Collaboration Network', 'created': '2025-10-23T20:01:28.206121', 'description': 'Multi-year collaboration network'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING ANNNET PROPERTIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test obs (vertex attributes)\n",
    "print(\"\\n1. obs (vertex attributes):\")\n",
    "print(G.obs)\n",
    "print(f\"\\n   Shape: {G.obs.shape}\")\n",
    "print(f\"   Columns: {G.obs.columns}\")\n",
    "\n",
    "# Test var (edge attributes)\n",
    "print(\"\\n2. var (edge attributes):\")\n",
    "print(G.var.head())\n",
    "print(f\"\\n   Shape: {G.var.shape}\")\n",
    "print(f\"   Columns: {G.var.columns}\")\n",
    "\n",
    "# Test X (incidence matrix)\n",
    "print(\"\\n3. X (incidence matrix):\")\n",
    "X = G.X()\n",
    "print(f\"   Type: {type(X)}\")\n",
    "print(f\"   Shape: {X.shape}\")\n",
    "print(f\"   Non-zero entries: {X.nnz}\")\n",
    "print(f\"   Density: {X.nnz / (X.shape[0] * X.shape[1]):.4f}\")\n",
    "\n",
    "# Test uns (unstructured metadata)\n",
    "print(\"\\n4. uns (unstructured metadata):\")\n",
    "G.uns[\"dataset_name\"] = \"Company Collaboration Network\"\n",
    "G.uns[\"created\"] = datetime.now().isoformat()\n",
    "G.uns[\"description\"] = \"Multi-year collaboration network\"\n",
    "print(f\"   {G.uns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "430ae4a4-ca2c-4663-8725-bebbb066fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING LAYERMANAGER\n",
      "============================================================\n",
      "\n",
      "1. Layer Info:\n",
      "   Active layer: 2024\n",
      "   All layers: ['2022', '2023', '2024']\n",
      "   Layer count: 4\n",
      "\n",
      "2. Layer Statistics:\n",
      "\n",
      "   2022:\n",
      "     Vertices: 4\n",
      "     Edges: 4\n",
      "     Attributes: {'year': 2022, 'description': 'Year 2022'}\n",
      "\n",
      "   2023:\n",
      "     Vertices: 5\n",
      "     Edges: 5\n",
      "     Attributes: {'year': 2023, 'description': 'Year 2023'}\n",
      "\n",
      "   2024:\n",
      "     Vertices: 5\n",
      "     Edges: 5\n",
      "     Attributes: {'year': 2024, 'description': 'Year 2024'}\n",
      "\n",
      "3. Union of 2022 and 2023:\n",
      "   Vertices: 5\n",
      "   Edges: 9\n",
      "   Vertex IDs: ['alice', 'bob', 'charlie', 'diana', 'eve']\n",
      "\n",
      "4. Intersection of 2022 and 2023:\n",
      "   Common vertices: ['alice', 'bob', 'charlie', 'diana']\n",
      "   Common edges: 0\n",
      "\n",
      "5. Create 'all_years' layer (union):\n",
      "   ✓ Created layer: all_years\n",
      "   Vertices: 6\n",
      "   Edges: 14\n",
      "\n",
      "6. Layer Summary:\n",
      "Layers: 5\n",
      "├─ default: 0 vertices, 0 edges\n",
      "├─ 2022: 4 vertices, 4 edges\n",
      "├─ 2023: 5 vertices, 5 edges\n",
      "├─ 2024: 5 vertices, 5 edges\n",
      "└─ all_years: 6 vertices, 14 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING LAYERMANAGER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic operations\n",
    "print(\"\\n1. Layer Info:\")\n",
    "print(f\"   Active layer: {G.layers.active}\")\n",
    "print(f\"   All layers: {G.layers.list()}\")\n",
    "print(f\"   Layer count: {G.layers.count()}\")\n",
    "\n",
    "# Layer statistics\n",
    "print(\"\\n2. Layer Statistics:\")\n",
    "stats = G.layers.stats()\n",
    "for layer_id, info in stats.items():\n",
    "    print(f\"\\n   {layer_id}:\")\n",
    "    print(f\"     Vertices: {info['vertices']}\")\n",
    "    print(f\"     Edges: {info['edges']}\")\n",
    "    print(f\"     Attributes: {info['attributes']}\")\n",
    "\n",
    "# Layer operations - union\n",
    "print(\"\\n3. Union of 2022 and 2023:\")\n",
    "union_result = G.layers.union([\"2022\", \"2023\"])\n",
    "print(f\"   Vertices: {len(union_result['vertices'])}\")\n",
    "print(f\"   Edges: {len(union_result['edges'])}\")\n",
    "print(f\"   Vertex IDs: {sorted(union_result['vertices'])}\")\n",
    "\n",
    "# Layer operations - intersection\n",
    "print(\"\\n4. Intersection of 2022 and 2023:\")\n",
    "intersect_result = G.layers.intersect([\"2022\", \"2023\"])\n",
    "print(f\"   Common vertices: {sorted(intersect_result['vertices'])}\")\n",
    "print(f\"   Common edges: {len(intersect_result['edges'])}\")\n",
    "\n",
    "# Create aggregated layer\n",
    "print(\"\\n5. Create 'all_years' layer (union):\")\n",
    "G.layers.union_create([\"2022\", \"2023\", \"2024\"], \"all_years\", \n",
    "                     description=\"All years combined\")\n",
    "print(f\"   ✓ Created layer: all_years\")\n",
    "print(f\"   Vertices: {len(G.layers.vertices('all_years'))}\")\n",
    "print(f\"   Edges: {len(G.layers.edges('all_years'))}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n6. Layer Summary:\")\n",
    "print(G.layers.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32da3ba8-b9eb-4776-a281-258ee295b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING CROSS-LAYER ANALYTICS\n",
      "============================================================\n",
      "\n",
      "1. Vertex Presence Across Layers:\n",
      "   alice: ['2022', '2023', '2024', 'all_years']\n",
      "   bob: ['2022', '2023', 'all_years']\n",
      "   eve: ['2023', '2024', 'all_years']\n",
      "   frank: ['2024', 'all_years']\n",
      "\n",
      "2. Edge Presence (alice→bob):\n",
      "   2022: ['edge_0']\n",
      "   2023: ['edge_4']\n",
      "   all_years: ['edge_4', 'edge_0']\n",
      "\n",
      "3. Conserved Edges (in 2+ layers):\n",
      "   Found 14 conserved edges:\n",
      "   edge_3: charlie → diana (in 2 layers)\n",
      "   edge_1: alice → charlie (in 2 layers)\n",
      "   edge_0: alice → bob (in 2 layers)\n",
      "   edge_2: bob → diana (in 2 layers)\n",
      "   edge_4: alice → bob (in 2 layers)\n",
      "\n",
      "4. Layer-Specific Edges:\n",
      "   2022 only: 0 edges\n",
      "   2023 only: 0 edges\n",
      "   2024 only: 0 edges\n",
      "\n",
      "5. Temporal Dynamics:\n",
      "\n",
      "   2022 → 2023:\n",
      "     Edges added: 5\n",
      "     Edges removed: 4\n",
      "     Net change: +1\n",
      "\n",
      "   2023 → 2024:\n",
      "     Edges added: 5\n",
      "     Edges removed: 5\n",
      "     Net change: +0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING CROSS-LAYER ANALYTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Vertex presence\n",
    "print(\"\\n1. Vertex Presence Across Layers:\")\n",
    "for vid in [\"alice\", \"bob\", \"eve\", \"frank\"]:\n",
    "    layers = G.layers.vertex_presence(vid)\n",
    "    print(f\"   {vid}: {layers}\")\n",
    "\n",
    "# Edge presence\n",
    "print(\"\\n2. Edge Presence (alice→bob):\")\n",
    "edge_presence = G.layers.edge_presence(source=\"alice\", target=\"bob\")\n",
    "for layer_id, edge_ids in edge_presence.items():\n",
    "    print(f\"   {layer_id}: {edge_ids}\")\n",
    "\n",
    "# Conserved edges\n",
    "print(\"\\n3. Conserved Edges (in 2+ layers):\")\n",
    "conserved = G.layers.conserved_edges(min_layers=2)\n",
    "print(f\"   Found {len(conserved)} conserved edges:\")\n",
    "for eid, count in sorted(conserved.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    edge_def = G.edge_definitions.get(eid)\n",
    "    if edge_def:\n",
    "        print(f\"   {eid}: {edge_def[0]} → {edge_def[1]} (in {count} layers)\")\n",
    "\n",
    "# Layer-specific edges\n",
    "print(\"\\n4. Layer-Specific Edges:\")\n",
    "for layer_id in [\"2022\", \"2023\", \"2024\"]:\n",
    "    specific = G.layers.specific_edges(layer_id)\n",
    "    print(f\"   {layer_id} only: {len(specific)} edges\")\n",
    "\n",
    "# Temporal dynamics\n",
    "print(\"\\n5. Temporal Dynamics:\")\n",
    "changes = G.layers.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"edge_change\")\n",
    "for i, change in enumerate(changes):\n",
    "    year_from = [\"2022\", \"2023\"][i]\n",
    "    year_to = [\"2023\", \"2024\"][i]\n",
    "    print(f\"\\n   {year_from} → {year_to}:\")\n",
    "    print(f\"     Edges added: {change['added']}\")\n",
    "    print(f\"     Edges removed: {change['removed']}\")\n",
    "    print(f\"     Net change: {change['net_change']:+d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b8cf64c-19f7-49ff-86d6-0c801ec9fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING INDEXMANAGER\n",
      "============================================================\n",
      "\n",
      "1. Entity Index Lookups:\n",
      "   alice → row index: 0\n",
      "   diana → row index: 3\n",
      "   Row 0 → entity: alice\n",
      "   Row 3 → entity: diana\n",
      "\n",
      "2. Edge Index Lookups:\n",
      "   edge_0 → col 0 → edge_0\n",
      "   edge_1 → col 1 → edge_1\n",
      "   edge_2 → col 2 → edge_2\n",
      "\n",
      "3. Batch Lookups:\n",
      "   ['alice', 'bob', 'charlie']\n",
      "   → rows: [0, 1, 2]\n",
      "   → back: ['alice', 'bob', 'charlie']\n",
      "\n",
      "4. Existence Checks:\n",
      "   'alice' exists: True\n",
      "   'unknown' exists: False\n",
      "   edge count: 14\n",
      "   entity count: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING INDEXMANAGER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Entity lookups\n",
    "print(\"\\n1. Entity Index Lookups:\")\n",
    "print(f\"   alice → row index: {G.idx.entity_to_row('alice')}\")\n",
    "print(f\"   diana → row index: {G.idx.entity_to_row('diana')}\")\n",
    "print(f\"   Row 0 → entity: {G.idx.row_to_entity(0)}\")\n",
    "print(f\"   Row 3 → entity: {G.idx.row_to_entity(3)}\")\n",
    "\n",
    "# Edge lookups\n",
    "print(\"\\n2. Edge Index Lookups:\")\n",
    "edge_ids = list(G.edge_to_idx.keys())[:3]\n",
    "for eid in edge_ids:\n",
    "    col = G.idx.edge_to_col(eid)\n",
    "    back = G.idx.col_to_edge(col)\n",
    "    print(f\"   {eid} → col {col} → {back}\")\n",
    "\n",
    "# Batch lookups\n",
    "print(\"\\n3. Batch Lookups:\")\n",
    "vertices = [\"alice\", \"bob\", \"charlie\"]\n",
    "rows = G.idx.entities_to_rows(vertices)\n",
    "print(f\"   {vertices}\")\n",
    "print(f\"   → rows: {rows}\")\n",
    "back_entities = G.idx.rows_to_entities(rows)\n",
    "print(f\"   → back: {back_entities}\")\n",
    "\n",
    "# Check existence\n",
    "print(\"\\n4. Existence Checks:\")\n",
    "print(f\"   'alice' exists: {G.idx.has_entity('alice')}\")\n",
    "print(f\"   'unknown' exists: {G.idx.has_entity('unknown')}\")\n",
    "print(f\"   edge count: {G.idx.edge_count()}\")\n",
    "print(f\"   entity count: {G.idx.entity_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34c7cf69-a61d-4417-91b9-d535ddddcfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING CACHEMANAGER\n",
      "============================================================\n",
      "\n",
      "1. Initial Cache Status:\n",
      "   CSR cached: False\n",
      "   CSC cached: False\n",
      "\n",
      "2. Building CSR cache...\n",
      "   ✓ Built in 0.93ms\n",
      "   Shape: (8, 16)\n",
      "   Type: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "\n",
      "3. Building CSC cache...\n",
      "   ✓ Built in 1.08ms\n",
      "   Shape: (8, 16)\n",
      "\n",
      "4. Cache Hit Test:\n",
      "   ✓ Retrieved in 0.0000ms (cached)\n",
      "\n",
      "5. Clearing Cache:\n",
      "   CSR cached: False\n",
      "   CSC cached: False\n",
      "\n",
      "6. Rebuild All:\n",
      "   ✓ CSR cached: True\n",
      "   ✓ CSC cached: True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING CACHEMANAGER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check cache status\n",
    "print(\"\\n1. Initial Cache Status:\")\n",
    "print(f\"   CSR cached: {G.cache.has_csr()}\")\n",
    "print(f\"   CSC cached: {G.cache.has_csc()}\")\n",
    "\n",
    "# Build CSR\n",
    "print(\"\\n2. Building CSR cache...\")\n",
    "import time\n",
    "t0 = time.time()\n",
    "csr = G.cache.get_csr()\n",
    "t1 = time.time()\n",
    "print(f\"   ✓ Built in {(t1-t0)*1000:.2f}ms\")\n",
    "print(f\"   Shape: {csr.shape}\")\n",
    "print(f\"   Type: {type(csr)}\")\n",
    "\n",
    "# Build CSC\n",
    "print(\"\\n3. Building CSC cache...\")\n",
    "t0 = time.time()\n",
    "csc = G.cache.get_csc()\n",
    "t1 = time.time()\n",
    "print(f\"   ✓ Built in {(t1-t0)*1000:.2f}ms\")\n",
    "print(f\"   Shape: {csc.shape}\")\n",
    "\n",
    "# Check cache hit\n",
    "print(\"\\n4. Cache Hit Test:\")\n",
    "t0 = time.time()\n",
    "csr2 = G.cache.get_csr()  # Should be instant\n",
    "t1 = time.time()\n",
    "print(f\"   ✓ Retrieved in {(t1-t0)*1000:.4f}ms (cached)\")\n",
    "\n",
    "# Clear cache\n",
    "print(\"\\n5. Clearing Cache:\")\n",
    "G.cache.clear()\n",
    "print(f\"   CSR cached: {G.cache.has_csr()}\")\n",
    "print(f\"   CSC cached: {G.cache.has_csc()}\")\n",
    "\n",
    "# Rebuild\n",
    "print(\"\\n6. Rebuild All:\")\n",
    "G.cache.build()\n",
    "print(f\"   ✓ CSR cached: {G.cache.has_csr()}\")\n",
    "print(f\"   ✓ CSC cached: {G.cache.has_csc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45dbdfcd-dbca-47ac-bf11-caa68408a76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING GRAPHVIEW - BASIC FILTERING\n",
      "============================================================\n",
      "\n",
      "1. View Specific Nodes:\n",
      "   View: GraphView(nodes=3, edges=14)\n",
      "   Nodes: 3\n",
      "   Edges: 14\n",
      "\n",
      "   Node table:\n",
      "shape: (3, 5)\n",
      "┌───────────┬─────────┬─────┬──────────┬────────┐\n",
      "│ vertex_id ┆ name    ┆ age ┆ role     ┆ salary │\n",
      "│ ---       ┆ ---     ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str       ┆ str     ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═══════════╪═════════╪═════╪══════════╪════════╡\n",
      "│ alice     ┆ Alice   ┆ 25  ┆ engineer ┆ 80000  │\n",
      "│ bob       ┆ Bob     ┆ 30  ┆ manager  ┆ 95000  │\n",
      "│ charlie   ┆ Charlie ┆ 28  ┆ engineer ┆ 85000  │\n",
      "└───────────┴─────────┴─────┴──────────┴────────┘\n",
      "\n",
      "2. View Layer 2023:\n",
      "   View: GraphView(nodes=5, edges=5)\n",
      "   Nodes: 5\n",
      "   Edges: 5\n",
      "\n",
      "3. View Layers 2022+2023:\n",
      "   View: GraphView(nodes=5, edges=9)\n",
      "   Nodes: 5\n",
      "   Edges: 9\n",
      "\n",
      "4. Combined: Specific nodes in 2023:\n",
      "   View: GraphView(nodes=2, edges=1)\n",
      "   Nodes: 2\n",
      "   Edges: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING GRAPHVIEW - BASIC FILTERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# View specific nodes\n",
    "print(\"\\n1. View Specific Nodes:\")\n",
    "v = G.view(nodes=[\"alice\", \"bob\", \"charlie\"])\n",
    "print(f\"   View: {v}\")\n",
    "print(f\"   Nodes: {v.node_count}\")\n",
    "print(f\"   Edges: {v.edge_count}\")\n",
    "print(f\"\\n   Node table:\")\n",
    "print(v.obs)\n",
    "\n",
    "# View specific layer\n",
    "print(\"\\n2. View Layer 2023:\")\n",
    "v2023 = G.view(layers=\"2023\")\n",
    "print(f\"   View: {v2023}\")\n",
    "print(f\"   Nodes: {v2023.node_count}\")\n",
    "print(f\"   Edges: {v2023.edge_count}\")\n",
    "\n",
    "# View multiple layers\n",
    "print(\"\\n3. View Layers 2022+2023:\")\n",
    "v_early = G.view(layers=[\"2022\", \"2023\"])\n",
    "print(f\"   View: {v_early}\")\n",
    "print(f\"   Nodes: {v_early.node_count}\")\n",
    "print(f\"   Edges: {v_early.edge_count}\")\n",
    "\n",
    "# Combined filters\n",
    "print(\"\\n4. Combined: Specific nodes in 2023:\")\n",
    "v_combo = G.view(nodes=[\"alice\", \"eve\"], layers=\"2023\")\n",
    "print(f\"   View: {v_combo}\")\n",
    "print(f\"   Nodes: {v_combo.node_count}\")\n",
    "print(f\"   Edges: {v_combo.edge_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df08d37f-a217-424f-bfef-6e472ff55a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING GRAPHVIEW - PREDICATE FILTERING\n",
      "============================================================\n",
      "\n",
      "1. High Salary Employees (>100k):\n",
      "   View: GraphView(nodes=1, edges=14)\n",
      "   High earners: ['diana']\n",
      "\n",
      "   Details:\n",
      "shape: (1, 4)\n",
      "┌───────────┬───────┬────────┬──────────┐\n",
      "│ vertex_id ┆ name  ┆ salary ┆ role     │\n",
      "│ ---       ┆ ---   ┆ ---    ┆ ---      │\n",
      "│ str       ┆ str   ┆ i64    ┆ str      │\n",
      "╞═══════════╪═══════╪════════╪══════════╡\n",
      "│ diana     ┆ Diana ┆ 120000 ┆ director │\n",
      "└───────────┴───────┴────────┴──────────┘\n",
      "\n",
      "2. Strong Collaborations (weight > 0.8):\n",
      "   View: GraphView(nodes=6, edges=6)\n",
      "   Strong edges: 6\n",
      "\n",
      "   Top collaborations:\n",
      "shape: (6, 4)\n",
      "┌─────────┬─────────┬─────────┬───────────────┐\n",
      "│ edge_id ┆ source  ┆ target  ┆ global_weight │\n",
      "│ ---     ┆ ---     ┆ ---     ┆ ---           │\n",
      "│ str     ┆ str     ┆ str     ┆ f64           │\n",
      "╞═════════╪═════════╪═════════╪═══════════════╡\n",
      "│ edge_1  ┆ alice   ┆ charlie ┆ 0.9           │\n",
      "│ edge_4  ┆ alice   ┆ bob     ┆ 0.85          │\n",
      "│ edge_5  ┆ alice   ┆ eve     ┆ 0.95          │\n",
      "│ edge_9  ┆ alice   ┆ frank   ┆ 0.9           │\n",
      "│ edge_10 ┆ alice   ┆ eve     ┆ 0.92          │\n",
      "│ edge_11 ┆ charlie ┆ eve     ┆ 0.85          │\n",
      "└─────────┴─────────┴─────────┴───────────────┘\n",
      "\n",
      "3. Engineers in 2023/2024:\n",
      "   View: GraphView(nodes=3, edges=4)\n",
      "   Engineers: ['alice', 'charlie', 'eve']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING GRAPHVIEW - PREDICATE FILTERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# View by node predicate (high salary)\n",
    "print(\"\\n1. High Salary Employees (>100k):\")\n",
    "v_rich = G.view(nodes=lambda vid: \n",
    "    G.get_vertex_attrs(vid).get(\"salary\", 0) > 100000\n",
    ")\n",
    "print(f\"   View: {v_rich}\")\n",
    "print(f\"   High earners: {sorted(v_rich.node_ids)}\")\n",
    "print(f\"\\n   Details:\")\n",
    "print(v_rich.obs.select([\"vertex_id\", \"name\", \"salary\", \"role\"]))\n",
    "\n",
    "# View by edge predicate (strong collaboration)\n",
    "print(\"\\n2. Strong Collaborations (weight > 0.8):\")\n",
    "v_strong = G.view(edges=lambda eid:\n",
    "    G.edge_weights.get(eid, 0) > 0.8\n",
    ")\n",
    "print(f\"   View: {v_strong}\")\n",
    "print(f\"   Strong edges: {v_strong.edge_count}\")\n",
    "edges_df = v_strong.edges_df(include_weight=True)\n",
    "print(f\"\\n   Top collaborations:\")\n",
    "print(edges_df.select([\"edge_id\", \"source\", \"target\", \"global_weight\"]).head(10))\n",
    "\n",
    "# Combined predicate (engineers in recent years)\n",
    "print(\"\\n3. Engineers in 2023/2024:\")\n",
    "v_eng = G.view(\n",
    "    nodes=lambda vid: \"engineer\" in G.get_vertex_attrs(vid).get(\"role\", \"\"),\n",
    "    layers=[\"2023\", \"2024\"]\n",
    ")\n",
    "print(f\"   View: {v_eng}\")\n",
    "print(f\"   Engineers: {sorted(v_eng.node_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a000bf8-6d8c-4c5a-9b4d-0b7eb180878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING GRAPHVIEW - ADVANCED OPERATIONS\n",
      "============================================================\n",
      "\n",
      "1. View Properties:\n",
      "   node_count: 5\n",
      "   edge_count: 5\n",
      "   node_ids: ['alice', 'bob', 'charlie', 'diana', 'eve']\n",
      "\n",
      "   Matrix shape: (5, 5)\n",
      "   Matrix nnz: 10\n",
      "\n",
      "2. View DataFrames:\n",
      "   Vertices DF: (5, 5)\n",
      "   Edges DF: (5, 13)\n",
      "\n",
      "3. View Summary:\n",
      "GraphView Summary\n",
      "──────────────────────────────\n",
      "Nodes: 5\n",
      "Edges: 5\n",
      "Filters: layers=['2023']\n",
      "\n",
      "4. Nested Views:\n",
      "   v1 (2023): 5 nodes, 5 edges\n",
      "   v2 (alice/bob/eve in 2023): 3 nodes, 2 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING GRAPHVIEW - ADVANCED OPERATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Access properties\n",
    "print(\"\\n1. View Properties:\")\n",
    "v = G.view(layers=\"2023\")\n",
    "print(f\"   node_count: {v.node_count}\")\n",
    "print(f\"   edge_count: {v.edge_count}\")\n",
    "print(f\"   node_ids: {sorted(list(v.node_ids))}\")\n",
    "print(f\"\\n   Matrix shape: {v.X.shape}\")\n",
    "print(f\"   Matrix nnz: {v.X.nnz}\")\n",
    "\n",
    "# Get DataFrames\n",
    "print(\"\\n2. View DataFrames:\")\n",
    "vertices_df = v.vertices_df()\n",
    "edges_df = v.edges_df(include_weight=True, include_directed=True)\n",
    "print(f\"   Vertices DF: {vertices_df.shape}\")\n",
    "print(f\"   Edges DF: {edges_df.shape}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n3. View Summary:\")\n",
    "print(v.summary())\n",
    "\n",
    "# Nested views\n",
    "print(\"\\n4. Nested Views:\")\n",
    "v1 = G.view(layers=\"2023\")\n",
    "print(f\"   v1 (2023): {v1.node_count} nodes, {v1.edge_count} edges\")\n",
    "\n",
    "v2 = v1.subview(nodes=[\"alice\", \"bob\", \"eve\"])\n",
    "print(f\"   v2 (alice/bob/eve in 2023): {v2.node_count} nodes, {v2.edge_count} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "218b98dd-cea1-4c5c-a221-330690f05a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING GRAPHVIEW - MATERIALIZATION\n",
      "============================================================\n",
      "\n",
      "1. Materialize Layer 2023:\n",
      "   Original graph: 6 nodes, 14 edges\n",
      "   Subgraph 2023: 5 nodes, 5 edges\n",
      "   Subgraph vertices: ['alice', 'bob', 'charlie', 'diana', 'eve']\n",
      "\n",
      "   Sample attributes:\n",
      "   alice: {'vertex_id': 'alice', 'name': 'Alice', 'age': 25, 'role': 'engineer', 'salary': 80000}\n",
      "\n",
      "2. Materialize High Earners Network:\n",
      "   High earners network: 2 nodes\n",
      "   Nodes: ['diana', 'frank']\n",
      "   Edges: 1\n",
      "\n",
      "3. Verify Independence:\n",
      "   Original graph edges: 14\n",
      "   Subgraph edges: 5\n",
      "   After modifying subgraph:\n",
      "     Original: 6 nodes\n",
      "     Subgraph: 6 nodes\n",
      "   ✓ Graphs are independent\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING GRAPHVIEW - MATERIALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Materialize layer 2023\n",
    "print(\"\\n1. Materialize Layer 2023:\")\n",
    "v2023 = G.view(layers=\"2023\")\n",
    "subG = v2023.materialize(copy_attributes=True)\n",
    "\n",
    "print(f\"   Original graph: {G.number_of_vertices()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"   Subgraph 2023: {subG.number_of_vertices()} nodes, {subG.number_of_edges()} edges\")\n",
    "print(f\"   Subgraph vertices: {sorted(subG.vertices())}\")\n",
    "\n",
    "# Check attributes were copied\n",
    "print(f\"\\n   Sample attributes:\")\n",
    "alice_attrs = subG.get_vertex_attrs(\"alice\")\n",
    "print(f\"   alice: {alice_attrs}\")\n",
    "\n",
    "# Materialize high earners\n",
    "print(\"\\n2. Materialize High Earners Network:\")\n",
    "v_rich = G.view(nodes=lambda vid: \n",
    "    G.get_vertex_attrs(vid).get(\"salary\", 0) > 95000\n",
    ")\n",
    "rich_network = v_rich.materialize(copy_attributes=True)\n",
    "\n",
    "print(f\"   High earners network: {rich_network.number_of_vertices()} nodes\")\n",
    "print(f\"   Nodes: {sorted(rich_network.vertices())}\")\n",
    "print(f\"   Edges: {rich_network.number_of_edges()}\")\n",
    "\n",
    "# Verify independence\n",
    "print(\"\\n3. Verify Independence:\")\n",
    "print(f\"   Original graph edges: {G.number_of_edges()}\")\n",
    "print(f\"   Subgraph edges: {subG.number_of_edges()}\")\n",
    "subG.add_vertex(\"test_node\")\n",
    "print(f\"   After modifying subgraph:\")\n",
    "print(f\"     Original: {G.number_of_vertices()} nodes\")\n",
    "print(f\"     Subgraph: {subG.number_of_vertices()} nodes\")\n",
    "print(f\"   ✓ Graphs are independent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc68b9ad-2209-4274-a97f-d67cc0507234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING SNAPSHOT AND DIFF\n",
      "============================================================\n",
      "\n",
      "1. Create Initial Snapshot:\n",
      "   ✓ Created snapshot: initial_state\n",
      "   Vertices: 6\n",
      "   Edges: 14\n",
      "   Layers: 5\n",
      "\n",
      "2. Make Changes:\n",
      "   Adding new vertices...\n",
      "   Adding new edges...\n",
      "   Removing a vertex...\n",
      "\n",
      "   ✓ Created snapshot: after_changes\n",
      "\n",
      "3. Compare Snapshots:\n",
      "Diff: initial_state → after_changes\n",
      "\n",
      "Vertices: +2 added, 1 removed\n",
      "Edges: +2 added, 2 removed\n",
      "Layers: +0 added, 0 removed\n",
      "\n",
      "   Details:\n",
      "   Added vertices: ['grace', 'henry']\n",
      "   Removed vertices: ['frank']\n",
      "   Added edges: 2\n",
      "   Removed edges: 2\n",
      "\n",
      "4. Compare with Current State:\n",
      "Diff: after_changes → current\n",
      "\n",
      "Vertices: +1 added, 0 removed\n",
      "Edges: +0 added, 0 removed\n",
      "Layers: +0 added, 0 removed\n",
      "\n",
      "5. List All Snapshots:\n",
      "\n",
      "   initial_state:\n",
      "     Timestamp: 2025-10-23T19:01:31.548907+00:00\n",
      "     Vertices: 6\n",
      "     Edges: 14\n",
      "\n",
      "   after_changes:\n",
      "     Timestamp: 2025-10-23T19:01:31.553366+00:00\n",
      "     Vertices: 7\n",
      "     Edges: 14\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING SNAPSHOT AND DIFF\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create initial snapshot\n",
    "print(\"\\n1. Create Initial Snapshot:\")\n",
    "G.layers.active = \"2024\"\n",
    "snap1 = G.snapshot(\"initial_state\")\n",
    "print(f\"   ✓ Created snapshot: {snap1['label']}\")\n",
    "print(f\"   Vertices: {snap1['counts']['vertices']}\")\n",
    "print(f\"   Edges: {snap1['counts']['edges']}\")\n",
    "print(f\"   Layers: {snap1['counts']['layers']}\")\n",
    "\n",
    "# Make changes\n",
    "print(\"\\n2. Make Changes:\")\n",
    "print(\"   Adding new vertices...\")\n",
    "G.add_vertex(\"grace\", name=\"Grace\", age=29, role=\"engineer\", salary=87000)\n",
    "G.add_vertex(\"henry\", name=\"Henry\", age=33, role=\"architect\", salary=115000)\n",
    "\n",
    "print(\"   Adding new edges...\")\n",
    "G.add_edge(\"grace\", \"alice\", weight=0.85, project=\"Innovation\")\n",
    "G.add_edge(\"henry\", \"diana\", weight=0.9, project=\"Architecture\")\n",
    "\n",
    "print(\"   Removing a vertex...\")\n",
    "G.remove_vertex(\"frank\")\n",
    "\n",
    "# Create second snapshot\n",
    "snap2 = G.snapshot(\"after_changes\")\n",
    "print(f\"\\n   ✓ Created snapshot: {snap2['label']}\")\n",
    "\n",
    "# Diff\n",
    "print(\"\\n3. Compare Snapshots:\")\n",
    "diff = G.diff(\"initial_state\", \"after_changes\")\n",
    "print(diff.summary())\n",
    "\n",
    "print(f\"\\n   Details:\")\n",
    "print(f\"   Added vertices: {sorted(diff.vertices_added)}\")\n",
    "print(f\"   Removed vertices: {sorted(diff.vertices_removed)}\")\n",
    "print(f\"   Added edges: {len(diff.edges_added)}\")\n",
    "print(f\"   Removed edges: {len(diff.edges_removed)}\")\n",
    "\n",
    "# Compare with current\n",
    "print(\"\\n4. Compare with Current State:\")\n",
    "G.add_vertex(\"iris\", name=\"Iris\", age=26, role=\"data_scientist\", salary=92000)\n",
    "diff_current = G.diff(\"after_changes\")\n",
    "print(diff_current.summary())\n",
    "\n",
    "# List all snapshots\n",
    "print(\"\\n5. List All Snapshots:\")\n",
    "snapshots = G.list_snapshots()\n",
    "for snap in snapshots:\n",
    "    print(f\"\\n   {snap['label']}:\")\n",
    "    print(f\"     Timestamp: {snap['timestamp']}\")\n",
    "    print(f\"     Vertices: {snap['counts']['vertices']}\")\n",
    "    print(f\"     Edges: {snap['counts']['edges']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef810453-37cc-406c-bdf2-8d555058bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ADVANCED ANALYSIS - NETWORK METRICS\n",
      "============================================================\n",
      "\n",
      "1. Per-Layer Network Metrics:\n",
      "\n",
      "   2022:\n",
      "     Nodes: 4\n",
      "     Edges: 4\n",
      "     Avg edge weight: 0.000\n",
      "     Avg degree: 2.00\n",
      "     Max degree: 2\n",
      "     Hub: charlie (degree=2)\n",
      "\n",
      "   2023:\n",
      "     Nodes: 5\n",
      "     Edges: 5\n",
      "     Avg edge weight: 0.000\n",
      "     Avg degree: 2.00\n",
      "     Max degree: 3\n",
      "     Hub: eve (degree=3)\n",
      "\n",
      "   2024:\n",
      "     Nodes: 7\n",
      "     Edges: 5\n",
      "     Avg edge weight: 0.000\n",
      "     Avg degree: 1.43\n",
      "     Max degree: 3\n",
      "     Hub: eve (degree=3)\n",
      "\n",
      "2. Layer Comparison:\n",
      "\n",
      "   Vertex changes over time:\n",
      "   2022→2023: +1 added, 0 removed\n",
      "   2023→2024: +3 added, 1 removed\n",
      "\n",
      "   Edge changes over time:\n",
      "   2022→2023: +5 added, 4 removed\n",
      "   2023→2024: +5 added, 5 removed\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ADVANCED ANALYSIS - NETWORK METRICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Per-layer analysis\n",
    "print(\"\\n1. Per-Layer Network Metrics:\")\n",
    "for layer_id in [\"2022\", \"2023\", \"2024\"]:\n",
    "    v = G.view(layers=layer_id)\n",
    "    \n",
    "    print(f\"\\n   {layer_id}:\")\n",
    "    print(f\"     Nodes: {v.node_count}\")\n",
    "    print(f\"     Edges: {v.edge_count}\")\n",
    "    \n",
    "    if v.edge_count > 0:\n",
    "        avg_weight = v.var.select(\"weight\").mean().item() if \"weight\" in v.var.columns else 0\n",
    "        print(f\"     Avg edge weight: {avg_weight:.3f}\")\n",
    "    \n",
    "    # Degree analysis (using materialized subgraph)\n",
    "    subG = v.materialize()\n",
    "    degrees = {vid: subG.degree(vid) for vid in subG.vertices()}\n",
    "    if degrees:\n",
    "        print(f\"     Avg degree: {sum(degrees.values()) / len(degrees):.2f}\")\n",
    "        print(f\"     Max degree: {max(degrees.values())}\")\n",
    "        max_degree_node = max(degrees, key=degrees.get)\n",
    "        print(f\"     Hub: {max_degree_node} (degree={degrees[max_degree_node]})\")\n",
    "\n",
    "# Compare layers\n",
    "print(\"\\n2. Layer Comparison:\")\n",
    "changes = G.layers.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"vertex_change\")\n",
    "print(\"\\n   Vertex changes over time:\")\n",
    "for i, change in enumerate(changes):\n",
    "    year_from = [\"2022\", \"2023\"][i]\n",
    "    year_to = [\"2023\", \"2024\"][i]\n",
    "    print(f\"   {year_from}→{year_to}: {change['added']:+d} added, {change['removed']} removed\")\n",
    "\n",
    "changes = G.layers.temporal_dynamics([\"2022\", \"2023\", \"2024\"], metric=\"edge_change\")\n",
    "print(\"\\n   Edge changes over time:\")\n",
    "for i, change in enumerate(changes):\n",
    "    year_from = [\"2022\", \"2023\"][i]\n",
    "    year_to = [\"2023\", \"2024\"][i]\n",
    "    print(f\"   {year_from}→{year_to}: {change['added']:+d} added, {change['removed']} removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c919cbe-3201-422e-b96a-c92332c41b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ADVANCED ANALYSIS - POLARS QUERIES\n",
      "============================================================\n",
      "\n",
      "1. Top 3 Earners:\n",
      "shape: (3, 4)\n",
      "┌───────────┬───────┬───────────┬────────┐\n",
      "│ vertex_id ┆ name  ┆ role      ┆ salary │\n",
      "│ ---       ┆ ---   ┆ ---       ┆ ---    │\n",
      "│ str       ┆ str   ┆ str       ┆ i64    │\n",
      "╞═══════════╪═══════╪═══════════╪════════╡\n",
      "│ diana     ┆ Diana ┆ director  ┆ 120000 │\n",
      "│ henry     ┆ Henry ┆ architect ┆ 115000 │\n",
      "│ bob       ┆ Bob   ┆ manager   ┆ 95000  │\n",
      "└───────────┴───────┴───────────┴────────┘\n",
      "\n",
      "2. Role Distribution:\n",
      "shape: (5, 3)\n",
      "┌────────────────┬───────┬────────────┐\n",
      "│ role           ┆ count ┆ avg_salary │\n",
      "│ ---            ┆ ---   ┆ ---        │\n",
      "│ str            ┆ u32   ┆ f64        │\n",
      "╞════════════════╪═══════╪════════════╡\n",
      "│ engineer       ┆ 4     ┆ 83750.0    │\n",
      "│ data_scientist ┆ 1     ┆ 92000.0    │\n",
      "│ director       ┆ 1     ┆ 120000.0   │\n",
      "│ manager        ┆ 1     ┆ 95000.0    │\n",
      "│ architect      ┆ 1     ┆ 115000.0   │\n",
      "└────────────────┴───────┴────────────┘\n",
      "\n",
      "3. Top 5 Collaborations by Weight:\n",
      "shape: (5, 2)\n",
      "┌─────────┬──────────────────┐\n",
      "│ edge_id ┆ effective_weight │\n",
      "│ ---     ┆ ---              │\n",
      "│ str     ┆ f64              │\n",
      "╞═════════╪══════════════════╡\n",
      "│ edge_5  ┆ 0.95             │\n",
      "│ edge_4  ┆ 0.85             │\n",
      "│ edge_7  ┆ 0.8              │\n",
      "│ edge_6  ┆ 0.75             │\n",
      "│ edge_8  ┆ 0.7              │\n",
      "└─────────┴──────────────────┘\n",
      "\n",
      "4. Total Hours by Project:\n",
      "shape: (9, 3)\n",
      "┌──────────────┬────────────────┬─────────────┐\n",
      "│ project      ┆ collaborations ┆ total_hours │\n",
      "│ ---          ┆ ---            ┆ ---         │\n",
      "│ str          ┆ u32            ┆ i64         │\n",
      "╞══════════════╪════════════════╪═════════════╡\n",
      "│ ProjectZ     ┆ 2              ┆ 320         │\n",
      "│ NextGen      ┆ 2              ┆ 290         │\n",
      "│ ProjectX     ┆ 2              ┆ 270         │\n",
      "│ ProjectW     ┆ 2              ┆ 170         │\n",
      "│ Management   ┆ 2              ┆ 170         │\n",
      "│ Strategy     ┆ 1              ┆ 80          │\n",
      "│ ProjectY     ┆ 1              ┆ 60          │\n",
      "│ Architecture ┆ 1              ┆ 0           │\n",
      "│ Innovation   ┆ 1              ┆ 0           │\n",
      "└──────────────┴────────────────┴─────────────┘\n",
      "\n",
      "5. Salary Statistics:\n",
      "shape: (1, 4)\n",
      "┌────────────┬────────────┬────────────┬───────────────┐\n",
      "│ min_salary ┆ max_salary ┆ avg_salary ┆ median_salary │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ ---           │\n",
      "│ i64        ┆ i64        ┆ f64        ┆ f64           │\n",
      "╞════════════╪════════════╪════════════╪═══════════════╡\n",
      "│ 80000      ┆ 120000     ┆ 94625.0    ┆ 89500.0       │\n",
      "└────────────┴────────────┴────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ADVANCED ANALYSIS - POLARS QUERIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Query 1: Top earners\n",
    "print(\"\\n1. Top 3 Earners:\")\n",
    "top_earners = G.obs.sort(\"salary\", descending=True).head(3)\n",
    "print(top_earners.select([\"vertex_id\", \"name\", \"role\", \"salary\"]))\n",
    "\n",
    "# Query 2: Role distribution\n",
    "print(\"\\n2. Role Distribution:\")\n",
    "role_dist = G.obs.group_by(\"role\").agg([\n",
    "    pl.count(\"vertex_id\").alias(\"count\"),\n",
    "    pl.mean(\"salary\").alias(\"avg_salary\")\n",
    "]).sort(\"count\", descending=True)\n",
    "print(role_dist)\n",
    "\n",
    "# Query 3: High-weight collaborations\n",
    "print(\"\\n3. Top 5 Collaborations by Weight:\")\n",
    "top_edges = (\n",
    "    G.view(layers=\"2023\")\n",
    "     .edges_df(layer=\"2023\", include_weight=True, resolved_weight=True)  # adds global_weight, layer_weight, effective_weight\n",
    "     .sort(\"effective_weight\", descending=True)\n",
    "     .select([\"edge_id\", \"effective_weight\"])\n",
    "     .head(5)\n",
    ")\n",
    "print(top_edges)\n",
    "\n",
    "# Query 4: Projects by hours\n",
    "print(\"\\n4. Total Hours by Project:\")\n",
    "if \"project\" in G.var.columns and \"hours\" in G.var.columns:\n",
    "    project_hours = G.var.group_by(\"project\").agg([\n",
    "        pl.count(\"edge_id\").alias(\"collaborations\"),\n",
    "        pl.sum(\"hours\").alias(\"total_hours\")\n",
    "    ]).sort(\"total_hours\", descending=True)\n",
    "    print(project_hours)\n",
    "\n",
    "# Query 5: Salary growth (across snapshots if attributes updated)\n",
    "print(\"\\n5. Salary Statistics:\")\n",
    "salary_stats = G.obs.select([\n",
    "    pl.col(\"salary\").min().alias(\"min_salary\"),\n",
    "    pl.col(\"salary\").max().alias(\"max_salary\"),\n",
    "    pl.col(\"salary\").mean().alias(\"avg_salary\"),\n",
    "    pl.col(\"salary\").median().alias(\"median_salary\")\n",
    "])\n",
    "print(salary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be06eac8-c889-4ec4-87dc-6e5bd0e23660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PERFORMANCE BENCHMARKS\n",
      "============================================================\n",
      "\n",
      "1. View Creation (1000 iterations):\n",
      "   Time: 1.00ms total (0.0010ms per view)\n",
      "\n",
      "2. Property Access (1000 iterations):\n",
      "   Time: 523.89ms total\n",
      "\n",
      "3. Materialization (100 iterations):\n",
      "   Time: 89.99ms total (0.90ms per materialization)\n",
      "\n",
      "4. Snapshot Creation (100 iterations):\n",
      "   Time: 0.00ms total (0.00ms per snapshot)\n",
      "   Total snapshots: 102\n",
      "\n",
      "5. DataFrame Filtering (1000 iterations):\n",
      "   Time: 194.86ms total (0.1949ms per filter)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMANCE BENCHMARKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import time\n",
    "\n",
    "# Benchmark 1: View creation\n",
    "print(\"\\n1. View Creation (1000 iterations):\")\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    v = G.view(layers=\"2023\")\n",
    "t1 = time.time()\n",
    "print(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0):.4f}ms per view)\")\n",
    "\n",
    "# Benchmark 2: Property access\n",
    "print(\"\\n2. Property Access (1000 iterations):\")\n",
    "v = G.view(layers=\"2023\")\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    _ = v.obs\n",
    "    _ = v.var\n",
    "t1 = time.time()\n",
    "print(f\"   Time: {(t1-t0)*1000:.2f}ms total\")\n",
    "\n",
    "# Benchmark 3: Materialization\n",
    "print(\"\\n3. Materialization (100 iterations):\")\n",
    "v = G.view(layers=\"2023\")\n",
    "t0 = time.time()\n",
    "for _ in range(100):\n",
    "    subG = v.materialize(copy_attributes=False)\n",
    "t1 = time.time()\n",
    "print(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0)*10:.2f}ms per materialization)\")\n",
    "\n",
    "# Benchmark 4: Snapshot creation\n",
    "print(\"\\n4. Snapshot Creation (100 iterations):\")\n",
    "t0 = time.time()\n",
    "for i in range(100):\n",
    "    G.snapshot(f\"bench_{i}\")\n",
    "t1 = time.time()\n",
    "print(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0)*10:.2f}ms per snapshot)\")\n",
    "print(f\"   Total snapshots: {len(G._snapshots)}\")\n",
    "\n",
    "# Benchmark 5: DataFrame filtering\n",
    "print(\"\\n5. DataFrame Filtering (1000 iterations):\")\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    filtered = G.obs.filter(pl.col(\"salary\") > 90000)\n",
    "t1 = time.time()\n",
    "print(f\"   Time: {(t1-t0)*1000:.2f}ms total ({(t1-t0):.4f}ms per filter)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "787e7c7a-a887-4338-9c55-08f68f10f45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANNNET COMPLETE TEST SUMMARY\n",
      "============================================================\n",
      "\n",
      "📊 GRAPH STATISTICS\n",
      "   Vertices: 8\n",
      "   Edges: 14\n",
      "   Layers: 5\n",
      "   Snapshots: 102\n",
      "\n",
      "✅ TESTED FEATURES\n",
      "    1. AnnNet Properties (X, obs, var, uns)\n",
      "    2. LayerManager (add, remove, union, intersect, stats)\n",
      "    3. IndexManager (entity/edge lookups)\n",
      "    4. CacheManager (CSR/CSC caching)\n",
      "    5. GraphView (filtering, predicates, materialization)\n",
      "    6. Snapshot & Diff (versioning, comparison)\n",
      "    7. I/O (save/load .annnet format)\n",
      "    8. Cross-layer analytics\n",
      "    9. Polars integration\n",
      "   10. Performance benchmarks\n",
      "\n",
      "📈 LAYER DETAILS\n",
      "Layers: 5\n",
      "├─ default: 0 vertices, 0 edges\n",
      "├─ 2022: 4 vertices, 4 edges\n",
      "├─ 2023: 5 vertices, 5 edges\n",
      "├─ 2024: 7 vertices, 5 edges\n",
      "└─ all_years: 5 vertices, 12 edges\n",
      "\n",
      "🎯 RECOMMENDATIONS\n",
      "   1. Use views for large subgraph operations (lazy, efficient)\n",
      "   2. Create snapshots before major graph modifications\n",
      "   3. Use layers for temporal/contextual data organization\n",
      "   4. Leverage Polars for fast attribute queries\n",
      "   5. Cache CSR/CSC for repeated matrix operations\n",
      "\n",
      "============================================================\n",
      "✓ ALL TESTS COMPLETED SUCCESSFULLY!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANNNET COMPLETE TEST SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n📊 GRAPH STATISTICS\")\n",
    "print(f\"   Vertices: {G.number_of_vertices()}\")\n",
    "print(f\"   Edges: {G.number_of_edges()}\")\n",
    "print(f\"   Layers: {G.layers.count()}\")\n",
    "print(f\"   Snapshots: {len(G._snapshots)}\")\n",
    "\n",
    "print(\"\\n✅ TESTED FEATURES\")\n",
    "features = [\n",
    "    \"AnnNet Properties (X, obs, var, uns)\",\n",
    "    \"LayerManager (add, remove, union, intersect, stats)\",\n",
    "    \"IndexManager (entity/edge lookups)\",\n",
    "    \"CacheManager (CSR/CSC caching)\",\n",
    "    \"GraphView (filtering, predicates, materialization)\",\n",
    "    \"Snapshot & Diff (versioning, comparison)\",\n",
    "    \"I/O (save/load .annnet format)\",\n",
    "    \"Cross-layer analytics\",\n",
    "    \"Polars integration\",\n",
    "    \"Performance benchmarks\"\n",
    "]\n",
    "\n",
    "for i, feature in enumerate(features, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "print(\"\\n📈 LAYER DETAILS\")\n",
    "print(G.layers.summary())\n",
    "\n",
    "print(\"\\n🎯 RECOMMENDATIONS\")\n",
    "print(\"   1. Use views for large subgraph operations (lazy, efficient)\")\n",
    "print(\"   2. Create snapshots before major graph modifications\")\n",
    "print(\"   3. Use layers for temporal/contextual data organization\")\n",
    "print(\"   4. Leverage Polars for fast attribute queries\")\n",
    "print(\"   5. Cache CSR/CSC for repeated matrix operations\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✓ ALL TESTS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e5114cd-8635-4bcf-9523-64b1c3a0d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLEANUP\n",
      "============================================================\n",
      "\n",
      "Removing test files:\n",
      "   ✓ Removed directory: company_network.annnet\n",
      "   ✓ Removed directory: network_2023.annnet\n",
      "\n",
      "✓ Cleanup complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLEANUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Clean up test files\n",
    "files_to_remove = [\n",
    "    \"company_network.annnet\",\n",
    "    \"network_2023.annnet\",\n",
    "]\n",
    "\n",
    "print(\"\\nRemoving test files:\")\n",
    "for filepath in files_to_remove:\n",
    "    if os.path.exists(filepath):\n",
    "        if os.path.isdir(filepath):\n",
    "            shutil.rmtree(filepath)\n",
    "            print(f\"   ✓ Removed directory: {filepath}\")\n",
    "        else:\n",
    "            os.remove(filepath)\n",
    "            print(f\"   ✓ Removed file: {filepath}\")\n",
    "    else:\n",
    "        print(f\"   ⊘ Not found: {filepath}\")\n",
    "\n",
    "print(\"\\n✓ Cleanup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ec23b-5a63-4ffa-9368-4fdee91eb9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc27eb4-a6dd-4117-b537-65d694a8b4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb75e00-0d0f-4993-8d26-eb39298c2256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048ad30-5a41-4da6-930f-8a33d7406921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e5072-b4c8-4d0f-b83d-4b90b4af6513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735c089-c6de-4662-aa64-1696488fee4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1dec90-abed-452c-baeb-15a5cba86914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04929a-cc40-409c-ab55-45a16f999a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed57a81-b9ac-41e6-ad06-4f4c1bfef34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd253c-7239-4632-a044-97f7bd955fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8ab58-38cf-44a5-b2e5-ee3ad2ba5e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce02eb8-8338-4c1a-b38e-de09ba0602c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59067e-bd7e-415e-a264-b84a3502fa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08740914-5083-4565-bfe6-c82daddd8427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b76c7-94e2-40de-bcd7-664c3b2014c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af994dd-a27d-4eee-a421-ad4e0170be63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6ffb5-48eb-486a-b95f-e7fa9cb48fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b42a4d-1c67-4566-8c40-503c19d3fbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9336f9-59b1-4465-9662-3a2d4022466d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d793b4-1449-49d9-ac5c-9e7a3b73398c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec03fd-d97d-4840-aa0e-a62fbea76dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
