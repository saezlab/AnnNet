{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1042de8d",
   "metadata": {},
   "source": [
    "# IncidenceGraph — End‑to‑End Stress Notebook\n",
    "\n",
    "**Goal:** build a realistic, multi‑layer biological interaction graph with **tens of thousands** of nodes and a mix of **binary edges, hyperedges, and node–edge (edge‑entity) links**, then **exercise every public API**: layers, presence queries, propagation (`shared` / `all`), views, analytics, set operations, aggregations, temporal dynamics, subgraph/copy, deletions, auditing, and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0184fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust import of IncidenceGraph\n",
    "import os, importlib.util, random, math, time\n",
    "from time import perf_counter\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # must be the parent folder that CONTAINS 'graphglue'\n",
    "\n",
    "from graphglue.core.incgraph import IncidenceGraph\n",
    "from graphglue.adapters.networkx import to_backend, to_nx, from_nx\n",
    "\n",
    "G = IncidenceGraph(directed=True)\n",
    "\n",
    "\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab386c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters — choose a scale\n",
    "# - DEMO runs fast on laptops\n",
    "# - STRESS creates 10^4–10^5 scale objects; adjust upward to your machine limits\n",
    "\n",
    "SCALE = \"DEMO\"  # \"DEMO\" or \"STRESS\"\n",
    "\n",
    "if SCALE.upper() == \"DEMO\":\n",
    "    N_PROTEINS = 5_00\n",
    "    N_TRANSCRIPTS = 2_00\n",
    "    N_METABOLITES = 1_00\n",
    "    N_EDGE_ENTITIES = 40\n",
    "    N_BIN_EDGES = 25_00       # binary protein-protein interactions (base layer)\n",
    "    N_HYPER_COMPLEX = 1_00    # undirected complexes\n",
    "    N_HYPER_CASCADE = 1_00    # directed signaling cascades\n",
    "    N_NODE_EDGE_BIDIR = 2_00  # node<->edge-entity links (counted as pairs)\n",
    "else:\n",
    "    N_PROTEINS = 30_000\n",
    "    N_TRANSCRIPTS = 12_000\n",
    "    N_METABOLITES = 8_000\n",
    "    N_EDGE_ENTITIES = 2_500\n",
    "    N_BIN_EDGES = 160_000\n",
    "    N_HYPER_COMPLEX = 4,000    # use commas? We'll correct below to int\n",
    "    N_HYPER_CASCADE = 4_000\n",
    "    N_NODE_EDGE_BIDIR = 10_000\n",
    "\n",
    "# fix typo for N_HYPER_COMPLEX in STRESS case\n",
    "if isinstance(N_HYPER_COMPLEX, tuple):\n",
    "    N_HYPER_COMPLEX = 4000\n",
    "\n",
    "LAYERS = [\"Healthy\",\"Stressed\",\"Disease\",\"DrugA\",\"DrugB\"]\n",
    "ORDERED_FOR_TEMPORAL = [\"Healthy\",\"Stressed\",\"Disease\",\"DrugA\",\"DrugB\"]\n",
    "\n",
    "# How many parallel edges to create as duplicates between random pairs\n",
    "N_PARALLEL_DUPES = max(1, N_BIN_EDGES // 20)\n",
    "\n",
    "# Fraction of nodes seeded into each non-default layer (to make propagate='shared'/'all' meaningful)\n",
    "SEED_FRAC_PER_LAYER = 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8886718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def rand_weight(base=1.0, jitter=0.5):\n",
    "    # positive weight with variability\n",
    "    w = base + (random.random() - 0.5) * 2 * jitter\n",
    "    return max(0.01, w)\n",
    "\n",
    "def try_to_pandas(df):\n",
    "    if df is None:\n",
    "        return None\n",
    "    if 'polars' in type(df).__module__.lower():\n",
    "        return df.to_pandas() if hasattr(df, \"to_pandas\") else None\n",
    "    return df  # assume already pandas-like\n",
    "\n",
    "def head_df(df, n=5):\n",
    "    p = try_to_pandas(df)\n",
    "    return p.head(n) if p is not None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a1f5394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers ready: ['Healthy', 'Stressed', 'Disease', 'DrugA', 'DrugB'] active: Healthy\n"
     ]
    }
   ],
   "source": [
    "# Build graph & layers\n",
    "t0 = perf_counter()\n",
    "G = IncidenceGraph(directed=True)\n",
    "\n",
    "for lid in LAYERS:\n",
    "    G.add_layer(lid, desc=f\"condition={lid}\")\n",
    "G.set_active_layer(LAYERS[0])\n",
    "build_layers_time = perf_counter() - t0\n",
    "print(\"Layers ready:\", G.list_layers(), \"active:\", G.get_active_layer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c91253-6eb4-4273-a1ee-a3991284af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- progress helpers ----\n",
    "from time import perf_counter\n",
    "try:\n",
    "    from tqdm.auto import tqdm  # uses notebook bar if available\n",
    "    _TQDM = True\n",
    "except Exception:\n",
    "    _TQDM = False\n",
    "\n",
    "def prog_iter(it, total=None, desc=\"\", mininterval=0.25):\n",
    "    \"\"\"Wrap any iterable with a progress display (tqdm if available, else no-op).\"\"\"\n",
    "    if _TQDM:\n",
    "        return tqdm(it, total=total, desc=desc, mininterval=mininterval, leave=False)\n",
    "    return it\n",
    "\n",
    "def batched(iterable, batch_size):\n",
    "    \"\"\"Yield lists of size <= batch_size (Py<3.12 compatible).\"\"\"\n",
    "    buf = []\n",
    "    for x in iterable:\n",
    "        buf.append(x)\n",
    "        if len(buf) == batch_size:\n",
    "            yield buf\n",
    "            buf = []\n",
    "    if buf:\n",
    "        yield buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a46b7589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceadb90a9ad04bfdadba19cae620a2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Healthy: proteins:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba99973094294095af3bb5aaa8a160d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Healthy: transcripts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206077bcc4704328ba3f6cf6c234fa25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Healthy: metabolites:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ef59df3f6c4a24846fa35db2764ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Healthy: edge-entities:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374118fa1e4a46619ad34764a756efd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Seeding other layers:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256f9e5facc6436b960eb07cadcf013c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stressed: proteins:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c9f97775d449bea14f8fc830182539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stressed: transcripts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6787f7ff8849d7a1b7ecec35491dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stressed: metabolites:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ad2740d7ef411e886cbb0fa17075b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Disease: proteins:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36dbcf4091f4294873e296c417eb758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Disease: transcripts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf40ebce70d44f0dae6615bba0be6c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Disease: metabolites:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d6b6bf01be4c83a8b0ca582aec3f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DrugA: proteins:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0f79b435f4436e889f16dce0854856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DrugA: transcripts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ebfe14b4ef4094954b767e414cc3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DrugA: metabolites:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c979d07059ed4841866828b02cb51aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DrugB: proteins:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddf9b0ee7474a3b919f0ab3634d2e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DrugB: transcripts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfb95b3a03d44b9869b67583603a412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DrugB: metabolites:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes done. #nodes: 800 Edge-entities: 40 time(s)= 16.536\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "t = perf_counter()\n",
    "\n",
    "proteins    = [f\"P{i}\"  for i in range(1, N_PROTEINS+1)]\n",
    "transcripts = [f\"T{i}\"  for i in range(1, N_TRANSCRIPTS+1)]\n",
    "metabolites = [f\"M{i}\"  for i in range(1, N_METABOLITES+1)]\n",
    "edge_entities = [f\"EE{i}\" for i in range(1, N_EDGE_ENTITIES+1)]\n",
    "\n",
    "add_node = G.add_node\n",
    "add_edge_entity = G.add_edge_entity\n",
    "\n",
    "# --- Seed nodes in \"Healthy\" (progress) ---\n",
    "kinase_mask = rng.random(len(proteins)) < 0.15\n",
    "for batch in prog_iter(batched(list(zip(proteins, kinase_mask)), 2000),\n",
    "                       total=(len(proteins)+1999)//2000, desc=\"Healthy: proteins\"):\n",
    "    for p, is_kinase in batch:\n",
    "        if is_kinase:\n",
    "            add_node(p, layer=\"Healthy\", family=\"kinase\", kind=\"protein\")\n",
    "        else:\n",
    "            add_node(p, layer=\"Healthy\", kind=\"protein\")\n",
    "\n",
    "for batch in prog_iter(batched(transcripts, 4000),\n",
    "                       total=(len(transcripts)+3999)//4000, desc=\"Healthy: transcripts\"):\n",
    "    for tnode in batch:\n",
    "        add_node(tnode, layer=\"Healthy\", kind=\"transcript\")\n",
    "\n",
    "for batch in prog_iter(batched(metabolites, 4000),\n",
    "                       total=(len(metabolites)+3999)//4000, desc=\"Healthy: metabolites\"):\n",
    "    for m in batch:\n",
    "        add_node(m, layer=\"Healthy\", kind=\"metabolite\")\n",
    "\n",
    "# --- Edge-entities (progress) ---\n",
    "pathways = np.array([\"glycolysis\",\"tca\",\"mapk\",\"pi3k\"])\n",
    "drawn_pathways = pathways[rng.integers(0, len(pathways), size=len(edge_entities))]\n",
    "for batch in prog_iter(batched(list(zip(edge_entities, drawn_pathways)), 5000),\n",
    "                       total=(len(edge_entities)+4999)//5000, desc=\"Healthy: edge-entities\"):\n",
    "    for ee, pw in batch:\n",
    "        add_edge_entity(ee, layer=\"Healthy\", role=\"enzyme\", pathway=pw)\n",
    "\n",
    "# --- Seed presence into other layers (progress per layer) ---\n",
    "p_keep = SEED_FRAC_PER_LAYER\n",
    "for lid in prog_iter(LAYERS[1:], total=len(LAYERS)-1, desc=\"Seeding other layers\"):\n",
    "    pmask = rng.random(len(proteins))    < p_keep\n",
    "    tmask = rng.random(len(transcripts)) < p_keep\n",
    "    mmask = rng.random(len(metabolites)) < p_keep\n",
    "\n",
    "    for batch in prog_iter(batched(list(zip(proteins, pmask)), 4000),\n",
    "                           total=(len(proteins)+3999)//4000, desc=f\"{lid}: proteins\", mininterval=0.3):\n",
    "        for n, keep in batch:\n",
    "            if keep:\n",
    "                add_node(n, layer=lid, kind=\"protein\")\n",
    "\n",
    "    for batch in prog_iter(batched(list(zip(transcripts, tmask)), 4000),\n",
    "                           total=(len(transcripts)+3999)//4000, desc=f\"{lid}: transcripts\", mininterval=0.3):\n",
    "        for n, keep in batch:\n",
    "            if keep:\n",
    "                add_node(n, layer=lid, kind=\"transcript\")\n",
    "\n",
    "    for batch in prog_iter(batched(list(zip(metabolites, mmask)), 4000),\n",
    "                           total=(len(metabolites)+3999)//4000, desc=f\"{lid}: metabolites\", mininterval=0.3):\n",
    "        for n, keep in batch:\n",
    "            if keep:\n",
    "                add_node(n, layer=lid, kind=\"metabolite\")\n",
    "\n",
    "build_nodes_time = perf_counter() - t\n",
    "print(\"Nodes done. #nodes:\", G.number_of_nodes(),\n",
    "      \"Edge-entities:\", sum(1 for k,v in G.entity_types.items() if v=='edge'),\n",
    "      \"time(s)=\", round(build_nodes_time, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b171451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary edges built: 2494 total edges now: 2619\n"
     ]
    }
   ],
   "source": [
    "# Binary edges (PPIs mostly among proteins), defined in Healthy then layered variants\n",
    "t = perf_counter()\n",
    "ppis = []\n",
    "for _ in range(N_BIN_EDGES):\n",
    "    u = random.choice(proteins)\n",
    "    v = random.choice(proteins)\n",
    "    if u == v:\n",
    "        continue\n",
    "    # random directedness: ~80% directed, 20% undirected\n",
    "    directed = (random.random() < 0.8)\n",
    "    e = G.add_edge(u, v, layer=\"Healthy\", weight=rand_weight(1.2, 0.6), edge_directed=directed)\n",
    "    ppis.append(e)\n",
    "\n",
    "# parallel dupes between random pairs\n",
    "for _ in range(N_PARALLEL_DUPES):\n",
    "    # pick a previously created edge id, and add another parallel edge for same (u,v)\n",
    "    # We'll sample pair via G.edge_definitions\n",
    "    eid = random.choice(ppis)\n",
    "    u, v = G.edge_definitions[eid][0], G.edge_definitions[eid][1]\n",
    "    G.add_parallel_edge(u, v, weight=rand_weight(1.0, 0.3))\n",
    "\n",
    "# Per-layer variants: copy presence and tweak weights\n",
    "for eid in ppis:\n",
    "    base_w = G.edge_weights[eid]\n",
    "    for lid in LAYERS[1:]:\n",
    "        G.add_edge_to_layer(lid, eid)\n",
    "        # apply layer-specific weight modifier\n",
    "        factor = {\n",
    "            \"Stressed\": rand_weight(1.10, 0.10),\n",
    "            \"Disease\":  0.7 if random.random() < 0.4 else rand_weight(1.30, 0.15),\n",
    "            \"DrugA\":    rand_weight(0.9, 0.25),\n",
    "            \"DrugB\":    rand_weight(1.2, 0.20),\n",
    "        }[lid]\n",
    "        G.set_edge_layer_attrs(lid, eid, weight=base_w * factor, note=f\"layer={lid}\")\n",
    "build_binary_time = perf_counter() - t\n",
    "print(\"Binary edges built:\", len(ppis), \"total edges now:\", G.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagation semantics via add_edge(..., propagate=...)\n",
    "t = perf_counter()\n",
    "# Ensure varied node presence across layers for a few pairs\n",
    "pairs = [(random.choice(proteins), random.choice(transcripts)) for _ in range(2000)]\n",
    "for u,v in pairs:\n",
    "    # 'shared': only layers where both endpoints already present\n",
    "    G.add_edge(u, v, layer=\"Healthy\", edge_type=None, weight=rand_weight(0.8,0.2), propagate=\"shared\")\n",
    "pairs2 = [(random.choice(proteins), random.choice(metabolites)) for _ in range(2000)]\n",
    "for u,v in pairs2:\n",
    "    # 'all': appears everywhere either endpoint exists (pulls other endpoint in)\n",
    "    G.add_edge(u, v, layer=\"Healthy\", edge_type=None, weight=rand_weight(0.8,0.2), propagate=\"all\")\n",
    "\n",
    "build_propagation_time = perf_counter() - t\n",
    "print(\"Propagation examples added (shared/all).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d79ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperedges: undirected complexes, directed cascades\n",
    "t = perf_counter()\n",
    "\n",
    "complex_ids = []\n",
    "for _ in range(N_HYPER_COMPLEX):\n",
    "    size = random.choice([3,4,5,6])\n",
    "    members = set(random.sample(proteins, size))\n",
    "    hid = G.add_hyperedge(members=members, layer=\"Healthy\", weight=rand_weight(1.0, 0.2), tag=\"complex\")\n",
    "    complex_ids.append(hid)\n",
    "    for lid in LAYERS[1:]:\n",
    "        G.add_edge_to_layer(lid, hid)\n",
    "\n",
    "cascade_ids = []\n",
    "tries = 0\n",
    "while len(cascade_ids) < N_HYPER_CASCADE and tries < N_HYPER_CASCADE*5:\n",
    "    tries += 1\n",
    "    head = set(random.sample(proteins, random.choice([1,2])))\n",
    "    tail = set(random.sample(proteins, random.choice([2,3,4])))\n",
    "    if head & tail:\n",
    "        continue\n",
    "    hid = G.add_hyperedge(head=head, tail=tail, layer=\"Healthy\", weight=rand_weight(1.0,0.4), tag=\"cascade\")\n",
    "    cascade_ids.append(hid)\n",
    "    for lid in LAYERS[1:]:\n",
    "        G.add_edge_to_layer(lid, hid)\n",
    "\n",
    "build_hyper_time = perf_counter() - t\n",
    "print(\"Hyperedges built: complexes=\", len(complex_ids), \"cascades=\", len(cascade_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node–edge (edge-entity) reactions: A -> EE -> B (bidir variants)\n",
    "t = perf_counter()\n",
    "for _ in range(N_NODE_EDGE_BIDIR):\n",
    "    ee = random.choice(edge_entities)\n",
    "    s = random.choice(proteins + transcripts + metabolites)\n",
    "    tnode = random.choice(proteins + transcripts + metabolites)\n",
    "    G.add_edge(s, ee, layer=\"Healthy\", edge_type=\"node_edge\", weight=rand_weight(1.0,0.5))\n",
    "    G.add_edge(ee, tnode, layer=\"Healthy\", edge_type=\"node_edge\", weight=rand_weight(1.0,0.5))\n",
    "    # reflect into other layers\n",
    "    for lid in LAYERS[1:]:\n",
    "        G.add_edge_to_layer(lid, list(G.get_edge_ids(s, ee))[-1])\n",
    "        G.add_edge_to_layer(lid, list(G.get_edge_ids(ee, tnode))[-1])\n",
    "\n",
    "build_nodeedge_time = perf_counter() - t\n",
    "print(\"Node–edge reaction links added (pairs):\", N_NODE_EDGE_BIDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b56ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity & counts\n",
    "print(\"Nodes:\", G.number_of_nodes(), \"Edges:\", G.number_of_edges())\n",
    "assert G.number_of_nodes() > 0 and G.number_of_edges() > 0\n",
    "\n",
    "# Edge-entity count\n",
    "edge_entity_count = sum(1 for _id, et in G.entity_types.items() if et == \"edge\" and _id in set(edge_entities))\n",
    "print(\"Edge-entities:\", edge_entity_count)\n",
    "assert edge_entity_count == len(edge_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Views & Top edges per layer\n",
    "try:\n",
    "    for lid in LAYERS:\n",
    "        EV = G.edges_view(layer=lid, resolved_weight=True)\n",
    "        print(f\"[{lid}] edges_view rows:\", getattr(EV, 'height', getattr(EV, 'shape', ['?','?'])[0]))\n",
    "        # filter binary only, sort by effective weight\n",
    "        if pl is not None and isinstance(EV, pl.DataFrame):\n",
    "            top = (EV.filter(pl.col(\"kind\")==\"binary\")\n",
    "                     .sort(\"effective_weight\", descending=True)\n",
    "                     .select([\"edge_id\",\"source\",\"target\",\"effective_weight\"])\n",
    "                     .head(5))\n",
    "            print(f\"Top 5 binary edges in {lid}:\\n\", top)\n",
    "        else:\n",
    "            # Try pandas-like\n",
    "            try:\n",
    "                df = EV\n",
    "                if hasattr(df, \"query\"):\n",
    "                    bf = df.query(\"kind == 'binary'\").sort_values(\"effective_weight\", ascending=False).head(5)\n",
    "                    print(bf[[\"edge_id\",\"source\",\"target\",\"effective_weight\"]])\n",
    "            except Exception:\n",
    "                pass\n",
    "except Exception as e:\n",
    "    print(\"edges_view failed softly:\", e)\n",
    "\n",
    "try:\n",
    "    NV = G.nodes_view()\n",
    "    LV = G.layers_view()\n",
    "    print(\"Nodes view cols:\", getattr(NV, 'columns', None))\n",
    "    print(\"Layers view cols:\", getattr(LV, 'columns', None))\n",
    "except Exception as e:\n",
    "    print(\"nodes_view/layers_view failed softly:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57cd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presence queries\n",
    "any_e = next(iter(G.edge_to_idx.keys()))\n",
    "print(\"Edge presence across layers:\", G.edge_presence_across_layers(edge_id=any_e))\n",
    "\n",
    "any_p = random.choice(proteins)\n",
    "print(\"Node presence across layers:\", G.node_presence_across_layers(any_p))\n",
    "\n",
    "# Hyperedge presence by members and head/tail\n",
    "if complex_ids:\n",
    "    m = random.choice(complex_ids)\n",
    "    members = G.hyperedge_definitions[m].get(\"members\", set())\n",
    "    if members:\n",
    "        print(\"Hyperedge presence (members):\", G.hyperedge_presence_across_layers(members=set(members)))\n",
    "if cascade_ids:\n",
    "    h = random.choice(cascade_ids)\n",
    "    hd = G.hyperedge_definitions[h]\n",
    "    if hd.get(\"head\") and hd.get(\"tail\"):\n",
    "        print(\"Hyperedge presence (head/tail):\", G.hyperedge_presence_across_layers(head=set(hd[\"head\"]), tail=set(hd[\"tail\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traversal\n",
    "q = random.choice(proteins)\n",
    "print(f\"Neighbors({q}) sample:\", G.neighbors(q)[:10])\n",
    "print(f\"Out({q}) sample:\", G.out_neighbors(q)[:10])\n",
    "print(f\"In({q}) sample:\", G.in_neighbors(q)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721928c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer analytics, conserved/specific, temporal\n",
    "stats = G.layer_statistics()\n",
    "print(\"Layer stats keys:\", list(stats.keys())[:5])\n",
    "\n",
    "conserved = G.conserved_edges(min_layers=len(LAYERS))\n",
    "print(\"Conserved edges (present in all layers):\", len(conserved))\n",
    "\n",
    "disease_specific = G.layer_specific_edges(\"Disease\")\n",
    "print(\"Disease-specific edges:\", len(disease_specific))\n",
    "\n",
    "changes_e = G.temporal_dynamics(ORDERED_FOR_TEMPORAL, metric=\"edge_change\")\n",
    "changes_n = G.temporal_dynamics(ORDERED_FOR_TEMPORAL, metric=\"node_change\")\n",
    "print(\"Temporal edge changes entries:\", len(changes_e), \"node changes entries:\", len(changes_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7953cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer set ops and derived layers\n",
    "u = G.layer_union([\"Healthy\",\"Stressed\"])\n",
    "i = G.layer_intersection([\"Healthy\",\"Stressed\"])\n",
    "d = G.layer_difference(\"Healthy\",\"Stressed\")\n",
    "print(\"Union edges>=intersection edges:\", len(u[\"edges\"]) >= len(i[\"edges\"]))\n",
    "\n",
    "lid_u = G.create_layer_from_operation(\"HS_union\", u, desc=\"H∪S\")\n",
    "lid_i = G.create_layer_from_operation(\"HS_intersection\", i, desc=\"H∩S\")\n",
    "lid_d = G.create_layer_from_operation(\"H_minus_S\", d, desc=\"H\\\\S\")\n",
    "print(\"Derived layers exist:\", G.has_layer(\"HS_union\"), G.has_layer(\"HS_intersection\"), G.has_layer(\"H_minus_S\"))\n",
    "\n",
    "# Aggregations\n",
    "G.create_aggregated_layer([\"Healthy\",\"Stressed\"], \"Agg_union\", method=\"union\", tag=\"agg_u\")\n",
    "G.create_aggregated_layer([\"Healthy\",\"Stressed\"], \"Agg_intersection\", method=\"intersection\", tag=\"agg_i\")\n",
    "print(\"Aggregated layers added.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge list & global counts\n",
    "el = G.edge_list()\n",
    "print(\"Edge list tuple length check (u,v,kind,id):\", all(len(t)==4 for t in el))\n",
    "print(\"Global entity/edge counts:\", G.global_entity_count(), G.global_edge_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a4cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subgraph & copy\n",
    "SG = G.subgraph_from_layer(\"DrugB\", resolve_layer_weights=True)\n",
    "print(\"DrugB subgraph nodes/edges:\", SG.number_of_nodes(), SG.number_of_edges())\n",
    "\n",
    "CP = G.copy()\n",
    "# quick consistency checks\n",
    "assert set(CP.nodes()) == set(G.nodes())\n",
    "assert set(CP.edges()) == set(G.edges())\n",
    "any_hyper = next(e for e,k in G.edge_kind.items() if k == \"hyper\")\n",
    "assert CP.edge_kind.get(any_hyper) == \"hyper\"\n",
    "for lid in G.list_layers(include_default=True):\n",
    "    assert CP._layers[lid][\"nodes\"] == G._layers[lid][\"nodes\"]\n",
    "    assert CP._layers[lid][\"edges\"] == G._layers[lid][\"edges\"]\n",
    "print(\"Deep copy OK.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removals: drop a slice of nodes/edges\n",
    "drop_nodes = random.sample(proteins, max(1, len(proteins)//100))  # ~1%\n",
    "for n in drop_nodes:\n",
    "    if n in G.entity_to_idx:\n",
    "        G.remove_node(n)\n",
    "\n",
    "drop_edges = list(G.edge_to_idx.keys())[: min(500, len(G.edge_to_idx))]\n",
    "for eid in drop_edges:\n",
    "    if eid in G.edge_to_idx:\n",
    "        G.remove_edge(eid)\n",
    "\n",
    "print(\"After removals: nodes=\", G.number_of_nodes(), \"edges=\", G.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audit & memory\n",
    "audit = G.audit_attributes()\n",
    "mem_bytes = G.memory_usage()\n",
    "print(\"Audit keys:\", list(audit.keys())[:10])\n",
    "print(\"Approx memory usage (bytes):\", int(mem_bytes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing summary\n",
    "import pandas as pd\n",
    "\n",
    "timings = {\n",
    "    \"build_layers\": build_layers_time,\n",
    "    \"build_nodes\": build_nodes_time,\n",
    "    \"build_binary_edges\": build_binary_time,\n",
    "    \"build_propagation\": build_propagation_time,\n",
    "    \"build_hyperedges\": build_hyper_time,\n",
    "    \"build_nodeedge\": build_nodeedge_time,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sorted(timings.items(), key=lambda x: x[0]), columns=[\"stage\",\"seconds\"])\n",
    "from caas_jupyter_tools import display_dataframe_to_user\n",
    "display_dataframe_to_user(\"Build timings (seconds)\", df)\n",
    "\n",
    "# Simple chart\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.bar(df[\"stage\"], df[\"seconds\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"seconds\")\n",
    "plt.title(\"IncidenceGraph Build Timings\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9caf79-3ebf-4afb-8fe9-3dd76c2409c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b8740-a83e-41de-80df-b3da45c4bbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c41f1c-f2d9-4ff6-9ed6-93def612410a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
